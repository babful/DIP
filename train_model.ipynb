{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c09d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ec6b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configuration import Config\n",
    "from dataset import train_dataset, valid_dataset, test_dataset\n",
    "from model import DIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2b09fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터들\n",
    "C = Config()\n",
    "\n",
    "valid_sample_num = C.get('valid_sample_num')\n",
    "test_sample_num = C.get('test_sample_num')\n",
    "\n",
    "device = C.get('device')\n",
    "input_size = C.get('input_size')\n",
    "hidden_size = C.get('hidden_size')\n",
    "output_size = C.get('output_size')\n",
    "\n",
    "batch_size = C.get('batch_size')\n",
    "num_workers = C.get('num_workers')\n",
    "lr = C.get('lr')\n",
    "weight_decay = C.get('weight_decay')\n",
    "\n",
    "epochs = C.get('epochs')\n",
    "clip_grad = C.get('clip_grad')\n",
    "print_every = C.get('print_every')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a069e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train_acc, train_smpl, train_input = train_dataset()\n",
    "valid_acc, valid_ori, valid_smpl = valid_dataset()\n",
    "test_acc, test_ori, test_smpl = test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475bb3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIP(\n",
       "  (input_layer): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=60, out_features=512, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (lstm): LSTM(512, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (output_layer_mu): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=150, bias=True)\n",
       "    (1): LogSoftmax(dim=2)\n",
       "  )\n",
       "  (output_layer_sigma): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=150, bias=True)\n",
       "    (1): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = DIP(input_size, hidden_size, output_size, n_layers=2, drop_prob=0.0)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b56811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.GaussianNLLLoss() # Loss Function\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f56bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋 형성\n",
    "train_dataset = TensorDataset(torch.from_numpy(train_input),\n",
    "                              torch.from_numpy(train_smpl),\n",
    "                              torch.from_numpy(train_acc))\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=num_workers,\n",
    "                          drop_last=False,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "defa89bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation 데이터셋 형성\n",
    "valid_input_list, valid_dataset = [], []\n",
    "\n",
    "for i in range(valid_sample_num):\n",
    "    valid_input_list.append(torch.concat((torch.tensor([valid_ori[i]]), torch.tensor([valid_acc[i]])), axis=2))\n",
    "    valid_dataset.append((valid_input_list[i], torch.tensor([valid_smpl[i]]), torch.tensor([valid_acc[i]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05aeb28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터셋 형성\n",
    "test_input_list, test_dataset = [], []\n",
    "\n",
    "for i in range(test_sample_num):\n",
    "    test_input_list.append(torch.concat((torch.tensor([test_ori[i]]), torch.tensor([test_acc[i]])), axis=2))\n",
    "    test_dataset.append((test_input_list[i], torch.tensor([test_smpl[i]]), torch.tensor([test_acc[i]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4baf3870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2000\t Step: 15/54\t Train Loss: 4.948278\t Valid Loss: 5.420880\n",
      "Epoch: 1/2000\t Step: 30/54\t Train Loss: 4.270013\t Valid Loss: 4.767088\n",
      "Epoch: 1/2000\t Step: 45/54\t Train Loss: 4.290290\t Valid Loss: 4.665405\n",
      "Epoch: 2/2000\t Step: 15/54\t Train Loss: 4.257997\t Valid Loss: 4.606669\n",
      "Epoch: 2/2000\t Step: 30/54\t Train Loss: 4.214086\t Valid Loss: 4.590758\n",
      "Epoch: 2/2000\t Step: 45/54\t Train Loss: 4.203246\t Valid Loss: 4.593370\n",
      "Epoch: 3/2000\t Step: 15/54\t Train Loss: 4.214173\t Valid Loss: 4.609880\n",
      "Epoch: 3/2000\t Step: 30/54\t Train Loss: 4.243536\t Valid Loss: 4.601630\n",
      "Epoch: 3/2000\t Step: 45/54\t Train Loss: 4.424133\t Valid Loss: 4.596706\n",
      "Epoch: 4/2000\t Step: 15/54\t Train Loss: 4.570402\t Valid Loss: 4.587574\n",
      "Epoch: 4/2000\t Step: 30/54\t Train Loss: 4.175492\t Valid Loss: 4.583365\n",
      "Epoch: 4/2000\t Step: 45/54\t Train Loss: 4.153076\t Valid Loss: 4.610445\n",
      "Epoch: 5/2000\t Step: 15/54\t Train Loss: 4.212808\t Valid Loss: 4.539682\n",
      "Epoch: 5/2000\t Step: 30/54\t Train Loss: 4.195412\t Valid Loss: 4.543993\n",
      "Epoch: 5/2000\t Step: 45/54\t Train Loss: 4.181951\t Valid Loss: 4.552601\n",
      "Epoch: 6/2000\t Step: 15/54\t Train Loss: 4.252152\t Valid Loss: 4.566597\n",
      "Epoch: 6/2000\t Step: 30/54\t Train Loss: 4.136630\t Valid Loss: 4.573622\n",
      "Epoch: 6/2000\t Step: 45/54\t Train Loss: 4.174122\t Valid Loss: 4.580997\n",
      "Epoch: 7/2000\t Step: 15/54\t Train Loss: 4.168551\t Valid Loss: 4.581827\n",
      "Epoch: 7/2000\t Step: 30/54\t Train Loss: 4.247449\t Valid Loss: 4.594939\n",
      "Epoch: 7/2000\t Step: 45/54\t Train Loss: 4.196858\t Valid Loss: 4.591329\n",
      "Epoch: 8/2000\t Step: 15/54\t Train Loss: 4.233473\t Valid Loss: 4.575782\n",
      "Epoch: 8/2000\t Step: 30/54\t Train Loss: 4.193478\t Valid Loss: 4.573423\n",
      "Epoch: 8/2000\t Step: 45/54\t Train Loss: 4.348584\t Valid Loss: 4.585619\n",
      "Epoch: 9/2000\t Step: 15/54\t Train Loss: 4.126149\t Valid Loss: 4.597233\n",
      "Epoch: 9/2000\t Step: 30/54\t Train Loss: 4.107680\t Valid Loss: 4.590036\n",
      "Epoch: 9/2000\t Step: 45/54\t Train Loss: 4.434522\t Valid Loss: 4.588441\n",
      "Epoch: 10/2000\t Step: 15/54\t Train Loss: 4.164099\t Valid Loss: 4.560939\n",
      "Epoch: 10/2000\t Step: 30/54\t Train Loss: 4.192587\t Valid Loss: 4.571321\n",
      "Epoch: 10/2000\t Step: 45/54\t Train Loss: 4.141981\t Valid Loss: 4.567320\n",
      "Epoch: 11/2000\t Step: 15/54\t Train Loss: 4.188576\t Valid Loss: 4.583356\n",
      "Epoch: 11/2000\t Step: 30/54\t Train Loss: 4.262922\t Valid Loss: 4.571757\n",
      "Epoch: 11/2000\t Step: 45/54\t Train Loss: 4.323557\t Valid Loss: 4.566315\n",
      "Epoch: 12/2000\t Step: 15/54\t Train Loss: 4.243959\t Valid Loss: 4.556466\n",
      "Epoch: 12/2000\t Step: 30/54\t Train Loss: 4.213560\t Valid Loss: 4.583830\n",
      "Epoch: 12/2000\t Step: 45/54\t Train Loss: 4.480911\t Valid Loss: 4.573568\n",
      "Epoch: 13/2000\t Step: 15/54\t Train Loss: 4.233141\t Valid Loss: 4.581574\n",
      "Epoch: 13/2000\t Step: 30/54\t Train Loss: 4.185637\t Valid Loss: 4.566944\n",
      "Epoch: 13/2000\t Step: 45/54\t Train Loss: 4.295409\t Valid Loss: 4.563175\n",
      "Epoch: 14/2000\t Step: 15/54\t Train Loss: 4.239814\t Valid Loss: 4.584750\n",
      "Epoch: 14/2000\t Step: 30/54\t Train Loss: 4.163205\t Valid Loss: 4.557797\n",
      "Epoch: 14/2000\t Step: 45/54\t Train Loss: 4.160287\t Valid Loss: 4.560102\n",
      "Epoch: 15/2000\t Step: 15/54\t Train Loss: 4.175972\t Valid Loss: 4.587734\n",
      "Epoch: 15/2000\t Step: 30/54\t Train Loss: 4.105337\t Valid Loss: 4.593890\n",
      "Epoch: 15/2000\t Step: 45/54\t Train Loss: 4.136641\t Valid Loss: 4.545865\n",
      "Epoch: 16/2000\t Step: 15/54\t Train Loss: 4.167966\t Valid Loss: 4.523508\n",
      "Epoch: 16/2000\t Step: 30/54\t Train Loss: 4.135477\t Valid Loss: 4.523288\n",
      "Epoch: 16/2000\t Step: 45/54\t Train Loss: 4.175022\t Valid Loss: 4.552722\n",
      "Epoch: 17/2000\t Step: 15/54\t Train Loss: 4.178649\t Valid Loss: 4.590260\n",
      "Epoch: 17/2000\t Step: 30/54\t Train Loss: 4.379869\t Valid Loss: 4.552950\n",
      "Epoch: 17/2000\t Step: 45/54\t Train Loss: 4.290937\t Valid Loss: 4.549182\n",
      "Epoch: 18/2000\t Step: 15/54\t Train Loss: 4.158848\t Valid Loss: 4.563906\n",
      "Epoch: 18/2000\t Step: 30/54\t Train Loss: 4.105155\t Valid Loss: 4.553693\n",
      "Epoch: 18/2000\t Step: 45/54\t Train Loss: 4.224440\t Valid Loss: 4.563585\n",
      "Epoch: 19/2000\t Step: 15/54\t Train Loss: 4.261056\t Valid Loss: 4.547999\n",
      "Epoch: 19/2000\t Step: 30/54\t Train Loss: 4.314294\t Valid Loss: 4.544608\n",
      "Epoch: 19/2000\t Step: 45/54\t Train Loss: 4.207871\t Valid Loss: 4.539766\n",
      "Epoch: 20/2000\t Step: 15/54\t Train Loss: 4.284833\t Valid Loss: 4.524077\n",
      "Epoch: 20/2000\t Step: 30/54\t Train Loss: 4.149182\t Valid Loss: 4.545495\n",
      "Epoch: 20/2000\t Step: 45/54\t Train Loss: 4.112766\t Valid Loss: 4.522756\n",
      "Epoch: 21/2000\t Step: 15/54\t Train Loss: 4.188219\t Valid Loss: 4.510592\n",
      "Epoch: 21/2000\t Step: 30/54\t Train Loss: 4.129357\t Valid Loss: 4.537976\n",
      "Epoch: 21/2000\t Step: 45/54\t Train Loss: 4.111348\t Valid Loss: 4.554849\n",
      "Epoch: 22/2000\t Step: 15/54\t Train Loss: 4.146722\t Valid Loss: 4.519600\n",
      "Epoch: 22/2000\t Step: 30/54\t Train Loss: 4.121179\t Valid Loss: 4.507979\n",
      "Epoch: 22/2000\t Step: 45/54\t Train Loss: 4.313290\t Valid Loss: 4.522758\n",
      "Epoch: 23/2000\t Step: 15/54\t Train Loss: 4.200661\t Valid Loss: 4.512323\n",
      "Epoch: 23/2000\t Step: 30/54\t Train Loss: 4.319313\t Valid Loss: 4.525980\n",
      "Epoch: 23/2000\t Step: 45/54\t Train Loss: 4.103433\t Valid Loss: 4.528118\n",
      "Epoch: 24/2000\t Step: 15/54\t Train Loss: 4.138579\t Valid Loss: 4.526077\n",
      "Epoch: 24/2000\t Step: 30/54\t Train Loss: 4.370906\t Valid Loss: 4.525148\n",
      "Epoch: 24/2000\t Step: 45/54\t Train Loss: 4.097908\t Valid Loss: 4.508674\n",
      "Epoch: 25/2000\t Step: 15/54\t Train Loss: 4.089027\t Valid Loss: 4.524621\n",
      "Epoch: 25/2000\t Step: 30/54\t Train Loss: 4.083513\t Valid Loss: 4.517456\n",
      "Epoch: 25/2000\t Step: 45/54\t Train Loss: 4.252737\t Valid Loss: 4.514698\n",
      "Epoch: 26/2000\t Step: 15/54\t Train Loss: 4.372688\t Valid Loss: 4.520928\n",
      "Epoch: 26/2000\t Step: 30/54\t Train Loss: 4.130473\t Valid Loss: 4.498040\n",
      "Epoch: 26/2000\t Step: 45/54\t Train Loss: 4.089595\t Valid Loss: 4.500719\n",
      "Epoch: 27/2000\t Step: 15/54\t Train Loss: 4.119261\t Valid Loss: 4.465456\n",
      "Epoch: 27/2000\t Step: 30/54\t Train Loss: 4.107107\t Valid Loss: 4.475755\n",
      "Epoch: 27/2000\t Step: 45/54\t Train Loss: 4.148370\t Valid Loss: 4.463373\n",
      "Epoch: 28/2000\t Step: 15/54\t Train Loss: 4.124970\t Valid Loss: 4.478234\n",
      "Epoch: 28/2000\t Step: 30/54\t Train Loss: 4.109067\t Valid Loss: 4.485262\n",
      "Epoch: 28/2000\t Step: 45/54\t Train Loss: 4.170692\t Valid Loss: 4.495108\n",
      "Epoch: 29/2000\t Step: 15/54\t Train Loss: 4.187169\t Valid Loss: 4.493318\n",
      "Epoch: 29/2000\t Step: 30/54\t Train Loss: 4.084752\t Valid Loss: 4.484900\n",
      "Epoch: 29/2000\t Step: 45/54\t Train Loss: 4.383869\t Valid Loss: 4.481893\n",
      "Epoch: 30/2000\t Step: 15/54\t Train Loss: 4.084504\t Valid Loss: 4.477423\n",
      "Epoch: 30/2000\t Step: 30/54\t Train Loss: 4.058460\t Valid Loss: 4.503563\n",
      "Epoch: 30/2000\t Step: 45/54\t Train Loss: 4.374920\t Valid Loss: 4.478674\n",
      "Epoch: 31/2000\t Step: 15/54\t Train Loss: 4.068064\t Valid Loss: 4.469679\n",
      "Epoch: 31/2000\t Step: 30/54\t Train Loss: 4.087579\t Valid Loss: 4.465984\n",
      "Epoch: 31/2000\t Step: 45/54\t Train Loss: 4.137392\t Valid Loss: 4.471167\n",
      "Epoch: 32/2000\t Step: 15/54\t Train Loss: 4.082804\t Valid Loss: 4.468503\n",
      "Epoch: 32/2000\t Step: 30/54\t Train Loss: 4.095160\t Valid Loss: 4.479300\n",
      "Epoch: 32/2000\t Step: 45/54\t Train Loss: 4.148778\t Valid Loss: 4.452173\n",
      "Epoch: 33/2000\t Step: 15/54\t Train Loss: 4.135137\t Valid Loss: 4.452065\n",
      "Epoch: 33/2000\t Step: 30/54\t Train Loss: 4.242174\t Valid Loss: 4.465090\n",
      "Epoch: 33/2000\t Step: 45/54\t Train Loss: 4.370753\t Valid Loss: 4.465992\n",
      "Epoch: 34/2000\t Step: 15/54\t Train Loss: 4.185012\t Valid Loss: 4.450782\n",
      "Epoch: 34/2000\t Step: 30/54\t Train Loss: 4.144335\t Valid Loss: 4.448897\n",
      "Epoch: 34/2000\t Step: 45/54\t Train Loss: 4.101281\t Valid Loss: 4.444702\n",
      "Epoch: 35/2000\t Step: 15/54\t Train Loss: 4.070420\t Valid Loss: 4.460189\n",
      "Epoch: 35/2000\t Step: 30/54\t Train Loss: 4.116280\t Valid Loss: 4.459942\n",
      "Epoch: 35/2000\t Step: 45/54\t Train Loss: 4.198798\t Valid Loss: 4.434134\n",
      "Epoch: 36/2000\t Step: 15/54\t Train Loss: 4.059875\t Valid Loss: 4.450115\n",
      "Epoch: 36/2000\t Step: 30/54\t Train Loss: 4.125419\t Valid Loss: 4.433407\n",
      "Epoch: 36/2000\t Step: 45/54\t Train Loss: 4.323750\t Valid Loss: 4.444583\n",
      "Epoch: 37/2000\t Step: 15/54\t Train Loss: 4.106416\t Valid Loss: 4.402032\n",
      "Epoch: 37/2000\t Step: 30/54\t Train Loss: 4.089989\t Valid Loss: 4.409703\n",
      "Epoch: 37/2000\t Step: 45/54\t Train Loss: 4.171407\t Valid Loss: 4.402349\n",
      "Epoch: 38/2000\t Step: 15/54\t Train Loss: 4.052488\t Valid Loss: 4.420400\n",
      "Epoch: 38/2000\t Step: 30/54\t Train Loss: 4.229973\t Valid Loss: 4.427133\n",
      "Epoch: 38/2000\t Step: 45/54\t Train Loss: 4.147844\t Valid Loss: 4.417319\n",
      "Epoch: 39/2000\t Step: 15/54\t Train Loss: 4.035986\t Valid Loss: 4.420460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/2000\t Step: 30/54\t Train Loss: 4.176334\t Valid Loss: 4.420855\n",
      "Epoch: 39/2000\t Step: 45/54\t Train Loss: 4.349921\t Valid Loss: 4.419517\n",
      "Epoch: 40/2000\t Step: 15/54\t Train Loss: 4.108655\t Valid Loss: 4.405229\n",
      "Epoch: 40/2000\t Step: 30/54\t Train Loss: 4.205279\t Valid Loss: 4.400505\n",
      "Epoch: 40/2000\t Step: 45/54\t Train Loss: 4.208703\t Valid Loss: 4.387789\n",
      "Epoch: 41/2000\t Step: 15/54\t Train Loss: 4.172663\t Valid Loss: 4.420063\n",
      "Epoch: 41/2000\t Step: 30/54\t Train Loss: 4.104518\t Valid Loss: 4.419863\n",
      "Epoch: 41/2000\t Step: 45/54\t Train Loss: 4.134052\t Valid Loss: 4.416978\n",
      "Epoch: 42/2000\t Step: 15/54\t Train Loss: 4.199532\t Valid Loss: 4.384967\n",
      "Epoch: 42/2000\t Step: 30/54\t Train Loss: 4.217034\t Valid Loss: 4.380745\n",
      "Epoch: 42/2000\t Step: 45/54\t Train Loss: 4.070380\t Valid Loss: 4.382704\n",
      "Epoch: 43/2000\t Step: 15/54\t Train Loss: 4.090750\t Valid Loss: 4.392191\n",
      "Epoch: 43/2000\t Step: 30/54\t Train Loss: 4.061602\t Valid Loss: 4.389310\n",
      "Epoch: 43/2000\t Step: 45/54\t Train Loss: 4.203986\t Valid Loss: 4.404940\n",
      "Epoch: 44/2000\t Step: 15/54\t Train Loss: 4.098011\t Valid Loss: 4.395344\n",
      "Epoch: 44/2000\t Step: 30/54\t Train Loss: 4.099603\t Valid Loss: 4.385771\n",
      "Epoch: 44/2000\t Step: 45/54\t Train Loss: 4.195741\t Valid Loss: 4.385191\n",
      "Epoch: 45/2000\t Step: 15/54\t Train Loss: 4.069321\t Valid Loss: 4.387935\n",
      "Epoch: 45/2000\t Step: 30/54\t Train Loss: 4.066869\t Valid Loss: 4.390366\n",
      "Epoch: 45/2000\t Step: 45/54\t Train Loss: 4.099735\t Valid Loss: 4.380882\n",
      "Epoch: 46/2000\t Step: 15/54\t Train Loss: 4.088441\t Valid Loss: 4.376004\n",
      "Epoch: 46/2000\t Step: 30/54\t Train Loss: 4.257889\t Valid Loss: 4.376849\n",
      "Epoch: 46/2000\t Step: 45/54\t Train Loss: 4.042977\t Valid Loss: 4.391560\n",
      "Epoch: 47/2000\t Step: 15/54\t Train Loss: 4.046453\t Valid Loss: 4.370761\n",
      "Epoch: 47/2000\t Step: 30/54\t Train Loss: 4.103701\t Valid Loss: 4.360704\n",
      "Epoch: 47/2000\t Step: 45/54\t Train Loss: 4.037847\t Valid Loss: 4.368285\n",
      "Epoch: 48/2000\t Step: 15/54\t Train Loss: 4.082983\t Valid Loss: 4.378099\n",
      "Epoch: 48/2000\t Step: 30/54\t Train Loss: 4.042192\t Valid Loss: 4.373793\n",
      "Epoch: 48/2000\t Step: 45/54\t Train Loss: 4.031172\t Valid Loss: 4.363876\n",
      "Epoch: 49/2000\t Step: 15/54\t Train Loss: 4.060893\t Valid Loss: 4.370378\n",
      "Epoch: 49/2000\t Step: 30/54\t Train Loss: 4.047700\t Valid Loss: 4.363048\n",
      "Epoch: 49/2000\t Step: 45/54\t Train Loss: 4.044800\t Valid Loss: 4.363788\n",
      "Epoch: 50/2000\t Step: 15/54\t Train Loss: 4.165703\t Valid Loss: 4.371701\n",
      "Epoch: 50/2000\t Step: 30/54\t Train Loss: 4.055023\t Valid Loss: 4.358117\n",
      "Epoch: 50/2000\t Step: 45/54\t Train Loss: 4.071264\t Valid Loss: 4.357787\n",
      "Epoch: 51/2000\t Step: 15/54\t Train Loss: 4.076467\t Valid Loss: 4.367337\n",
      "Epoch: 51/2000\t Step: 30/54\t Train Loss: 4.039866\t Valid Loss: 4.362632\n",
      "Epoch: 51/2000\t Step: 45/54\t Train Loss: 4.045586\t Valid Loss: 4.354004\n",
      "Epoch: 52/2000\t Step: 15/54\t Train Loss: 4.037367\t Valid Loss: 4.366669\n",
      "Epoch: 52/2000\t Step: 30/54\t Train Loss: 4.027799\t Valid Loss: 4.359795\n",
      "Epoch: 52/2000\t Step: 45/54\t Train Loss: 4.206204\t Valid Loss: 4.359060\n",
      "Epoch: 53/2000\t Step: 15/54\t Train Loss: 4.030603\t Valid Loss: 4.355501\n",
      "Epoch: 53/2000\t Step: 30/54\t Train Loss: 4.130347\t Valid Loss: 4.358824\n",
      "Epoch: 53/2000\t Step: 45/54\t Train Loss: 4.103525\t Valid Loss: 4.337106\n",
      "Epoch: 54/2000\t Step: 15/54\t Train Loss: 4.033329\t Valid Loss: 4.358090\n",
      "Epoch: 54/2000\t Step: 30/54\t Train Loss: 4.089918\t Valid Loss: 4.358937\n",
      "Epoch: 54/2000\t Step: 45/54\t Train Loss: 4.087300\t Valid Loss: 4.349691\n",
      "Epoch: 55/2000\t Step: 15/54\t Train Loss: 4.044773\t Valid Loss: 4.338251\n",
      "Epoch: 55/2000\t Step: 30/54\t Train Loss: 4.077309\t Valid Loss: 4.346191\n",
      "Epoch: 55/2000\t Step: 45/54\t Train Loss: 4.048592\t Valid Loss: 4.343743\n",
      "Epoch: 56/2000\t Step: 15/54\t Train Loss: 4.033655\t Valid Loss: 4.346966\n",
      "Epoch: 56/2000\t Step: 30/54\t Train Loss: 4.028076\t Valid Loss: 4.341897\n",
      "Epoch: 56/2000\t Step: 45/54\t Train Loss: 4.062808\t Valid Loss: 4.338592\n",
      "Epoch: 57/2000\t Step: 15/54\t Train Loss: 4.016526\t Valid Loss: 4.343002\n",
      "Epoch: 57/2000\t Step: 30/54\t Train Loss: 4.027544\t Valid Loss: 4.339291\n",
      "Epoch: 57/2000\t Step: 45/54\t Train Loss: 4.050508\t Valid Loss: 4.334653\n",
      "Epoch: 58/2000\t Step: 15/54\t Train Loss: 4.069137\t Valid Loss: 4.340089\n",
      "Epoch: 58/2000\t Step: 30/54\t Train Loss: 4.050539\t Valid Loss: 4.343064\n",
      "Epoch: 58/2000\t Step: 45/54\t Train Loss: 4.047311\t Valid Loss: 4.337286\n",
      "Epoch: 59/2000\t Step: 15/54\t Train Loss: 4.080235\t Valid Loss: 4.327157\n",
      "Epoch: 59/2000\t Step: 30/54\t Train Loss: 4.124751\t Valid Loss: 4.329971\n",
      "Epoch: 59/2000\t Step: 45/54\t Train Loss: 4.071987\t Valid Loss: 4.341941\n",
      "Epoch: 60/2000\t Step: 15/54\t Train Loss: 4.159918\t Valid Loss: 4.327041\n",
      "Epoch: 60/2000\t Step: 30/54\t Train Loss: 4.110420\t Valid Loss: 4.323549\n",
      "Epoch: 60/2000\t Step: 45/54\t Train Loss: 4.114881\t Valid Loss: 4.330633\n",
      "Epoch: 61/2000\t Step: 15/54\t Train Loss: 4.026727\t Valid Loss: 4.345119\n",
      "Epoch: 61/2000\t Step: 30/54\t Train Loss: 4.020214\t Valid Loss: 4.327441\n",
      "Epoch: 61/2000\t Step: 45/54\t Train Loss: 4.046401\t Valid Loss: 4.322538\n",
      "Epoch: 62/2000\t Step: 15/54\t Train Loss: 4.002280\t Valid Loss: 4.328749\n",
      "Epoch: 62/2000\t Step: 30/54\t Train Loss: 3.998482\t Valid Loss: 4.327795\n",
      "Epoch: 62/2000\t Step: 45/54\t Train Loss: 4.048954\t Valid Loss: 4.323748\n",
      "Epoch: 63/2000\t Step: 15/54\t Train Loss: 4.036195\t Valid Loss: 4.322144\n",
      "Epoch: 63/2000\t Step: 30/54\t Train Loss: 4.030307\t Valid Loss: 4.330225\n",
      "Epoch: 63/2000\t Step: 45/54\t Train Loss: 4.171865\t Valid Loss: 4.319022\n",
      "Epoch: 64/2000\t Step: 15/54\t Train Loss: 4.047635\t Valid Loss: 4.320244\n",
      "Epoch: 64/2000\t Step: 30/54\t Train Loss: 4.065090\t Valid Loss: 4.321687\n",
      "Epoch: 64/2000\t Step: 45/54\t Train Loss: 4.013280\t Valid Loss: 4.315973\n",
      "Epoch: 65/2000\t Step: 15/54\t Train Loss: 4.002859\t Valid Loss: 4.318576\n",
      "Epoch: 65/2000\t Step: 30/54\t Train Loss: 4.017105\t Valid Loss: 4.316184\n",
      "Epoch: 65/2000\t Step: 45/54\t Train Loss: 4.095161\t Valid Loss: 4.317871\n",
      "Epoch: 66/2000\t Step: 15/54\t Train Loss: 4.014435\t Valid Loss: 4.322745\n",
      "Epoch: 66/2000\t Step: 30/54\t Train Loss: 4.046908\t Valid Loss: 4.313073\n",
      "Epoch: 66/2000\t Step: 45/54\t Train Loss: 4.010673\t Valid Loss: 4.309635\n",
      "Epoch: 67/2000\t Step: 15/54\t Train Loss: 3.994403\t Valid Loss: 4.309088\n",
      "Epoch: 67/2000\t Step: 30/54\t Train Loss: 3.990242\t Valid Loss: 4.325366\n",
      "Epoch: 67/2000\t Step: 45/54\t Train Loss: 4.089028\t Valid Loss: 4.309176\n",
      "Epoch: 68/2000\t Step: 15/54\t Train Loss: 4.032280\t Valid Loss: 4.310626\n",
      "Epoch: 68/2000\t Step: 30/54\t Train Loss: 4.061001\t Valid Loss: 4.310250\n",
      "Epoch: 68/2000\t Step: 45/54\t Train Loss: 4.052760\t Valid Loss: 4.318613\n",
      "Epoch: 69/2000\t Step: 15/54\t Train Loss: 4.177268\t Valid Loss: 4.314037\n",
      "Epoch: 69/2000\t Step: 30/54\t Train Loss: 4.022711\t Valid Loss: 4.302077\n",
      "Epoch: 69/2000\t Step: 45/54\t Train Loss: 4.019948\t Valid Loss: 4.306425\n",
      "Epoch: 70/2000\t Step: 15/54\t Train Loss: 4.011171\t Valid Loss: 4.308326\n",
      "Epoch: 70/2000\t Step: 30/54\t Train Loss: 4.010883\t Valid Loss: 4.306084\n",
      "Epoch: 70/2000\t Step: 45/54\t Train Loss: 4.042483\t Valid Loss: 4.317115\n",
      "Epoch: 71/2000\t Step: 15/54\t Train Loss: 4.053604\t Valid Loss: 4.311591\n",
      "Epoch: 71/2000\t Step: 30/54\t Train Loss: 4.050180\t Valid Loss: 4.309137\n",
      "Epoch: 71/2000\t Step: 45/54\t Train Loss: 4.036301\t Valid Loss: 4.306533\n",
      "Epoch: 72/2000\t Step: 15/54\t Train Loss: 3.997182\t Valid Loss: 4.304689\n",
      "Epoch: 72/2000\t Step: 30/54\t Train Loss: 4.013500\t Valid Loss: 4.306446\n",
      "Epoch: 72/2000\t Step: 45/54\t Train Loss: 4.120139\t Valid Loss: 4.305243\n",
      "Epoch: 73/2000\t Step: 15/54\t Train Loss: 3.983461\t Valid Loss: 4.306707\n",
      "Epoch: 73/2000\t Step: 30/54\t Train Loss: 4.096750\t Valid Loss: 4.312542\n",
      "Epoch: 73/2000\t Step: 45/54\t Train Loss: 4.150587\t Valid Loss: 4.299650\n",
      "Epoch: 74/2000\t Step: 15/54\t Train Loss: 4.028844\t Valid Loss: 4.303092\n",
      "Epoch: 74/2000\t Step: 30/54\t Train Loss: 4.049430\t Valid Loss: 4.303481\n",
      "Epoch: 74/2000\t Step: 45/54\t Train Loss: 4.192774\t Valid Loss: 4.296431\n",
      "Epoch: 75/2000\t Step: 15/54\t Train Loss: 4.112202\t Valid Loss: 4.298628\n",
      "Epoch: 75/2000\t Step: 30/54\t Train Loss: 4.031017\t Valid Loss: 4.304212\n",
      "Epoch: 75/2000\t Step: 45/54\t Train Loss: 4.025443\t Valid Loss: 4.300712\n",
      "Epoch: 76/2000\t Step: 15/54\t Train Loss: 3.989030\t Valid Loss: 4.303845\n",
      "Epoch: 76/2000\t Step: 30/54\t Train Loss: 4.155994\t Valid Loss: 4.297975\n",
      "Epoch: 76/2000\t Step: 45/54\t Train Loss: 4.001895\t Valid Loss: 4.298504\n",
      "Epoch: 77/2000\t Step: 15/54\t Train Loss: 4.007570\t Valid Loss: 4.298296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/2000\t Step: 30/54\t Train Loss: 4.040817\t Valid Loss: 4.293677\n",
      "Epoch: 77/2000\t Step: 45/54\t Train Loss: 4.010643\t Valid Loss: 4.294997\n",
      "Epoch: 78/2000\t Step: 15/54\t Train Loss: 4.013539\t Valid Loss: 4.293667\n",
      "Epoch: 78/2000\t Step: 30/54\t Train Loss: 4.042760\t Valid Loss: 4.300342\n",
      "Epoch: 78/2000\t Step: 45/54\t Train Loss: 3.990843\t Valid Loss: 4.298628\n",
      "Epoch: 79/2000\t Step: 15/54\t Train Loss: 3.981423\t Valid Loss: 4.297348\n",
      "Epoch: 79/2000\t Step: 30/54\t Train Loss: 4.037476\t Valid Loss: 4.286177\n",
      "Epoch: 79/2000\t Step: 45/54\t Train Loss: 3.997378\t Valid Loss: 4.283463\n",
      "Epoch: 80/2000\t Step: 15/54\t Train Loss: 4.033975\t Valid Loss: 4.286113\n",
      "Epoch: 80/2000\t Step: 30/54\t Train Loss: 3.988654\t Valid Loss: 4.303567\n",
      "Epoch: 80/2000\t Step: 45/54\t Train Loss: 3.973862\t Valid Loss: 4.297772\n",
      "Epoch: 81/2000\t Step: 15/54\t Train Loss: 4.007290\t Valid Loss: 4.294929\n",
      "Epoch: 81/2000\t Step: 30/54\t Train Loss: 4.100029\t Valid Loss: 4.299829\n",
      "Epoch: 81/2000\t Step: 45/54\t Train Loss: 4.157792\t Valid Loss: 4.286714\n",
      "Epoch: 82/2000\t Step: 15/54\t Train Loss: 4.035224\t Valid Loss: 4.282634\n",
      "Epoch: 82/2000\t Step: 30/54\t Train Loss: 3.988164\t Valid Loss: 4.284077\n",
      "Epoch: 82/2000\t Step: 45/54\t Train Loss: 4.019422\t Valid Loss: 4.293802\n",
      "Epoch: 83/2000\t Step: 15/54\t Train Loss: 4.019040\t Valid Loss: 4.283600\n",
      "Epoch: 83/2000\t Step: 30/54\t Train Loss: 4.043792\t Valid Loss: 4.297043\n",
      "Epoch: 83/2000\t Step: 45/54\t Train Loss: 4.024304\t Valid Loss: 4.287771\n",
      "Epoch: 84/2000\t Step: 15/54\t Train Loss: 4.060354\t Valid Loss: 4.282677\n",
      "Epoch: 84/2000\t Step: 30/54\t Train Loss: 4.139302\t Valid Loss: 4.276258\n",
      "Epoch: 84/2000\t Step: 45/54\t Train Loss: 3.945377\t Valid Loss: 4.321735\n",
      "Epoch: 85/2000\t Step: 15/54\t Train Loss: 3.987969\t Valid Loss: 4.288188\n",
      "Epoch: 85/2000\t Step: 30/54\t Train Loss: 4.002668\t Valid Loss: 4.278825\n",
      "Epoch: 85/2000\t Step: 45/54\t Train Loss: 4.038346\t Valid Loss: 4.282239\n",
      "Epoch: 86/2000\t Step: 15/54\t Train Loss: 3.968161\t Valid Loss: 4.287798\n",
      "Epoch: 86/2000\t Step: 30/54\t Train Loss: 4.033668\t Valid Loss: 4.286395\n",
      "Epoch: 86/2000\t Step: 45/54\t Train Loss: 4.018036\t Valid Loss: 4.284141\n",
      "Epoch: 87/2000\t Step: 15/54\t Train Loss: 4.023869\t Valid Loss: 4.278791\n",
      "Epoch: 87/2000\t Step: 30/54\t Train Loss: 3.969531\t Valid Loss: 4.298826\n",
      "Epoch: 87/2000\t Step: 45/54\t Train Loss: 4.001122\t Valid Loss: 4.283017\n",
      "Epoch: 88/2000\t Step: 15/54\t Train Loss: 4.015692\t Valid Loss: 4.284647\n",
      "Epoch: 88/2000\t Step: 30/54\t Train Loss: 4.064823\t Valid Loss: 4.295327\n",
      "Epoch: 88/2000\t Step: 45/54\t Train Loss: 3.981493\t Valid Loss: 4.270677\n",
      "Epoch: 89/2000\t Step: 15/54\t Train Loss: 3.998585\t Valid Loss: 4.274052\n",
      "Epoch: 89/2000\t Step: 30/54\t Train Loss: 4.054036\t Valid Loss: 4.291772\n",
      "Epoch: 89/2000\t Step: 45/54\t Train Loss: 3.997632\t Valid Loss: 4.283392\n",
      "Epoch: 90/2000\t Step: 15/54\t Train Loss: 4.067299\t Valid Loss: 4.278019\n",
      "Epoch: 90/2000\t Step: 30/54\t Train Loss: 3.966381\t Valid Loss: 4.281577\n",
      "Epoch: 90/2000\t Step: 45/54\t Train Loss: 3.988686\t Valid Loss: 4.286496\n",
      "Epoch: 91/2000\t Step: 15/54\t Train Loss: 4.015102\t Valid Loss: 4.284643\n",
      "Epoch: 91/2000\t Step: 30/54\t Train Loss: 4.023240\t Valid Loss: 4.280292\n",
      "Epoch: 91/2000\t Step: 45/54\t Train Loss: 3.967305\t Valid Loss: 4.283344\n",
      "Epoch: 92/2000\t Step: 15/54\t Train Loss: 4.004048\t Valid Loss: 4.269913\n",
      "Epoch: 92/2000\t Step: 30/54\t Train Loss: 4.061455\t Valid Loss: 4.285470\n",
      "Epoch: 92/2000\t Step: 45/54\t Train Loss: 4.138268\t Valid Loss: 4.264220\n",
      "Epoch: 93/2000\t Step: 15/54\t Train Loss: 4.107267\t Valid Loss: 4.281644\n",
      "Epoch: 93/2000\t Step: 30/54\t Train Loss: 4.003492\t Valid Loss: 4.288389\n",
      "Epoch: 93/2000\t Step: 45/54\t Train Loss: 3.952658\t Valid Loss: 4.283625\n",
      "Epoch: 94/2000\t Step: 15/54\t Train Loss: 4.003876\t Valid Loss: 4.284691\n",
      "Epoch: 94/2000\t Step: 30/54\t Train Loss: 4.011817\t Valid Loss: 4.266670\n",
      "Epoch: 94/2000\t Step: 45/54\t Train Loss: 4.080767\t Valid Loss: 4.278021\n",
      "Epoch: 95/2000\t Step: 15/54\t Train Loss: 3.996712\t Valid Loss: 4.271907\n",
      "Epoch: 95/2000\t Step: 30/54\t Train Loss: 3.971875\t Valid Loss: 4.268066\n",
      "Epoch: 95/2000\t Step: 45/54\t Train Loss: 3.967354\t Valid Loss: 4.282275\n",
      "Epoch: 96/2000\t Step: 15/54\t Train Loss: 4.007280\t Valid Loss: 4.280733\n",
      "Epoch: 96/2000\t Step: 30/54\t Train Loss: 4.005093\t Valid Loss: 4.287437\n",
      "Epoch: 96/2000\t Step: 45/54\t Train Loss: 3.968009\t Valid Loss: 4.270141\n",
      "Epoch: 97/2000\t Step: 15/54\t Train Loss: 4.116893\t Valid Loss: 4.267159\n",
      "Epoch: 97/2000\t Step: 30/54\t Train Loss: 4.095475\t Valid Loss: 4.273365\n",
      "Epoch: 97/2000\t Step: 45/54\t Train Loss: 3.983243\t Valid Loss: 4.264259\n",
      "Epoch: 98/2000\t Step: 15/54\t Train Loss: 4.009521\t Valid Loss: 4.283854\n",
      "Epoch: 98/2000\t Step: 30/54\t Train Loss: 3.996987\t Valid Loss: 4.280004\n",
      "Epoch: 98/2000\t Step: 45/54\t Train Loss: 4.005864\t Valid Loss: 4.291501\n",
      "Epoch: 99/2000\t Step: 15/54\t Train Loss: 4.000887\t Valid Loss: 4.294005\n",
      "Epoch: 99/2000\t Step: 30/54\t Train Loss: 3.986760\t Valid Loss: 4.281189\n",
      "Epoch: 99/2000\t Step: 45/54\t Train Loss: 4.132259\t Valid Loss: 4.268608\n",
      "Epoch: 100/2000\t Step: 15/54\t Train Loss: 3.957758\t Valid Loss: 4.271156\n",
      "Epoch: 100/2000\t Step: 30/54\t Train Loss: 4.113033\t Valid Loss: 4.284718\n",
      "Epoch: 100/2000\t Step: 45/54\t Train Loss: 3.973702\t Valid Loss: 4.261638\n",
      "Epoch: 101/2000\t Step: 15/54\t Train Loss: 4.024650\t Valid Loss: 4.296126\n",
      "Epoch: 101/2000\t Step: 30/54\t Train Loss: 4.025317\t Valid Loss: 4.277173\n",
      "Epoch: 101/2000\t Step: 45/54\t Train Loss: 4.003130\t Valid Loss: 4.266659\n",
      "Epoch: 102/2000\t Step: 15/54\t Train Loss: 3.975569\t Valid Loss: 4.273552\n",
      "Epoch: 102/2000\t Step: 30/54\t Train Loss: 3.964142\t Valid Loss: 4.269261\n",
      "Epoch: 102/2000\t Step: 45/54\t Train Loss: 3.999611\t Valid Loss: 4.299991\n",
      "Epoch: 103/2000\t Step: 15/54\t Train Loss: 4.111433\t Valid Loss: 4.272570\n",
      "Epoch: 103/2000\t Step: 30/54\t Train Loss: 3.963510\t Valid Loss: 4.258109\n",
      "Epoch: 103/2000\t Step: 45/54\t Train Loss: 4.087853\t Valid Loss: 4.258758\n",
      "Epoch: 104/2000\t Step: 15/54\t Train Loss: 3.992523\t Valid Loss: 4.254484\n",
      "Epoch: 104/2000\t Step: 30/54\t Train Loss: 3.966043\t Valid Loss: 4.267688\n",
      "Epoch: 104/2000\t Step: 45/54\t Train Loss: 3.947067\t Valid Loss: 4.265373\n",
      "Epoch: 105/2000\t Step: 15/54\t Train Loss: 3.982326\t Valid Loss: 4.264749\n",
      "Epoch: 105/2000\t Step: 30/54\t Train Loss: 4.124932\t Valid Loss: 4.268720\n",
      "Epoch: 105/2000\t Step: 45/54\t Train Loss: 3.991252\t Valid Loss: 4.268189\n",
      "Epoch: 106/2000\t Step: 15/54\t Train Loss: 4.092724\t Valid Loss: 4.284873\n",
      "Epoch: 106/2000\t Step: 30/54\t Train Loss: 3.970064\t Valid Loss: 4.294106\n",
      "Epoch: 106/2000\t Step: 45/54\t Train Loss: 3.967855\t Valid Loss: 4.268999\n",
      "Epoch: 107/2000\t Step: 15/54\t Train Loss: 4.102694\t Valid Loss: 4.282391\n",
      "Epoch: 107/2000\t Step: 30/54\t Train Loss: 3.970426\t Valid Loss: 4.270711\n",
      "Epoch: 107/2000\t Step: 45/54\t Train Loss: 3.981958\t Valid Loss: 4.265420\n",
      "Epoch: 108/2000\t Step: 15/54\t Train Loss: 4.081343\t Valid Loss: 4.261702\n",
      "Epoch: 108/2000\t Step: 30/54\t Train Loss: 4.188763\t Valid Loss: 4.261796\n",
      "Epoch: 108/2000\t Step: 45/54\t Train Loss: 3.943865\t Valid Loss: 4.259866\n",
      "Epoch: 109/2000\t Step: 15/54\t Train Loss: 4.018430\t Valid Loss: 4.248275\n",
      "Epoch: 109/2000\t Step: 30/54\t Train Loss: 4.096527\t Valid Loss: 4.264483\n",
      "Epoch: 109/2000\t Step: 45/54\t Train Loss: 3.954033\t Valid Loss: 4.262546\n",
      "Epoch: 110/2000\t Step: 15/54\t Train Loss: 3.972089\t Valid Loss: 4.275369\n",
      "Epoch: 110/2000\t Step: 30/54\t Train Loss: 4.003379\t Valid Loss: 4.277938\n",
      "Epoch: 110/2000\t Step: 45/54\t Train Loss: 3.999417\t Valid Loss: 4.284667\n",
      "Epoch: 111/2000\t Step: 15/54\t Train Loss: 4.020921\t Valid Loss: 4.277725\n",
      "Epoch: 111/2000\t Step: 30/54\t Train Loss: 3.979141\t Valid Loss: 4.259226\n",
      "Epoch: 111/2000\t Step: 45/54\t Train Loss: 3.952848\t Valid Loss: 4.271697\n",
      "Epoch: 112/2000\t Step: 15/54\t Train Loss: 3.973049\t Valid Loss: 4.263860\n",
      "Epoch: 112/2000\t Step: 30/54\t Train Loss: 3.962640\t Valid Loss: 4.269268\n",
      "Epoch: 112/2000\t Step: 45/54\t Train Loss: 3.940288\t Valid Loss: 4.262938\n",
      "Epoch: 113/2000\t Step: 15/54\t Train Loss: 3.949019\t Valid Loss: 4.257482\n",
      "Epoch: 113/2000\t Step: 30/54\t Train Loss: 4.096428\t Valid Loss: 4.275248\n",
      "Epoch: 113/2000\t Step: 45/54\t Train Loss: 4.083436\t Valid Loss: 4.257494\n",
      "Epoch: 114/2000\t Step: 15/54\t Train Loss: 3.970865\t Valid Loss: 4.261127\n",
      "Epoch: 114/2000\t Step: 30/54\t Train Loss: 4.044739\t Valid Loss: 4.313368\n",
      "Epoch: 114/2000\t Step: 45/54\t Train Loss: 4.054492\t Valid Loss: 4.262191\n",
      "Epoch: 115/2000\t Step: 15/54\t Train Loss: 3.974194\t Valid Loss: 4.244370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115/2000\t Step: 30/54\t Train Loss: 3.996095\t Valid Loss: 4.261285\n",
      "Epoch: 115/2000\t Step: 45/54\t Train Loss: 4.109751\t Valid Loss: 4.255563\n",
      "Epoch: 116/2000\t Step: 15/54\t Train Loss: 3.983687\t Valid Loss: 4.300638\n",
      "Epoch: 116/2000\t Step: 30/54\t Train Loss: 4.023596\t Valid Loss: 4.272422\n",
      "Epoch: 116/2000\t Step: 45/54\t Train Loss: 3.994385\t Valid Loss: 4.309840\n",
      "Epoch: 117/2000\t Step: 15/54\t Train Loss: 3.986089\t Valid Loss: 4.266768\n",
      "Epoch: 117/2000\t Step: 30/54\t Train Loss: 3.961692\t Valid Loss: 4.249484\n",
      "Epoch: 117/2000\t Step: 45/54\t Train Loss: 4.003109\t Valid Loss: 4.260480\n",
      "Epoch: 118/2000\t Step: 15/54\t Train Loss: 3.946548\t Valid Loss: 4.259951\n",
      "Epoch: 118/2000\t Step: 30/54\t Train Loss: 4.108142\t Valid Loss: 4.238351\n",
      "Epoch: 118/2000\t Step: 45/54\t Train Loss: 3.943371\t Valid Loss: 4.289529\n",
      "Epoch: 119/2000\t Step: 15/54\t Train Loss: 4.040477\t Valid Loss: 4.294614\n",
      "Epoch: 119/2000\t Step: 30/54\t Train Loss: 3.970417\t Valid Loss: 4.279266\n",
      "Epoch: 119/2000\t Step: 45/54\t Train Loss: 4.048325\t Valid Loss: 4.246330\n",
      "Epoch: 120/2000\t Step: 15/54\t Train Loss: 4.060868\t Valid Loss: 4.264438\n",
      "Epoch: 120/2000\t Step: 30/54\t Train Loss: 3.986841\t Valid Loss: 4.250122\n",
      "Epoch: 120/2000\t Step: 45/54\t Train Loss: 3.991089\t Valid Loss: 4.285565\n",
      "Epoch: 121/2000\t Step: 15/54\t Train Loss: 3.951790\t Valid Loss: 4.253913\n",
      "Epoch: 121/2000\t Step: 30/54\t Train Loss: 3.954024\t Valid Loss: 4.254690\n",
      "Epoch: 121/2000\t Step: 45/54\t Train Loss: 4.005285\t Valid Loss: 4.264418\n",
      "Epoch: 122/2000\t Step: 15/54\t Train Loss: 3.963177\t Valid Loss: 4.268370\n",
      "Epoch: 122/2000\t Step: 30/54\t Train Loss: 4.009999\t Valid Loss: 4.284126\n",
      "Epoch: 122/2000\t Step: 45/54\t Train Loss: 3.978620\t Valid Loss: 4.251417\n",
      "Epoch: 123/2000\t Step: 15/54\t Train Loss: 3.969197\t Valid Loss: 4.248345\n",
      "Epoch: 123/2000\t Step: 30/54\t Train Loss: 3.962519\t Valid Loss: 4.286409\n",
      "Epoch: 123/2000\t Step: 45/54\t Train Loss: 3.965430\t Valid Loss: 4.254883\n",
      "Epoch: 124/2000\t Step: 15/54\t Train Loss: 3.998588\t Valid Loss: 4.245239\n",
      "Epoch: 124/2000\t Step: 30/54\t Train Loss: 3.964067\t Valid Loss: 4.268134\n",
      "Epoch: 124/2000\t Step: 45/54\t Train Loss: 4.113931\t Valid Loss: 4.269531\n",
      "Epoch: 125/2000\t Step: 15/54\t Train Loss: 3.942420\t Valid Loss: 4.243725\n",
      "Epoch: 125/2000\t Step: 30/54\t Train Loss: 3.986734\t Valid Loss: 4.340470\n",
      "Epoch: 125/2000\t Step: 45/54\t Train Loss: 3.971115\t Valid Loss: 4.278713\n",
      "Epoch: 126/2000\t Step: 15/54\t Train Loss: 3.952893\t Valid Loss: 4.242663\n",
      "Epoch: 126/2000\t Step: 30/54\t Train Loss: 3.998976\t Valid Loss: 4.250017\n",
      "Epoch: 126/2000\t Step: 45/54\t Train Loss: 3.995748\t Valid Loss: 4.252261\n",
      "Epoch: 127/2000\t Step: 15/54\t Train Loss: 4.070641\t Valid Loss: 4.259189\n",
      "Epoch: 127/2000\t Step: 30/54\t Train Loss: 3.930147\t Valid Loss: 4.250567\n",
      "Epoch: 127/2000\t Step: 45/54\t Train Loss: 3.975818\t Valid Loss: 4.258921\n",
      "Epoch: 128/2000\t Step: 15/54\t Train Loss: 3.992705\t Valid Loss: 4.237524\n",
      "Epoch: 128/2000\t Step: 30/54\t Train Loss: 3.952711\t Valid Loss: 4.269611\n",
      "Epoch: 128/2000\t Step: 45/54\t Train Loss: 4.120546\t Valid Loss: 4.264856\n",
      "Epoch: 129/2000\t Step: 15/54\t Train Loss: 3.977868\t Valid Loss: 4.262603\n",
      "Epoch: 129/2000\t Step: 30/54\t Train Loss: 4.123266\t Valid Loss: 4.255224\n",
      "Epoch: 129/2000\t Step: 45/54\t Train Loss: 3.965003\t Valid Loss: 4.284576\n",
      "Epoch: 130/2000\t Step: 15/54\t Train Loss: 3.969571\t Valid Loss: 4.249725\n",
      "Epoch: 130/2000\t Step: 30/54\t Train Loss: 3.995143\t Valid Loss: 4.277652\n",
      "Epoch: 130/2000\t Step: 45/54\t Train Loss: 3.946391\t Valid Loss: 4.257506\n",
      "Epoch: 131/2000\t Step: 15/54\t Train Loss: 3.962985\t Valid Loss: 4.285136\n",
      "Epoch: 131/2000\t Step: 30/54\t Train Loss: 4.054794\t Valid Loss: 4.289958\n",
      "Epoch: 131/2000\t Step: 45/54\t Train Loss: 3.960121\t Valid Loss: 4.238651\n",
      "Epoch: 132/2000\t Step: 15/54\t Train Loss: 4.011804\t Valid Loss: 4.242845\n",
      "Epoch: 132/2000\t Step: 30/54\t Train Loss: 4.060231\t Valid Loss: 4.295462\n",
      "Epoch: 132/2000\t Step: 45/54\t Train Loss: 3.985929\t Valid Loss: 4.226776\n",
      "Epoch: 133/2000\t Step: 15/54\t Train Loss: 3.940334\t Valid Loss: 4.259136\n",
      "Epoch: 133/2000\t Step: 30/54\t Train Loss: 3.956706\t Valid Loss: 4.251090\n",
      "Epoch: 133/2000\t Step: 45/54\t Train Loss: 4.105167\t Valid Loss: 4.242764\n",
      "Epoch: 134/2000\t Step: 15/54\t Train Loss: 4.020317\t Valid Loss: 4.260787\n",
      "Epoch: 134/2000\t Step: 30/54\t Train Loss: 4.006722\t Valid Loss: 4.254929\n",
      "Epoch: 134/2000\t Step: 45/54\t Train Loss: 3.973567\t Valid Loss: 4.243469\n",
      "Epoch: 135/2000\t Step: 15/54\t Train Loss: 4.001878\t Valid Loss: 4.233713\n",
      "Epoch: 135/2000\t Step: 30/54\t Train Loss: 3.948123\t Valid Loss: 4.245656\n",
      "Epoch: 135/2000\t Step: 45/54\t Train Loss: 3.970929\t Valid Loss: 4.256433\n",
      "Epoch: 136/2000\t Step: 15/54\t Train Loss: 4.059698\t Valid Loss: 4.249972\n",
      "Epoch: 136/2000\t Step: 30/54\t Train Loss: 3.941365\t Valid Loss: 4.297892\n",
      "Epoch: 136/2000\t Step: 45/54\t Train Loss: 4.002490\t Valid Loss: 4.267271\n",
      "Epoch: 137/2000\t Step: 15/54\t Train Loss: 3.929807\t Valid Loss: 4.241121\n",
      "Epoch: 137/2000\t Step: 30/54\t Train Loss: 4.054903\t Valid Loss: 4.230438\n",
      "Epoch: 137/2000\t Step: 45/54\t Train Loss: 3.956882\t Valid Loss: 4.252434\n",
      "Epoch: 138/2000\t Step: 15/54\t Train Loss: 3.970813\t Valid Loss: 4.277629\n",
      "Epoch: 138/2000\t Step: 30/54\t Train Loss: 3.985590\t Valid Loss: 4.229283\n",
      "Epoch: 138/2000\t Step: 45/54\t Train Loss: 3.979662\t Valid Loss: 4.273263\n",
      "Epoch: 139/2000\t Step: 15/54\t Train Loss: 3.970945\t Valid Loss: 4.241033\n",
      "Epoch: 139/2000\t Step: 30/54\t Train Loss: 3.964319\t Valid Loss: 4.272357\n",
      "Epoch: 139/2000\t Step: 45/54\t Train Loss: 3.963598\t Valid Loss: 4.268025\n",
      "Epoch: 140/2000\t Step: 15/54\t Train Loss: 3.950360\t Valid Loss: 4.232224\n",
      "Epoch: 140/2000\t Step: 30/54\t Train Loss: 4.020180\t Valid Loss: 4.234172\n",
      "Epoch: 140/2000\t Step: 45/54\t Train Loss: 3.988884\t Valid Loss: 4.249122\n",
      "Epoch: 141/2000\t Step: 15/54\t Train Loss: 4.031230\t Valid Loss: 4.278446\n",
      "Epoch: 141/2000\t Step: 30/54\t Train Loss: 3.938495\t Valid Loss: 4.245390\n",
      "Epoch: 141/2000\t Step: 45/54\t Train Loss: 3.947478\t Valid Loss: 4.274165\n",
      "Epoch: 142/2000\t Step: 15/54\t Train Loss: 3.946853\t Valid Loss: 4.263947\n",
      "Epoch: 142/2000\t Step: 30/54\t Train Loss: 4.041842\t Valid Loss: 4.268026\n",
      "Epoch: 142/2000\t Step: 45/54\t Train Loss: 4.038219\t Valid Loss: 4.240407\n",
      "Epoch: 143/2000\t Step: 15/54\t Train Loss: 3.951217\t Valid Loss: 4.258311\n",
      "Epoch: 143/2000\t Step: 30/54\t Train Loss: 3.976246\t Valid Loss: 4.274471\n",
      "Epoch: 143/2000\t Step: 45/54\t Train Loss: 3.962454\t Valid Loss: 4.263562\n",
      "Epoch: 144/2000\t Step: 15/54\t Train Loss: 3.937141\t Valid Loss: 4.235169\n",
      "Epoch: 144/2000\t Step: 30/54\t Train Loss: 3.981886\t Valid Loss: 4.267995\n",
      "Epoch: 144/2000\t Step: 45/54\t Train Loss: 3.994669\t Valid Loss: 4.234686\n",
      "Epoch: 145/2000\t Step: 15/54\t Train Loss: 3.964172\t Valid Loss: 4.252550\n",
      "Epoch: 145/2000\t Step: 30/54\t Train Loss: 3.969000\t Valid Loss: 4.220063\n",
      "Epoch: 145/2000\t Step: 45/54\t Train Loss: 4.132883\t Valid Loss: 4.223837\n",
      "Epoch: 146/2000\t Step: 15/54\t Train Loss: 3.960989\t Valid Loss: 4.299979\n",
      "Epoch: 146/2000\t Step: 30/54\t Train Loss: 3.987205\t Valid Loss: 4.273152\n",
      "Epoch: 146/2000\t Step: 45/54\t Train Loss: 4.033560\t Valid Loss: 4.234108\n",
      "Epoch: 147/2000\t Step: 15/54\t Train Loss: 3.944410\t Valid Loss: 4.230733\n",
      "Epoch: 147/2000\t Step: 30/54\t Train Loss: 3.968705\t Valid Loss: 4.265244\n",
      "Epoch: 147/2000\t Step: 45/54\t Train Loss: 3.959351\t Valid Loss: 4.284608\n",
      "Epoch: 148/2000\t Step: 15/54\t Train Loss: 4.118729\t Valid Loss: 4.250357\n",
      "Epoch: 148/2000\t Step: 30/54\t Train Loss: 3.952040\t Valid Loss: 4.260665\n",
      "Epoch: 148/2000\t Step: 45/54\t Train Loss: 3.961710\t Valid Loss: 4.222343\n",
      "Epoch: 149/2000\t Step: 15/54\t Train Loss: 3.952198\t Valid Loss: 4.239140\n",
      "Epoch: 149/2000\t Step: 30/54\t Train Loss: 3.961397\t Valid Loss: 4.234865\n",
      "Epoch: 149/2000\t Step: 45/54\t Train Loss: 3.979956\t Valid Loss: 4.255344\n",
      "Epoch: 150/2000\t Step: 15/54\t Train Loss: 3.966878\t Valid Loss: 4.253574\n",
      "Epoch: 150/2000\t Step: 30/54\t Train Loss: 3.974293\t Valid Loss: 4.248194\n",
      "Epoch: 150/2000\t Step: 45/54\t Train Loss: 3.975677\t Valid Loss: 4.269667\n",
      "Epoch: 151/2000\t Step: 15/54\t Train Loss: 3.955071\t Valid Loss: 4.253564\n",
      "Epoch: 151/2000\t Step: 30/54\t Train Loss: 4.008319\t Valid Loss: 4.277467\n",
      "Epoch: 151/2000\t Step: 45/54\t Train Loss: 3.944611\t Valid Loss: 4.256544\n",
      "Epoch: 152/2000\t Step: 15/54\t Train Loss: 4.203807\t Valid Loss: 4.254987\n",
      "Epoch: 152/2000\t Step: 30/54\t Train Loss: 4.104692\t Valid Loss: 4.244517\n",
      "Epoch: 152/2000\t Step: 45/54\t Train Loss: 3.951006\t Valid Loss: 4.245586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 153/2000\t Step: 15/54\t Train Loss: 4.055418\t Valid Loss: 4.240119\n",
      "Epoch: 153/2000\t Step: 30/54\t Train Loss: 3.995863\t Valid Loss: 4.214244\n",
      "Epoch: 153/2000\t Step: 45/54\t Train Loss: 3.932275\t Valid Loss: 4.331688\n",
      "Epoch: 154/2000\t Step: 15/54\t Train Loss: 4.048003\t Valid Loss: 4.280096\n",
      "Epoch: 154/2000\t Step: 30/54\t Train Loss: 3.939783\t Valid Loss: 4.280968\n",
      "Epoch: 154/2000\t Step: 45/54\t Train Loss: 3.935083\t Valid Loss: 4.255805\n",
      "Epoch: 155/2000\t Step: 15/54\t Train Loss: 4.091999\t Valid Loss: 4.219060\n",
      "Epoch: 155/2000\t Step: 30/54\t Train Loss: 4.103626\t Valid Loss: 4.221656\n",
      "Epoch: 155/2000\t Step: 45/54\t Train Loss: 3.922685\t Valid Loss: 4.224186\n",
      "Epoch: 156/2000\t Step: 15/54\t Train Loss: 3.950006\t Valid Loss: 4.253622\n",
      "Epoch: 156/2000\t Step: 30/54\t Train Loss: 3.908916\t Valid Loss: 4.249808\n",
      "Epoch: 156/2000\t Step: 45/54\t Train Loss: 3.994973\t Valid Loss: 4.298502\n",
      "Epoch: 157/2000\t Step: 15/54\t Train Loss: 3.968346\t Valid Loss: 4.267135\n",
      "Epoch: 157/2000\t Step: 30/54\t Train Loss: 4.031865\t Valid Loss: 4.276350\n",
      "Epoch: 157/2000\t Step: 45/54\t Train Loss: 3.955605\t Valid Loss: 4.230241\n",
      "Epoch: 158/2000\t Step: 15/54\t Train Loss: 3.994000\t Valid Loss: 4.233088\n",
      "Epoch: 158/2000\t Step: 30/54\t Train Loss: 3.999725\t Valid Loss: 4.272379\n",
      "Epoch: 158/2000\t Step: 45/54\t Train Loss: 3.999431\t Valid Loss: 4.234668\n",
      "Epoch: 159/2000\t Step: 15/54\t Train Loss: 3.927697\t Valid Loss: 4.268935\n",
      "Epoch: 159/2000\t Step: 30/54\t Train Loss: 3.980406\t Valid Loss: 4.242358\n",
      "Epoch: 159/2000\t Step: 45/54\t Train Loss: 3.995866\t Valid Loss: 4.252688\n",
      "Epoch: 160/2000\t Step: 15/54\t Train Loss: 3.930779\t Valid Loss: 4.264896\n",
      "Epoch: 160/2000\t Step: 30/54\t Train Loss: 3.958933\t Valid Loss: 4.256327\n",
      "Epoch: 160/2000\t Step: 45/54\t Train Loss: 3.976759\t Valid Loss: 4.229434\n",
      "Epoch: 161/2000\t Step: 15/54\t Train Loss: 3.957082\t Valid Loss: 4.247552\n",
      "Epoch: 161/2000\t Step: 30/54\t Train Loss: 4.017272\t Valid Loss: 4.334047\n",
      "Epoch: 161/2000\t Step: 45/54\t Train Loss: 3.980505\t Valid Loss: 4.255723\n",
      "Epoch: 162/2000\t Step: 15/54\t Train Loss: 4.093988\t Valid Loss: 4.220827\n",
      "Epoch: 162/2000\t Step: 30/54\t Train Loss: 3.945586\t Valid Loss: 4.252052\n",
      "Epoch: 162/2000\t Step: 45/54\t Train Loss: 3.970035\t Valid Loss: 4.249556\n",
      "Epoch: 163/2000\t Step: 15/54\t Train Loss: 3.918957\t Valid Loss: 4.246215\n",
      "Epoch: 163/2000\t Step: 30/54\t Train Loss: 3.938497\t Valid Loss: 4.245217\n",
      "Epoch: 163/2000\t Step: 45/54\t Train Loss: 3.986122\t Valid Loss: 4.240826\n",
      "Epoch: 164/2000\t Step: 15/54\t Train Loss: 3.963390\t Valid Loss: 4.274772\n",
      "Epoch: 164/2000\t Step: 30/54\t Train Loss: 3.990272\t Valid Loss: 4.313988\n",
      "Epoch: 164/2000\t Step: 45/54\t Train Loss: 4.010383\t Valid Loss: 4.251729\n",
      "Epoch: 165/2000\t Step: 15/54\t Train Loss: 3.956352\t Valid Loss: 4.226292\n",
      "Epoch: 165/2000\t Step: 30/54\t Train Loss: 3.978121\t Valid Loss: 4.246961\n",
      "Epoch: 165/2000\t Step: 45/54\t Train Loss: 3.942949\t Valid Loss: 4.219673\n",
      "Epoch: 166/2000\t Step: 15/54\t Train Loss: 4.071313\t Valid Loss: 4.219073\n",
      "Epoch: 166/2000\t Step: 30/54\t Train Loss: 3.991262\t Valid Loss: 4.269469\n",
      "Epoch: 166/2000\t Step: 45/54\t Train Loss: 3.950667\t Valid Loss: 4.304865\n",
      "Epoch: 167/2000\t Step: 15/54\t Train Loss: 3.932996\t Valid Loss: 4.257444\n",
      "Epoch: 167/2000\t Step: 30/54\t Train Loss: 3.944402\t Valid Loss: 4.209545\n",
      "Epoch: 167/2000\t Step: 45/54\t Train Loss: 3.924952\t Valid Loss: 4.255489\n",
      "Epoch: 168/2000\t Step: 15/54\t Train Loss: 4.009872\t Valid Loss: 4.228853\n",
      "Epoch: 168/2000\t Step: 30/54\t Train Loss: 4.033479\t Valid Loss: 4.259784\n",
      "Epoch: 168/2000\t Step: 45/54\t Train Loss: 3.984392\t Valid Loss: 4.322030\n",
      "Epoch: 169/2000\t Step: 15/54\t Train Loss: 3.932993\t Valid Loss: 4.237841\n",
      "Epoch: 169/2000\t Step: 30/54\t Train Loss: 3.908302\t Valid Loss: 4.243227\n",
      "Epoch: 169/2000\t Step: 45/54\t Train Loss: 3.943898\t Valid Loss: 4.262173\n",
      "Epoch: 170/2000\t Step: 15/54\t Train Loss: 3.924571\t Valid Loss: 4.265922\n",
      "Epoch: 170/2000\t Step: 30/54\t Train Loss: 3.980463\t Valid Loss: 4.269613\n",
      "Epoch: 170/2000\t Step: 45/54\t Train Loss: 3.960742\t Valid Loss: 4.268423\n",
      "Epoch: 171/2000\t Step: 15/54\t Train Loss: 3.944901\t Valid Loss: 4.231496\n",
      "Epoch: 171/2000\t Step: 30/54\t Train Loss: 3.954561\t Valid Loss: 4.245603\n",
      "Epoch: 171/2000\t Step: 45/54\t Train Loss: 3.942793\t Valid Loss: 4.246339\n",
      "Epoch: 172/2000\t Step: 15/54\t Train Loss: 3.927371\t Valid Loss: 4.244417\n",
      "Epoch: 172/2000\t Step: 30/54\t Train Loss: 3.940435\t Valid Loss: 4.244197\n",
      "Epoch: 172/2000\t Step: 45/54\t Train Loss: 4.030284\t Valid Loss: 4.273348\n",
      "Epoch: 173/2000\t Step: 15/54\t Train Loss: 3.922940\t Valid Loss: 4.241454\n",
      "Epoch: 173/2000\t Step: 30/54\t Train Loss: 4.047591\t Valid Loss: 4.238798\n",
      "Epoch: 173/2000\t Step: 45/54\t Train Loss: 4.048079\t Valid Loss: 4.306785\n",
      "Epoch: 174/2000\t Step: 15/54\t Train Loss: 3.937554\t Valid Loss: 4.223917\n",
      "Epoch: 174/2000\t Step: 30/54\t Train Loss: 3.988246\t Valid Loss: 4.229382\n",
      "Epoch: 174/2000\t Step: 45/54\t Train Loss: 3.939440\t Valid Loss: 4.230140\n",
      "Epoch: 175/2000\t Step: 15/54\t Train Loss: 3.945986\t Valid Loss: 4.232849\n",
      "Epoch: 175/2000\t Step: 30/54\t Train Loss: 3.918088\t Valid Loss: 4.269454\n",
      "Epoch: 175/2000\t Step: 45/54\t Train Loss: 3.920079\t Valid Loss: 4.262416\n",
      "Epoch: 176/2000\t Step: 15/54\t Train Loss: 3.945315\t Valid Loss: 4.279581\n",
      "Epoch: 176/2000\t Step: 30/54\t Train Loss: 3.942578\t Valid Loss: 4.242091\n",
      "Epoch: 176/2000\t Step: 45/54\t Train Loss: 3.913162\t Valid Loss: 4.230780\n",
      "Epoch: 177/2000\t Step: 15/54\t Train Loss: 3.985908\t Valid Loss: 4.253886\n",
      "Epoch: 177/2000\t Step: 30/54\t Train Loss: 3.934597\t Valid Loss: 4.230608\n",
      "Epoch: 177/2000\t Step: 45/54\t Train Loss: 3.939586\t Valid Loss: 4.259032\n",
      "Epoch: 178/2000\t Step: 15/54\t Train Loss: 4.025169\t Valid Loss: 4.246915\n",
      "Epoch: 178/2000\t Step: 30/54\t Train Loss: 4.044357\t Valid Loss: 4.250609\n",
      "Epoch: 178/2000\t Step: 45/54\t Train Loss: 3.951125\t Valid Loss: 4.263327\n",
      "Epoch: 179/2000\t Step: 15/54\t Train Loss: 3.933211\t Valid Loss: 4.248472\n",
      "Epoch: 179/2000\t Step: 30/54\t Train Loss: 3.978007\t Valid Loss: 4.252427\n",
      "Epoch: 179/2000\t Step: 45/54\t Train Loss: 3.964272\t Valid Loss: 4.264786\n",
      "Epoch: 180/2000\t Step: 15/54\t Train Loss: 3.930140\t Valid Loss: 4.248801\n",
      "Epoch: 180/2000\t Step: 30/54\t Train Loss: 4.055740\t Valid Loss: 4.237174\n",
      "Epoch: 180/2000\t Step: 45/54\t Train Loss: 4.045431\t Valid Loss: 4.223632\n",
      "Epoch: 181/2000\t Step: 15/54\t Train Loss: 4.038022\t Valid Loss: 4.241320\n",
      "Epoch: 181/2000\t Step: 30/54\t Train Loss: 3.916478\t Valid Loss: 4.251347\n",
      "Epoch: 181/2000\t Step: 45/54\t Train Loss: 3.986784\t Valid Loss: 4.220351\n",
      "Epoch: 182/2000\t Step: 15/54\t Train Loss: 3.948161\t Valid Loss: 4.221385\n",
      "Epoch: 182/2000\t Step: 30/54\t Train Loss: 3.924491\t Valid Loss: 4.257414\n",
      "Epoch: 182/2000\t Step: 45/54\t Train Loss: 3.941509\t Valid Loss: 4.290848\n",
      "Epoch: 183/2000\t Step: 15/54\t Train Loss: 3.982461\t Valid Loss: 4.220267\n",
      "Epoch: 183/2000\t Step: 30/54\t Train Loss: 3.950894\t Valid Loss: 4.229374\n",
      "Epoch: 183/2000\t Step: 45/54\t Train Loss: 3.940091\t Valid Loss: 4.217348\n",
      "Epoch: 184/2000\t Step: 15/54\t Train Loss: 3.918668\t Valid Loss: 4.272998\n",
      "Epoch: 184/2000\t Step: 30/54\t Train Loss: 3.955715\t Valid Loss: 4.333940\n",
      "Epoch: 184/2000\t Step: 45/54\t Train Loss: 4.035428\t Valid Loss: 4.269183\n",
      "Epoch: 185/2000\t Step: 15/54\t Train Loss: 4.040663\t Valid Loss: 4.278524\n",
      "Epoch: 185/2000\t Step: 30/54\t Train Loss: 3.947108\t Valid Loss: 4.267457\n",
      "Epoch: 185/2000\t Step: 45/54\t Train Loss: 3.922263\t Valid Loss: 4.243827\n",
      "Epoch: 186/2000\t Step: 15/54\t Train Loss: 3.918184\t Valid Loss: 4.235510\n",
      "Epoch: 186/2000\t Step: 30/54\t Train Loss: 3.946600\t Valid Loss: 4.236334\n",
      "Epoch: 186/2000\t Step: 45/54\t Train Loss: 4.035420\t Valid Loss: 4.236823\n",
      "Epoch: 187/2000\t Step: 15/54\t Train Loss: 3.958938\t Valid Loss: 4.273483\n",
      "Epoch: 187/2000\t Step: 30/54\t Train Loss: 3.956795\t Valid Loss: 4.240600\n",
      "Epoch: 187/2000\t Step: 45/54\t Train Loss: 3.909653\t Valid Loss: 4.272046\n",
      "Epoch: 188/2000\t Step: 15/54\t Train Loss: 3.968083\t Valid Loss: 4.222390\n",
      "Epoch: 188/2000\t Step: 30/54\t Train Loss: 3.980526\t Valid Loss: 4.269504\n",
      "Epoch: 188/2000\t Step: 45/54\t Train Loss: 4.109129\t Valid Loss: 4.253345\n",
      "Epoch: 189/2000\t Step: 15/54\t Train Loss: 3.930405\t Valid Loss: 4.240641\n",
      "Epoch: 189/2000\t Step: 30/54\t Train Loss: 3.944667\t Valid Loss: 4.265490\n",
      "Epoch: 189/2000\t Step: 45/54\t Train Loss: 3.931714\t Valid Loss: 4.257550\n",
      "Epoch: 190/2000\t Step: 15/54\t Train Loss: 3.966971\t Valid Loss: 4.231973\n",
      "Epoch: 190/2000\t Step: 30/54\t Train Loss: 3.921611\t Valid Loss: 4.208940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190/2000\t Step: 45/54\t Train Loss: 3.981365\t Valid Loss: 4.259384\n",
      "Epoch: 191/2000\t Step: 15/54\t Train Loss: 3.944141\t Valid Loss: 4.243071\n",
      "Epoch: 191/2000\t Step: 30/54\t Train Loss: 3.928343\t Valid Loss: 4.231498\n",
      "Epoch: 191/2000\t Step: 45/54\t Train Loss: 3.922585\t Valid Loss: 4.261974\n",
      "Epoch: 192/2000\t Step: 15/54\t Train Loss: 3.999063\t Valid Loss: 4.225883\n",
      "Epoch: 192/2000\t Step: 30/54\t Train Loss: 3.902307\t Valid Loss: 4.241110\n",
      "Epoch: 192/2000\t Step: 45/54\t Train Loss: 4.014229\t Valid Loss: 4.235099\n",
      "Epoch: 193/2000\t Step: 15/54\t Train Loss: 3.896382\t Valid Loss: 4.230365\n",
      "Epoch: 193/2000\t Step: 30/54\t Train Loss: 3.945832\t Valid Loss: 4.278328\n",
      "Epoch: 193/2000\t Step: 45/54\t Train Loss: 3.912922\t Valid Loss: 4.281750\n",
      "Epoch: 194/2000\t Step: 15/54\t Train Loss: 3.959517\t Valid Loss: 4.259509\n",
      "Epoch: 194/2000\t Step: 30/54\t Train Loss: 4.007577\t Valid Loss: 4.225531\n",
      "Epoch: 194/2000\t Step: 45/54\t Train Loss: 3.933385\t Valid Loss: 4.228703\n",
      "Epoch: 195/2000\t Step: 15/54\t Train Loss: 3.958046\t Valid Loss: 4.259322\n",
      "Epoch: 195/2000\t Step: 30/54\t Train Loss: 3.894153\t Valid Loss: 4.261434\n",
      "Epoch: 195/2000\t Step: 45/54\t Train Loss: 3.946410\t Valid Loss: 4.247459\n",
      "Epoch: 196/2000\t Step: 15/54\t Train Loss: 4.017141\t Valid Loss: 4.288139\n",
      "Epoch: 196/2000\t Step: 30/54\t Train Loss: 4.009580\t Valid Loss: 4.218626\n",
      "Epoch: 196/2000\t Step: 45/54\t Train Loss: 3.927287\t Valid Loss: 4.301893\n",
      "Epoch: 197/2000\t Step: 15/54\t Train Loss: 3.953320\t Valid Loss: 4.260329\n",
      "Epoch: 197/2000\t Step: 30/54\t Train Loss: 3.961531\t Valid Loss: 4.313812\n",
      "Epoch: 197/2000\t Step: 45/54\t Train Loss: 3.933350\t Valid Loss: 4.275088\n",
      "Epoch: 198/2000\t Step: 15/54\t Train Loss: 3.979970\t Valid Loss: 4.286412\n",
      "Epoch: 198/2000\t Step: 30/54\t Train Loss: 3.957394\t Valid Loss: 4.234908\n",
      "Epoch: 198/2000\t Step: 45/54\t Train Loss: 3.952128\t Valid Loss: 4.250992\n",
      "Epoch: 199/2000\t Step: 15/54\t Train Loss: 3.986140\t Valid Loss: 4.257779\n",
      "Epoch: 199/2000\t Step: 30/54\t Train Loss: 3.941126\t Valid Loss: 4.250476\n",
      "Epoch: 199/2000\t Step: 45/54\t Train Loss: 3.923587\t Valid Loss: 4.247455\n",
      "Epoch: 200/2000\t Step: 15/54\t Train Loss: 3.963209\t Valid Loss: 4.271514\n",
      "Epoch: 200/2000\t Step: 30/54\t Train Loss: 3.939723\t Valid Loss: 4.252416\n",
      "Epoch: 200/2000\t Step: 45/54\t Train Loss: 3.950172\t Valid Loss: 4.294820\n",
      "Epoch: 201/2000\t Step: 15/54\t Train Loss: 4.054335\t Valid Loss: 4.250374\n",
      "Epoch: 201/2000\t Step: 30/54\t Train Loss: 3.963012\t Valid Loss: 4.225131\n",
      "Epoch: 201/2000\t Step: 45/54\t Train Loss: 3.975482\t Valid Loss: 4.223537\n",
      "Epoch: 202/2000\t Step: 15/54\t Train Loss: 3.890554\t Valid Loss: 4.248138\n",
      "Epoch: 202/2000\t Step: 30/54\t Train Loss: 3.933394\t Valid Loss: 4.238581\n",
      "Epoch: 202/2000\t Step: 45/54\t Train Loss: 3.926197\t Valid Loss: 4.287534\n",
      "Epoch: 203/2000\t Step: 15/54\t Train Loss: 3.932106\t Valid Loss: 4.269908\n",
      "Epoch: 203/2000\t Step: 30/54\t Train Loss: 4.014076\t Valid Loss: 4.251791\n",
      "Epoch: 203/2000\t Step: 45/54\t Train Loss: 3.936437\t Valid Loss: 4.258577\n",
      "Epoch: 204/2000\t Step: 15/54\t Train Loss: 3.937689\t Valid Loss: 4.300686\n",
      "Epoch: 204/2000\t Step: 30/54\t Train Loss: 4.013054\t Valid Loss: 4.231239\n",
      "Epoch: 204/2000\t Step: 45/54\t Train Loss: 4.040142\t Valid Loss: 4.272339\n",
      "Epoch: 205/2000\t Step: 15/54\t Train Loss: 3.913991\t Valid Loss: 4.325402\n",
      "Epoch: 205/2000\t Step: 30/54\t Train Loss: 3.964259\t Valid Loss: 4.237773\n",
      "Epoch: 205/2000\t Step: 45/54\t Train Loss: 3.966285\t Valid Loss: 4.236504\n",
      "Epoch: 206/2000\t Step: 15/54\t Train Loss: 4.027263\t Valid Loss: 4.252983\n",
      "Epoch: 206/2000\t Step: 30/54\t Train Loss: 3.922877\t Valid Loss: 4.226278\n",
      "Epoch: 206/2000\t Step: 45/54\t Train Loss: 3.925076\t Valid Loss: 4.233514\n",
      "Epoch: 207/2000\t Step: 15/54\t Train Loss: 3.913904\t Valid Loss: 4.236642\n",
      "Epoch: 207/2000\t Step: 30/54\t Train Loss: 3.933928\t Valid Loss: 4.229580\n",
      "Epoch: 207/2000\t Step: 45/54\t Train Loss: 3.933811\t Valid Loss: 4.287637\n",
      "Epoch: 208/2000\t Step: 15/54\t Train Loss: 3.899345\t Valid Loss: 4.222163\n",
      "Epoch: 208/2000\t Step: 30/54\t Train Loss: 4.045665\t Valid Loss: 4.268141\n",
      "Epoch: 208/2000\t Step: 45/54\t Train Loss: 3.940744\t Valid Loss: 4.248582\n",
      "Epoch: 209/2000\t Step: 15/54\t Train Loss: 3.921018\t Valid Loss: 4.257327\n",
      "Epoch: 209/2000\t Step: 30/54\t Train Loss: 3.909214\t Valid Loss: 4.265218\n",
      "Epoch: 209/2000\t Step: 45/54\t Train Loss: 3.931261\t Valid Loss: 4.221433\n",
      "Epoch: 210/2000\t Step: 15/54\t Train Loss: 3.951024\t Valid Loss: 4.213536\n",
      "Epoch: 210/2000\t Step: 30/54\t Train Loss: 3.903811\t Valid Loss: 4.253676\n",
      "Epoch: 210/2000\t Step: 45/54\t Train Loss: 3.959401\t Valid Loss: 4.241917\n",
      "Epoch: 211/2000\t Step: 15/54\t Train Loss: 3.917341\t Valid Loss: 4.268715\n",
      "Epoch: 211/2000\t Step: 30/54\t Train Loss: 3.896782\t Valid Loss: 4.244543\n",
      "Epoch: 211/2000\t Step: 45/54\t Train Loss: 3.924750\t Valid Loss: 4.276623\n",
      "Epoch: 212/2000\t Step: 15/54\t Train Loss: 3.919973\t Valid Loss: 4.210134\n",
      "Epoch: 212/2000\t Step: 30/54\t Train Loss: 3.897494\t Valid Loss: 4.228280\n",
      "Epoch: 212/2000\t Step: 45/54\t Train Loss: 3.920469\t Valid Loss: 4.277384\n",
      "Epoch: 213/2000\t Step: 15/54\t Train Loss: 4.083463\t Valid Loss: 4.240500\n",
      "Epoch: 213/2000\t Step: 30/54\t Train Loss: 4.021697\t Valid Loss: 4.283867\n",
      "Epoch: 213/2000\t Step: 45/54\t Train Loss: 3.977507\t Valid Loss: 4.287560\n",
      "Epoch: 214/2000\t Step: 15/54\t Train Loss: 3.942928\t Valid Loss: 4.274606\n",
      "Epoch: 214/2000\t Step: 30/54\t Train Loss: 3.933171\t Valid Loss: 4.212323\n",
      "Epoch: 214/2000\t Step: 45/54\t Train Loss: 3.886381\t Valid Loss: 4.299122\n",
      "Epoch: 215/2000\t Step: 15/54\t Train Loss: 3.999197\t Valid Loss: 4.229667\n",
      "Epoch: 215/2000\t Step: 30/54\t Train Loss: 3.898002\t Valid Loss: 4.286898\n",
      "Epoch: 215/2000\t Step: 45/54\t Train Loss: 4.076108\t Valid Loss: 4.285828\n",
      "Epoch: 216/2000\t Step: 15/54\t Train Loss: 3.937500\t Valid Loss: 4.236190\n",
      "Epoch: 216/2000\t Step: 30/54\t Train Loss: 3.930490\t Valid Loss: 4.226919\n",
      "Epoch: 216/2000\t Step: 45/54\t Train Loss: 3.905438\t Valid Loss: 4.252291\n",
      "Epoch: 217/2000\t Step: 15/54\t Train Loss: 3.964379\t Valid Loss: 4.296359\n",
      "Epoch: 217/2000\t Step: 30/54\t Train Loss: 3.907119\t Valid Loss: 4.237689\n",
      "Epoch: 217/2000\t Step: 45/54\t Train Loss: 3.927916\t Valid Loss: 4.279040\n",
      "Epoch: 218/2000\t Step: 15/54\t Train Loss: 3.907690\t Valid Loss: 4.279196\n",
      "Epoch: 218/2000\t Step: 30/54\t Train Loss: 3.919377\t Valid Loss: 4.237960\n",
      "Epoch: 218/2000\t Step: 45/54\t Train Loss: 3.937574\t Valid Loss: 4.260176\n",
      "Epoch: 219/2000\t Step: 15/54\t Train Loss: 3.896658\t Valid Loss: 4.317174\n",
      "Epoch: 219/2000\t Step: 30/54\t Train Loss: 3.926409\t Valid Loss: 4.253177\n",
      "Epoch: 219/2000\t Step: 45/54\t Train Loss: 3.931707\t Valid Loss: 4.253793\n",
      "Epoch: 220/2000\t Step: 15/54\t Train Loss: 3.960109\t Valid Loss: 4.274996\n",
      "Epoch: 220/2000\t Step: 30/54\t Train Loss: 4.025315\t Valid Loss: 4.318644\n",
      "Epoch: 220/2000\t Step: 45/54\t Train Loss: 3.885016\t Valid Loss: 4.265433\n",
      "Epoch: 221/2000\t Step: 15/54\t Train Loss: 3.978156\t Valid Loss: 4.318818\n",
      "Epoch: 221/2000\t Step: 30/54\t Train Loss: 3.923083\t Valid Loss: 4.277109\n",
      "Epoch: 221/2000\t Step: 45/54\t Train Loss: 3.957700\t Valid Loss: 4.242980\n",
      "Epoch: 222/2000\t Step: 15/54\t Train Loss: 4.003298\t Valid Loss: 4.255236\n",
      "Epoch: 222/2000\t Step: 30/54\t Train Loss: 3.938706\t Valid Loss: 4.255540\n",
      "Epoch: 222/2000\t Step: 45/54\t Train Loss: 3.891299\t Valid Loss: 4.279421\n",
      "Epoch: 223/2000\t Step: 15/54\t Train Loss: 4.002522\t Valid Loss: 4.378752\n",
      "Epoch: 223/2000\t Step: 30/54\t Train Loss: 3.959888\t Valid Loss: 4.243414\n",
      "Epoch: 223/2000\t Step: 45/54\t Train Loss: 3.935840\t Valid Loss: 4.276195\n",
      "Epoch: 224/2000\t Step: 15/54\t Train Loss: 3.936780\t Valid Loss: 4.197963\n",
      "Epoch: 224/2000\t Step: 30/54\t Train Loss: 3.899018\t Valid Loss: 4.246796\n",
      "Epoch: 224/2000\t Step: 45/54\t Train Loss: 3.897308\t Valid Loss: 4.244773\n",
      "Epoch: 225/2000\t Step: 15/54\t Train Loss: 3.958918\t Valid Loss: 4.235938\n",
      "Epoch: 225/2000\t Step: 30/54\t Train Loss: 3.917288\t Valid Loss: 4.240843\n",
      "Epoch: 225/2000\t Step: 45/54\t Train Loss: 3.950439\t Valid Loss: 4.296139\n",
      "Epoch: 226/2000\t Step: 15/54\t Train Loss: 3.915633\t Valid Loss: 4.235704\n",
      "Epoch: 226/2000\t Step: 30/54\t Train Loss: 4.054759\t Valid Loss: 4.287901\n",
      "Epoch: 226/2000\t Step: 45/54\t Train Loss: 3.946424\t Valid Loss: 4.306395\n",
      "Epoch: 227/2000\t Step: 15/54\t Train Loss: 3.993211\t Valid Loss: 4.227401\n",
      "Epoch: 227/2000\t Step: 30/54\t Train Loss: 3.899741\t Valid Loss: 4.264591\n",
      "Epoch: 227/2000\t Step: 45/54\t Train Loss: 3.911546\t Valid Loss: 4.288935\n",
      "Epoch: 228/2000\t Step: 15/54\t Train Loss: 3.958416\t Valid Loss: 4.244138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 228/2000\t Step: 30/54\t Train Loss: 3.964878\t Valid Loss: 4.246204\n",
      "Epoch: 228/2000\t Step: 45/54\t Train Loss: 3.930163\t Valid Loss: 4.268523\n",
      "Epoch: 229/2000\t Step: 15/54\t Train Loss: 3.915456\t Valid Loss: 4.247548\n",
      "Epoch: 229/2000\t Step: 30/54\t Train Loss: 3.868173\t Valid Loss: 4.239390\n",
      "Epoch: 229/2000\t Step: 45/54\t Train Loss: 3.940570\t Valid Loss: 4.226310\n",
      "Epoch: 230/2000\t Step: 15/54\t Train Loss: 3.904596\t Valid Loss: 4.262616\n",
      "Epoch: 230/2000\t Step: 30/54\t Train Loss: 3.948417\t Valid Loss: 4.338950\n",
      "Epoch: 230/2000\t Step: 45/54\t Train Loss: 3.899314\t Valid Loss: 4.273142\n",
      "Epoch: 231/2000\t Step: 15/54\t Train Loss: 3.921423\t Valid Loss: 4.266596\n",
      "Epoch: 231/2000\t Step: 30/54\t Train Loss: 3.976108\t Valid Loss: 4.299095\n",
      "Epoch: 231/2000\t Step: 45/54\t Train Loss: 3.906914\t Valid Loss: 4.239260\n",
      "Epoch: 232/2000\t Step: 15/54\t Train Loss: 3.908589\t Valid Loss: 4.259029\n",
      "Epoch: 232/2000\t Step: 30/54\t Train Loss: 3.961418\t Valid Loss: 4.222183\n",
      "Epoch: 232/2000\t Step: 45/54\t Train Loss: 3.933838\t Valid Loss: 4.266676\n",
      "Epoch: 233/2000\t Step: 15/54\t Train Loss: 3.931018\t Valid Loss: 4.231356\n",
      "Epoch: 233/2000\t Step: 30/54\t Train Loss: 3.991913\t Valid Loss: 4.217215\n",
      "Epoch: 233/2000\t Step: 45/54\t Train Loss: 3.949676\t Valid Loss: 4.279292\n",
      "Epoch: 234/2000\t Step: 15/54\t Train Loss: 3.932439\t Valid Loss: 4.259171\n",
      "Epoch: 234/2000\t Step: 30/54\t Train Loss: 3.906885\t Valid Loss: 4.322683\n",
      "Epoch: 234/2000\t Step: 45/54\t Train Loss: 4.051548\t Valid Loss: 4.264713\n",
      "Epoch: 235/2000\t Step: 15/54\t Train Loss: 3.903751\t Valid Loss: 4.262359\n",
      "Epoch: 235/2000\t Step: 30/54\t Train Loss: 3.948296\t Valid Loss: 4.248013\n",
      "Epoch: 235/2000\t Step: 45/54\t Train Loss: 3.894656\t Valid Loss: 4.260246\n",
      "Epoch: 236/2000\t Step: 15/54\t Train Loss: 3.938710\t Valid Loss: 4.338549\n",
      "Epoch: 236/2000\t Step: 30/54\t Train Loss: 3.930315\t Valid Loss: 4.212602\n",
      "Epoch: 236/2000\t Step: 45/54\t Train Loss: 3.927393\t Valid Loss: 4.208420\n",
      "Epoch: 237/2000\t Step: 15/54\t Train Loss: 3.985802\t Valid Loss: 4.246775\n",
      "Epoch: 237/2000\t Step: 30/54\t Train Loss: 3.983455\t Valid Loss: 4.289278\n",
      "Epoch: 237/2000\t Step: 45/54\t Train Loss: 3.962132\t Valid Loss: 4.277703\n",
      "Epoch: 238/2000\t Step: 15/54\t Train Loss: 3.963940\t Valid Loss: 4.252426\n",
      "Epoch: 238/2000\t Step: 30/54\t Train Loss: 3.912450\t Valid Loss: 4.253153\n",
      "Epoch: 238/2000\t Step: 45/54\t Train Loss: 3.920142\t Valid Loss: 4.262014\n",
      "Epoch: 239/2000\t Step: 15/54\t Train Loss: 3.893279\t Valid Loss: 4.228536\n",
      "Epoch: 239/2000\t Step: 30/54\t Train Loss: 3.881185\t Valid Loss: 4.282942\n",
      "Epoch: 239/2000\t Step: 45/54\t Train Loss: 4.014212\t Valid Loss: 4.242204\n",
      "Epoch: 240/2000\t Step: 15/54\t Train Loss: 3.901273\t Valid Loss: 4.240377\n",
      "Epoch: 240/2000\t Step: 30/54\t Train Loss: 3.890839\t Valid Loss: 4.218432\n",
      "Epoch: 240/2000\t Step: 45/54\t Train Loss: 3.954554\t Valid Loss: 4.306227\n",
      "Epoch: 241/2000\t Step: 15/54\t Train Loss: 3.918942\t Valid Loss: 4.239707\n",
      "Epoch: 241/2000\t Step: 30/54\t Train Loss: 3.932832\t Valid Loss: 4.290279\n",
      "Epoch: 241/2000\t Step: 45/54\t Train Loss: 3.912483\t Valid Loss: 4.239276\n",
      "Epoch: 242/2000\t Step: 15/54\t Train Loss: 3.915235\t Valid Loss: 4.241524\n",
      "Epoch: 242/2000\t Step: 30/54\t Train Loss: 3.886945\t Valid Loss: 4.234253\n",
      "Epoch: 242/2000\t Step: 45/54\t Train Loss: 3.927145\t Valid Loss: 4.249479\n",
      "Epoch: 243/2000\t Step: 15/54\t Train Loss: 3.898734\t Valid Loss: 4.222624\n",
      "Epoch: 243/2000\t Step: 30/54\t Train Loss: 3.924804\t Valid Loss: 4.254443\n",
      "Epoch: 243/2000\t Step: 45/54\t Train Loss: 3.865325\t Valid Loss: 4.298736\n",
      "Epoch: 244/2000\t Step: 15/54\t Train Loss: 3.954423\t Valid Loss: 4.244008\n",
      "Epoch: 244/2000\t Step: 30/54\t Train Loss: 3.943495\t Valid Loss: 4.239302\n",
      "Epoch: 244/2000\t Step: 45/54\t Train Loss: 3.930288\t Valid Loss: 4.216475\n",
      "Epoch: 245/2000\t Step: 15/54\t Train Loss: 3.910922\t Valid Loss: 4.244901\n",
      "Epoch: 245/2000\t Step: 30/54\t Train Loss: 3.983431\t Valid Loss: 4.381931\n",
      "Epoch: 245/2000\t Step: 45/54\t Train Loss: 3.898419\t Valid Loss: 4.223187\n",
      "Epoch: 246/2000\t Step: 15/54\t Train Loss: 4.027405\t Valid Loss: 4.239517\n",
      "Epoch: 246/2000\t Step: 30/54\t Train Loss: 3.909256\t Valid Loss: 4.254480\n",
      "Epoch: 246/2000\t Step: 45/54\t Train Loss: 3.893046\t Valid Loss: 4.284303\n",
      "Epoch: 247/2000\t Step: 15/54\t Train Loss: 3.913922\t Valid Loss: 4.289295\n",
      "Epoch: 247/2000\t Step: 30/54\t Train Loss: 3.920162\t Valid Loss: 4.236627\n",
      "Epoch: 247/2000\t Step: 45/54\t Train Loss: 3.918859\t Valid Loss: 4.196501\n",
      "Epoch: 248/2000\t Step: 15/54\t Train Loss: 3.879328\t Valid Loss: 4.239081\n",
      "Epoch: 248/2000\t Step: 30/54\t Train Loss: 3.986372\t Valid Loss: 4.233679\n",
      "Epoch: 248/2000\t Step: 45/54\t Train Loss: 3.935868\t Valid Loss: 4.246779\n",
      "Epoch: 249/2000\t Step: 15/54\t Train Loss: 3.943473\t Valid Loss: 4.303337\n",
      "Epoch: 249/2000\t Step: 30/54\t Train Loss: 3.892220\t Valid Loss: 4.245653\n",
      "Epoch: 249/2000\t Step: 45/54\t Train Loss: 3.908197\t Valid Loss: 4.319836\n",
      "Epoch: 250/2000\t Step: 15/54\t Train Loss: 3.904001\t Valid Loss: 4.230798\n",
      "Epoch: 250/2000\t Step: 30/54\t Train Loss: 3.899351\t Valid Loss: 4.289440\n",
      "Epoch: 250/2000\t Step: 45/54\t Train Loss: 3.869983\t Valid Loss: 4.261393\n",
      "Epoch: 251/2000\t Step: 15/54\t Train Loss: 3.931890\t Valid Loss: 4.252860\n",
      "Epoch: 251/2000\t Step: 30/54\t Train Loss: 3.917979\t Valid Loss: 4.270024\n",
      "Epoch: 251/2000\t Step: 45/54\t Train Loss: 3.900660\t Valid Loss: 4.275625\n",
      "Epoch: 252/2000\t Step: 15/54\t Train Loss: 3.900555\t Valid Loss: 4.261614\n",
      "Epoch: 252/2000\t Step: 30/54\t Train Loss: 3.930437\t Valid Loss: 4.248001\n",
      "Epoch: 252/2000\t Step: 45/54\t Train Loss: 3.905867\t Valid Loss: 4.248873\n",
      "Epoch: 253/2000\t Step: 15/54\t Train Loss: 3.880775\t Valid Loss: 4.234730\n",
      "Epoch: 253/2000\t Step: 30/54\t Train Loss: 3.881341\t Valid Loss: 4.222857\n",
      "Epoch: 253/2000\t Step: 45/54\t Train Loss: 3.920672\t Valid Loss: 4.252583\n",
      "Epoch: 254/2000\t Step: 15/54\t Train Loss: 3.907060\t Valid Loss: 4.244953\n",
      "Epoch: 254/2000\t Step: 30/54\t Train Loss: 3.887855\t Valid Loss: 4.233655\n",
      "Epoch: 254/2000\t Step: 45/54\t Train Loss: 3.920441\t Valid Loss: 4.232479\n",
      "Epoch: 255/2000\t Step: 15/54\t Train Loss: 3.992325\t Valid Loss: 4.276407\n",
      "Epoch: 255/2000\t Step: 30/54\t Train Loss: 3.910751\t Valid Loss: 4.255812\n",
      "Epoch: 255/2000\t Step: 45/54\t Train Loss: 3.903174\t Valid Loss: 4.311242\n",
      "Epoch: 256/2000\t Step: 15/54\t Train Loss: 3.964993\t Valid Loss: 4.209732\n",
      "Epoch: 256/2000\t Step: 30/54\t Train Loss: 3.954526\t Valid Loss: 4.243744\n",
      "Epoch: 256/2000\t Step: 45/54\t Train Loss: 3.934652\t Valid Loss: 4.229901\n",
      "Epoch: 257/2000\t Step: 15/54\t Train Loss: 3.913796\t Valid Loss: 4.334072\n",
      "Epoch: 257/2000\t Step: 30/54\t Train Loss: 3.978012\t Valid Loss: 4.256153\n",
      "Epoch: 257/2000\t Step: 45/54\t Train Loss: 3.966877\t Valid Loss: 4.325829\n",
      "Epoch: 258/2000\t Step: 15/54\t Train Loss: 3.969552\t Valid Loss: 4.249575\n",
      "Epoch: 258/2000\t Step: 30/54\t Train Loss: 3.901133\t Valid Loss: 4.236991\n",
      "Epoch: 258/2000\t Step: 45/54\t Train Loss: 4.003601\t Valid Loss: 4.310246\n",
      "Epoch: 259/2000\t Step: 15/54\t Train Loss: 4.006019\t Valid Loss: 4.306547\n",
      "Epoch: 259/2000\t Step: 30/54\t Train Loss: 3.998414\t Valid Loss: 4.253490\n",
      "Epoch: 259/2000\t Step: 45/54\t Train Loss: 3.921249\t Valid Loss: 4.232678\n",
      "Epoch: 260/2000\t Step: 15/54\t Train Loss: 4.020179\t Valid Loss: 4.306439\n",
      "Epoch: 260/2000\t Step: 30/54\t Train Loss: 3.905211\t Valid Loss: 4.339164\n",
      "Epoch: 260/2000\t Step: 45/54\t Train Loss: 3.921412\t Valid Loss: 4.295906\n",
      "Epoch: 261/2000\t Step: 15/54\t Train Loss: 3.884005\t Valid Loss: 4.322213\n",
      "Epoch: 261/2000\t Step: 30/54\t Train Loss: 3.930758\t Valid Loss: 4.203258\n",
      "Epoch: 261/2000\t Step: 45/54\t Train Loss: 4.060707\t Valid Loss: 4.237735\n",
      "Epoch: 262/2000\t Step: 15/54\t Train Loss: 3.910472\t Valid Loss: 4.252767\n",
      "Epoch: 262/2000\t Step: 30/54\t Train Loss: 3.934422\t Valid Loss: 4.200024\n",
      "Epoch: 262/2000\t Step: 45/54\t Train Loss: 3.996965\t Valid Loss: 4.297962\n",
      "Epoch: 263/2000\t Step: 15/54\t Train Loss: 3.912327\t Valid Loss: 4.230099\n",
      "Epoch: 263/2000\t Step: 30/54\t Train Loss: 4.158541\t Valid Loss: 4.292612\n",
      "Epoch: 263/2000\t Step: 45/54\t Train Loss: 3.974334\t Valid Loss: 4.287275\n",
      "Epoch: 264/2000\t Step: 15/54\t Train Loss: 3.870581\t Valid Loss: 4.283927\n",
      "Epoch: 264/2000\t Step: 30/54\t Train Loss: 4.008951\t Valid Loss: 4.272548\n",
      "Epoch: 264/2000\t Step: 45/54\t Train Loss: 3.858593\t Valid Loss: 4.286660\n",
      "Epoch: 265/2000\t Step: 15/54\t Train Loss: 4.032270\t Valid Loss: 4.271019\n",
      "Epoch: 265/2000\t Step: 30/54\t Train Loss: 3.914301\t Valid Loss: 4.249747\n",
      "Epoch: 265/2000\t Step: 45/54\t Train Loss: 4.066937\t Valid Loss: 4.213877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 266/2000\t Step: 15/54\t Train Loss: 3.900271\t Valid Loss: 4.254062\n",
      "Epoch: 266/2000\t Step: 30/54\t Train Loss: 3.907750\t Valid Loss: 4.289555\n",
      "Epoch: 266/2000\t Step: 45/54\t Train Loss: 3.882555\t Valid Loss: 4.286146\n",
      "Epoch: 267/2000\t Step: 15/54\t Train Loss: 3.917558\t Valid Loss: 4.260542\n",
      "Epoch: 267/2000\t Step: 30/54\t Train Loss: 3.910540\t Valid Loss: 4.262897\n",
      "Epoch: 267/2000\t Step: 45/54\t Train Loss: 3.879990\t Valid Loss: 4.312008\n",
      "Epoch: 268/2000\t Step: 15/54\t Train Loss: 3.998779\t Valid Loss: 4.231853\n",
      "Epoch: 268/2000\t Step: 30/54\t Train Loss: 3.933471\t Valid Loss: 4.278586\n",
      "Epoch: 268/2000\t Step: 45/54\t Train Loss: 3.988322\t Valid Loss: 4.273665\n",
      "Epoch: 269/2000\t Step: 15/54\t Train Loss: 3.901080\t Valid Loss: 4.288956\n",
      "Epoch: 269/2000\t Step: 30/54\t Train Loss: 3.966868\t Valid Loss: 4.222093\n",
      "Epoch: 269/2000\t Step: 45/54\t Train Loss: 3.867757\t Valid Loss: 4.262527\n",
      "Epoch: 270/2000\t Step: 15/54\t Train Loss: 3.931519\t Valid Loss: 4.236481\n",
      "Epoch: 270/2000\t Step: 30/54\t Train Loss: 3.876719\t Valid Loss: 4.293666\n",
      "Epoch: 270/2000\t Step: 45/54\t Train Loss: 4.001624\t Valid Loss: 4.234189\n",
      "Epoch: 271/2000\t Step: 15/54\t Train Loss: 3.900419\t Valid Loss: 4.238829\n",
      "Epoch: 271/2000\t Step: 30/54\t Train Loss: 3.939446\t Valid Loss: 4.237307\n",
      "Epoch: 271/2000\t Step: 45/54\t Train Loss: 3.890936\t Valid Loss: 4.253157\n",
      "Epoch: 272/2000\t Step: 15/54\t Train Loss: 3.963315\t Valid Loss: 4.247320\n",
      "Epoch: 272/2000\t Step: 30/54\t Train Loss: 3.880878\t Valid Loss: 4.334036\n",
      "Epoch: 272/2000\t Step: 45/54\t Train Loss: 3.988630\t Valid Loss: 4.225202\n",
      "Epoch: 273/2000\t Step: 15/54\t Train Loss: 3.964144\t Valid Loss: 4.303397\n",
      "Epoch: 273/2000\t Step: 30/54\t Train Loss: 3.946864\t Valid Loss: 4.267099\n",
      "Epoch: 273/2000\t Step: 45/54\t Train Loss: 3.947159\t Valid Loss: 4.282948\n",
      "Epoch: 274/2000\t Step: 15/54\t Train Loss: 3.876805\t Valid Loss: 4.296229\n",
      "Epoch: 274/2000\t Step: 30/54\t Train Loss: 3.869398\t Valid Loss: 4.421556\n",
      "Epoch: 274/2000\t Step: 45/54\t Train Loss: 3.884081\t Valid Loss: 4.263699\n",
      "Epoch: 275/2000\t Step: 15/54\t Train Loss: 3.838932\t Valid Loss: 4.253613\n",
      "Epoch: 275/2000\t Step: 30/54\t Train Loss: 3.942257\t Valid Loss: 4.249352\n",
      "Epoch: 275/2000\t Step: 45/54\t Train Loss: 3.889160\t Valid Loss: 4.295751\n",
      "Epoch: 276/2000\t Step: 15/54\t Train Loss: 3.874967\t Valid Loss: 4.269482\n",
      "Epoch: 276/2000\t Step: 30/54\t Train Loss: 3.890440\t Valid Loss: 4.311028\n",
      "Epoch: 276/2000\t Step: 45/54\t Train Loss: 3.922811\t Valid Loss: 4.304944\n",
      "Epoch: 277/2000\t Step: 15/54\t Train Loss: 4.069462\t Valid Loss: 4.261830\n",
      "Epoch: 277/2000\t Step: 30/54\t Train Loss: 3.886109\t Valid Loss: 4.295660\n",
      "Epoch: 277/2000\t Step: 45/54\t Train Loss: 3.883205\t Valid Loss: 4.278308\n",
      "Epoch: 278/2000\t Step: 15/54\t Train Loss: 3.909355\t Valid Loss: 4.290325\n",
      "Epoch: 278/2000\t Step: 30/54\t Train Loss: 3.896588\t Valid Loss: 4.247744\n",
      "Epoch: 278/2000\t Step: 45/54\t Train Loss: 4.004052\t Valid Loss: 4.229754\n",
      "Epoch: 279/2000\t Step: 15/54\t Train Loss: 3.929445\t Valid Loss: 4.258053\n",
      "Epoch: 279/2000\t Step: 30/54\t Train Loss: 3.956623\t Valid Loss: 4.242897\n",
      "Epoch: 279/2000\t Step: 45/54\t Train Loss: 3.992381\t Valid Loss: 4.278149\n",
      "Epoch: 280/2000\t Step: 15/54\t Train Loss: 4.008592\t Valid Loss: 4.222788\n",
      "Epoch: 280/2000\t Step: 30/54\t Train Loss: 3.899015\t Valid Loss: 4.237844\n",
      "Epoch: 280/2000\t Step: 45/54\t Train Loss: 3.963615\t Valid Loss: 4.211843\n",
      "Epoch: 281/2000\t Step: 15/54\t Train Loss: 3.854315\t Valid Loss: 4.287557\n",
      "Epoch: 281/2000\t Step: 30/54\t Train Loss: 3.883451\t Valid Loss: 4.243773\n",
      "Epoch: 281/2000\t Step: 45/54\t Train Loss: 3.924525\t Valid Loss: 4.221595\n",
      "Epoch: 282/2000\t Step: 15/54\t Train Loss: 3.920092\t Valid Loss: 4.229554\n",
      "Epoch: 282/2000\t Step: 30/54\t Train Loss: 4.063402\t Valid Loss: 4.237090\n",
      "Epoch: 282/2000\t Step: 45/54\t Train Loss: 3.884666\t Valid Loss: 4.265314\n",
      "Epoch: 283/2000\t Step: 15/54\t Train Loss: 3.906356\t Valid Loss: 4.257785\n",
      "Epoch: 283/2000\t Step: 30/54\t Train Loss: 3.895371\t Valid Loss: 4.266425\n",
      "Epoch: 283/2000\t Step: 45/54\t Train Loss: 3.910309\t Valid Loss: 4.275159\n",
      "Epoch: 284/2000\t Step: 15/54\t Train Loss: 3.947124\t Valid Loss: 4.229622\n",
      "Epoch: 284/2000\t Step: 30/54\t Train Loss: 3.904144\t Valid Loss: 4.200248\n",
      "Epoch: 284/2000\t Step: 45/54\t Train Loss: 3.927598\t Valid Loss: 4.259167\n",
      "Epoch: 285/2000\t Step: 15/54\t Train Loss: 3.922199\t Valid Loss: 4.250078\n",
      "Epoch: 285/2000\t Step: 30/54\t Train Loss: 3.852409\t Valid Loss: 4.314329\n",
      "Epoch: 285/2000\t Step: 45/54\t Train Loss: 3.974324\t Valid Loss: 4.307640\n",
      "Epoch: 286/2000\t Step: 15/54\t Train Loss: 3.897563\t Valid Loss: 4.260589\n",
      "Epoch: 286/2000\t Step: 30/54\t Train Loss: 3.886173\t Valid Loss: 4.273754\n",
      "Epoch: 286/2000\t Step: 45/54\t Train Loss: 3.900915\t Valid Loss: 4.277397\n",
      "Epoch: 287/2000\t Step: 15/54\t Train Loss: 3.899564\t Valid Loss: 4.225257\n",
      "Epoch: 287/2000\t Step: 30/54\t Train Loss: 3.945199\t Valid Loss: 4.229099\n",
      "Epoch: 287/2000\t Step: 45/54\t Train Loss: 3.872462\t Valid Loss: 4.300220\n",
      "Epoch: 288/2000\t Step: 15/54\t Train Loss: 3.963887\t Valid Loss: 4.268999\n",
      "Epoch: 288/2000\t Step: 30/54\t Train Loss: 3.912977\t Valid Loss: 4.264602\n",
      "Epoch: 288/2000\t Step: 45/54\t Train Loss: 3.870048\t Valid Loss: 4.306038\n",
      "Epoch: 289/2000\t Step: 15/54\t Train Loss: 3.864782\t Valid Loss: 4.320232\n",
      "Epoch: 289/2000\t Step: 30/54\t Train Loss: 3.880924\t Valid Loss: 4.287800\n",
      "Epoch: 289/2000\t Step: 45/54\t Train Loss: 3.897841\t Valid Loss: 4.278029\n",
      "Epoch: 290/2000\t Step: 15/54\t Train Loss: 3.945639\t Valid Loss: 4.253945\n",
      "Epoch: 290/2000\t Step: 30/54\t Train Loss: 3.887077\t Valid Loss: 4.328899\n",
      "Epoch: 290/2000\t Step: 45/54\t Train Loss: 3.935016\t Valid Loss: 4.255629\n",
      "Epoch: 291/2000\t Step: 15/54\t Train Loss: 3.932367\t Valid Loss: 4.308817\n",
      "Epoch: 291/2000\t Step: 30/54\t Train Loss: 3.909503\t Valid Loss: 4.287117\n",
      "Epoch: 291/2000\t Step: 45/54\t Train Loss: 3.911493\t Valid Loss: 4.212322\n",
      "Epoch: 292/2000\t Step: 15/54\t Train Loss: 3.890916\t Valid Loss: 4.269736\n",
      "Epoch: 292/2000\t Step: 30/54\t Train Loss: 3.948381\t Valid Loss: 4.266983\n",
      "Epoch: 292/2000\t Step: 45/54\t Train Loss: 3.875593\t Valid Loss: 4.253173\n",
      "Epoch: 293/2000\t Step: 15/54\t Train Loss: 3.878568\t Valid Loss: 4.261045\n",
      "Epoch: 293/2000\t Step: 30/54\t Train Loss: 3.874730\t Valid Loss: 4.260260\n",
      "Epoch: 293/2000\t Step: 45/54\t Train Loss: 3.999329\t Valid Loss: 4.234179\n",
      "Epoch: 294/2000\t Step: 15/54\t Train Loss: 3.886331\t Valid Loss: 4.266912\n",
      "Epoch: 294/2000\t Step: 30/54\t Train Loss: 3.868547\t Valid Loss: 4.304292\n",
      "Epoch: 294/2000\t Step: 45/54\t Train Loss: 3.966062\t Valid Loss: 4.265890\n",
      "Epoch: 295/2000\t Step: 15/54\t Train Loss: 3.821214\t Valid Loss: 4.356926\n",
      "Epoch: 295/2000\t Step: 30/54\t Train Loss: 3.888993\t Valid Loss: 4.239408\n",
      "Epoch: 295/2000\t Step: 45/54\t Train Loss: 3.949021\t Valid Loss: 4.334513\n",
      "Epoch: 296/2000\t Step: 15/54\t Train Loss: 3.884283\t Valid Loss: 4.221221\n",
      "Epoch: 296/2000\t Step: 30/54\t Train Loss: 3.993435\t Valid Loss: 4.278433\n",
      "Epoch: 296/2000\t Step: 45/54\t Train Loss: 3.882433\t Valid Loss: 4.279511\n",
      "Epoch: 297/2000\t Step: 15/54\t Train Loss: 3.941597\t Valid Loss: 4.255966\n",
      "Epoch: 297/2000\t Step: 30/54\t Train Loss: 3.889481\t Valid Loss: 4.298618\n",
      "Epoch: 297/2000\t Step: 45/54\t Train Loss: 3.976325\t Valid Loss: 4.225640\n",
      "Epoch: 298/2000\t Step: 15/54\t Train Loss: 3.942012\t Valid Loss: 4.270319\n",
      "Epoch: 298/2000\t Step: 30/54\t Train Loss: 3.904566\t Valid Loss: 4.240431\n",
      "Epoch: 298/2000\t Step: 45/54\t Train Loss: 3.883042\t Valid Loss: 4.294300\n",
      "Epoch: 299/2000\t Step: 15/54\t Train Loss: 3.994703\t Valid Loss: 4.251929\n",
      "Epoch: 299/2000\t Step: 30/54\t Train Loss: 3.977245\t Valid Loss: 4.263786\n",
      "Epoch: 299/2000\t Step: 45/54\t Train Loss: 3.914318\t Valid Loss: 4.224084\n",
      "Epoch: 300/2000\t Step: 15/54\t Train Loss: 3.985521\t Valid Loss: 4.262189\n",
      "Epoch: 300/2000\t Step: 30/54\t Train Loss: 3.879369\t Valid Loss: 4.240072\n",
      "Epoch: 300/2000\t Step: 45/54\t Train Loss: 3.849278\t Valid Loss: 4.339694\n",
      "Epoch: 301/2000\t Step: 15/54\t Train Loss: 3.897230\t Valid Loss: 4.232948\n",
      "Epoch: 301/2000\t Step: 30/54\t Train Loss: 3.952321\t Valid Loss: 4.256172\n",
      "Epoch: 301/2000\t Step: 45/54\t Train Loss: 3.863041\t Valid Loss: 4.256943\n",
      "Epoch: 302/2000\t Step: 15/54\t Train Loss: 3.896130\t Valid Loss: 4.212697\n",
      "Epoch: 302/2000\t Step: 30/54\t Train Loss: 4.025862\t Valid Loss: 4.273073\n",
      "Epoch: 302/2000\t Step: 45/54\t Train Loss: 3.906690\t Valid Loss: 4.282634\n",
      "Epoch: 303/2000\t Step: 15/54\t Train Loss: 3.979692\t Valid Loss: 4.280221\n",
      "Epoch: 303/2000\t Step: 30/54\t Train Loss: 3.936980\t Valid Loss: 4.281505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 303/2000\t Step: 45/54\t Train Loss: 3.898087\t Valid Loss: 4.238618\n",
      "Epoch: 304/2000\t Step: 15/54\t Train Loss: 3.857826\t Valid Loss: 4.257949\n",
      "Epoch: 304/2000\t Step: 30/54\t Train Loss: 3.897054\t Valid Loss: 4.257928\n",
      "Epoch: 304/2000\t Step: 45/54\t Train Loss: 3.959019\t Valid Loss: 4.275072\n",
      "Epoch: 305/2000\t Step: 15/54\t Train Loss: 3.949027\t Valid Loss: 4.242307\n",
      "Epoch: 305/2000\t Step: 30/54\t Train Loss: 3.887156\t Valid Loss: 4.239241\n",
      "Epoch: 305/2000\t Step: 45/54\t Train Loss: 3.840874\t Valid Loss: 4.326046\n",
      "Epoch: 306/2000\t Step: 15/54\t Train Loss: 3.874193\t Valid Loss: 4.245490\n",
      "Epoch: 306/2000\t Step: 30/54\t Train Loss: 3.901100\t Valid Loss: 4.261906\n",
      "Epoch: 306/2000\t Step: 45/54\t Train Loss: 3.876107\t Valid Loss: 4.387637\n",
      "Epoch: 307/2000\t Step: 15/54\t Train Loss: 3.897762\t Valid Loss: 4.357285\n",
      "Epoch: 307/2000\t Step: 30/54\t Train Loss: 3.887421\t Valid Loss: 4.327363\n",
      "Epoch: 307/2000\t Step: 45/54\t Train Loss: 3.879576\t Valid Loss: 4.243120\n",
      "Epoch: 308/2000\t Step: 15/54\t Train Loss: 3.878204\t Valid Loss: 4.270097\n",
      "Epoch: 308/2000\t Step: 30/54\t Train Loss: 3.847294\t Valid Loss: 4.356342\n",
      "Epoch: 308/2000\t Step: 45/54\t Train Loss: 3.939304\t Valid Loss: 4.224050\n",
      "Epoch: 309/2000\t Step: 15/54\t Train Loss: 3.911839\t Valid Loss: 4.198936\n",
      "Epoch: 309/2000\t Step: 30/54\t Train Loss: 3.969342\t Valid Loss: 4.275651\n",
      "Epoch: 309/2000\t Step: 45/54\t Train Loss: 3.911136\t Valid Loss: 4.348402\n",
      "Epoch: 310/2000\t Step: 15/54\t Train Loss: 3.905865\t Valid Loss: 4.261818\n",
      "Epoch: 310/2000\t Step: 30/54\t Train Loss: 3.914834\t Valid Loss: 4.233179\n",
      "Epoch: 310/2000\t Step: 45/54\t Train Loss: 3.897942\t Valid Loss: 4.209443\n",
      "Epoch: 311/2000\t Step: 15/54\t Train Loss: 3.901573\t Valid Loss: 4.252373\n",
      "Epoch: 311/2000\t Step: 30/54\t Train Loss: 3.893214\t Valid Loss: 4.254094\n",
      "Epoch: 311/2000\t Step: 45/54\t Train Loss: 3.881914\t Valid Loss: 4.269262\n",
      "Epoch: 312/2000\t Step: 15/54\t Train Loss: 3.910925\t Valid Loss: 4.265278\n",
      "Epoch: 312/2000\t Step: 30/54\t Train Loss: 3.868886\t Valid Loss: 4.232639\n",
      "Epoch: 312/2000\t Step: 45/54\t Train Loss: 3.866848\t Valid Loss: 4.232582\n",
      "Epoch: 313/2000\t Step: 15/54\t Train Loss: 3.876360\t Valid Loss: 4.276520\n",
      "Epoch: 313/2000\t Step: 30/54\t Train Loss: 3.910954\t Valid Loss: 4.213662\n",
      "Epoch: 313/2000\t Step: 45/54\t Train Loss: 4.010819\t Valid Loss: 4.301156\n",
      "Epoch: 314/2000\t Step: 15/54\t Train Loss: 4.060951\t Valid Loss: 4.299855\n",
      "Epoch: 314/2000\t Step: 30/54\t Train Loss: 3.854372\t Valid Loss: 4.372850\n",
      "Epoch: 314/2000\t Step: 45/54\t Train Loss: 3.951602\t Valid Loss: 4.230122\n",
      "Epoch: 315/2000\t Step: 15/54\t Train Loss: 4.044156\t Valid Loss: 4.256171\n",
      "Epoch: 315/2000\t Step: 30/54\t Train Loss: 3.880328\t Valid Loss: 4.228587\n",
      "Epoch: 315/2000\t Step: 45/54\t Train Loss: 3.850056\t Valid Loss: 4.281756\n",
      "Epoch: 316/2000\t Step: 15/54\t Train Loss: 3.879874\t Valid Loss: 4.314668\n",
      "Epoch: 316/2000\t Step: 30/54\t Train Loss: 3.915100\t Valid Loss: 4.277618\n",
      "Epoch: 316/2000\t Step: 45/54\t Train Loss: 4.007783\t Valid Loss: 4.274142\n",
      "Epoch: 317/2000\t Step: 15/54\t Train Loss: 3.891050\t Valid Loss: 4.268233\n",
      "Epoch: 317/2000\t Step: 30/54\t Train Loss: 3.938567\t Valid Loss: 4.234149\n",
      "Epoch: 317/2000\t Step: 45/54\t Train Loss: 3.876070\t Valid Loss: 4.287141\n",
      "Epoch: 318/2000\t Step: 15/54\t Train Loss: 3.873777\t Valid Loss: 4.261974\n",
      "Epoch: 318/2000\t Step: 30/54\t Train Loss: 3.869893\t Valid Loss: 4.244488\n",
      "Epoch: 318/2000\t Step: 45/54\t Train Loss: 3.892765\t Valid Loss: 4.221943\n",
      "Epoch: 319/2000\t Step: 15/54\t Train Loss: 3.928970\t Valid Loss: 4.244541\n",
      "Epoch: 319/2000\t Step: 30/54\t Train Loss: 3.890682\t Valid Loss: 4.289861\n",
      "Epoch: 319/2000\t Step: 45/54\t Train Loss: 3.870394\t Valid Loss: 4.243866\n",
      "Epoch: 320/2000\t Step: 15/54\t Train Loss: 3.869338\t Valid Loss: 4.262798\n",
      "Epoch: 320/2000\t Step: 30/54\t Train Loss: 3.882747\t Valid Loss: 4.326406\n",
      "Epoch: 320/2000\t Step: 45/54\t Train Loss: 3.889856\t Valid Loss: 4.259304\n",
      "Epoch: 321/2000\t Step: 15/54\t Train Loss: 3.935795\t Valid Loss: 4.325708\n",
      "Epoch: 321/2000\t Step: 30/54\t Train Loss: 3.900629\t Valid Loss: 4.198192\n",
      "Epoch: 321/2000\t Step: 45/54\t Train Loss: 3.854002\t Valid Loss: 4.305631\n",
      "Epoch: 322/2000\t Step: 15/54\t Train Loss: 3.962224\t Valid Loss: 4.286333\n",
      "Epoch: 322/2000\t Step: 30/54\t Train Loss: 3.886493\t Valid Loss: 4.320937\n",
      "Epoch: 322/2000\t Step: 45/54\t Train Loss: 3.970071\t Valid Loss: 4.275489\n",
      "Epoch: 323/2000\t Step: 15/54\t Train Loss: 3.847049\t Valid Loss: 4.363411\n",
      "Epoch: 323/2000\t Step: 30/54\t Train Loss: 3.858002\t Valid Loss: 4.328657\n",
      "Epoch: 323/2000\t Step: 45/54\t Train Loss: 3.966703\t Valid Loss: 4.276686\n",
      "Epoch: 324/2000\t Step: 15/54\t Train Loss: 3.921750\t Valid Loss: 4.273675\n",
      "Epoch: 324/2000\t Step: 30/54\t Train Loss: 3.879770\t Valid Loss: 4.271904\n",
      "Epoch: 324/2000\t Step: 45/54\t Train Loss: 3.870225\t Valid Loss: 4.262041\n",
      "Epoch: 325/2000\t Step: 15/54\t Train Loss: 3.918521\t Valid Loss: 4.291922\n",
      "Epoch: 325/2000\t Step: 30/54\t Train Loss: 3.870193\t Valid Loss: 4.321499\n",
      "Epoch: 325/2000\t Step: 45/54\t Train Loss: 3.882215\t Valid Loss: 4.215646\n",
      "Epoch: 326/2000\t Step: 15/54\t Train Loss: 3.890786\t Valid Loss: 4.267944\n",
      "Epoch: 326/2000\t Step: 30/54\t Train Loss: 3.889063\t Valid Loss: 4.321639\n",
      "Epoch: 326/2000\t Step: 45/54\t Train Loss: 3.901604\t Valid Loss: 4.274648\n",
      "Epoch: 327/2000\t Step: 15/54\t Train Loss: 3.895813\t Valid Loss: 4.229322\n",
      "Epoch: 327/2000\t Step: 30/54\t Train Loss: 4.033011\t Valid Loss: 4.252402\n",
      "Epoch: 327/2000\t Step: 45/54\t Train Loss: 3.889723\t Valid Loss: 4.271514\n",
      "Epoch: 328/2000\t Step: 15/54\t Train Loss: 3.973324\t Valid Loss: 4.273072\n",
      "Epoch: 328/2000\t Step: 30/54\t Train Loss: 3.868328\t Valid Loss: 4.246240\n",
      "Epoch: 328/2000\t Step: 45/54\t Train Loss: 3.836323\t Valid Loss: 4.225155\n",
      "Epoch: 329/2000\t Step: 15/54\t Train Loss: 3.874985\t Valid Loss: 4.366074\n",
      "Epoch: 329/2000\t Step: 30/54\t Train Loss: 3.939749\t Valid Loss: 4.286049\n",
      "Epoch: 329/2000\t Step: 45/54\t Train Loss: 3.899089\t Valid Loss: 4.252898\n",
      "Epoch: 330/2000\t Step: 15/54\t Train Loss: 3.867159\t Valid Loss: 4.254191\n",
      "Epoch: 330/2000\t Step: 30/54\t Train Loss: 3.953265\t Valid Loss: 4.335247\n",
      "Epoch: 330/2000\t Step: 45/54\t Train Loss: 3.867725\t Valid Loss: 4.319332\n",
      "Epoch: 331/2000\t Step: 15/54\t Train Loss: 4.122354\t Valid Loss: 4.289301\n",
      "Epoch: 331/2000\t Step: 30/54\t Train Loss: 4.005090\t Valid Loss: 4.294157\n",
      "Epoch: 331/2000\t Step: 45/54\t Train Loss: 3.851026\t Valid Loss: 4.333772\n",
      "Epoch: 332/2000\t Step: 15/54\t Train Loss: 3.870366\t Valid Loss: 4.258804\n",
      "Epoch: 332/2000\t Step: 30/54\t Train Loss: 3.882838\t Valid Loss: 4.280607\n",
      "Epoch: 332/2000\t Step: 45/54\t Train Loss: 3.888829\t Valid Loss: 4.349860\n",
      "Epoch: 333/2000\t Step: 15/54\t Train Loss: 3.866329\t Valid Loss: 4.225428\n",
      "Epoch: 333/2000\t Step: 30/54\t Train Loss: 3.876566\t Valid Loss: 4.234994\n",
      "Epoch: 333/2000\t Step: 45/54\t Train Loss: 3.916950\t Valid Loss: 4.272370\n",
      "Epoch: 334/2000\t Step: 15/54\t Train Loss: 3.871137\t Valid Loss: 4.297530\n",
      "Epoch: 334/2000\t Step: 30/54\t Train Loss: 3.906330\t Valid Loss: 4.241653\n",
      "Epoch: 334/2000\t Step: 45/54\t Train Loss: 3.855487\t Valid Loss: 4.482828\n",
      "Epoch: 335/2000\t Step: 15/54\t Train Loss: 3.873824\t Valid Loss: 4.293694\n",
      "Epoch: 335/2000\t Step: 30/54\t Train Loss: 3.923990\t Valid Loss: 4.262746\n",
      "Epoch: 335/2000\t Step: 45/54\t Train Loss: 3.909712\t Valid Loss: 4.289779\n",
      "Epoch: 336/2000\t Step: 15/54\t Train Loss: 3.898661\t Valid Loss: 4.219165\n",
      "Epoch: 336/2000\t Step: 30/54\t Train Loss: 3.876824\t Valid Loss: 4.259937\n",
      "Epoch: 336/2000\t Step: 45/54\t Train Loss: 3.855044\t Valid Loss: 4.388816\n",
      "Epoch: 337/2000\t Step: 15/54\t Train Loss: 3.846652\t Valid Loss: 4.291812\n",
      "Epoch: 337/2000\t Step: 30/54\t Train Loss: 3.906962\t Valid Loss: 4.295160\n",
      "Epoch: 337/2000\t Step: 45/54\t Train Loss: 3.896396\t Valid Loss: 4.316257\n",
      "Epoch: 338/2000\t Step: 15/54\t Train Loss: 3.893252\t Valid Loss: 4.219609\n",
      "Epoch: 338/2000\t Step: 30/54\t Train Loss: 3.864059\t Valid Loss: 4.275346\n",
      "Epoch: 338/2000\t Step: 45/54\t Train Loss: 3.987514\t Valid Loss: 4.278515\n",
      "Epoch: 339/2000\t Step: 15/54\t Train Loss: 3.869220\t Valid Loss: 4.290419\n",
      "Epoch: 339/2000\t Step: 30/54\t Train Loss: 3.895051\t Valid Loss: 4.319534\n",
      "Epoch: 339/2000\t Step: 45/54\t Train Loss: 3.892631\t Valid Loss: 4.265559\n",
      "Epoch: 340/2000\t Step: 15/54\t Train Loss: 3.913704\t Valid Loss: 4.325750\n",
      "Epoch: 340/2000\t Step: 30/54\t Train Loss: 3.909890\t Valid Loss: 4.276234\n",
      "Epoch: 340/2000\t Step: 45/54\t Train Loss: 3.915299\t Valid Loss: 4.311132\n",
      "Epoch: 341/2000\t Step: 15/54\t Train Loss: 3.898315\t Valid Loss: 4.318409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 341/2000\t Step: 30/54\t Train Loss: 3.949072\t Valid Loss: 4.313714\n",
      "Epoch: 341/2000\t Step: 45/54\t Train Loss: 3.860033\t Valid Loss: 4.391568\n",
      "Epoch: 342/2000\t Step: 15/54\t Train Loss: 3.909305\t Valid Loss: 4.254452\n",
      "Epoch: 342/2000\t Step: 30/54\t Train Loss: 3.904279\t Valid Loss: 4.246029\n",
      "Epoch: 342/2000\t Step: 45/54\t Train Loss: 3.986808\t Valid Loss: 4.251925\n",
      "Epoch: 343/2000\t Step: 15/54\t Train Loss: 3.843177\t Valid Loss: 4.281261\n",
      "Epoch: 343/2000\t Step: 30/54\t Train Loss: 3.877796\t Valid Loss: 4.317989\n",
      "Epoch: 343/2000\t Step: 45/54\t Train Loss: 3.885403\t Valid Loss: 4.409170\n",
      "Epoch: 344/2000\t Step: 15/54\t Train Loss: 3.877872\t Valid Loss: 4.280071\n",
      "Epoch: 344/2000\t Step: 30/54\t Train Loss: 4.026634\t Valid Loss: 4.345569\n",
      "Epoch: 344/2000\t Step: 45/54\t Train Loss: 3.859414\t Valid Loss: 4.336092\n",
      "Epoch: 345/2000\t Step: 15/54\t Train Loss: 3.846111\t Valid Loss: 4.339025\n",
      "Epoch: 345/2000\t Step: 30/54\t Train Loss: 3.853000\t Valid Loss: 4.273124\n",
      "Epoch: 345/2000\t Step: 45/54\t Train Loss: 3.887442\t Valid Loss: 4.288386\n",
      "Epoch: 346/2000\t Step: 15/54\t Train Loss: 3.880411\t Valid Loss: 4.302286\n",
      "Epoch: 346/2000\t Step: 30/54\t Train Loss: 3.855162\t Valid Loss: 4.252106\n",
      "Epoch: 346/2000\t Step: 45/54\t Train Loss: 3.875199\t Valid Loss: 4.306373\n",
      "Epoch: 347/2000\t Step: 15/54\t Train Loss: 3.826691\t Valid Loss: 4.277517\n",
      "Epoch: 347/2000\t Step: 30/54\t Train Loss: 3.894077\t Valid Loss: 4.345476\n",
      "Epoch: 347/2000\t Step: 45/54\t Train Loss: 3.935283\t Valid Loss: 4.270400\n",
      "Epoch: 348/2000\t Step: 15/54\t Train Loss: 4.000485\t Valid Loss: 4.246874\n",
      "Epoch: 348/2000\t Step: 30/54\t Train Loss: 3.869035\t Valid Loss: 4.288207\n",
      "Epoch: 348/2000\t Step: 45/54\t Train Loss: 3.936950\t Valid Loss: 4.266607\n",
      "Epoch: 349/2000\t Step: 15/54\t Train Loss: 3.864930\t Valid Loss: 4.293307\n",
      "Epoch: 349/2000\t Step: 30/54\t Train Loss: 3.870218\t Valid Loss: 4.261663\n",
      "Epoch: 349/2000\t Step: 45/54\t Train Loss: 3.920390\t Valid Loss: 4.291265\n",
      "Epoch: 350/2000\t Step: 15/54\t Train Loss: 3.882497\t Valid Loss: 4.411859\n",
      "Epoch: 350/2000\t Step: 30/54\t Train Loss: 3.891470\t Valid Loss: 4.320739\n",
      "Epoch: 350/2000\t Step: 45/54\t Train Loss: 3.923805\t Valid Loss: 4.307647\n",
      "Epoch: 351/2000\t Step: 15/54\t Train Loss: 3.927825\t Valid Loss: 4.219759\n",
      "Epoch: 351/2000\t Step: 30/54\t Train Loss: 3.886673\t Valid Loss: 4.306093\n",
      "Epoch: 351/2000\t Step: 45/54\t Train Loss: 3.895556\t Valid Loss: 4.329300\n",
      "Epoch: 352/2000\t Step: 15/54\t Train Loss: 3.876996\t Valid Loss: 4.269999\n",
      "Epoch: 352/2000\t Step: 30/54\t Train Loss: 3.983789\t Valid Loss: 4.216248\n",
      "Epoch: 352/2000\t Step: 45/54\t Train Loss: 3.865287\t Valid Loss: 4.256194\n",
      "Epoch: 353/2000\t Step: 15/54\t Train Loss: 3.880235\t Valid Loss: 4.314832\n",
      "Epoch: 353/2000\t Step: 30/54\t Train Loss: 3.886558\t Valid Loss: 4.299183\n",
      "Epoch: 353/2000\t Step: 45/54\t Train Loss: 3.882812\t Valid Loss: 4.344974\n",
      "Epoch: 354/2000\t Step: 15/54\t Train Loss: 3.848184\t Valid Loss: 4.257310\n",
      "Epoch: 354/2000\t Step: 30/54\t Train Loss: 3.926864\t Valid Loss: 4.282149\n",
      "Epoch: 354/2000\t Step: 45/54\t Train Loss: 3.848003\t Valid Loss: 4.325264\n",
      "Epoch: 355/2000\t Step: 15/54\t Train Loss: 3.872024\t Valid Loss: 4.236884\n",
      "Epoch: 355/2000\t Step: 30/54\t Train Loss: 3.898320\t Valid Loss: 4.290284\n",
      "Epoch: 355/2000\t Step: 45/54\t Train Loss: 3.876572\t Valid Loss: 4.335821\n",
      "Epoch: 356/2000\t Step: 15/54\t Train Loss: 4.024512\t Valid Loss: 4.253758\n",
      "Epoch: 356/2000\t Step: 30/54\t Train Loss: 3.925890\t Valid Loss: 4.260411\n",
      "Epoch: 356/2000\t Step: 45/54\t Train Loss: 3.927976\t Valid Loss: 4.269867\n",
      "Epoch: 357/2000\t Step: 15/54\t Train Loss: 3.887707\t Valid Loss: 4.241879\n",
      "Epoch: 357/2000\t Step: 30/54\t Train Loss: 3.844055\t Valid Loss: 4.264152\n",
      "Epoch: 357/2000\t Step: 45/54\t Train Loss: 3.875880\t Valid Loss: 4.241767\n",
      "Epoch: 358/2000\t Step: 15/54\t Train Loss: 3.902448\t Valid Loss: 4.223933\n",
      "Epoch: 358/2000\t Step: 30/54\t Train Loss: 3.904634\t Valid Loss: 4.238714\n",
      "Epoch: 358/2000\t Step: 45/54\t Train Loss: 3.973398\t Valid Loss: 4.290801\n",
      "Epoch: 359/2000\t Step: 15/54\t Train Loss: 3.898186\t Valid Loss: 4.255832\n",
      "Epoch: 359/2000\t Step: 30/54\t Train Loss: 3.879157\t Valid Loss: 4.329460\n",
      "Epoch: 359/2000\t Step: 45/54\t Train Loss: 3.895830\t Valid Loss: 4.355174\n",
      "Epoch: 360/2000\t Step: 15/54\t Train Loss: 3.833507\t Valid Loss: 4.278061\n",
      "Epoch: 360/2000\t Step: 30/54\t Train Loss: 3.839787\t Valid Loss: 4.388408\n",
      "Epoch: 360/2000\t Step: 45/54\t Train Loss: 3.946410\t Valid Loss: 4.305160\n",
      "Epoch: 361/2000\t Step: 15/54\t Train Loss: 3.867289\t Valid Loss: 4.287582\n",
      "Epoch: 361/2000\t Step: 30/54\t Train Loss: 3.857262\t Valid Loss: 4.283796\n",
      "Epoch: 361/2000\t Step: 45/54\t Train Loss: 3.887873\t Valid Loss: 4.260348\n",
      "Epoch: 362/2000\t Step: 15/54\t Train Loss: 3.873922\t Valid Loss: 4.265009\n",
      "Epoch: 362/2000\t Step: 30/54\t Train Loss: 3.862132\t Valid Loss: 4.312105\n",
      "Epoch: 362/2000\t Step: 45/54\t Train Loss: 3.914756\t Valid Loss: 4.341729\n",
      "Epoch: 363/2000\t Step: 15/54\t Train Loss: 3.867237\t Valid Loss: 4.327216\n",
      "Epoch: 363/2000\t Step: 30/54\t Train Loss: 3.903876\t Valid Loss: 4.197424\n",
      "Epoch: 363/2000\t Step: 45/54\t Train Loss: 3.895215\t Valid Loss: 4.256986\n",
      "Epoch: 364/2000\t Step: 15/54\t Train Loss: 3.842494\t Valid Loss: 4.335895\n",
      "Epoch: 364/2000\t Step: 30/54\t Train Loss: 3.860548\t Valid Loss: 4.232741\n",
      "Epoch: 364/2000\t Step: 45/54\t Train Loss: 3.919343\t Valid Loss: 4.272111\n",
      "Epoch: 365/2000\t Step: 15/54\t Train Loss: 3.921562\t Valid Loss: 4.296347\n",
      "Epoch: 365/2000\t Step: 30/54\t Train Loss: 3.888501\t Valid Loss: 4.292356\n",
      "Epoch: 365/2000\t Step: 45/54\t Train Loss: 3.874761\t Valid Loss: 4.295450\n",
      "Epoch: 366/2000\t Step: 15/54\t Train Loss: 3.880891\t Valid Loss: 4.228501\n",
      "Epoch: 366/2000\t Step: 30/54\t Train Loss: 3.925560\t Valid Loss: 4.255239\n",
      "Epoch: 366/2000\t Step: 45/54\t Train Loss: 3.883604\t Valid Loss: 4.393446\n",
      "Epoch: 367/2000\t Step: 15/54\t Train Loss: 3.955182\t Valid Loss: 4.323221\n",
      "Epoch: 367/2000\t Step: 30/54\t Train Loss: 3.884378\t Valid Loss: 4.341619\n",
      "Epoch: 367/2000\t Step: 45/54\t Train Loss: 3.864458\t Valid Loss: 4.272424\n",
      "Epoch: 368/2000\t Step: 15/54\t Train Loss: 3.879443\t Valid Loss: 4.284122\n",
      "Epoch: 368/2000\t Step: 30/54\t Train Loss: 3.827576\t Valid Loss: 4.307361\n",
      "Epoch: 368/2000\t Step: 45/54\t Train Loss: 3.843883\t Valid Loss: 4.338465\n",
      "Epoch: 369/2000\t Step: 15/54\t Train Loss: 3.865252\t Valid Loss: 4.346081\n",
      "Epoch: 369/2000\t Step: 30/54\t Train Loss: 3.917354\t Valid Loss: 4.296173\n",
      "Epoch: 369/2000\t Step: 45/54\t Train Loss: 3.885836\t Valid Loss: 4.234732\n",
      "Epoch: 370/2000\t Step: 15/54\t Train Loss: 3.919972\t Valid Loss: 4.240787\n",
      "Epoch: 370/2000\t Step: 30/54\t Train Loss: 3.871946\t Valid Loss: 4.256655\n",
      "Epoch: 370/2000\t Step: 45/54\t Train Loss: 3.885149\t Valid Loss: 4.268474\n",
      "Epoch: 371/2000\t Step: 15/54\t Train Loss: 3.888584\t Valid Loss: 4.241456\n",
      "Epoch: 371/2000\t Step: 30/54\t Train Loss: 3.874821\t Valid Loss: 4.285105\n",
      "Epoch: 371/2000\t Step: 45/54\t Train Loss: 3.890455\t Valid Loss: 4.310946\n",
      "Epoch: 372/2000\t Step: 15/54\t Train Loss: 3.938566\t Valid Loss: 4.318011\n",
      "Epoch: 372/2000\t Step: 30/54\t Train Loss: 3.974978\t Valid Loss: 4.364339\n",
      "Epoch: 372/2000\t Step: 45/54\t Train Loss: 3.870150\t Valid Loss: 4.275932\n",
      "Epoch: 373/2000\t Step: 15/54\t Train Loss: 3.936684\t Valid Loss: 4.217187\n",
      "Epoch: 373/2000\t Step: 30/54\t Train Loss: 3.882850\t Valid Loss: 4.296160\n",
      "Epoch: 373/2000\t Step: 45/54\t Train Loss: 3.973580\t Valid Loss: 4.234158\n",
      "Epoch: 374/2000\t Step: 15/54\t Train Loss: 3.856308\t Valid Loss: 4.349277\n",
      "Epoch: 374/2000\t Step: 30/54\t Train Loss: 3.851034\t Valid Loss: 4.364064\n",
      "Epoch: 374/2000\t Step: 45/54\t Train Loss: 3.931332\t Valid Loss: 4.233779\n",
      "Epoch: 375/2000\t Step: 15/54\t Train Loss: 3.992390\t Valid Loss: 4.301818\n",
      "Epoch: 375/2000\t Step: 30/54\t Train Loss: 3.881067\t Valid Loss: 4.287429\n",
      "Epoch: 375/2000\t Step: 45/54\t Train Loss: 3.860682\t Valid Loss: 4.304339\n",
      "Epoch: 376/2000\t Step: 15/54\t Train Loss: 3.883004\t Valid Loss: 4.296601\n",
      "Epoch: 376/2000\t Step: 30/54\t Train Loss: 3.858510\t Valid Loss: 4.279539\n",
      "Epoch: 376/2000\t Step: 45/54\t Train Loss: 3.960811\t Valid Loss: 4.252805\n",
      "Epoch: 377/2000\t Step: 15/54\t Train Loss: 3.993470\t Valid Loss: 4.261583\n",
      "Epoch: 377/2000\t Step: 30/54\t Train Loss: 3.851229\t Valid Loss: 4.289726\n",
      "Epoch: 377/2000\t Step: 45/54\t Train Loss: 3.901018\t Valid Loss: 4.269854\n",
      "Epoch: 378/2000\t Step: 15/54\t Train Loss: 3.859884\t Valid Loss: 4.236922\n",
      "Epoch: 378/2000\t Step: 30/54\t Train Loss: 3.880085\t Valid Loss: 4.312893\n",
      "Epoch: 378/2000\t Step: 45/54\t Train Loss: 3.877429\t Valid Loss: 4.315529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 379/2000\t Step: 15/54\t Train Loss: 3.842088\t Valid Loss: 4.277110\n",
      "Epoch: 379/2000\t Step: 30/54\t Train Loss: 3.873823\t Valid Loss: 4.375036\n",
      "Epoch: 379/2000\t Step: 45/54\t Train Loss: 3.869577\t Valid Loss: 4.310490\n",
      "Epoch: 380/2000\t Step: 15/54\t Train Loss: 3.831368\t Valid Loss: 4.350171\n",
      "Epoch: 380/2000\t Step: 30/54\t Train Loss: 3.845760\t Valid Loss: 4.263628\n",
      "Epoch: 380/2000\t Step: 45/54\t Train Loss: 3.854741\t Valid Loss: 4.295756\n",
      "Epoch: 381/2000\t Step: 15/54\t Train Loss: 3.853246\t Valid Loss: 4.303177\n",
      "Epoch: 381/2000\t Step: 30/54\t Train Loss: 3.907009\t Valid Loss: 4.278653\n",
      "Epoch: 381/2000\t Step: 45/54\t Train Loss: 3.953483\t Valid Loss: 4.299551\n",
      "Epoch: 382/2000\t Step: 15/54\t Train Loss: 3.869209\t Valid Loss: 4.264938\n",
      "Epoch: 382/2000\t Step: 30/54\t Train Loss: 3.837934\t Valid Loss: 4.278617\n",
      "Epoch: 382/2000\t Step: 45/54\t Train Loss: 3.913324\t Valid Loss: 4.331848\n",
      "Epoch: 383/2000\t Step: 15/54\t Train Loss: 3.891692\t Valid Loss: 4.295927\n",
      "Epoch: 383/2000\t Step: 30/54\t Train Loss: 3.858249\t Valid Loss: 4.338418\n",
      "Epoch: 383/2000\t Step: 45/54\t Train Loss: 3.873620\t Valid Loss: 4.335280\n",
      "Epoch: 384/2000\t Step: 15/54\t Train Loss: 3.833679\t Valid Loss: 4.394860\n",
      "Epoch: 384/2000\t Step: 30/54\t Train Loss: 3.900189\t Valid Loss: 4.299464\n",
      "Epoch: 384/2000\t Step: 45/54\t Train Loss: 3.832036\t Valid Loss: 4.340833\n",
      "Epoch: 385/2000\t Step: 15/54\t Train Loss: 3.835669\t Valid Loss: 4.348788\n",
      "Epoch: 385/2000\t Step: 30/54\t Train Loss: 3.894102\t Valid Loss: 4.312165\n",
      "Epoch: 385/2000\t Step: 45/54\t Train Loss: 3.999230\t Valid Loss: 4.231835\n",
      "Epoch: 386/2000\t Step: 15/54\t Train Loss: 3.947129\t Valid Loss: 4.289641\n",
      "Epoch: 386/2000\t Step: 30/54\t Train Loss: 3.877013\t Valid Loss: 4.255045\n",
      "Epoch: 386/2000\t Step: 45/54\t Train Loss: 3.938472\t Valid Loss: 4.287017\n",
      "Epoch: 387/2000\t Step: 15/54\t Train Loss: 3.854976\t Valid Loss: 4.243240\n",
      "Epoch: 387/2000\t Step: 30/54\t Train Loss: 3.865741\t Valid Loss: 4.274786\n",
      "Epoch: 387/2000\t Step: 45/54\t Train Loss: 3.843716\t Valid Loss: 4.303155\n",
      "Epoch: 388/2000\t Step: 15/54\t Train Loss: 3.835732\t Valid Loss: 4.277372\n",
      "Epoch: 388/2000\t Step: 30/54\t Train Loss: 3.870330\t Valid Loss: 4.292049\n",
      "Epoch: 388/2000\t Step: 45/54\t Train Loss: 3.988733\t Valid Loss: 4.264080\n",
      "Epoch: 389/2000\t Step: 15/54\t Train Loss: 3.878145\t Valid Loss: 4.309830\n",
      "Epoch: 389/2000\t Step: 30/54\t Train Loss: 3.931616\t Valid Loss: 4.355712\n",
      "Epoch: 389/2000\t Step: 45/54\t Train Loss: 3.871787\t Valid Loss: 4.270315\n",
      "Epoch: 390/2000\t Step: 15/54\t Train Loss: 3.929654\t Valid Loss: 4.263598\n",
      "Epoch: 390/2000\t Step: 30/54\t Train Loss: 3.892273\t Valid Loss: 4.193049\n",
      "Epoch: 390/2000\t Step: 45/54\t Train Loss: 3.874493\t Valid Loss: 4.303390\n",
      "Epoch: 391/2000\t Step: 15/54\t Train Loss: 3.881680\t Valid Loss: 4.257489\n",
      "Epoch: 391/2000\t Step: 30/54\t Train Loss: 3.864480\t Valid Loss: 4.354216\n",
      "Epoch: 391/2000\t Step: 45/54\t Train Loss: 3.927585\t Valid Loss: 4.290595\n",
      "Epoch: 392/2000\t Step: 15/54\t Train Loss: 3.896009\t Valid Loss: 4.277115\n",
      "Epoch: 392/2000\t Step: 30/54\t Train Loss: 3.867994\t Valid Loss: 4.326830\n",
      "Epoch: 392/2000\t Step: 45/54\t Train Loss: 3.806639\t Valid Loss: 4.306999\n",
      "Epoch: 393/2000\t Step: 15/54\t Train Loss: 3.903322\t Valid Loss: 4.229549\n",
      "Epoch: 393/2000\t Step: 30/54\t Train Loss: 3.899588\t Valid Loss: 4.263039\n",
      "Epoch: 393/2000\t Step: 45/54\t Train Loss: 3.812974\t Valid Loss: 4.265406\n",
      "Epoch: 394/2000\t Step: 15/54\t Train Loss: 3.927386\t Valid Loss: 4.279442\n",
      "Epoch: 394/2000\t Step: 30/54\t Train Loss: 3.865489\t Valid Loss: 4.319208\n",
      "Epoch: 394/2000\t Step: 45/54\t Train Loss: 3.815046\t Valid Loss: 4.265753\n",
      "Epoch: 395/2000\t Step: 15/54\t Train Loss: 3.952168\t Valid Loss: 4.280875\n",
      "Epoch: 395/2000\t Step: 30/54\t Train Loss: 3.893714\t Valid Loss: 4.241310\n",
      "Epoch: 395/2000\t Step: 45/54\t Train Loss: 3.848482\t Valid Loss: 4.262606\n",
      "Epoch: 396/2000\t Step: 15/54\t Train Loss: 3.906194\t Valid Loss: 4.269377\n",
      "Epoch: 396/2000\t Step: 30/54\t Train Loss: 3.895075\t Valid Loss: 4.205248\n",
      "Epoch: 396/2000\t Step: 45/54\t Train Loss: 3.864264\t Valid Loss: 4.328400\n",
      "Epoch: 397/2000\t Step: 15/54\t Train Loss: 3.858060\t Valid Loss: 4.337689\n",
      "Epoch: 397/2000\t Step: 30/54\t Train Loss: 3.857001\t Valid Loss: 4.304089\n",
      "Epoch: 397/2000\t Step: 45/54\t Train Loss: 3.876437\t Valid Loss: 4.449649\n",
      "Epoch: 398/2000\t Step: 15/54\t Train Loss: 3.864953\t Valid Loss: 4.295903\n",
      "Epoch: 398/2000\t Step: 30/54\t Train Loss: 3.838083\t Valid Loss: 4.311197\n",
      "Epoch: 398/2000\t Step: 45/54\t Train Loss: 3.870459\t Valid Loss: 4.322190\n",
      "Epoch: 399/2000\t Step: 15/54\t Train Loss: 3.840612\t Valid Loss: 4.265792\n",
      "Epoch: 399/2000\t Step: 30/54\t Train Loss: 3.869616\t Valid Loss: 4.247301\n",
      "Epoch: 399/2000\t Step: 45/54\t Train Loss: 3.833527\t Valid Loss: 4.201620\n",
      "Epoch: 400/2000\t Step: 15/54\t Train Loss: 3.862515\t Valid Loss: 4.301634\n",
      "Epoch: 400/2000\t Step: 30/54\t Train Loss: 3.840195\t Valid Loss: 4.257375\n",
      "Epoch: 400/2000\t Step: 45/54\t Train Loss: 3.839104\t Valid Loss: 4.265601\n",
      "Epoch: 401/2000\t Step: 15/54\t Train Loss: 3.840077\t Valid Loss: 4.339781\n",
      "Epoch: 401/2000\t Step: 30/54\t Train Loss: 3.860442\t Valid Loss: 4.360555\n",
      "Epoch: 401/2000\t Step: 45/54\t Train Loss: 3.809380\t Valid Loss: 4.281403\n",
      "Epoch: 402/2000\t Step: 15/54\t Train Loss: 3.879796\t Valid Loss: 4.244709\n",
      "Epoch: 402/2000\t Step: 30/54\t Train Loss: 3.863573\t Valid Loss: 4.321545\n",
      "Epoch: 402/2000\t Step: 45/54\t Train Loss: 3.854800\t Valid Loss: 4.253891\n",
      "Epoch: 403/2000\t Step: 15/54\t Train Loss: 3.931084\t Valid Loss: 4.224415\n",
      "Epoch: 403/2000\t Step: 30/54\t Train Loss: 3.955997\t Valid Loss: 4.318920\n",
      "Epoch: 403/2000\t Step: 45/54\t Train Loss: 3.958308\t Valid Loss: 4.293874\n",
      "Epoch: 404/2000\t Step: 15/54\t Train Loss: 3.881443\t Valid Loss: 4.218788\n",
      "Epoch: 404/2000\t Step: 30/54\t Train Loss: 3.865171\t Valid Loss: 4.251741\n",
      "Epoch: 404/2000\t Step: 45/54\t Train Loss: 3.853213\t Valid Loss: 4.406164\n",
      "Epoch: 405/2000\t Step: 15/54\t Train Loss: 3.846364\t Valid Loss: 4.293948\n",
      "Epoch: 405/2000\t Step: 30/54\t Train Loss: 3.873662\t Valid Loss: 4.334293\n",
      "Epoch: 405/2000\t Step: 45/54\t Train Loss: 3.853123\t Valid Loss: 4.370991\n",
      "Epoch: 406/2000\t Step: 15/54\t Train Loss: 3.866390\t Valid Loss: 4.338783\n",
      "Epoch: 406/2000\t Step: 30/54\t Train Loss: 3.890061\t Valid Loss: 4.300210\n",
      "Epoch: 406/2000\t Step: 45/54\t Train Loss: 3.854462\t Valid Loss: 4.372173\n",
      "Epoch: 407/2000\t Step: 15/54\t Train Loss: 3.859905\t Valid Loss: 4.291941\n",
      "Epoch: 407/2000\t Step: 30/54\t Train Loss: 3.957136\t Valid Loss: 4.412107\n",
      "Epoch: 407/2000\t Step: 45/54\t Train Loss: 3.983916\t Valid Loss: 4.254966\n",
      "Epoch: 408/2000\t Step: 15/54\t Train Loss: 3.851344\t Valid Loss: 4.341397\n",
      "Epoch: 408/2000\t Step: 30/54\t Train Loss: 3.860631\t Valid Loss: 4.343890\n",
      "Epoch: 408/2000\t Step: 45/54\t Train Loss: 3.832479\t Valid Loss: 4.326648\n",
      "Epoch: 409/2000\t Step: 15/54\t Train Loss: 3.853865\t Valid Loss: 4.310244\n",
      "Epoch: 409/2000\t Step: 30/54\t Train Loss: 3.856138\t Valid Loss: 4.331163\n",
      "Epoch: 409/2000\t Step: 45/54\t Train Loss: 3.903006\t Valid Loss: 4.281430\n",
      "Epoch: 410/2000\t Step: 15/54\t Train Loss: 3.860186\t Valid Loss: 4.325167\n",
      "Epoch: 410/2000\t Step: 30/54\t Train Loss: 3.814975\t Valid Loss: 4.331564\n",
      "Epoch: 410/2000\t Step: 45/54\t Train Loss: 3.865452\t Valid Loss: 4.266884\n",
      "Epoch: 411/2000\t Step: 15/54\t Train Loss: 3.891997\t Valid Loss: 4.368976\n",
      "Epoch: 411/2000\t Step: 30/54\t Train Loss: 3.921939\t Valid Loss: 4.357408\n",
      "Epoch: 411/2000\t Step: 45/54\t Train Loss: 3.908210\t Valid Loss: 4.251771\n",
      "Epoch: 412/2000\t Step: 15/54\t Train Loss: 3.902364\t Valid Loss: 4.264783\n",
      "Epoch: 412/2000\t Step: 30/54\t Train Loss: 3.851713\t Valid Loss: 4.286744\n",
      "Epoch: 412/2000\t Step: 45/54\t Train Loss: 3.869784\t Valid Loss: 4.343376\n",
      "Epoch: 413/2000\t Step: 15/54\t Train Loss: 3.834781\t Valid Loss: 4.299690\n",
      "Epoch: 413/2000\t Step: 30/54\t Train Loss: 3.820569\t Valid Loss: 4.388088\n",
      "Epoch: 413/2000\t Step: 45/54\t Train Loss: 3.975929\t Valid Loss: 4.394246\n",
      "Epoch: 414/2000\t Step: 15/54\t Train Loss: 3.865618\t Valid Loss: 4.189971\n",
      "Epoch: 414/2000\t Step: 30/54\t Train Loss: 3.890016\t Valid Loss: 4.355105\n",
      "Epoch: 414/2000\t Step: 45/54\t Train Loss: 3.939174\t Valid Loss: 4.355602\n",
      "Epoch: 415/2000\t Step: 15/54\t Train Loss: 3.874796\t Valid Loss: 4.268490\n",
      "Epoch: 415/2000\t Step: 30/54\t Train Loss: 3.978680\t Valid Loss: 4.234478\n",
      "Epoch: 415/2000\t Step: 45/54\t Train Loss: 3.897529\t Valid Loss: 4.307312\n",
      "Epoch: 416/2000\t Step: 15/54\t Train Loss: 3.896424\t Valid Loss: 4.280244\n",
      "Epoch: 416/2000\t Step: 30/54\t Train Loss: 3.817451\t Valid Loss: 4.369567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 416/2000\t Step: 45/54\t Train Loss: 3.971815\t Valid Loss: 4.333481\n",
      "Epoch: 417/2000\t Step: 15/54\t Train Loss: 3.860526\t Valid Loss: 4.313857\n",
      "Epoch: 417/2000\t Step: 30/54\t Train Loss: 3.823825\t Valid Loss: 4.338453\n",
      "Epoch: 417/2000\t Step: 45/54\t Train Loss: 3.874018\t Valid Loss: 4.288763\n",
      "Epoch: 418/2000\t Step: 15/54\t Train Loss: 3.869485\t Valid Loss: 4.289168\n",
      "Epoch: 418/2000\t Step: 30/54\t Train Loss: 3.833546\t Valid Loss: 4.241163\n",
      "Epoch: 418/2000\t Step: 45/54\t Train Loss: 3.927972\t Valid Loss: 4.357012\n",
      "Epoch: 419/2000\t Step: 15/54\t Train Loss: 3.832850\t Valid Loss: 4.308434\n",
      "Epoch: 419/2000\t Step: 30/54\t Train Loss: 3.859619\t Valid Loss: 4.302675\n",
      "Epoch: 419/2000\t Step: 45/54\t Train Loss: 3.880320\t Valid Loss: 4.256396\n",
      "Epoch: 420/2000\t Step: 15/54\t Train Loss: 3.846337\t Valid Loss: 4.303260\n",
      "Epoch: 420/2000\t Step: 30/54\t Train Loss: 3.825328\t Valid Loss: 4.371767\n",
      "Epoch: 420/2000\t Step: 45/54\t Train Loss: 3.839871\t Valid Loss: 4.281808\n",
      "Epoch: 421/2000\t Step: 15/54\t Train Loss: 3.852715\t Valid Loss: 4.282301\n",
      "Epoch: 421/2000\t Step: 30/54\t Train Loss: 3.919580\t Valid Loss: 4.345905\n",
      "Epoch: 421/2000\t Step: 45/54\t Train Loss: 3.856682\t Valid Loss: 4.352056\n",
      "Epoch: 422/2000\t Step: 15/54\t Train Loss: 3.881000\t Valid Loss: 4.501100\n",
      "Epoch: 422/2000\t Step: 30/54\t Train Loss: 3.857508\t Valid Loss: 4.401585\n",
      "Epoch: 422/2000\t Step: 45/54\t Train Loss: 4.038314\t Valid Loss: 4.258026\n",
      "Epoch: 423/2000\t Step: 15/54\t Train Loss: 3.836458\t Valid Loss: 4.416409\n",
      "Epoch: 423/2000\t Step: 30/54\t Train Loss: 3.841007\t Valid Loss: 4.388469\n",
      "Epoch: 423/2000\t Step: 45/54\t Train Loss: 3.848347\t Valid Loss: 4.274542\n",
      "Epoch: 424/2000\t Step: 15/54\t Train Loss: 3.853802\t Valid Loss: 4.321357\n",
      "Epoch: 424/2000\t Step: 30/54\t Train Loss: 3.935745\t Valid Loss: 4.281508\n",
      "Epoch: 424/2000\t Step: 45/54\t Train Loss: 3.871432\t Valid Loss: 4.268279\n",
      "Epoch: 425/2000\t Step: 15/54\t Train Loss: 3.860414\t Valid Loss: 4.267908\n",
      "Epoch: 425/2000\t Step: 30/54\t Train Loss: 3.893810\t Valid Loss: 4.355679\n",
      "Epoch: 425/2000\t Step: 45/54\t Train Loss: 3.877138\t Valid Loss: 4.402344\n",
      "Epoch: 426/2000\t Step: 15/54\t Train Loss: 3.848102\t Valid Loss: 4.336644\n",
      "Epoch: 426/2000\t Step: 30/54\t Train Loss: 3.871071\t Valid Loss: 4.275291\n",
      "Epoch: 426/2000\t Step: 45/54\t Train Loss: 3.912813\t Valid Loss: 4.265754\n",
      "Epoch: 427/2000\t Step: 15/54\t Train Loss: 3.829854\t Valid Loss: 4.267497\n",
      "Epoch: 427/2000\t Step: 30/54\t Train Loss: 3.937905\t Valid Loss: 4.387554\n",
      "Epoch: 427/2000\t Step: 45/54\t Train Loss: 3.855397\t Valid Loss: 4.286054\n",
      "Epoch: 428/2000\t Step: 15/54\t Train Loss: 3.947294\t Valid Loss: 4.322398\n",
      "Epoch: 428/2000\t Step: 30/54\t Train Loss: 3.826594\t Valid Loss: 4.293104\n",
      "Epoch: 428/2000\t Step: 45/54\t Train Loss: 3.831698\t Valid Loss: 4.318096\n",
      "Epoch: 429/2000\t Step: 15/54\t Train Loss: 3.869037\t Valid Loss: 4.313726\n",
      "Epoch: 429/2000\t Step: 30/54\t Train Loss: 4.047840\t Valid Loss: 4.304461\n",
      "Epoch: 429/2000\t Step: 45/54\t Train Loss: 3.876641\t Valid Loss: 4.487706\n",
      "Epoch: 430/2000\t Step: 15/54\t Train Loss: 3.860665\t Valid Loss: 4.505022\n",
      "Epoch: 430/2000\t Step: 30/54\t Train Loss: 3.928367\t Valid Loss: 4.245364\n",
      "Epoch: 430/2000\t Step: 45/54\t Train Loss: 3.863171\t Valid Loss: 4.254537\n",
      "Epoch: 431/2000\t Step: 15/54\t Train Loss: 3.918067\t Valid Loss: 4.328382\n",
      "Epoch: 431/2000\t Step: 30/54\t Train Loss: 3.823191\t Valid Loss: 4.433984\n",
      "Epoch: 431/2000\t Step: 45/54\t Train Loss: 3.876535\t Valid Loss: 4.299469\n",
      "Epoch: 432/2000\t Step: 15/54\t Train Loss: 3.834718\t Valid Loss: 4.411701\n",
      "Epoch: 432/2000\t Step: 30/54\t Train Loss: 3.870489\t Valid Loss: 4.226006\n",
      "Epoch: 432/2000\t Step: 45/54\t Train Loss: 3.828021\t Valid Loss: 4.342874\n",
      "Epoch: 433/2000\t Step: 15/54\t Train Loss: 3.873412\t Valid Loss: 4.236677\n",
      "Epoch: 433/2000\t Step: 30/54\t Train Loss: 3.896765\t Valid Loss: 4.263745\n",
      "Epoch: 433/2000\t Step: 45/54\t Train Loss: 4.037613\t Valid Loss: 4.248007\n",
      "Epoch: 434/2000\t Step: 15/54\t Train Loss: 3.823463\t Valid Loss: 4.288307\n",
      "Epoch: 434/2000\t Step: 30/54\t Train Loss: 3.831293\t Valid Loss: 4.353399\n",
      "Epoch: 434/2000\t Step: 45/54\t Train Loss: 3.811553\t Valid Loss: 4.317815\n",
      "Epoch: 435/2000\t Step: 15/54\t Train Loss: 3.868740\t Valid Loss: 4.244670\n",
      "Epoch: 435/2000\t Step: 30/54\t Train Loss: 3.891526\t Valid Loss: 4.321649\n",
      "Epoch: 435/2000\t Step: 45/54\t Train Loss: 4.065159\t Valid Loss: 4.278439\n",
      "Epoch: 436/2000\t Step: 15/54\t Train Loss: 3.856741\t Valid Loss: 4.309670\n",
      "Epoch: 436/2000\t Step: 30/54\t Train Loss: 3.848093\t Valid Loss: 4.340702\n",
      "Epoch: 436/2000\t Step: 45/54\t Train Loss: 3.869643\t Valid Loss: 4.336300\n",
      "Epoch: 437/2000\t Step: 15/54\t Train Loss: 3.998670\t Valid Loss: 4.237893\n",
      "Epoch: 437/2000\t Step: 30/54\t Train Loss: 3.867056\t Valid Loss: 4.388693\n",
      "Epoch: 437/2000\t Step: 45/54\t Train Loss: 3.819206\t Valid Loss: 4.427520\n",
      "Epoch: 438/2000\t Step: 15/54\t Train Loss: 3.904684\t Valid Loss: 4.319560\n",
      "Epoch: 438/2000\t Step: 30/54\t Train Loss: 3.875804\t Valid Loss: 4.287163\n",
      "Epoch: 438/2000\t Step: 45/54\t Train Loss: 3.924228\t Valid Loss: 4.269720\n",
      "Epoch: 439/2000\t Step: 15/54\t Train Loss: 3.870274\t Valid Loss: 4.350461\n",
      "Epoch: 439/2000\t Step: 30/54\t Train Loss: 3.859298\t Valid Loss: 4.542426\n",
      "Epoch: 439/2000\t Step: 45/54\t Train Loss: 3.886346\t Valid Loss: 4.266733\n",
      "Epoch: 440/2000\t Step: 15/54\t Train Loss: 3.859990\t Valid Loss: 4.196925\n",
      "Epoch: 440/2000\t Step: 30/54\t Train Loss: 3.848701\t Valid Loss: 4.346459\n",
      "Epoch: 440/2000\t Step: 45/54\t Train Loss: 3.965159\t Valid Loss: 4.471950\n",
      "Epoch: 441/2000\t Step: 15/54\t Train Loss: 3.866963\t Valid Loss: 4.343781\n",
      "Epoch: 441/2000\t Step: 30/54\t Train Loss: 3.869495\t Valid Loss: 4.406066\n",
      "Epoch: 441/2000\t Step: 45/54\t Train Loss: 3.805291\t Valid Loss: 4.345689\n",
      "Epoch: 442/2000\t Step: 15/54\t Train Loss: 3.976769\t Valid Loss: 4.310649\n",
      "Epoch: 442/2000\t Step: 30/54\t Train Loss: 3.837299\t Valid Loss: 4.471504\n",
      "Epoch: 442/2000\t Step: 45/54\t Train Loss: 3.815727\t Valid Loss: 4.372693\n",
      "Epoch: 443/2000\t Step: 15/54\t Train Loss: 3.846202\t Valid Loss: 4.283064\n",
      "Epoch: 443/2000\t Step: 30/54\t Train Loss: 3.850368\t Valid Loss: 4.390658\n",
      "Epoch: 443/2000\t Step: 45/54\t Train Loss: 3.895929\t Valid Loss: 4.407980\n",
      "Epoch: 444/2000\t Step: 15/54\t Train Loss: 3.864087\t Valid Loss: 4.294301\n",
      "Epoch: 444/2000\t Step: 30/54\t Train Loss: 3.892452\t Valid Loss: 4.314214\n",
      "Epoch: 444/2000\t Step: 45/54\t Train Loss: 3.950907\t Valid Loss: 4.334765\n",
      "Epoch: 445/2000\t Step: 15/54\t Train Loss: 3.878612\t Valid Loss: 4.432719\n",
      "Epoch: 445/2000\t Step: 30/54\t Train Loss: 3.831377\t Valid Loss: 4.274789\n",
      "Epoch: 445/2000\t Step: 45/54\t Train Loss: 3.853710\t Valid Loss: 4.411026\n",
      "Epoch: 446/2000\t Step: 15/54\t Train Loss: 3.832213\t Valid Loss: 4.344300\n",
      "Epoch: 446/2000\t Step: 30/54\t Train Loss: 3.858618\t Valid Loss: 4.252527\n",
      "Epoch: 446/2000\t Step: 45/54\t Train Loss: 3.816858\t Valid Loss: 4.304234\n",
      "Epoch: 447/2000\t Step: 15/54\t Train Loss: 3.831721\t Valid Loss: 4.327046\n",
      "Epoch: 447/2000\t Step: 30/54\t Train Loss: 3.888803\t Valid Loss: 4.305473\n",
      "Epoch: 447/2000\t Step: 45/54\t Train Loss: 3.868981\t Valid Loss: 4.357091\n",
      "Epoch: 448/2000\t Step: 15/54\t Train Loss: 3.822952\t Valid Loss: 4.295426\n",
      "Epoch: 448/2000\t Step: 30/54\t Train Loss: 3.828249\t Valid Loss: 4.305203\n",
      "Epoch: 448/2000\t Step: 45/54\t Train Loss: 3.898553\t Valid Loss: 4.328656\n",
      "Epoch: 449/2000\t Step: 15/54\t Train Loss: 3.898753\t Valid Loss: 4.270489\n",
      "Epoch: 449/2000\t Step: 30/54\t Train Loss: 3.864950\t Valid Loss: 4.517601\n",
      "Epoch: 449/2000\t Step: 45/54\t Train Loss: 3.888654\t Valid Loss: 4.566125\n",
      "Epoch: 450/2000\t Step: 15/54\t Train Loss: 3.850544\t Valid Loss: 4.377472\n",
      "Epoch: 450/2000\t Step: 30/54\t Train Loss: 3.916514\t Valid Loss: 4.353182\n",
      "Epoch: 450/2000\t Step: 45/54\t Train Loss: 3.955904\t Valid Loss: 4.204072\n",
      "Epoch: 451/2000\t Step: 15/54\t Train Loss: 3.869574\t Valid Loss: 4.205417\n",
      "Epoch: 451/2000\t Step: 30/54\t Train Loss: 3.852651\t Valid Loss: 4.289735\n",
      "Epoch: 451/2000\t Step: 45/54\t Train Loss: 3.895408\t Valid Loss: 4.175861\n",
      "Epoch: 452/2000\t Step: 15/54\t Train Loss: 3.849949\t Valid Loss: 4.295868\n",
      "Epoch: 452/2000\t Step: 30/54\t Train Loss: 3.879197\t Valid Loss: 4.281338\n",
      "Epoch: 452/2000\t Step: 45/54\t Train Loss: 3.887352\t Valid Loss: 4.344175\n",
      "Epoch: 453/2000\t Step: 15/54\t Train Loss: 3.911181\t Valid Loss: 4.284923\n",
      "Epoch: 453/2000\t Step: 30/54\t Train Loss: 3.932456\t Valid Loss: 4.363630\n",
      "Epoch: 453/2000\t Step: 45/54\t Train Loss: 3.864907\t Valid Loss: 4.328132\n",
      "Epoch: 454/2000\t Step: 15/54\t Train Loss: 3.853505\t Valid Loss: 4.249820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 454/2000\t Step: 30/54\t Train Loss: 3.864267\t Valid Loss: 4.329745\n",
      "Epoch: 454/2000\t Step: 45/54\t Train Loss: 3.924705\t Valid Loss: 4.344785\n",
      "Epoch: 455/2000\t Step: 15/54\t Train Loss: 3.941637\t Valid Loss: 4.431243\n",
      "Epoch: 455/2000\t Step: 30/54\t Train Loss: 3.799457\t Valid Loss: 4.389901\n",
      "Epoch: 455/2000\t Step: 45/54\t Train Loss: 3.826321\t Valid Loss: 4.319562\n",
      "Epoch: 456/2000\t Step: 15/54\t Train Loss: 3.897196\t Valid Loss: 4.328113\n",
      "Epoch: 456/2000\t Step: 30/54\t Train Loss: 3.865628\t Valid Loss: 4.192065\n",
      "Epoch: 456/2000\t Step: 45/54\t Train Loss: 3.848107\t Valid Loss: 4.235092\n",
      "Epoch: 457/2000\t Step: 15/54\t Train Loss: 4.045466\t Valid Loss: 4.321700\n",
      "Epoch: 457/2000\t Step: 30/54\t Train Loss: 3.829369\t Valid Loss: 4.314384\n",
      "Epoch: 457/2000\t Step: 45/54\t Train Loss: 3.837994\t Valid Loss: 4.279265\n",
      "Epoch: 458/2000\t Step: 15/54\t Train Loss: 3.924756\t Valid Loss: 4.286567\n",
      "Epoch: 458/2000\t Step: 30/54\t Train Loss: 3.828932\t Valid Loss: 4.316253\n",
      "Epoch: 458/2000\t Step: 45/54\t Train Loss: 3.878519\t Valid Loss: 4.263076\n",
      "Epoch: 459/2000\t Step: 15/54\t Train Loss: 3.966063\t Valid Loss: 4.441436\n",
      "Epoch: 459/2000\t Step: 30/54\t Train Loss: 3.847810\t Valid Loss: 4.223464\n",
      "Epoch: 459/2000\t Step: 45/54\t Train Loss: 3.827629\t Valid Loss: 4.355883\n",
      "Epoch: 460/2000\t Step: 15/54\t Train Loss: 3.847380\t Valid Loss: 4.374526\n",
      "Epoch: 460/2000\t Step: 30/54\t Train Loss: 3.833189\t Valid Loss: 4.426226\n",
      "Epoch: 460/2000\t Step: 45/54\t Train Loss: 3.882321\t Valid Loss: 4.262957\n",
      "Epoch: 461/2000\t Step: 15/54\t Train Loss: 3.831071\t Valid Loss: 4.334757\n",
      "Epoch: 461/2000\t Step: 30/54\t Train Loss: 3.877094\t Valid Loss: 4.357442\n",
      "Epoch: 461/2000\t Step: 45/54\t Train Loss: 3.841517\t Valid Loss: 4.353253\n",
      "Epoch: 462/2000\t Step: 15/54\t Train Loss: 3.822140\t Valid Loss: 4.299919\n",
      "Epoch: 462/2000\t Step: 30/54\t Train Loss: 3.865965\t Valid Loss: 4.277941\n",
      "Epoch: 462/2000\t Step: 45/54\t Train Loss: 3.866189\t Valid Loss: 4.301042\n",
      "Epoch: 463/2000\t Step: 15/54\t Train Loss: 3.849786\t Valid Loss: 4.300205\n",
      "Epoch: 463/2000\t Step: 30/54\t Train Loss: 3.831572\t Valid Loss: 4.359121\n",
      "Epoch: 463/2000\t Step: 45/54\t Train Loss: 3.856676\t Valid Loss: 4.455009\n",
      "Epoch: 464/2000\t Step: 15/54\t Train Loss: 3.834044\t Valid Loss: 4.295280\n",
      "Epoch: 464/2000\t Step: 30/54\t Train Loss: 3.874281\t Valid Loss: 4.301710\n",
      "Epoch: 464/2000\t Step: 45/54\t Train Loss: 3.899302\t Valid Loss: 4.432331\n",
      "Epoch: 465/2000\t Step: 15/54\t Train Loss: 3.805771\t Valid Loss: 4.399030\n",
      "Epoch: 465/2000\t Step: 30/54\t Train Loss: 3.891789\t Valid Loss: 4.222339\n",
      "Epoch: 465/2000\t Step: 45/54\t Train Loss: 3.863343\t Valid Loss: 4.332793\n",
      "Epoch: 466/2000\t Step: 15/54\t Train Loss: 3.809514\t Valid Loss: 4.393359\n",
      "Epoch: 466/2000\t Step: 30/54\t Train Loss: 3.864082\t Valid Loss: 4.514784\n",
      "Epoch: 466/2000\t Step: 45/54\t Train Loss: 3.925593\t Valid Loss: 4.349500\n",
      "Epoch: 467/2000\t Step: 15/54\t Train Loss: 3.819446\t Valid Loss: 4.336939\n",
      "Epoch: 467/2000\t Step: 30/54\t Train Loss: 3.870283\t Valid Loss: 4.339735\n",
      "Epoch: 467/2000\t Step: 45/54\t Train Loss: 3.947634\t Valid Loss: 4.242796\n",
      "Epoch: 468/2000\t Step: 15/54\t Train Loss: 3.852061\t Valid Loss: 4.373062\n",
      "Epoch: 468/2000\t Step: 30/54\t Train Loss: 3.939012\t Valid Loss: 4.447512\n",
      "Epoch: 468/2000\t Step: 45/54\t Train Loss: 3.870728\t Valid Loss: 4.237818\n",
      "Epoch: 469/2000\t Step: 15/54\t Train Loss: 3.861133\t Valid Loss: 4.302601\n",
      "Epoch: 469/2000\t Step: 30/54\t Train Loss: 3.971708\t Valid Loss: 4.289240\n",
      "Epoch: 469/2000\t Step: 45/54\t Train Loss: 3.888722\t Valid Loss: 4.328252\n",
      "Epoch: 470/2000\t Step: 15/54\t Train Loss: 3.877819\t Valid Loss: 4.459872\n",
      "Epoch: 470/2000\t Step: 30/54\t Train Loss: 3.860699\t Valid Loss: 4.345055\n",
      "Epoch: 470/2000\t Step: 45/54\t Train Loss: 3.837960\t Valid Loss: 4.313474\n",
      "Epoch: 471/2000\t Step: 15/54\t Train Loss: 3.834618\t Valid Loss: 4.209085\n",
      "Epoch: 471/2000\t Step: 30/54\t Train Loss: 3.951602\t Valid Loss: 4.298598\n",
      "Epoch: 471/2000\t Step: 45/54\t Train Loss: 3.878859\t Valid Loss: 4.237228\n",
      "Epoch: 472/2000\t Step: 15/54\t Train Loss: 3.886422\t Valid Loss: 4.248024\n",
      "Epoch: 472/2000\t Step: 30/54\t Train Loss: 3.858864\t Valid Loss: 4.536086\n",
      "Epoch: 472/2000\t Step: 45/54\t Train Loss: 3.871440\t Valid Loss: 4.331843\n",
      "Epoch: 473/2000\t Step: 15/54\t Train Loss: 3.935880\t Valid Loss: 4.260369\n",
      "Epoch: 473/2000\t Step: 30/54\t Train Loss: 3.953228\t Valid Loss: 4.253819\n",
      "Epoch: 473/2000\t Step: 45/54\t Train Loss: 3.797563\t Valid Loss: 4.330290\n",
      "Epoch: 474/2000\t Step: 15/54\t Train Loss: 3.879445\t Valid Loss: 4.338348\n",
      "Epoch: 474/2000\t Step: 30/54\t Train Loss: 3.820802\t Valid Loss: 4.308612\n",
      "Epoch: 474/2000\t Step: 45/54\t Train Loss: 3.858918\t Valid Loss: 4.319173\n",
      "Epoch: 475/2000\t Step: 15/54\t Train Loss: 3.856286\t Valid Loss: 4.267325\n",
      "Epoch: 475/2000\t Step: 30/54\t Train Loss: 3.816353\t Valid Loss: 4.298509\n",
      "Epoch: 475/2000\t Step: 45/54\t Train Loss: 3.829278\t Valid Loss: 4.429496\n",
      "Epoch: 476/2000\t Step: 15/54\t Train Loss: 3.856637\t Valid Loss: 4.407196\n",
      "Epoch: 476/2000\t Step: 30/54\t Train Loss: 3.823304\t Valid Loss: 4.305436\n",
      "Epoch: 476/2000\t Step: 45/54\t Train Loss: 3.819396\t Valid Loss: 4.305616\n",
      "Epoch: 477/2000\t Step: 15/54\t Train Loss: 3.829584\t Valid Loss: 4.364182\n",
      "Epoch: 477/2000\t Step: 30/54\t Train Loss: 3.851884\t Valid Loss: 4.328700\n",
      "Epoch: 477/2000\t Step: 45/54\t Train Loss: 3.886568\t Valid Loss: 4.347437\n",
      "Epoch: 478/2000\t Step: 15/54\t Train Loss: 3.850554\t Valid Loss: 4.339063\n",
      "Epoch: 478/2000\t Step: 30/54\t Train Loss: 3.855049\t Valid Loss: 4.318559\n",
      "Epoch: 478/2000\t Step: 45/54\t Train Loss: 3.806512\t Valid Loss: 4.542739\n",
      "Epoch: 479/2000\t Step: 15/54\t Train Loss: 3.836501\t Valid Loss: 4.384775\n",
      "Epoch: 479/2000\t Step: 30/54\t Train Loss: 3.887650\t Valid Loss: 4.356504\n",
      "Epoch: 479/2000\t Step: 45/54\t Train Loss: 3.842873\t Valid Loss: 4.427967\n",
      "Epoch: 480/2000\t Step: 15/54\t Train Loss: 3.856887\t Valid Loss: 4.306648\n",
      "Epoch: 480/2000\t Step: 30/54\t Train Loss: 3.803802\t Valid Loss: 4.301185\n",
      "Epoch: 480/2000\t Step: 45/54\t Train Loss: 3.797388\t Valid Loss: 4.456732\n",
      "Epoch: 481/2000\t Step: 15/54\t Train Loss: 3.897531\t Valid Loss: 4.447201\n",
      "Epoch: 481/2000\t Step: 30/54\t Train Loss: 3.876828\t Valid Loss: 4.300417\n",
      "Epoch: 481/2000\t Step: 45/54\t Train Loss: 3.835151\t Valid Loss: 4.427963\n",
      "Epoch: 482/2000\t Step: 15/54\t Train Loss: 3.827043\t Valid Loss: 4.313585\n",
      "Epoch: 482/2000\t Step: 30/54\t Train Loss: 3.836864\t Valid Loss: 4.344134\n",
      "Epoch: 482/2000\t Step: 45/54\t Train Loss: 3.886162\t Valid Loss: 4.291323\n",
      "Epoch: 483/2000\t Step: 15/54\t Train Loss: 3.822853\t Valid Loss: 4.333099\n",
      "Epoch: 483/2000\t Step: 30/54\t Train Loss: 3.873650\t Valid Loss: 4.354961\n",
      "Epoch: 483/2000\t Step: 45/54\t Train Loss: 3.849437\t Valid Loss: 4.364477\n",
      "Epoch: 484/2000\t Step: 15/54\t Train Loss: 3.858181\t Valid Loss: 4.453759\n",
      "Epoch: 484/2000\t Step: 30/54\t Train Loss: 3.825287\t Valid Loss: 4.314911\n",
      "Epoch: 484/2000\t Step: 45/54\t Train Loss: 3.891792\t Valid Loss: 4.402848\n",
      "Epoch: 485/2000\t Step: 15/54\t Train Loss: 3.774697\t Valid Loss: 4.486723\n",
      "Epoch: 485/2000\t Step: 30/54\t Train Loss: 3.829257\t Valid Loss: 4.278359\n",
      "Epoch: 485/2000\t Step: 45/54\t Train Loss: 3.893682\t Valid Loss: 4.402265\n",
      "Epoch: 486/2000\t Step: 15/54\t Train Loss: 3.839967\t Valid Loss: 4.282212\n",
      "Epoch: 486/2000\t Step: 30/54\t Train Loss: 3.863275\t Valid Loss: 4.266977\n",
      "Epoch: 486/2000\t Step: 45/54\t Train Loss: 3.920559\t Valid Loss: 4.284739\n",
      "Epoch: 487/2000\t Step: 15/54\t Train Loss: 3.867063\t Valid Loss: 4.281370\n",
      "Epoch: 487/2000\t Step: 30/54\t Train Loss: 3.814840\t Valid Loss: 4.279441\n",
      "Epoch: 487/2000\t Step: 45/54\t Train Loss: 3.847445\t Valid Loss: 4.321814\n",
      "Epoch: 488/2000\t Step: 15/54\t Train Loss: 3.812990\t Valid Loss: 4.339905\n",
      "Epoch: 488/2000\t Step: 30/54\t Train Loss: 3.822380\t Valid Loss: 4.348733\n",
      "Epoch: 488/2000\t Step: 45/54\t Train Loss: 3.860059\t Valid Loss: 4.270668\n",
      "Epoch: 489/2000\t Step: 15/54\t Train Loss: 3.861683\t Valid Loss: 4.422930\n",
      "Epoch: 489/2000\t Step: 30/54\t Train Loss: 3.824876\t Valid Loss: 4.314347\n",
      "Epoch: 489/2000\t Step: 45/54\t Train Loss: 3.876059\t Valid Loss: 4.390057\n",
      "Epoch: 490/2000\t Step: 15/54\t Train Loss: 3.856843\t Valid Loss: 4.381752\n",
      "Epoch: 490/2000\t Step: 30/54\t Train Loss: 3.829648\t Valid Loss: 4.242757\n",
      "Epoch: 490/2000\t Step: 45/54\t Train Loss: 3.849853\t Valid Loss: 4.297054\n",
      "Epoch: 491/2000\t Step: 15/54\t Train Loss: 3.848932\t Valid Loss: 4.226344\n",
      "Epoch: 491/2000\t Step: 30/54\t Train Loss: 3.877615\t Valid Loss: 4.281678\n",
      "Epoch: 491/2000\t Step: 45/54\t Train Loss: 3.911492\t Valid Loss: 4.378969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 492/2000\t Step: 15/54\t Train Loss: 3.833745\t Valid Loss: 4.389522\n",
      "Epoch: 492/2000\t Step: 30/54\t Train Loss: 3.853649\t Valid Loss: 4.442342\n",
      "Epoch: 492/2000\t Step: 45/54\t Train Loss: 3.975899\t Valid Loss: 4.253053\n",
      "Epoch: 493/2000\t Step: 15/54\t Train Loss: 3.844960\t Valid Loss: 4.443315\n",
      "Epoch: 493/2000\t Step: 30/54\t Train Loss: 3.875254\t Valid Loss: 4.245003\n",
      "Epoch: 493/2000\t Step: 45/54\t Train Loss: 3.905080\t Valid Loss: 4.351525\n",
      "Epoch: 494/2000\t Step: 15/54\t Train Loss: 3.836928\t Valid Loss: 4.308437\n",
      "Epoch: 494/2000\t Step: 30/54\t Train Loss: 3.830079\t Valid Loss: 4.543431\n",
      "Epoch: 494/2000\t Step: 45/54\t Train Loss: 3.839600\t Valid Loss: 4.322021\n",
      "Epoch: 495/2000\t Step: 15/54\t Train Loss: 3.848415\t Valid Loss: 4.347025\n",
      "Epoch: 495/2000\t Step: 30/54\t Train Loss: 3.834342\t Valid Loss: 4.333725\n",
      "Epoch: 495/2000\t Step: 45/54\t Train Loss: 3.888432\t Valid Loss: 4.288893\n",
      "Epoch: 496/2000\t Step: 15/54\t Train Loss: 3.880735\t Valid Loss: 4.258270\n",
      "Epoch: 496/2000\t Step: 30/54\t Train Loss: 3.855299\t Valid Loss: 4.380505\n",
      "Epoch: 496/2000\t Step: 45/54\t Train Loss: 3.898219\t Valid Loss: 4.450726\n",
      "Epoch: 497/2000\t Step: 15/54\t Train Loss: 3.820331\t Valid Loss: 4.410374\n",
      "Epoch: 497/2000\t Step: 30/54\t Train Loss: 3.845662\t Valid Loss: 4.329992\n",
      "Epoch: 497/2000\t Step: 45/54\t Train Loss: 3.831933\t Valid Loss: 4.349809\n",
      "Epoch: 498/2000\t Step: 15/54\t Train Loss: 3.760194\t Valid Loss: 4.450159\n",
      "Epoch: 498/2000\t Step: 30/54\t Train Loss: 3.811651\t Valid Loss: 4.431808\n",
      "Epoch: 498/2000\t Step: 45/54\t Train Loss: 3.829653\t Valid Loss: 4.403036\n",
      "Epoch: 499/2000\t Step: 15/54\t Train Loss: 3.840339\t Valid Loss: 4.268287\n",
      "Epoch: 499/2000\t Step: 30/54\t Train Loss: 3.874193\t Valid Loss: 4.244388\n",
      "Epoch: 499/2000\t Step: 45/54\t Train Loss: 3.841338\t Valid Loss: 4.368989\n",
      "Epoch: 500/2000\t Step: 15/54\t Train Loss: 3.851134\t Valid Loss: 4.618764\n",
      "Epoch: 500/2000\t Step: 30/54\t Train Loss: 3.898366\t Valid Loss: 4.487794\n",
      "Epoch: 500/2000\t Step: 45/54\t Train Loss: 3.853278\t Valid Loss: 4.407687\n",
      "Epoch: 501/2000\t Step: 15/54\t Train Loss: 3.864406\t Valid Loss: 4.360665\n",
      "Epoch: 501/2000\t Step: 30/54\t Train Loss: 3.813134\t Valid Loss: 4.251920\n",
      "Epoch: 501/2000\t Step: 45/54\t Train Loss: 3.847559\t Valid Loss: 4.324729\n",
      "Epoch: 502/2000\t Step: 15/54\t Train Loss: 3.857491\t Valid Loss: 4.337513\n",
      "Epoch: 502/2000\t Step: 30/54\t Train Loss: 3.860488\t Valid Loss: 4.412706\n",
      "Epoch: 502/2000\t Step: 45/54\t Train Loss: 3.834140\t Valid Loss: 4.520514\n",
      "Epoch: 503/2000\t Step: 15/54\t Train Loss: 3.846319\t Valid Loss: 4.302774\n",
      "Epoch: 503/2000\t Step: 30/54\t Train Loss: 3.930506\t Valid Loss: 4.238874\n",
      "Epoch: 503/2000\t Step: 45/54\t Train Loss: 3.813456\t Valid Loss: 4.464401\n",
      "Epoch: 504/2000\t Step: 15/54\t Train Loss: 3.857106\t Valid Loss: 4.395555\n",
      "Epoch: 504/2000\t Step: 30/54\t Train Loss: 3.854177\t Valid Loss: 4.328431\n",
      "Epoch: 504/2000\t Step: 45/54\t Train Loss: 3.842949\t Valid Loss: 4.501698\n",
      "Epoch: 505/2000\t Step: 15/54\t Train Loss: 3.833353\t Valid Loss: 4.376435\n",
      "Epoch: 505/2000\t Step: 30/54\t Train Loss: 3.769809\t Valid Loss: 4.355813\n",
      "Epoch: 505/2000\t Step: 45/54\t Train Loss: 3.847388\t Valid Loss: 4.292785\n",
      "Epoch: 506/2000\t Step: 15/54\t Train Loss: 3.823928\t Valid Loss: 4.371221\n",
      "Epoch: 506/2000\t Step: 30/54\t Train Loss: 3.831624\t Valid Loss: 4.370721\n",
      "Epoch: 506/2000\t Step: 45/54\t Train Loss: 3.822332\t Valid Loss: 4.508546\n",
      "Epoch: 507/2000\t Step: 15/54\t Train Loss: 3.785147\t Valid Loss: 4.388009\n",
      "Epoch: 507/2000\t Step: 30/54\t Train Loss: 3.855220\t Valid Loss: 4.293821\n",
      "Epoch: 507/2000\t Step: 45/54\t Train Loss: 3.884979\t Valid Loss: 4.326572\n",
      "Epoch: 508/2000\t Step: 15/54\t Train Loss: 3.915602\t Valid Loss: 4.359479\n",
      "Epoch: 508/2000\t Step: 30/54\t Train Loss: 3.851069\t Valid Loss: 4.270785\n",
      "Epoch: 508/2000\t Step: 45/54\t Train Loss: 3.839870\t Valid Loss: 4.233099\n",
      "Epoch: 509/2000\t Step: 15/54\t Train Loss: 3.838531\t Valid Loss: 4.357362\n",
      "Epoch: 509/2000\t Step: 30/54\t Train Loss: 3.855779\t Valid Loss: 4.318916\n",
      "Epoch: 509/2000\t Step: 45/54\t Train Loss: 3.920117\t Valid Loss: 4.272474\n",
      "Epoch: 510/2000\t Step: 15/54\t Train Loss: 3.850159\t Valid Loss: 4.348253\n",
      "Epoch: 510/2000\t Step: 30/54\t Train Loss: 3.843518\t Valid Loss: 4.434471\n",
      "Epoch: 510/2000\t Step: 45/54\t Train Loss: 3.896902\t Valid Loss: 4.326800\n",
      "Epoch: 511/2000\t Step: 15/54\t Train Loss: 3.881882\t Valid Loss: 4.330033\n",
      "Epoch: 511/2000\t Step: 30/54\t Train Loss: 3.831475\t Valid Loss: 4.338534\n",
      "Epoch: 511/2000\t Step: 45/54\t Train Loss: 3.850205\t Valid Loss: 4.352850\n",
      "Epoch: 512/2000\t Step: 15/54\t Train Loss: 3.883221\t Valid Loss: 4.222721\n",
      "Epoch: 512/2000\t Step: 30/54\t Train Loss: 3.842138\t Valid Loss: 4.286745\n",
      "Epoch: 512/2000\t Step: 45/54\t Train Loss: 3.866076\t Valid Loss: 4.315323\n",
      "Epoch: 513/2000\t Step: 15/54\t Train Loss: 3.919662\t Valid Loss: 4.518768\n",
      "Epoch: 513/2000\t Step: 30/54\t Train Loss: 3.893296\t Valid Loss: 4.383384\n",
      "Epoch: 513/2000\t Step: 45/54\t Train Loss: 3.848946\t Valid Loss: 4.338747\n",
      "Epoch: 514/2000\t Step: 15/54\t Train Loss: 3.831479\t Valid Loss: 4.418973\n",
      "Epoch: 514/2000\t Step: 30/54\t Train Loss: 3.851733\t Valid Loss: 4.335881\n",
      "Epoch: 514/2000\t Step: 45/54\t Train Loss: 3.853196\t Valid Loss: 4.562380\n",
      "Epoch: 515/2000\t Step: 15/54\t Train Loss: 3.844716\t Valid Loss: 4.351734\n",
      "Epoch: 515/2000\t Step: 30/54\t Train Loss: 3.850021\t Valid Loss: 4.333586\n",
      "Epoch: 515/2000\t Step: 45/54\t Train Loss: 3.817256\t Valid Loss: 4.462969\n",
      "Epoch: 516/2000\t Step: 15/54\t Train Loss: 3.842753\t Valid Loss: 4.320204\n",
      "Epoch: 516/2000\t Step: 30/54\t Train Loss: 3.847541\t Valid Loss: 4.344054\n",
      "Epoch: 516/2000\t Step: 45/54\t Train Loss: 3.811122\t Valid Loss: 4.527450\n",
      "Epoch: 517/2000\t Step: 15/54\t Train Loss: 3.833581\t Valid Loss: 4.379762\n",
      "Epoch: 517/2000\t Step: 30/54\t Train Loss: 3.843153\t Valid Loss: 4.486330\n",
      "Epoch: 517/2000\t Step: 45/54\t Train Loss: 3.792424\t Valid Loss: 4.473877\n",
      "Epoch: 518/2000\t Step: 15/54\t Train Loss: 3.829120\t Valid Loss: 4.566144\n",
      "Epoch: 518/2000\t Step: 30/54\t Train Loss: 3.823075\t Valid Loss: 4.312983\n",
      "Epoch: 518/2000\t Step: 45/54\t Train Loss: 3.853913\t Valid Loss: 4.412857\n",
      "Epoch: 519/2000\t Step: 15/54\t Train Loss: 3.844507\t Valid Loss: 4.337297\n",
      "Epoch: 519/2000\t Step: 30/54\t Train Loss: 3.812267\t Valid Loss: 4.405020\n",
      "Epoch: 519/2000\t Step: 45/54\t Train Loss: 3.820535\t Valid Loss: 4.460716\n",
      "Epoch: 520/2000\t Step: 15/54\t Train Loss: 3.882143\t Valid Loss: 4.362895\n",
      "Epoch: 520/2000\t Step: 30/54\t Train Loss: 3.909619\t Valid Loss: 4.394842\n",
      "Epoch: 520/2000\t Step: 45/54\t Train Loss: 3.792998\t Valid Loss: 4.443022\n",
      "Epoch: 521/2000\t Step: 15/54\t Train Loss: 3.836297\t Valid Loss: 4.503707\n",
      "Epoch: 521/2000\t Step: 30/54\t Train Loss: 3.833887\t Valid Loss: 4.379359\n",
      "Epoch: 521/2000\t Step: 45/54\t Train Loss: 3.875145\t Valid Loss: 4.622368\n",
      "Epoch: 522/2000\t Step: 15/54\t Train Loss: 3.853419\t Valid Loss: 4.307882\n",
      "Epoch: 522/2000\t Step: 30/54\t Train Loss: 3.801633\t Valid Loss: 4.411111\n",
      "Epoch: 522/2000\t Step: 45/54\t Train Loss: 3.911153\t Valid Loss: 4.525596\n",
      "Epoch: 523/2000\t Step: 15/54\t Train Loss: 3.835038\t Valid Loss: 4.510813\n",
      "Epoch: 523/2000\t Step: 30/54\t Train Loss: 3.910260\t Valid Loss: 4.320628\n",
      "Epoch: 523/2000\t Step: 45/54\t Train Loss: 3.833840\t Valid Loss: 4.423312\n",
      "Epoch: 524/2000\t Step: 15/54\t Train Loss: 3.798255\t Valid Loss: 4.424061\n",
      "Epoch: 524/2000\t Step: 30/54\t Train Loss: 3.852279\t Valid Loss: 4.392931\n",
      "Epoch: 524/2000\t Step: 45/54\t Train Loss: 3.934300\t Valid Loss: 4.374554\n",
      "Epoch: 525/2000\t Step: 15/54\t Train Loss: 3.794888\t Valid Loss: 4.437957\n",
      "Epoch: 525/2000\t Step: 30/54\t Train Loss: 3.819177\t Valid Loss: 4.298183\n",
      "Epoch: 525/2000\t Step: 45/54\t Train Loss: 3.851644\t Valid Loss: 4.278156\n",
      "Epoch: 526/2000\t Step: 15/54\t Train Loss: 3.897892\t Valid Loss: 4.258117\n",
      "Epoch: 526/2000\t Step: 30/54\t Train Loss: 3.862404\t Valid Loss: 4.336224\n",
      "Epoch: 526/2000\t Step: 45/54\t Train Loss: 3.851004\t Valid Loss: 4.429780\n",
      "Epoch: 527/2000\t Step: 15/54\t Train Loss: 3.856085\t Valid Loss: 4.405043\n",
      "Epoch: 527/2000\t Step: 30/54\t Train Loss: 3.871357\t Valid Loss: 4.345855\n",
      "Epoch: 527/2000\t Step: 45/54\t Train Loss: 3.834101\t Valid Loss: 4.280847\n",
      "Epoch: 528/2000\t Step: 15/54\t Train Loss: 3.841192\t Valid Loss: 4.393248\n",
      "Epoch: 528/2000\t Step: 30/54\t Train Loss: 3.926330\t Valid Loss: 4.346438\n",
      "Epoch: 528/2000\t Step: 45/54\t Train Loss: 3.874915\t Valid Loss: 4.318823\n",
      "Epoch: 529/2000\t Step: 15/54\t Train Loss: 3.811285\t Valid Loss: 4.315572\n",
      "Epoch: 529/2000\t Step: 30/54\t Train Loss: 3.858173\t Valid Loss: 4.268807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 529/2000\t Step: 45/54\t Train Loss: 3.886158\t Valid Loss: 4.263846\n",
      "Epoch: 530/2000\t Step: 15/54\t Train Loss: 3.864790\t Valid Loss: 4.412333\n",
      "Epoch: 530/2000\t Step: 30/54\t Train Loss: 3.838139\t Valid Loss: 4.401623\n",
      "Epoch: 530/2000\t Step: 45/54\t Train Loss: 3.839689\t Valid Loss: 4.416252\n",
      "Epoch: 531/2000\t Step: 15/54\t Train Loss: 3.810168\t Valid Loss: 4.513236\n",
      "Epoch: 531/2000\t Step: 30/54\t Train Loss: 3.792659\t Valid Loss: 4.375170\n",
      "Epoch: 531/2000\t Step: 45/54\t Train Loss: 3.843949\t Valid Loss: 4.592350\n",
      "Epoch: 532/2000\t Step: 15/54\t Train Loss: 3.904125\t Valid Loss: 4.355145\n",
      "Epoch: 532/2000\t Step: 30/54\t Train Loss: 3.928187\t Valid Loss: 4.473952\n",
      "Epoch: 532/2000\t Step: 45/54\t Train Loss: 3.830625\t Valid Loss: 4.291866\n",
      "Epoch: 533/2000\t Step: 15/54\t Train Loss: 3.824903\t Valid Loss: 4.357188\n",
      "Epoch: 533/2000\t Step: 30/54\t Train Loss: 3.786300\t Valid Loss: 4.327555\n",
      "Epoch: 533/2000\t Step: 45/54\t Train Loss: 3.863153\t Valid Loss: 4.332105\n",
      "Epoch: 534/2000\t Step: 15/54\t Train Loss: 3.836134\t Valid Loss: 4.344535\n",
      "Epoch: 534/2000\t Step: 30/54\t Train Loss: 3.813955\t Valid Loss: 4.325252\n",
      "Epoch: 534/2000\t Step: 45/54\t Train Loss: 3.840931\t Valid Loss: 4.379221\n",
      "Epoch: 535/2000\t Step: 15/54\t Train Loss: 3.821762\t Valid Loss: 4.649737\n",
      "Epoch: 535/2000\t Step: 30/54\t Train Loss: 3.884462\t Valid Loss: 4.414536\n",
      "Epoch: 535/2000\t Step: 45/54\t Train Loss: 3.822317\t Valid Loss: 4.297271\n",
      "Epoch: 536/2000\t Step: 15/54\t Train Loss: 3.883734\t Valid Loss: 4.348096\n",
      "Epoch: 536/2000\t Step: 30/54\t Train Loss: 3.841499\t Valid Loss: 4.422995\n",
      "Epoch: 536/2000\t Step: 45/54\t Train Loss: 3.901519\t Valid Loss: 4.507283\n",
      "Epoch: 537/2000\t Step: 15/54\t Train Loss: 3.822374\t Valid Loss: 4.327110\n",
      "Epoch: 537/2000\t Step: 30/54\t Train Loss: 3.807602\t Valid Loss: 4.659427\n",
      "Epoch: 537/2000\t Step: 45/54\t Train Loss: 3.873148\t Valid Loss: 4.541391\n",
      "Epoch: 538/2000\t Step: 15/54\t Train Loss: 3.854088\t Valid Loss: 4.302116\n",
      "Epoch: 538/2000\t Step: 30/54\t Train Loss: 3.788266\t Valid Loss: 4.573366\n",
      "Epoch: 538/2000\t Step: 45/54\t Train Loss: 3.811145\t Valid Loss: 4.421836\n",
      "Epoch: 539/2000\t Step: 15/54\t Train Loss: 3.825064\t Valid Loss: 4.486723\n",
      "Epoch: 539/2000\t Step: 30/54\t Train Loss: 3.822203\t Valid Loss: 4.508688\n",
      "Epoch: 539/2000\t Step: 45/54\t Train Loss: 3.831428\t Valid Loss: 4.387961\n",
      "Epoch: 540/2000\t Step: 15/54\t Train Loss: 3.845249\t Valid Loss: 4.416125\n",
      "Epoch: 540/2000\t Step: 30/54\t Train Loss: 3.849049\t Valid Loss: 4.486866\n",
      "Epoch: 540/2000\t Step: 45/54\t Train Loss: 3.921662\t Valid Loss: 4.271044\n",
      "Epoch: 541/2000\t Step: 15/54\t Train Loss: 3.838588\t Valid Loss: 4.436843\n",
      "Epoch: 541/2000\t Step: 30/54\t Train Loss: 3.786307\t Valid Loss: 4.357997\n",
      "Epoch: 541/2000\t Step: 45/54\t Train Loss: 3.895926\t Valid Loss: 4.513546\n",
      "Epoch: 542/2000\t Step: 15/54\t Train Loss: 3.845965\t Valid Loss: 4.630615\n",
      "Epoch: 542/2000\t Step: 30/54\t Train Loss: 3.857593\t Valid Loss: 4.383361\n",
      "Epoch: 542/2000\t Step: 45/54\t Train Loss: 3.805801\t Valid Loss: 4.360967\n",
      "Epoch: 543/2000\t Step: 15/54\t Train Loss: 3.808815\t Valid Loss: 4.287398\n",
      "Epoch: 543/2000\t Step: 30/54\t Train Loss: 3.844833\t Valid Loss: 4.369003\n",
      "Epoch: 543/2000\t Step: 45/54\t Train Loss: 3.819287\t Valid Loss: 4.361063\n",
      "Epoch: 544/2000\t Step: 15/54\t Train Loss: 3.803651\t Valid Loss: 4.371156\n",
      "Epoch: 544/2000\t Step: 30/54\t Train Loss: 3.847799\t Valid Loss: 4.421627\n",
      "Epoch: 544/2000\t Step: 45/54\t Train Loss: 3.843216\t Valid Loss: 4.377045\n",
      "Epoch: 545/2000\t Step: 15/54\t Train Loss: 3.878675\t Valid Loss: 4.409379\n",
      "Epoch: 545/2000\t Step: 30/54\t Train Loss: 3.821685\t Valid Loss: 4.455901\n",
      "Epoch: 545/2000\t Step: 45/54\t Train Loss: 3.790651\t Valid Loss: 4.548374\n",
      "Epoch: 546/2000\t Step: 15/54\t Train Loss: 3.857387\t Valid Loss: 4.517933\n",
      "Epoch: 546/2000\t Step: 30/54\t Train Loss: 3.883692\t Valid Loss: 4.307720\n",
      "Epoch: 546/2000\t Step: 45/54\t Train Loss: 3.819354\t Valid Loss: 4.438007\n",
      "Epoch: 547/2000\t Step: 15/54\t Train Loss: 3.824939\t Valid Loss: 4.415701\n",
      "Epoch: 547/2000\t Step: 30/54\t Train Loss: 3.815798\t Valid Loss: 4.371366\n",
      "Epoch: 547/2000\t Step: 45/54\t Train Loss: 3.816080\t Valid Loss: 4.268068\n",
      "Epoch: 548/2000\t Step: 15/54\t Train Loss: 3.865073\t Valid Loss: 4.361633\n",
      "Epoch: 548/2000\t Step: 30/54\t Train Loss: 3.846112\t Valid Loss: 4.452016\n",
      "Epoch: 548/2000\t Step: 45/54\t Train Loss: 3.809028\t Valid Loss: 4.715905\n",
      "Epoch: 549/2000\t Step: 15/54\t Train Loss: 3.872206\t Valid Loss: 4.449907\n",
      "Epoch: 549/2000\t Step: 30/54\t Train Loss: 3.821145\t Valid Loss: 4.428988\n",
      "Epoch: 549/2000\t Step: 45/54\t Train Loss: 3.799287\t Valid Loss: 4.429203\n",
      "Epoch: 550/2000\t Step: 15/54\t Train Loss: 3.844184\t Valid Loss: 4.259492\n",
      "Epoch: 550/2000\t Step: 30/54\t Train Loss: 3.839215\t Valid Loss: 4.566422\n",
      "Epoch: 550/2000\t Step: 45/54\t Train Loss: 3.876456\t Valid Loss: 4.360313\n",
      "Epoch: 551/2000\t Step: 15/54\t Train Loss: 3.834706\t Valid Loss: 4.376670\n",
      "Epoch: 551/2000\t Step: 30/54\t Train Loss: 3.814442\t Valid Loss: 4.427711\n",
      "Epoch: 551/2000\t Step: 45/54\t Train Loss: 3.908277\t Valid Loss: 4.316942\n",
      "Epoch: 552/2000\t Step: 15/54\t Train Loss: 3.896718\t Valid Loss: 4.312900\n",
      "Epoch: 552/2000\t Step: 30/54\t Train Loss: 3.837197\t Valid Loss: 4.342631\n",
      "Epoch: 552/2000\t Step: 45/54\t Train Loss: 3.817260\t Valid Loss: 4.455322\n",
      "Epoch: 553/2000\t Step: 15/54\t Train Loss: 3.840609\t Valid Loss: 4.350997\n",
      "Epoch: 553/2000\t Step: 30/54\t Train Loss: 3.843103\t Valid Loss: 4.325716\n",
      "Epoch: 553/2000\t Step: 45/54\t Train Loss: 3.831951\t Valid Loss: 4.460991\n",
      "Epoch: 554/2000\t Step: 15/54\t Train Loss: 3.824779\t Valid Loss: 4.405731\n",
      "Epoch: 554/2000\t Step: 30/54\t Train Loss: 3.850851\t Valid Loss: 4.430386\n",
      "Epoch: 554/2000\t Step: 45/54\t Train Loss: 3.795989\t Valid Loss: 4.344965\n",
      "Epoch: 555/2000\t Step: 15/54\t Train Loss: 3.899679\t Valid Loss: 4.516380\n",
      "Epoch: 555/2000\t Step: 30/54\t Train Loss: 3.789696\t Valid Loss: 4.301763\n",
      "Epoch: 555/2000\t Step: 45/54\t Train Loss: 3.851659\t Valid Loss: 4.526947\n",
      "Epoch: 556/2000\t Step: 15/54\t Train Loss: 3.797969\t Valid Loss: 4.381319\n",
      "Epoch: 556/2000\t Step: 30/54\t Train Loss: 3.882040\t Valid Loss: 4.772528\n",
      "Epoch: 556/2000\t Step: 45/54\t Train Loss: 3.931205\t Valid Loss: 4.550471\n",
      "Epoch: 557/2000\t Step: 15/54\t Train Loss: 3.812777\t Valid Loss: 4.371179\n",
      "Epoch: 557/2000\t Step: 30/54\t Train Loss: 3.859614\t Valid Loss: 4.318932\n",
      "Epoch: 557/2000\t Step: 45/54\t Train Loss: 3.862273\t Valid Loss: 4.487584\n",
      "Epoch: 558/2000\t Step: 15/54\t Train Loss: 3.839704\t Valid Loss: 4.271251\n",
      "Epoch: 558/2000\t Step: 30/54\t Train Loss: 3.838631\t Valid Loss: 4.328419\n",
      "Epoch: 558/2000\t Step: 45/54\t Train Loss: 3.833751\t Valid Loss: 4.283690\n",
      "Epoch: 559/2000\t Step: 15/54\t Train Loss: 3.843277\t Valid Loss: 4.305819\n",
      "Epoch: 559/2000\t Step: 30/54\t Train Loss: 3.821068\t Valid Loss: 4.376840\n",
      "Epoch: 559/2000\t Step: 45/54\t Train Loss: 3.905832\t Valid Loss: 4.291743\n",
      "Epoch: 560/2000\t Step: 15/54\t Train Loss: 3.884133\t Valid Loss: 4.339324\n",
      "Epoch: 560/2000\t Step: 30/54\t Train Loss: 3.959033\t Valid Loss: 4.428026\n",
      "Epoch: 560/2000\t Step: 45/54\t Train Loss: 3.824337\t Valid Loss: 4.311588\n",
      "Epoch: 561/2000\t Step: 15/54\t Train Loss: 3.874056\t Valid Loss: 4.278039\n",
      "Epoch: 561/2000\t Step: 30/54\t Train Loss: 3.826551\t Valid Loss: 4.599345\n",
      "Epoch: 561/2000\t Step: 45/54\t Train Loss: 3.832916\t Valid Loss: 4.354791\n",
      "Epoch: 562/2000\t Step: 15/54\t Train Loss: 3.854075\t Valid Loss: 4.273421\n",
      "Epoch: 562/2000\t Step: 30/54\t Train Loss: 3.856004\t Valid Loss: 4.424953\n",
      "Epoch: 562/2000\t Step: 45/54\t Train Loss: 3.852870\t Valid Loss: 4.228678\n",
      "Epoch: 563/2000\t Step: 15/54\t Train Loss: 3.821277\t Valid Loss: 4.517014\n",
      "Epoch: 563/2000\t Step: 30/54\t Train Loss: 3.803943\t Valid Loss: 4.342178\n",
      "Epoch: 563/2000\t Step: 45/54\t Train Loss: 3.795494\t Valid Loss: 4.313346\n",
      "Epoch: 564/2000\t Step: 15/54\t Train Loss: 3.832743\t Valid Loss: 4.487313\n",
      "Epoch: 564/2000\t Step: 30/54\t Train Loss: 3.847112\t Valid Loss: 4.350063\n",
      "Epoch: 564/2000\t Step: 45/54\t Train Loss: 3.814386\t Valid Loss: 4.387906\n",
      "Epoch: 565/2000\t Step: 15/54\t Train Loss: 3.915637\t Valid Loss: 4.410534\n",
      "Epoch: 565/2000\t Step: 30/54\t Train Loss: 3.919562\t Valid Loss: 4.499612\n",
      "Epoch: 565/2000\t Step: 45/54\t Train Loss: 3.902654\t Valid Loss: 4.480020\n",
      "Epoch: 566/2000\t Step: 15/54\t Train Loss: 3.913538\t Valid Loss: 4.604007\n",
      "Epoch: 566/2000\t Step: 30/54\t Train Loss: 3.857943\t Valid Loss: 4.267450\n",
      "Epoch: 566/2000\t Step: 45/54\t Train Loss: 3.827055\t Valid Loss: 4.578465\n",
      "Epoch: 567/2000\t Step: 15/54\t Train Loss: 3.754481\t Valid Loss: 4.491950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 567/2000\t Step: 30/54\t Train Loss: 3.818285\t Valid Loss: 4.703763\n",
      "Epoch: 567/2000\t Step: 45/54\t Train Loss: 3.893877\t Valid Loss: 4.470222\n",
      "Epoch: 568/2000\t Step: 15/54\t Train Loss: 3.800598\t Valid Loss: 4.469559\n",
      "Epoch: 568/2000\t Step: 30/54\t Train Loss: 3.878457\t Valid Loss: 4.571011\n",
      "Epoch: 568/2000\t Step: 45/54\t Train Loss: 3.857209\t Valid Loss: 4.544665\n",
      "Epoch: 569/2000\t Step: 15/54\t Train Loss: 3.850043\t Valid Loss: 4.334324\n",
      "Epoch: 569/2000\t Step: 30/54\t Train Loss: 3.931709\t Valid Loss: 4.361920\n",
      "Epoch: 569/2000\t Step: 45/54\t Train Loss: 3.825476\t Valid Loss: 4.407690\n",
      "Epoch: 570/2000\t Step: 15/54\t Train Loss: 3.844974\t Valid Loss: 4.403642\n",
      "Epoch: 570/2000\t Step: 30/54\t Train Loss: 3.777652\t Valid Loss: 4.445083\n",
      "Epoch: 570/2000\t Step: 45/54\t Train Loss: 3.887196\t Valid Loss: 4.430033\n",
      "Epoch: 571/2000\t Step: 15/54\t Train Loss: 3.889927\t Valid Loss: 4.349442\n",
      "Epoch: 571/2000\t Step: 30/54\t Train Loss: 3.805798\t Valid Loss: 4.432825\n",
      "Epoch: 571/2000\t Step: 45/54\t Train Loss: 3.803909\t Valid Loss: 4.727415\n",
      "Epoch: 572/2000\t Step: 15/54\t Train Loss: 3.836012\t Valid Loss: 4.429725\n",
      "Epoch: 572/2000\t Step: 30/54\t Train Loss: 3.816584\t Valid Loss: 4.433626\n",
      "Epoch: 572/2000\t Step: 45/54\t Train Loss: 3.860141\t Valid Loss: 4.265383\n",
      "Epoch: 573/2000\t Step: 15/54\t Train Loss: 3.917171\t Valid Loss: 4.345222\n",
      "Epoch: 573/2000\t Step: 30/54\t Train Loss: 3.849809\t Valid Loss: 4.525849\n",
      "Epoch: 573/2000\t Step: 45/54\t Train Loss: 3.874597\t Valid Loss: 4.280070\n",
      "Epoch: 574/2000\t Step: 15/54\t Train Loss: 3.818259\t Valid Loss: 4.388427\n",
      "Epoch: 574/2000\t Step: 30/54\t Train Loss: 3.863976\t Valid Loss: 4.326187\n",
      "Epoch: 574/2000\t Step: 45/54\t Train Loss: 3.818819\t Valid Loss: 4.671320\n",
      "Epoch: 575/2000\t Step: 15/54\t Train Loss: 3.932040\t Valid Loss: 4.420155\n",
      "Epoch: 575/2000\t Step: 30/54\t Train Loss: 3.828892\t Valid Loss: 4.312184\n",
      "Epoch: 575/2000\t Step: 45/54\t Train Loss: 3.864460\t Valid Loss: 4.340718\n",
      "Epoch: 576/2000\t Step: 15/54\t Train Loss: 3.901168\t Valid Loss: 4.269982\n",
      "Epoch: 576/2000\t Step: 30/54\t Train Loss: 3.800781\t Valid Loss: 4.710679\n",
      "Epoch: 576/2000\t Step: 45/54\t Train Loss: 3.781779\t Valid Loss: 4.479037\n",
      "Epoch: 577/2000\t Step: 15/54\t Train Loss: 3.928145\t Valid Loss: 4.316343\n",
      "Epoch: 577/2000\t Step: 30/54\t Train Loss: 3.823841\t Valid Loss: 4.317234\n",
      "Epoch: 577/2000\t Step: 45/54\t Train Loss: 3.870258\t Valid Loss: 4.380376\n",
      "Epoch: 578/2000\t Step: 15/54\t Train Loss: 3.825386\t Valid Loss: 4.601029\n",
      "Epoch: 578/2000\t Step: 30/54\t Train Loss: 3.787441\t Valid Loss: 4.462295\n",
      "Epoch: 578/2000\t Step: 45/54\t Train Loss: 3.829961\t Valid Loss: 4.349565\n",
      "Epoch: 579/2000\t Step: 15/54\t Train Loss: 3.834955\t Valid Loss: 4.402147\n",
      "Epoch: 579/2000\t Step: 30/54\t Train Loss: 3.805618\t Valid Loss: 4.447782\n",
      "Epoch: 579/2000\t Step: 45/54\t Train Loss: 3.822716\t Valid Loss: 4.359818\n",
      "Epoch: 580/2000\t Step: 15/54\t Train Loss: 3.850606\t Valid Loss: 4.331480\n",
      "Epoch: 580/2000\t Step: 30/54\t Train Loss: 3.826535\t Valid Loss: 4.259715\n",
      "Epoch: 580/2000\t Step: 45/54\t Train Loss: 3.848252\t Valid Loss: 4.483139\n",
      "Epoch: 581/2000\t Step: 15/54\t Train Loss: 3.828577\t Valid Loss: 4.448874\n",
      "Epoch: 581/2000\t Step: 30/54\t Train Loss: 3.771398\t Valid Loss: 4.676055\n",
      "Epoch: 581/2000\t Step: 45/54\t Train Loss: 3.794062\t Valid Loss: 4.304524\n",
      "Epoch: 582/2000\t Step: 15/54\t Train Loss: 3.882397\t Valid Loss: 4.311027\n",
      "Epoch: 582/2000\t Step: 30/54\t Train Loss: 3.796649\t Valid Loss: 4.360072\n",
      "Epoch: 582/2000\t Step: 45/54\t Train Loss: 3.891097\t Valid Loss: 4.263998\n",
      "Epoch: 583/2000\t Step: 15/54\t Train Loss: 3.860617\t Valid Loss: 4.322666\n",
      "Epoch: 583/2000\t Step: 30/54\t Train Loss: 3.879513\t Valid Loss: 4.395775\n",
      "Epoch: 583/2000\t Step: 45/54\t Train Loss: 3.819428\t Valid Loss: 4.342491\n",
      "Epoch: 584/2000\t Step: 15/54\t Train Loss: 3.851017\t Valid Loss: 4.431688\n",
      "Epoch: 584/2000\t Step: 30/54\t Train Loss: 3.810769\t Valid Loss: 4.673755\n",
      "Epoch: 584/2000\t Step: 45/54\t Train Loss: 3.739580\t Valid Loss: 4.654895\n",
      "Epoch: 585/2000\t Step: 15/54\t Train Loss: 3.764763\t Valid Loss: 4.628090\n",
      "Epoch: 585/2000\t Step: 30/54\t Train Loss: 3.864444\t Valid Loss: 4.588121\n",
      "Epoch: 585/2000\t Step: 45/54\t Train Loss: 3.876738\t Valid Loss: 4.244465\n",
      "Epoch: 586/2000\t Step: 15/54\t Train Loss: 3.902729\t Valid Loss: 4.418795\n",
      "Epoch: 586/2000\t Step: 30/54\t Train Loss: 3.894264\t Valid Loss: 4.350711\n",
      "Epoch: 586/2000\t Step: 45/54\t Train Loss: 3.822012\t Valid Loss: 4.514827\n",
      "Epoch: 587/2000\t Step: 15/54\t Train Loss: 3.898876\t Valid Loss: 4.330674\n",
      "Epoch: 587/2000\t Step: 30/54\t Train Loss: 3.764341\t Valid Loss: 4.544597\n",
      "Epoch: 587/2000\t Step: 45/54\t Train Loss: 3.869425\t Valid Loss: 4.522678\n",
      "Epoch: 588/2000\t Step: 15/54\t Train Loss: 3.851943\t Valid Loss: 4.507020\n",
      "Epoch: 588/2000\t Step: 30/54\t Train Loss: 3.796278\t Valid Loss: 4.509341\n",
      "Epoch: 588/2000\t Step: 45/54\t Train Loss: 3.924848\t Valid Loss: 4.388361\n",
      "Epoch: 589/2000\t Step: 15/54\t Train Loss: 3.810189\t Valid Loss: 4.448008\n",
      "Epoch: 589/2000\t Step: 30/54\t Train Loss: 3.867386\t Valid Loss: 4.552605\n",
      "Epoch: 589/2000\t Step: 45/54\t Train Loss: 3.829144\t Valid Loss: 4.407739\n",
      "Epoch: 590/2000\t Step: 15/54\t Train Loss: 3.967530\t Valid Loss: 4.268992\n",
      "Epoch: 590/2000\t Step: 30/54\t Train Loss: 3.792156\t Valid Loss: 4.333811\n",
      "Epoch: 590/2000\t Step: 45/54\t Train Loss: 3.786772\t Valid Loss: 4.447524\n",
      "Epoch: 591/2000\t Step: 15/54\t Train Loss: 3.837544\t Valid Loss: 4.495403\n",
      "Epoch: 591/2000\t Step: 30/54\t Train Loss: 3.830135\t Valid Loss: 4.336051\n",
      "Epoch: 591/2000\t Step: 45/54\t Train Loss: 3.818638\t Valid Loss: 4.507139\n",
      "Epoch: 592/2000\t Step: 15/54\t Train Loss: 3.834574\t Valid Loss: 4.205595\n",
      "Epoch: 592/2000\t Step: 30/54\t Train Loss: 3.846409\t Valid Loss: 4.296221\n",
      "Epoch: 592/2000\t Step: 45/54\t Train Loss: 3.896896\t Valid Loss: 4.504576\n",
      "Epoch: 593/2000\t Step: 15/54\t Train Loss: 3.766102\t Valid Loss: 4.512319\n",
      "Epoch: 593/2000\t Step: 30/54\t Train Loss: 3.809906\t Valid Loss: 4.405269\n",
      "Epoch: 593/2000\t Step: 45/54\t Train Loss: 3.845378\t Valid Loss: 4.466155\n",
      "Epoch: 594/2000\t Step: 15/54\t Train Loss: 3.820436\t Valid Loss: 4.474520\n",
      "Epoch: 594/2000\t Step: 30/54\t Train Loss: 3.809549\t Valid Loss: 4.407347\n",
      "Epoch: 594/2000\t Step: 45/54\t Train Loss: 3.857841\t Valid Loss: 4.573194\n",
      "Epoch: 595/2000\t Step: 15/54\t Train Loss: 3.816544\t Valid Loss: 4.585212\n",
      "Epoch: 595/2000\t Step: 30/54\t Train Loss: 3.836929\t Valid Loss: 4.536464\n",
      "Epoch: 595/2000\t Step: 45/54\t Train Loss: 3.840949\t Valid Loss: 4.336411\n",
      "Epoch: 596/2000\t Step: 15/54\t Train Loss: 3.864607\t Valid Loss: 4.256972\n",
      "Epoch: 596/2000\t Step: 30/54\t Train Loss: 3.807869\t Valid Loss: 4.439534\n",
      "Epoch: 596/2000\t Step: 45/54\t Train Loss: 3.856385\t Valid Loss: 4.330199\n",
      "Epoch: 597/2000\t Step: 15/54\t Train Loss: 3.837604\t Valid Loss: 4.301976\n",
      "Epoch: 597/2000\t Step: 30/54\t Train Loss: 3.823169\t Valid Loss: 4.439872\n",
      "Epoch: 597/2000\t Step: 45/54\t Train Loss: 3.815531\t Valid Loss: 4.379737\n",
      "Epoch: 598/2000\t Step: 15/54\t Train Loss: 3.816705\t Valid Loss: 4.304632\n",
      "Epoch: 598/2000\t Step: 30/54\t Train Loss: 3.814604\t Valid Loss: 4.444081\n",
      "Epoch: 598/2000\t Step: 45/54\t Train Loss: 3.782594\t Valid Loss: 4.399223\n",
      "Epoch: 599/2000\t Step: 15/54\t Train Loss: 3.797322\t Valid Loss: 4.554977\n",
      "Epoch: 599/2000\t Step: 30/54\t Train Loss: 3.853087\t Valid Loss: 4.411900\n",
      "Epoch: 599/2000\t Step: 45/54\t Train Loss: 3.830257\t Valid Loss: 4.463733\n",
      "Epoch: 600/2000\t Step: 15/54\t Train Loss: 3.837125\t Valid Loss: 4.510330\n",
      "Epoch: 600/2000\t Step: 30/54\t Train Loss: 3.809766\t Valid Loss: 4.404493\n",
      "Epoch: 600/2000\t Step: 45/54\t Train Loss: 3.803190\t Valid Loss: 4.392536\n",
      "Epoch: 601/2000\t Step: 15/54\t Train Loss: 3.835568\t Valid Loss: 4.527229\n",
      "Epoch: 601/2000\t Step: 30/54\t Train Loss: 3.943109\t Valid Loss: 4.273873\n",
      "Epoch: 601/2000\t Step: 45/54\t Train Loss: 3.796702\t Valid Loss: 4.524118\n",
      "Epoch: 602/2000\t Step: 15/54\t Train Loss: 3.826911\t Valid Loss: 4.352025\n",
      "Epoch: 602/2000\t Step: 30/54\t Train Loss: 3.799269\t Valid Loss: 4.358319\n",
      "Epoch: 602/2000\t Step: 45/54\t Train Loss: 3.880229\t Valid Loss: 4.450473\n",
      "Epoch: 603/2000\t Step: 15/54\t Train Loss: 3.827425\t Valid Loss: 4.426030\n",
      "Epoch: 603/2000\t Step: 30/54\t Train Loss: 3.822456\t Valid Loss: 4.416789\n",
      "Epoch: 603/2000\t Step: 45/54\t Train Loss: 3.856276\t Valid Loss: 4.467662\n",
      "Epoch: 604/2000\t Step: 15/54\t Train Loss: 3.841094\t Valid Loss: 4.394166\n",
      "Epoch: 604/2000\t Step: 30/54\t Train Loss: 3.840475\t Valid Loss: 4.489141\n",
      "Epoch: 604/2000\t Step: 45/54\t Train Loss: 3.853111\t Valid Loss: 4.288856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 605/2000\t Step: 15/54\t Train Loss: 3.841006\t Valid Loss: 4.252315\n",
      "Epoch: 605/2000\t Step: 30/54\t Train Loss: 3.905429\t Valid Loss: 4.204776\n",
      "Epoch: 605/2000\t Step: 45/54\t Train Loss: 4.009132\t Valid Loss: 4.233291\n",
      "Epoch: 606/2000\t Step: 15/54\t Train Loss: 3.773579\t Valid Loss: 4.427369\n",
      "Epoch: 606/2000\t Step: 30/54\t Train Loss: 3.836596\t Valid Loss: 4.517956\n",
      "Epoch: 606/2000\t Step: 45/54\t Train Loss: 3.843449\t Valid Loss: 4.393349\n",
      "Epoch: 607/2000\t Step: 15/54\t Train Loss: 3.818323\t Valid Loss: 4.483234\n",
      "Epoch: 607/2000\t Step: 30/54\t Train Loss: 3.824299\t Valid Loss: 4.315578\n",
      "Epoch: 607/2000\t Step: 45/54\t Train Loss: 3.781738\t Valid Loss: 4.271769\n",
      "Epoch: 608/2000\t Step: 15/54\t Train Loss: 3.821307\t Valid Loss: 4.420949\n",
      "Epoch: 608/2000\t Step: 30/54\t Train Loss: 3.838378\t Valid Loss: 4.531642\n",
      "Epoch: 608/2000\t Step: 45/54\t Train Loss: 3.844571\t Valid Loss: 4.382176\n",
      "Epoch: 609/2000\t Step: 15/54\t Train Loss: 3.852817\t Valid Loss: 4.472646\n",
      "Epoch: 609/2000\t Step: 30/54\t Train Loss: 3.851508\t Valid Loss: 4.513961\n",
      "Epoch: 609/2000\t Step: 45/54\t Train Loss: 3.819372\t Valid Loss: 4.526953\n",
      "Epoch: 610/2000\t Step: 15/54\t Train Loss: 3.857227\t Valid Loss: 4.512603\n",
      "Epoch: 610/2000\t Step: 30/54\t Train Loss: 3.826074\t Valid Loss: 4.597584\n",
      "Epoch: 610/2000\t Step: 45/54\t Train Loss: 3.989358\t Valid Loss: 4.524921\n",
      "Epoch: 611/2000\t Step: 15/54\t Train Loss: 3.822378\t Valid Loss: 4.526786\n",
      "Epoch: 611/2000\t Step: 30/54\t Train Loss: 3.865492\t Valid Loss: 4.507682\n",
      "Epoch: 611/2000\t Step: 45/54\t Train Loss: 3.798007\t Valid Loss: 4.477324\n",
      "Epoch: 612/2000\t Step: 15/54\t Train Loss: 3.842920\t Valid Loss: 4.386201\n",
      "Epoch: 612/2000\t Step: 30/54\t Train Loss: 3.792736\t Valid Loss: 4.376039\n",
      "Epoch: 612/2000\t Step: 45/54\t Train Loss: 3.865649\t Valid Loss: 4.498414\n",
      "Epoch: 613/2000\t Step: 15/54\t Train Loss: 3.881979\t Valid Loss: 4.531085\n",
      "Epoch: 613/2000\t Step: 30/54\t Train Loss: 3.832211\t Valid Loss: 4.276499\n",
      "Epoch: 613/2000\t Step: 45/54\t Train Loss: 3.773644\t Valid Loss: 4.643854\n",
      "Epoch: 614/2000\t Step: 15/54\t Train Loss: 3.845671\t Valid Loss: 4.434371\n",
      "Epoch: 614/2000\t Step: 30/54\t Train Loss: 3.817236\t Valid Loss: 4.413332\n",
      "Epoch: 614/2000\t Step: 45/54\t Train Loss: 3.806500\t Valid Loss: 4.365718\n",
      "Epoch: 615/2000\t Step: 15/54\t Train Loss: 3.844660\t Valid Loss: 4.240432\n",
      "Epoch: 615/2000\t Step: 30/54\t Train Loss: 3.870872\t Valid Loss: 4.439552\n",
      "Epoch: 615/2000\t Step: 45/54\t Train Loss: 3.838492\t Valid Loss: 4.349379\n",
      "Epoch: 616/2000\t Step: 15/54\t Train Loss: 3.854508\t Valid Loss: 4.521946\n",
      "Epoch: 616/2000\t Step: 30/54\t Train Loss: 3.864028\t Valid Loss: 4.374161\n",
      "Epoch: 616/2000\t Step: 45/54\t Train Loss: 3.795882\t Valid Loss: 4.347916\n",
      "Epoch: 617/2000\t Step: 15/54\t Train Loss: 3.822980\t Valid Loss: 4.373194\n",
      "Epoch: 617/2000\t Step: 30/54\t Train Loss: 3.767528\t Valid Loss: 4.377705\n",
      "Epoch: 617/2000\t Step: 45/54\t Train Loss: 3.833215\t Valid Loss: 4.387727\n",
      "Epoch: 618/2000\t Step: 15/54\t Train Loss: 3.772505\t Valid Loss: 4.320128\n",
      "Epoch: 618/2000\t Step: 30/54\t Train Loss: 3.874270\t Valid Loss: 4.365880\n",
      "Epoch: 618/2000\t Step: 45/54\t Train Loss: 3.799104\t Valid Loss: 4.433974\n",
      "Epoch: 619/2000\t Step: 15/54\t Train Loss: 3.819993\t Valid Loss: 4.502509\n",
      "Epoch: 619/2000\t Step: 30/54\t Train Loss: 3.824609\t Valid Loss: 4.442400\n",
      "Epoch: 619/2000\t Step: 45/54\t Train Loss: 3.846213\t Valid Loss: 4.456801\n",
      "Epoch: 620/2000\t Step: 15/54\t Train Loss: 3.863240\t Valid Loss: 4.296501\n",
      "Epoch: 620/2000\t Step: 30/54\t Train Loss: 3.827697\t Valid Loss: 4.312110\n",
      "Epoch: 620/2000\t Step: 45/54\t Train Loss: 3.776550\t Valid Loss: 4.464271\n",
      "Epoch: 621/2000\t Step: 15/54\t Train Loss: 3.837798\t Valid Loss: 4.365567\n",
      "Epoch: 621/2000\t Step: 30/54\t Train Loss: 3.779460\t Valid Loss: 4.618195\n",
      "Epoch: 621/2000\t Step: 45/54\t Train Loss: 3.761459\t Valid Loss: 4.383471\n",
      "Epoch: 622/2000\t Step: 15/54\t Train Loss: 3.827523\t Valid Loss: 4.395943\n",
      "Epoch: 622/2000\t Step: 30/54\t Train Loss: 3.846251\t Valid Loss: 4.464209\n",
      "Epoch: 622/2000\t Step: 45/54\t Train Loss: 3.798867\t Valid Loss: 4.468105\n",
      "Epoch: 623/2000\t Step: 15/54\t Train Loss: 3.819787\t Valid Loss: 4.455664\n",
      "Epoch: 623/2000\t Step: 30/54\t Train Loss: 3.836592\t Valid Loss: 4.492761\n",
      "Epoch: 623/2000\t Step: 45/54\t Train Loss: 3.785002\t Valid Loss: 4.375410\n",
      "Epoch: 624/2000\t Step: 15/54\t Train Loss: 3.816539\t Valid Loss: 4.679201\n",
      "Epoch: 624/2000\t Step: 30/54\t Train Loss: 3.843699\t Valid Loss: 4.548576\n",
      "Epoch: 624/2000\t Step: 45/54\t Train Loss: 3.802297\t Valid Loss: 4.541098\n",
      "Epoch: 625/2000\t Step: 15/54\t Train Loss: 3.938143\t Valid Loss: 4.531314\n",
      "Epoch: 625/2000\t Step: 30/54\t Train Loss: 3.853092\t Valid Loss: 4.703648\n",
      "Epoch: 625/2000\t Step: 45/54\t Train Loss: 3.830866\t Valid Loss: 4.431142\n",
      "Epoch: 626/2000\t Step: 15/54\t Train Loss: 3.802999\t Valid Loss: 4.423994\n",
      "Epoch: 626/2000\t Step: 30/54\t Train Loss: 3.827456\t Valid Loss: 4.266241\n",
      "Epoch: 626/2000\t Step: 45/54\t Train Loss: 3.837723\t Valid Loss: 4.630215\n",
      "Epoch: 627/2000\t Step: 15/54\t Train Loss: 3.873368\t Valid Loss: 4.461466\n",
      "Epoch: 627/2000\t Step: 30/54\t Train Loss: 3.845243\t Valid Loss: 4.280944\n",
      "Epoch: 627/2000\t Step: 45/54\t Train Loss: 3.796752\t Valid Loss: 4.403094\n",
      "Epoch: 628/2000\t Step: 15/54\t Train Loss: 3.865294\t Valid Loss: 4.754451\n",
      "Epoch: 628/2000\t Step: 30/54\t Train Loss: 3.799594\t Valid Loss: 4.596415\n",
      "Epoch: 628/2000\t Step: 45/54\t Train Loss: 3.860241\t Valid Loss: 4.322848\n",
      "Epoch: 629/2000\t Step: 15/54\t Train Loss: 3.830366\t Valid Loss: 4.360959\n",
      "Epoch: 629/2000\t Step: 30/54\t Train Loss: 3.837015\t Valid Loss: 4.436744\n",
      "Epoch: 629/2000\t Step: 45/54\t Train Loss: 3.851432\t Valid Loss: 4.358404\n",
      "Epoch: 630/2000\t Step: 15/54\t Train Loss: 3.839529\t Valid Loss: 4.456456\n",
      "Epoch: 630/2000\t Step: 30/54\t Train Loss: 3.887080\t Valid Loss: 4.377088\n",
      "Epoch: 630/2000\t Step: 45/54\t Train Loss: 3.854637\t Valid Loss: 4.375615\n",
      "Epoch: 631/2000\t Step: 15/54\t Train Loss: 3.796800\t Valid Loss: 4.356294\n",
      "Epoch: 631/2000\t Step: 30/54\t Train Loss: 3.824587\t Valid Loss: 4.513769\n",
      "Epoch: 631/2000\t Step: 45/54\t Train Loss: 3.812005\t Valid Loss: 4.533966\n",
      "Epoch: 632/2000\t Step: 15/54\t Train Loss: 3.942919\t Valid Loss: 4.452784\n",
      "Epoch: 632/2000\t Step: 30/54\t Train Loss: 3.812311\t Valid Loss: 4.398613\n",
      "Epoch: 632/2000\t Step: 45/54\t Train Loss: 3.834241\t Valid Loss: 4.494488\n",
      "Epoch: 633/2000\t Step: 15/54\t Train Loss: 3.796080\t Valid Loss: 4.409914\n",
      "Epoch: 633/2000\t Step: 30/54\t Train Loss: 3.799804\t Valid Loss: 4.623052\n",
      "Epoch: 633/2000\t Step: 45/54\t Train Loss: 3.825961\t Valid Loss: 4.421884\n",
      "Epoch: 634/2000\t Step: 15/54\t Train Loss: 3.866576\t Valid Loss: 4.434143\n",
      "Epoch: 634/2000\t Step: 30/54\t Train Loss: 3.808625\t Valid Loss: 4.447135\n",
      "Epoch: 634/2000\t Step: 45/54\t Train Loss: 3.852774\t Valid Loss: 4.649577\n",
      "Epoch: 635/2000\t Step: 15/54\t Train Loss: 3.833853\t Valid Loss: 4.496960\n",
      "Epoch: 635/2000\t Step: 30/54\t Train Loss: 3.823375\t Valid Loss: 4.397511\n",
      "Epoch: 635/2000\t Step: 45/54\t Train Loss: 3.863014\t Valid Loss: 4.271951\n",
      "Epoch: 636/2000\t Step: 15/54\t Train Loss: 3.824734\t Valid Loss: 4.368636\n",
      "Epoch: 636/2000\t Step: 30/54\t Train Loss: 3.769760\t Valid Loss: 4.512050\n",
      "Epoch: 636/2000\t Step: 45/54\t Train Loss: 3.832630\t Valid Loss: 4.354853\n",
      "Epoch: 637/2000\t Step: 15/54\t Train Loss: 3.774646\t Valid Loss: 4.488486\n",
      "Epoch: 637/2000\t Step: 30/54\t Train Loss: 3.781931\t Valid Loss: 4.372393\n",
      "Epoch: 637/2000\t Step: 45/54\t Train Loss: 3.851185\t Valid Loss: 4.515639\n",
      "Epoch: 638/2000\t Step: 15/54\t Train Loss: 3.816889\t Valid Loss: 4.289318\n",
      "Epoch: 638/2000\t Step: 30/54\t Train Loss: 3.846628\t Valid Loss: 4.486286\n",
      "Epoch: 638/2000\t Step: 45/54\t Train Loss: 3.804332\t Valid Loss: 4.425821\n",
      "Epoch: 639/2000\t Step: 15/54\t Train Loss: 3.916026\t Valid Loss: 4.479988\n",
      "Epoch: 639/2000\t Step: 30/54\t Train Loss: 3.841020\t Valid Loss: 4.261348\n",
      "Epoch: 639/2000\t Step: 45/54\t Train Loss: 3.831081\t Valid Loss: 4.349090\n",
      "Epoch: 640/2000\t Step: 15/54\t Train Loss: 3.826887\t Valid Loss: 4.452189\n",
      "Epoch: 640/2000\t Step: 30/54\t Train Loss: 3.844198\t Valid Loss: 4.245622\n",
      "Epoch: 640/2000\t Step: 45/54\t Train Loss: 3.842445\t Valid Loss: 4.390138\n",
      "Epoch: 641/2000\t Step: 15/54\t Train Loss: 3.803769\t Valid Loss: 4.523131\n",
      "Epoch: 641/2000\t Step: 30/54\t Train Loss: 3.852063\t Valid Loss: 4.350596\n",
      "Epoch: 641/2000\t Step: 45/54\t Train Loss: 3.836270\t Valid Loss: 4.406890\n",
      "Epoch: 642/2000\t Step: 15/54\t Train Loss: 3.865178\t Valid Loss: 4.327911\n",
      "Epoch: 642/2000\t Step: 30/54\t Train Loss: 3.926302\t Valid Loss: 4.479938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 642/2000\t Step: 45/54\t Train Loss: 3.905459\t Valid Loss: 4.376932\n",
      "Epoch: 643/2000\t Step: 15/54\t Train Loss: 3.791858\t Valid Loss: 4.519734\n",
      "Epoch: 643/2000\t Step: 30/54\t Train Loss: 3.897952\t Valid Loss: 4.385044\n",
      "Epoch: 643/2000\t Step: 45/54\t Train Loss: 3.868467\t Valid Loss: 4.410878\n",
      "Epoch: 644/2000\t Step: 15/54\t Train Loss: 3.805094\t Valid Loss: 4.314406\n",
      "Epoch: 644/2000\t Step: 30/54\t Train Loss: 3.800045\t Valid Loss: 4.728115\n",
      "Epoch: 644/2000\t Step: 45/54\t Train Loss: 3.812113\t Valid Loss: 4.405246\n",
      "Epoch: 645/2000\t Step: 15/54\t Train Loss: 3.806247\t Valid Loss: 4.420846\n",
      "Epoch: 645/2000\t Step: 30/54\t Train Loss: 3.878339\t Valid Loss: 4.555298\n",
      "Epoch: 645/2000\t Step: 45/54\t Train Loss: 3.919504\t Valid Loss: 4.780518\n",
      "Epoch: 646/2000\t Step: 15/54\t Train Loss: 3.838063\t Valid Loss: 4.444390\n",
      "Epoch: 646/2000\t Step: 30/54\t Train Loss: 3.909193\t Valid Loss: 4.619071\n",
      "Epoch: 646/2000\t Step: 45/54\t Train Loss: 3.827129\t Valid Loss: 4.300940\n",
      "Epoch: 647/2000\t Step: 15/54\t Train Loss: 3.824834\t Valid Loss: 4.314252\n",
      "Epoch: 647/2000\t Step: 30/54\t Train Loss: 3.909375\t Valid Loss: 4.507533\n",
      "Epoch: 647/2000\t Step: 45/54\t Train Loss: 3.793078\t Valid Loss: 4.569549\n",
      "Epoch: 648/2000\t Step: 15/54\t Train Loss: 3.889598\t Valid Loss: 4.581721\n",
      "Epoch: 648/2000\t Step: 30/54\t Train Loss: 3.873467\t Valid Loss: 4.438796\n",
      "Epoch: 648/2000\t Step: 45/54\t Train Loss: 3.805644\t Valid Loss: 4.514206\n",
      "Epoch: 649/2000\t Step: 15/54\t Train Loss: 3.838292\t Valid Loss: 4.392596\n",
      "Epoch: 649/2000\t Step: 30/54\t Train Loss: 3.843219\t Valid Loss: 4.484649\n",
      "Epoch: 649/2000\t Step: 45/54\t Train Loss: 3.835106\t Valid Loss: 4.691826\n",
      "Epoch: 650/2000\t Step: 15/54\t Train Loss: 3.842210\t Valid Loss: 4.589376\n",
      "Epoch: 650/2000\t Step: 30/54\t Train Loss: 3.824571\t Valid Loss: 4.267995\n",
      "Epoch: 650/2000\t Step: 45/54\t Train Loss: 3.844313\t Valid Loss: 4.498569\n",
      "Epoch: 651/2000\t Step: 15/54\t Train Loss: 3.804253\t Valid Loss: 4.418461\n",
      "Epoch: 651/2000\t Step: 30/54\t Train Loss: 3.823286\t Valid Loss: 4.262329\n",
      "Epoch: 651/2000\t Step: 45/54\t Train Loss: 3.879065\t Valid Loss: 4.323550\n",
      "Epoch: 652/2000\t Step: 15/54\t Train Loss: 3.852756\t Valid Loss: 4.447480\n",
      "Epoch: 652/2000\t Step: 30/54\t Train Loss: 3.870580\t Valid Loss: 4.308585\n",
      "Epoch: 652/2000\t Step: 45/54\t Train Loss: 3.815916\t Valid Loss: 4.256796\n",
      "Epoch: 653/2000\t Step: 15/54\t Train Loss: 3.811973\t Valid Loss: 4.525041\n",
      "Epoch: 653/2000\t Step: 30/54\t Train Loss: 3.809757\t Valid Loss: 4.386457\n",
      "Epoch: 653/2000\t Step: 45/54\t Train Loss: 3.813598\t Valid Loss: 4.876393\n",
      "Epoch: 654/2000\t Step: 15/54\t Train Loss: 3.870579\t Valid Loss: 4.408436\n",
      "Epoch: 654/2000\t Step: 30/54\t Train Loss: 3.834360\t Valid Loss: 4.432415\n",
      "Epoch: 654/2000\t Step: 45/54\t Train Loss: 3.823672\t Valid Loss: 4.372845\n",
      "Epoch: 655/2000\t Step: 15/54\t Train Loss: 3.841195\t Valid Loss: 4.545238\n",
      "Epoch: 655/2000\t Step: 30/54\t Train Loss: 3.818029\t Valid Loss: 4.385438\n",
      "Epoch: 655/2000\t Step: 45/54\t Train Loss: 3.804098\t Valid Loss: 4.363360\n",
      "Epoch: 656/2000\t Step: 15/54\t Train Loss: 3.927374\t Valid Loss: 4.382299\n",
      "Epoch: 656/2000\t Step: 30/54\t Train Loss: 3.823970\t Valid Loss: 4.703002\n",
      "Epoch: 656/2000\t Step: 45/54\t Train Loss: 3.806506\t Valid Loss: 4.430888\n",
      "Epoch: 657/2000\t Step: 15/54\t Train Loss: 3.817794\t Valid Loss: 4.216497\n",
      "Epoch: 657/2000\t Step: 30/54\t Train Loss: 3.848876\t Valid Loss: 4.572141\n",
      "Epoch: 657/2000\t Step: 45/54\t Train Loss: 3.810743\t Valid Loss: 4.469770\n",
      "Epoch: 658/2000\t Step: 15/54\t Train Loss: 3.797961\t Valid Loss: 4.560056\n",
      "Epoch: 658/2000\t Step: 30/54\t Train Loss: 3.795251\t Valid Loss: 4.431830\n",
      "Epoch: 658/2000\t Step: 45/54\t Train Loss: 3.822405\t Valid Loss: 4.297304\n",
      "Epoch: 659/2000\t Step: 15/54\t Train Loss: 3.775649\t Valid Loss: 4.543063\n",
      "Epoch: 659/2000\t Step: 30/54\t Train Loss: 3.830962\t Valid Loss: 4.488857\n",
      "Epoch: 659/2000\t Step: 45/54\t Train Loss: 3.877846\t Valid Loss: 4.350591\n",
      "Epoch: 660/2000\t Step: 15/54\t Train Loss: 3.876435\t Valid Loss: 4.530149\n",
      "Epoch: 660/2000\t Step: 30/54\t Train Loss: 3.840761\t Valid Loss: 4.560348\n",
      "Epoch: 660/2000\t Step: 45/54\t Train Loss: 3.816948\t Valid Loss: 4.291905\n",
      "Epoch: 661/2000\t Step: 15/54\t Train Loss: 3.814722\t Valid Loss: 4.327893\n",
      "Epoch: 661/2000\t Step: 30/54\t Train Loss: 3.885872\t Valid Loss: 4.582082\n",
      "Epoch: 661/2000\t Step: 45/54\t Train Loss: 3.888013\t Valid Loss: 4.358287\n",
      "Epoch: 662/2000\t Step: 15/54\t Train Loss: 3.824717\t Valid Loss: 4.334475\n",
      "Epoch: 662/2000\t Step: 30/54\t Train Loss: 3.791919\t Valid Loss: 4.293062\n",
      "Epoch: 662/2000\t Step: 45/54\t Train Loss: 3.861213\t Valid Loss: 4.554262\n",
      "Epoch: 663/2000\t Step: 15/54\t Train Loss: 3.840197\t Valid Loss: 4.380478\n",
      "Epoch: 663/2000\t Step: 30/54\t Train Loss: 3.844347\t Valid Loss: 4.381691\n",
      "Epoch: 663/2000\t Step: 45/54\t Train Loss: 3.798820\t Valid Loss: 4.510084\n",
      "Epoch: 664/2000\t Step: 15/54\t Train Loss: 3.793595\t Valid Loss: 4.311521\n",
      "Epoch: 664/2000\t Step: 30/54\t Train Loss: 3.792214\t Valid Loss: 4.500660\n",
      "Epoch: 664/2000\t Step: 45/54\t Train Loss: 3.881570\t Valid Loss: 4.447120\n",
      "Epoch: 665/2000\t Step: 15/54\t Train Loss: 3.798066\t Valid Loss: 4.564874\n",
      "Epoch: 665/2000\t Step: 30/54\t Train Loss: 3.840413\t Valid Loss: 4.316366\n",
      "Epoch: 665/2000\t Step: 45/54\t Train Loss: 3.889372\t Valid Loss: 4.283419\n",
      "Epoch: 666/2000\t Step: 15/54\t Train Loss: 3.886858\t Valid Loss: 4.540616\n",
      "Epoch: 666/2000\t Step: 30/54\t Train Loss: 3.792143\t Valid Loss: 4.352508\n",
      "Epoch: 666/2000\t Step: 45/54\t Train Loss: 3.806905\t Valid Loss: 4.438346\n",
      "Epoch: 667/2000\t Step: 15/54\t Train Loss: 3.816751\t Valid Loss: 4.378936\n",
      "Epoch: 667/2000\t Step: 30/54\t Train Loss: 3.832170\t Valid Loss: 4.429727\n",
      "Epoch: 667/2000\t Step: 45/54\t Train Loss: 3.861116\t Valid Loss: 4.532266\n",
      "Epoch: 668/2000\t Step: 15/54\t Train Loss: 3.870414\t Valid Loss: 4.514097\n",
      "Epoch: 668/2000\t Step: 30/54\t Train Loss: 3.775036\t Valid Loss: 4.521753\n",
      "Epoch: 668/2000\t Step: 45/54\t Train Loss: 3.795341\t Valid Loss: 4.429669\n",
      "Epoch: 669/2000\t Step: 15/54\t Train Loss: 3.795673\t Valid Loss: 4.494465\n",
      "Epoch: 669/2000\t Step: 30/54\t Train Loss: 3.791835\t Valid Loss: 4.395609\n",
      "Epoch: 669/2000\t Step: 45/54\t Train Loss: 3.842473\t Valid Loss: 4.257351\n",
      "Epoch: 670/2000\t Step: 15/54\t Train Loss: 3.879013\t Valid Loss: 4.578721\n",
      "Epoch: 670/2000\t Step: 30/54\t Train Loss: 3.823905\t Valid Loss: 4.412290\n",
      "Epoch: 670/2000\t Step: 45/54\t Train Loss: 3.838351\t Valid Loss: 4.338806\n",
      "Epoch: 671/2000\t Step: 15/54\t Train Loss: 3.849561\t Valid Loss: 4.340930\n",
      "Epoch: 671/2000\t Step: 30/54\t Train Loss: 3.895839\t Valid Loss: 4.335583\n",
      "Epoch: 671/2000\t Step: 45/54\t Train Loss: 3.772446\t Valid Loss: 4.509065\n",
      "Epoch: 672/2000\t Step: 15/54\t Train Loss: 3.805129\t Valid Loss: 4.485065\n",
      "Epoch: 672/2000\t Step: 30/54\t Train Loss: 3.787262\t Valid Loss: 4.518241\n",
      "Epoch: 672/2000\t Step: 45/54\t Train Loss: 3.877444\t Valid Loss: 4.502778\n",
      "Epoch: 673/2000\t Step: 15/54\t Train Loss: 3.868730\t Valid Loss: 4.305476\n",
      "Epoch: 673/2000\t Step: 30/54\t Train Loss: 3.830870\t Valid Loss: 4.490380\n",
      "Epoch: 673/2000\t Step: 45/54\t Train Loss: 3.847259\t Valid Loss: 4.479132\n",
      "Epoch: 674/2000\t Step: 15/54\t Train Loss: 3.806450\t Valid Loss: 4.386761\n",
      "Epoch: 674/2000\t Step: 30/54\t Train Loss: 3.793995\t Valid Loss: 4.511539\n",
      "Epoch: 674/2000\t Step: 45/54\t Train Loss: 3.811687\t Valid Loss: 4.272138\n",
      "Epoch: 675/2000\t Step: 15/54\t Train Loss: 3.744135\t Valid Loss: 4.817220\n",
      "Epoch: 675/2000\t Step: 30/54\t Train Loss: 3.812547\t Valid Loss: 4.539169\n",
      "Epoch: 675/2000\t Step: 45/54\t Train Loss: 3.797235\t Valid Loss: 4.419784\n",
      "Epoch: 676/2000\t Step: 15/54\t Train Loss: 3.869898\t Valid Loss: 4.447519\n",
      "Epoch: 676/2000\t Step: 30/54\t Train Loss: 3.788008\t Valid Loss: 4.367542\n",
      "Epoch: 676/2000\t Step: 45/54\t Train Loss: 3.803684\t Valid Loss: 4.679059\n",
      "Epoch: 677/2000\t Step: 15/54\t Train Loss: 3.829640\t Valid Loss: 4.391659\n",
      "Epoch: 677/2000\t Step: 30/54\t Train Loss: 3.885020\t Valid Loss: 4.484108\n",
      "Epoch: 677/2000\t Step: 45/54\t Train Loss: 3.783659\t Valid Loss: 4.479462\n",
      "Epoch: 678/2000\t Step: 15/54\t Train Loss: 3.788140\t Valid Loss: 4.548806\n",
      "Epoch: 678/2000\t Step: 30/54\t Train Loss: 3.797465\t Valid Loss: 4.544056\n",
      "Epoch: 678/2000\t Step: 45/54\t Train Loss: 3.822899\t Valid Loss: 4.528337\n",
      "Epoch: 679/2000\t Step: 15/54\t Train Loss: 3.835765\t Valid Loss: 4.521072\n",
      "Epoch: 679/2000\t Step: 30/54\t Train Loss: 3.823663\t Valid Loss: 4.559119\n",
      "Epoch: 679/2000\t Step: 45/54\t Train Loss: 3.760533\t Valid Loss: 4.797280\n",
      "Epoch: 680/2000\t Step: 15/54\t Train Loss: 3.900294\t Valid Loss: 4.353832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 680/2000\t Step: 30/54\t Train Loss: 3.848860\t Valid Loss: 4.460724\n",
      "Epoch: 680/2000\t Step: 45/54\t Train Loss: 3.801501\t Valid Loss: 4.485283\n",
      "Epoch: 681/2000\t Step: 15/54\t Train Loss: 3.860509\t Valid Loss: 4.396116\n",
      "Epoch: 681/2000\t Step: 30/54\t Train Loss: 3.896327\t Valid Loss: 4.497695\n",
      "Epoch: 681/2000\t Step: 45/54\t Train Loss: 3.827766\t Valid Loss: 4.590594\n",
      "Epoch: 682/2000\t Step: 15/54\t Train Loss: 3.814262\t Valid Loss: 4.367491\n",
      "Epoch: 682/2000\t Step: 30/54\t Train Loss: 3.817296\t Valid Loss: 4.414047\n",
      "Epoch: 682/2000\t Step: 45/54\t Train Loss: 3.796062\t Valid Loss: 4.363152\n",
      "Epoch: 683/2000\t Step: 15/54\t Train Loss: 3.838530\t Valid Loss: 4.406070\n",
      "Epoch: 683/2000\t Step: 30/54\t Train Loss: 3.833923\t Valid Loss: 4.352394\n",
      "Epoch: 683/2000\t Step: 45/54\t Train Loss: 3.782674\t Valid Loss: 4.577939\n",
      "Epoch: 684/2000\t Step: 15/54\t Train Loss: 3.767516\t Valid Loss: 4.571188\n",
      "Epoch: 684/2000\t Step: 30/54\t Train Loss: 3.805189\t Valid Loss: 4.387001\n",
      "Epoch: 684/2000\t Step: 45/54\t Train Loss: 3.844177\t Valid Loss: 4.347980\n",
      "Epoch: 685/2000\t Step: 15/54\t Train Loss: 3.792978\t Valid Loss: 4.424010\n",
      "Epoch: 685/2000\t Step: 30/54\t Train Loss: 3.752937\t Valid Loss: 4.509482\n",
      "Epoch: 685/2000\t Step: 45/54\t Train Loss: 3.926495\t Valid Loss: 4.519389\n",
      "Epoch: 686/2000\t Step: 15/54\t Train Loss: 3.968670\t Valid Loss: 4.430513\n",
      "Epoch: 686/2000\t Step: 30/54\t Train Loss: 3.829380\t Valid Loss: 4.483229\n",
      "Epoch: 686/2000\t Step: 45/54\t Train Loss: 3.827826\t Valid Loss: 4.550329\n",
      "Epoch: 687/2000\t Step: 15/54\t Train Loss: 3.787903\t Valid Loss: 4.345884\n",
      "Epoch: 687/2000\t Step: 30/54\t Train Loss: 3.829301\t Valid Loss: 4.516878\n",
      "Epoch: 687/2000\t Step: 45/54\t Train Loss: 3.893909\t Valid Loss: 4.441580\n",
      "Epoch: 688/2000\t Step: 15/54\t Train Loss: 3.918023\t Valid Loss: 4.450750\n",
      "Epoch: 688/2000\t Step: 30/54\t Train Loss: 3.850711\t Valid Loss: 4.464635\n",
      "Epoch: 688/2000\t Step: 45/54\t Train Loss: 3.786934\t Valid Loss: 4.482256\n",
      "Epoch: 689/2000\t Step: 15/54\t Train Loss: 3.847558\t Valid Loss: 4.585374\n",
      "Epoch: 689/2000\t Step: 30/54\t Train Loss: 3.808629\t Valid Loss: 4.722341\n",
      "Epoch: 689/2000\t Step: 45/54\t Train Loss: 3.767725\t Valid Loss: 4.651434\n",
      "Epoch: 690/2000\t Step: 15/54\t Train Loss: 3.833058\t Valid Loss: 4.264784\n",
      "Epoch: 690/2000\t Step: 30/54\t Train Loss: 3.776771\t Valid Loss: 4.566318\n",
      "Epoch: 690/2000\t Step: 45/54\t Train Loss: 3.836370\t Valid Loss: 4.369410\n",
      "Epoch: 691/2000\t Step: 15/54\t Train Loss: 3.840461\t Valid Loss: 4.718403\n",
      "Epoch: 691/2000\t Step: 30/54\t Train Loss: 3.824466\t Valid Loss: 4.428364\n",
      "Epoch: 691/2000\t Step: 45/54\t Train Loss: 3.788395\t Valid Loss: 4.320553\n",
      "Epoch: 692/2000\t Step: 15/54\t Train Loss: 3.820384\t Valid Loss: 4.655697\n",
      "Epoch: 692/2000\t Step: 30/54\t Train Loss: 3.789869\t Valid Loss: 4.750634\n",
      "Epoch: 692/2000\t Step: 45/54\t Train Loss: 3.832972\t Valid Loss: 4.391541\n",
      "Epoch: 693/2000\t Step: 15/54\t Train Loss: 3.905436\t Valid Loss: 4.279965\n",
      "Epoch: 693/2000\t Step: 30/54\t Train Loss: 3.904652\t Valid Loss: 4.448923\n",
      "Epoch: 693/2000\t Step: 45/54\t Train Loss: 3.864026\t Valid Loss: 4.340147\n",
      "Epoch: 694/2000\t Step: 15/54\t Train Loss: 3.875607\t Valid Loss: 4.356732\n",
      "Epoch: 694/2000\t Step: 30/54\t Train Loss: 3.779118\t Valid Loss: 4.413947\n",
      "Epoch: 694/2000\t Step: 45/54\t Train Loss: 3.882140\t Valid Loss: 4.416716\n",
      "Epoch: 695/2000\t Step: 15/54\t Train Loss: 3.843557\t Valid Loss: 4.308252\n",
      "Epoch: 695/2000\t Step: 30/54\t Train Loss: 3.770323\t Valid Loss: 4.414020\n",
      "Epoch: 695/2000\t Step: 45/54\t Train Loss: 3.826259\t Valid Loss: 4.469240\n",
      "Epoch: 696/2000\t Step: 15/54\t Train Loss: 3.802106\t Valid Loss: 4.703614\n",
      "Epoch: 696/2000\t Step: 30/54\t Train Loss: 3.797481\t Valid Loss: 4.450826\n",
      "Epoch: 696/2000\t Step: 45/54\t Train Loss: 3.772126\t Valid Loss: 4.535878\n",
      "Epoch: 697/2000\t Step: 15/54\t Train Loss: 3.808518\t Valid Loss: 4.444995\n",
      "Epoch: 697/2000\t Step: 30/54\t Train Loss: 3.756436\t Valid Loss: 4.722045\n",
      "Epoch: 697/2000\t Step: 45/54\t Train Loss: 3.777754\t Valid Loss: 4.251325\n",
      "Epoch: 698/2000\t Step: 15/54\t Train Loss: 3.877796\t Valid Loss: 4.422672\n",
      "Epoch: 698/2000\t Step: 30/54\t Train Loss: 3.812330\t Valid Loss: 4.425006\n",
      "Epoch: 698/2000\t Step: 45/54\t Train Loss: 3.822948\t Valid Loss: 4.375126\n",
      "Epoch: 699/2000\t Step: 15/54\t Train Loss: 3.807645\t Valid Loss: 4.687675\n",
      "Epoch: 699/2000\t Step: 30/54\t Train Loss: 3.875926\t Valid Loss: 4.470014\n",
      "Epoch: 699/2000\t Step: 45/54\t Train Loss: 3.804141\t Valid Loss: 4.656859\n",
      "Epoch: 700/2000\t Step: 15/54\t Train Loss: 3.837471\t Valid Loss: 4.388817\n",
      "Epoch: 700/2000\t Step: 30/54\t Train Loss: 3.815074\t Valid Loss: 4.296462\n",
      "Epoch: 700/2000\t Step: 45/54\t Train Loss: 3.818438\t Valid Loss: 4.437824\n",
      "Epoch: 701/2000\t Step: 15/54\t Train Loss: 3.824982\t Valid Loss: 4.545392\n",
      "Epoch: 701/2000\t Step: 30/54\t Train Loss: 3.776378\t Valid Loss: 4.536565\n",
      "Epoch: 701/2000\t Step: 45/54\t Train Loss: 3.798794\t Valid Loss: 4.457653\n",
      "Epoch: 702/2000\t Step: 15/54\t Train Loss: 3.774165\t Valid Loss: 4.624246\n",
      "Epoch: 702/2000\t Step: 30/54\t Train Loss: 3.867096\t Valid Loss: 4.387049\n",
      "Epoch: 702/2000\t Step: 45/54\t Train Loss: 3.875723\t Valid Loss: 4.457531\n",
      "Epoch: 703/2000\t Step: 15/54\t Train Loss: 3.845815\t Valid Loss: 4.682444\n",
      "Epoch: 703/2000\t Step: 30/54\t Train Loss: 3.848601\t Valid Loss: 4.425867\n",
      "Epoch: 703/2000\t Step: 45/54\t Train Loss: 3.811129\t Valid Loss: 4.668074\n",
      "Epoch: 704/2000\t Step: 15/54\t Train Loss: 3.843903\t Valid Loss: 4.371126\n",
      "Epoch: 704/2000\t Step: 30/54\t Train Loss: 3.774502\t Valid Loss: 4.534676\n",
      "Epoch: 704/2000\t Step: 45/54\t Train Loss: 3.778415\t Valid Loss: 4.712555\n",
      "Epoch: 705/2000\t Step: 15/54\t Train Loss: 3.828352\t Valid Loss: 4.640008\n",
      "Epoch: 705/2000\t Step: 30/54\t Train Loss: 3.831996\t Valid Loss: 4.661246\n",
      "Epoch: 705/2000\t Step: 45/54\t Train Loss: 3.790252\t Valid Loss: 4.488201\n",
      "Epoch: 706/2000\t Step: 15/54\t Train Loss: 3.808809\t Valid Loss: 4.483414\n",
      "Epoch: 706/2000\t Step: 30/54\t Train Loss: 3.943034\t Valid Loss: 4.240722\n",
      "Epoch: 706/2000\t Step: 45/54\t Train Loss: 3.898572\t Valid Loss: 4.571635\n",
      "Epoch: 707/2000\t Step: 15/54\t Train Loss: 3.846772\t Valid Loss: 4.364059\n",
      "Epoch: 707/2000\t Step: 30/54\t Train Loss: 3.837361\t Valid Loss: 4.468169\n",
      "Epoch: 707/2000\t Step: 45/54\t Train Loss: 3.817457\t Valid Loss: 4.440610\n",
      "Epoch: 708/2000\t Step: 15/54\t Train Loss: 3.857699\t Valid Loss: 4.579597\n",
      "Epoch: 708/2000\t Step: 30/54\t Train Loss: 3.799977\t Valid Loss: 4.487706\n",
      "Epoch: 708/2000\t Step: 45/54\t Train Loss: 3.891489\t Valid Loss: 4.515561\n",
      "Epoch: 709/2000\t Step: 15/54\t Train Loss: 3.799852\t Valid Loss: 4.419929\n",
      "Epoch: 709/2000\t Step: 30/54\t Train Loss: 3.823618\t Valid Loss: 4.313792\n",
      "Epoch: 709/2000\t Step: 45/54\t Train Loss: 3.885560\t Valid Loss: 4.346840\n",
      "Epoch: 710/2000\t Step: 15/54\t Train Loss: 3.848804\t Valid Loss: 4.521105\n",
      "Epoch: 710/2000\t Step: 30/54\t Train Loss: 3.866081\t Valid Loss: 4.511709\n",
      "Epoch: 710/2000\t Step: 45/54\t Train Loss: 3.792995\t Valid Loss: 4.493383\n",
      "Epoch: 711/2000\t Step: 15/54\t Train Loss: 3.794545\t Valid Loss: 4.504491\n",
      "Epoch: 711/2000\t Step: 30/54\t Train Loss: 3.776695\t Valid Loss: 4.488809\n",
      "Epoch: 711/2000\t Step: 45/54\t Train Loss: 3.789743\t Valid Loss: 4.534850\n",
      "Epoch: 712/2000\t Step: 15/54\t Train Loss: 3.824178\t Valid Loss: 4.296800\n",
      "Epoch: 712/2000\t Step: 30/54\t Train Loss: 3.808424\t Valid Loss: 4.377190\n",
      "Epoch: 712/2000\t Step: 45/54\t Train Loss: 3.896058\t Valid Loss: 4.571980\n",
      "Epoch: 713/2000\t Step: 15/54\t Train Loss: 3.814947\t Valid Loss: 4.496429\n",
      "Epoch: 713/2000\t Step: 30/54\t Train Loss: 3.813112\t Valid Loss: 4.575933\n",
      "Epoch: 713/2000\t Step: 45/54\t Train Loss: 3.752213\t Valid Loss: 4.586963\n",
      "Epoch: 714/2000\t Step: 15/54\t Train Loss: 3.857544\t Valid Loss: 4.488598\n",
      "Epoch: 714/2000\t Step: 30/54\t Train Loss: 3.853449\t Valid Loss: 4.560550\n",
      "Epoch: 714/2000\t Step: 45/54\t Train Loss: 3.807126\t Valid Loss: 4.509121\n",
      "Epoch: 715/2000\t Step: 15/54\t Train Loss: 3.806870\t Valid Loss: 4.427707\n",
      "Epoch: 715/2000\t Step: 30/54\t Train Loss: 3.735912\t Valid Loss: 4.478912\n",
      "Epoch: 715/2000\t Step: 45/54\t Train Loss: 3.824457\t Valid Loss: 4.491095\n",
      "Epoch: 716/2000\t Step: 15/54\t Train Loss: 3.834130\t Valid Loss: 4.429090\n",
      "Epoch: 716/2000\t Step: 30/54\t Train Loss: 3.847386\t Valid Loss: 4.286954\n",
      "Epoch: 716/2000\t Step: 45/54\t Train Loss: 3.805380\t Valid Loss: 4.321380\n",
      "Epoch: 717/2000\t Step: 15/54\t Train Loss: 3.864888\t Valid Loss: 4.377215\n",
      "Epoch: 717/2000\t Step: 30/54\t Train Loss: 3.857484\t Valid Loss: 4.385247\n",
      "Epoch: 717/2000\t Step: 45/54\t Train Loss: 3.761554\t Valid Loss: 4.400434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 718/2000\t Step: 15/54\t Train Loss: 3.772660\t Valid Loss: 4.566228\n",
      "Epoch: 718/2000\t Step: 30/54\t Train Loss: 3.786863\t Valid Loss: 4.506336\n",
      "Epoch: 718/2000\t Step: 45/54\t Train Loss: 3.805197\t Valid Loss: 4.552806\n",
      "Epoch: 719/2000\t Step: 15/54\t Train Loss: 3.798724\t Valid Loss: 4.460484\n",
      "Epoch: 719/2000\t Step: 30/54\t Train Loss: 3.807626\t Valid Loss: 4.486492\n",
      "Epoch: 719/2000\t Step: 45/54\t Train Loss: 3.816878\t Valid Loss: 4.430925\n",
      "Epoch: 720/2000\t Step: 15/54\t Train Loss: 3.765277\t Valid Loss: 4.417728\n",
      "Epoch: 720/2000\t Step: 30/54\t Train Loss: 3.779091\t Valid Loss: 4.516335\n",
      "Epoch: 720/2000\t Step: 45/54\t Train Loss: 3.826298\t Valid Loss: 4.402402\n",
      "Epoch: 721/2000\t Step: 15/54\t Train Loss: 3.779995\t Valid Loss: 4.363928\n",
      "Epoch: 721/2000\t Step: 30/54\t Train Loss: 3.789371\t Valid Loss: 4.363775\n",
      "Epoch: 721/2000\t Step: 45/54\t Train Loss: 3.811316\t Valid Loss: 4.575073\n",
      "Epoch: 722/2000\t Step: 15/54\t Train Loss: 3.885680\t Valid Loss: 4.367435\n",
      "Epoch: 722/2000\t Step: 30/54\t Train Loss: 3.798269\t Valid Loss: 4.633662\n",
      "Epoch: 722/2000\t Step: 45/54\t Train Loss: 3.873093\t Valid Loss: 4.390357\n",
      "Epoch: 723/2000\t Step: 15/54\t Train Loss: 3.788673\t Valid Loss: 4.432947\n",
      "Epoch: 723/2000\t Step: 30/54\t Train Loss: 3.771131\t Valid Loss: 4.723255\n",
      "Epoch: 723/2000\t Step: 45/54\t Train Loss: 3.879535\t Valid Loss: 4.568406\n",
      "Epoch: 724/2000\t Step: 15/54\t Train Loss: 3.899705\t Valid Loss: 4.451541\n",
      "Epoch: 724/2000\t Step: 30/54\t Train Loss: 3.774308\t Valid Loss: 4.629166\n",
      "Epoch: 724/2000\t Step: 45/54\t Train Loss: 3.756968\t Valid Loss: 4.753288\n",
      "Epoch: 725/2000\t Step: 15/54\t Train Loss: 3.809280\t Valid Loss: 4.500490\n",
      "Epoch: 725/2000\t Step: 30/54\t Train Loss: 3.901685\t Valid Loss: 4.476627\n",
      "Epoch: 725/2000\t Step: 45/54\t Train Loss: 3.751150\t Valid Loss: 4.374045\n",
      "Epoch: 726/2000\t Step: 15/54\t Train Loss: 3.798489\t Valid Loss: 4.767296\n",
      "Epoch: 726/2000\t Step: 30/54\t Train Loss: 3.788584\t Valid Loss: 4.519988\n",
      "Epoch: 726/2000\t Step: 45/54\t Train Loss: 3.897446\t Valid Loss: 4.522220\n",
      "Epoch: 727/2000\t Step: 15/54\t Train Loss: 3.899700\t Valid Loss: 4.518550\n",
      "Epoch: 727/2000\t Step: 30/54\t Train Loss: 3.827106\t Valid Loss: 4.509651\n",
      "Epoch: 727/2000\t Step: 45/54\t Train Loss: 3.806541\t Valid Loss: 4.403608\n",
      "Epoch: 728/2000\t Step: 15/54\t Train Loss: 3.779757\t Valid Loss: 4.549144\n",
      "Epoch: 728/2000\t Step: 30/54\t Train Loss: 3.839641\t Valid Loss: 4.740262\n",
      "Epoch: 728/2000\t Step: 45/54\t Train Loss: 3.819221\t Valid Loss: 4.555671\n",
      "Epoch: 729/2000\t Step: 15/54\t Train Loss: 3.773672\t Valid Loss: 4.479140\n",
      "Epoch: 729/2000\t Step: 30/54\t Train Loss: 3.771065\t Valid Loss: 4.653374\n",
      "Epoch: 729/2000\t Step: 45/54\t Train Loss: 3.759488\t Valid Loss: 4.558894\n",
      "Epoch: 730/2000\t Step: 15/54\t Train Loss: 3.826934\t Valid Loss: 4.434625\n",
      "Epoch: 730/2000\t Step: 30/54\t Train Loss: 3.817130\t Valid Loss: 4.709929\n",
      "Epoch: 730/2000\t Step: 45/54\t Train Loss: 3.858272\t Valid Loss: 4.427484\n",
      "Epoch: 731/2000\t Step: 15/54\t Train Loss: 3.783192\t Valid Loss: 4.501567\n",
      "Epoch: 731/2000\t Step: 30/54\t Train Loss: 3.886104\t Valid Loss: 4.462403\n",
      "Epoch: 731/2000\t Step: 45/54\t Train Loss: 3.898646\t Valid Loss: 4.376518\n",
      "Epoch: 732/2000\t Step: 15/54\t Train Loss: 3.839343\t Valid Loss: 4.293289\n",
      "Epoch: 732/2000\t Step: 30/54\t Train Loss: 3.831492\t Valid Loss: 4.479215\n",
      "Epoch: 732/2000\t Step: 45/54\t Train Loss: 3.804374\t Valid Loss: 4.617981\n",
      "Epoch: 733/2000\t Step: 15/54\t Train Loss: 3.798267\t Valid Loss: 4.582979\n",
      "Epoch: 733/2000\t Step: 30/54\t Train Loss: 3.780929\t Valid Loss: 4.456420\n",
      "Epoch: 733/2000\t Step: 45/54\t Train Loss: 3.858844\t Valid Loss: 4.575320\n",
      "Epoch: 734/2000\t Step: 15/54\t Train Loss: 3.817376\t Valid Loss: 4.447396\n",
      "Epoch: 734/2000\t Step: 30/54\t Train Loss: 3.883394\t Valid Loss: 4.232830\n",
      "Epoch: 734/2000\t Step: 45/54\t Train Loss: 3.806411\t Valid Loss: 4.334019\n",
      "Epoch: 735/2000\t Step: 15/54\t Train Loss: 3.870114\t Valid Loss: 4.338120\n",
      "Epoch: 735/2000\t Step: 30/54\t Train Loss: 3.795210\t Valid Loss: 4.518249\n",
      "Epoch: 735/2000\t Step: 45/54\t Train Loss: 3.790760\t Valid Loss: 4.619117\n",
      "Epoch: 736/2000\t Step: 15/54\t Train Loss: 3.807706\t Valid Loss: 4.769816\n",
      "Epoch: 736/2000\t Step: 30/54\t Train Loss: 3.815433\t Valid Loss: 4.394397\n",
      "Epoch: 736/2000\t Step: 45/54\t Train Loss: 3.816962\t Valid Loss: 4.669293\n",
      "Epoch: 737/2000\t Step: 15/54\t Train Loss: 3.817369\t Valid Loss: 4.409602\n",
      "Epoch: 737/2000\t Step: 30/54\t Train Loss: 3.787871\t Valid Loss: 4.760360\n",
      "Epoch: 737/2000\t Step: 45/54\t Train Loss: 3.758673\t Valid Loss: 4.682093\n",
      "Epoch: 738/2000\t Step: 15/54\t Train Loss: 3.803945\t Valid Loss: 4.746182\n",
      "Epoch: 738/2000\t Step: 30/54\t Train Loss: 3.873243\t Valid Loss: 4.557220\n",
      "Epoch: 738/2000\t Step: 45/54\t Train Loss: 3.918349\t Valid Loss: 4.493444\n",
      "Epoch: 739/2000\t Step: 15/54\t Train Loss: 3.828844\t Valid Loss: 4.513692\n",
      "Epoch: 739/2000\t Step: 30/54\t Train Loss: 3.749797\t Valid Loss: 4.578750\n",
      "Epoch: 739/2000\t Step: 45/54\t Train Loss: 3.810091\t Valid Loss: 4.476855\n",
      "Epoch: 740/2000\t Step: 15/54\t Train Loss: 3.815629\t Valid Loss: 4.567490\n",
      "Epoch: 740/2000\t Step: 30/54\t Train Loss: 3.859954\t Valid Loss: 4.534128\n",
      "Epoch: 740/2000\t Step: 45/54\t Train Loss: 3.791768\t Valid Loss: 4.367354\n",
      "Epoch: 741/2000\t Step: 15/54\t Train Loss: 3.840353\t Valid Loss: 4.653830\n",
      "Epoch: 741/2000\t Step: 30/54\t Train Loss: 3.829134\t Valid Loss: 4.449536\n",
      "Epoch: 741/2000\t Step: 45/54\t Train Loss: 3.877101\t Valid Loss: 4.411247\n",
      "Epoch: 742/2000\t Step: 15/54\t Train Loss: 3.923662\t Valid Loss: 4.237716\n",
      "Epoch: 742/2000\t Step: 30/54\t Train Loss: 3.792428\t Valid Loss: 4.485731\n",
      "Epoch: 742/2000\t Step: 45/54\t Train Loss: 3.835578\t Valid Loss: 4.397118\n",
      "Epoch: 743/2000\t Step: 15/54\t Train Loss: 3.788480\t Valid Loss: 4.496372\n",
      "Epoch: 743/2000\t Step: 30/54\t Train Loss: 3.831396\t Valid Loss: 4.557601\n",
      "Epoch: 743/2000\t Step: 45/54\t Train Loss: 3.825104\t Valid Loss: 4.625217\n",
      "Epoch: 744/2000\t Step: 15/54\t Train Loss: 3.806006\t Valid Loss: 4.667218\n",
      "Epoch: 744/2000\t Step: 30/54\t Train Loss: 3.842779\t Valid Loss: 4.573827\n",
      "Epoch: 744/2000\t Step: 45/54\t Train Loss: 3.779031\t Valid Loss: 4.699664\n",
      "Epoch: 745/2000\t Step: 15/54\t Train Loss: 3.783354\t Valid Loss: 4.699606\n",
      "Epoch: 745/2000\t Step: 30/54\t Train Loss: 3.792404\t Valid Loss: 4.445162\n",
      "Epoch: 745/2000\t Step: 45/54\t Train Loss: 3.793000\t Valid Loss: 4.533224\n",
      "Epoch: 746/2000\t Step: 15/54\t Train Loss: 3.800711\t Valid Loss: 4.466102\n",
      "Epoch: 746/2000\t Step: 30/54\t Train Loss: 3.740421\t Valid Loss: 4.364202\n",
      "Epoch: 746/2000\t Step: 45/54\t Train Loss: 3.790398\t Valid Loss: 4.588554\n",
      "Epoch: 747/2000\t Step: 15/54\t Train Loss: 3.792757\t Valid Loss: 4.414286\n",
      "Epoch: 747/2000\t Step: 30/54\t Train Loss: 3.794823\t Valid Loss: 4.520467\n",
      "Epoch: 747/2000\t Step: 45/54\t Train Loss: 3.758605\t Valid Loss: 4.498724\n",
      "Epoch: 748/2000\t Step: 15/54\t Train Loss: 3.781937\t Valid Loss: 4.375802\n",
      "Epoch: 748/2000\t Step: 30/54\t Train Loss: 3.815506\t Valid Loss: 4.620399\n",
      "Epoch: 748/2000\t Step: 45/54\t Train Loss: 3.827523\t Valid Loss: 4.580710\n",
      "Epoch: 749/2000\t Step: 15/54\t Train Loss: 3.746811\t Valid Loss: 4.592904\n",
      "Epoch: 749/2000\t Step: 30/54\t Train Loss: 3.819710\t Valid Loss: 4.471701\n",
      "Epoch: 749/2000\t Step: 45/54\t Train Loss: 3.836654\t Valid Loss: 4.368557\n",
      "Epoch: 750/2000\t Step: 15/54\t Train Loss: 3.828914\t Valid Loss: 4.554816\n",
      "Epoch: 750/2000\t Step: 30/54\t Train Loss: 3.910557\t Valid Loss: 4.690430\n",
      "Epoch: 750/2000\t Step: 45/54\t Train Loss: 3.860998\t Valid Loss: 4.463628\n",
      "Epoch: 751/2000\t Step: 15/54\t Train Loss: 3.813713\t Valid Loss: 4.335687\n",
      "Epoch: 751/2000\t Step: 30/54\t Train Loss: 3.771973\t Valid Loss: 4.398522\n",
      "Epoch: 751/2000\t Step: 45/54\t Train Loss: 3.802927\t Valid Loss: 4.339930\n",
      "Epoch: 752/2000\t Step: 15/54\t Train Loss: 3.777208\t Valid Loss: 4.695454\n",
      "Epoch: 752/2000\t Step: 30/54\t Train Loss: 3.817379\t Valid Loss: 4.499392\n",
      "Epoch: 752/2000\t Step: 45/54\t Train Loss: 3.792141\t Valid Loss: 4.500286\n",
      "Epoch: 753/2000\t Step: 15/54\t Train Loss: 3.803162\t Valid Loss: 4.568877\n",
      "Epoch: 753/2000\t Step: 30/54\t Train Loss: 3.842325\t Valid Loss: 4.464324\n",
      "Epoch: 753/2000\t Step: 45/54\t Train Loss: 3.760161\t Valid Loss: 4.356625\n",
      "Epoch: 754/2000\t Step: 15/54\t Train Loss: 3.824801\t Valid Loss: 4.546818\n",
      "Epoch: 754/2000\t Step: 30/54\t Train Loss: 3.812796\t Valid Loss: 4.473618\n",
      "Epoch: 754/2000\t Step: 45/54\t Train Loss: 3.779794\t Valid Loss: 4.571710\n",
      "Epoch: 755/2000\t Step: 15/54\t Train Loss: 3.797295\t Valid Loss: 4.772977\n",
      "Epoch: 755/2000\t Step: 30/54\t Train Loss: 3.797565\t Valid Loss: 4.457151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 755/2000\t Step: 45/54\t Train Loss: 3.858166\t Valid Loss: 4.443076\n",
      "Epoch: 756/2000\t Step: 15/54\t Train Loss: 3.814710\t Valid Loss: 4.524317\n",
      "Epoch: 756/2000\t Step: 30/54\t Train Loss: 3.789138\t Valid Loss: 4.657928\n",
      "Epoch: 756/2000\t Step: 45/54\t Train Loss: 3.856337\t Valid Loss: 4.576057\n",
      "Epoch: 757/2000\t Step: 15/54\t Train Loss: 3.827021\t Valid Loss: 4.471979\n",
      "Epoch: 757/2000\t Step: 30/54\t Train Loss: 3.805915\t Valid Loss: 4.400860\n",
      "Epoch: 757/2000\t Step: 45/54\t Train Loss: 3.741203\t Valid Loss: 4.583377\n",
      "Epoch: 758/2000\t Step: 15/54\t Train Loss: 3.822072\t Valid Loss: 4.779920\n",
      "Epoch: 758/2000\t Step: 30/54\t Train Loss: 3.838720\t Valid Loss: 4.508720\n",
      "Epoch: 758/2000\t Step: 45/54\t Train Loss: 3.819310\t Valid Loss: 4.568299\n",
      "Epoch: 759/2000\t Step: 15/54\t Train Loss: 3.814718\t Valid Loss: 4.481803\n",
      "Epoch: 759/2000\t Step: 30/54\t Train Loss: 3.830778\t Valid Loss: 4.712121\n",
      "Epoch: 759/2000\t Step: 45/54\t Train Loss: 3.796312\t Valid Loss: 4.446010\n",
      "Epoch: 760/2000\t Step: 15/54\t Train Loss: 3.808390\t Valid Loss: 4.377326\n",
      "Epoch: 760/2000\t Step: 30/54\t Train Loss: 3.825655\t Valid Loss: 4.562313\n",
      "Epoch: 760/2000\t Step: 45/54\t Train Loss: 3.799276\t Valid Loss: 4.487869\n",
      "Epoch: 761/2000\t Step: 15/54\t Train Loss: 3.823343\t Valid Loss: 4.463215\n",
      "Epoch: 761/2000\t Step: 30/54\t Train Loss: 3.885467\t Valid Loss: 4.628227\n",
      "Epoch: 761/2000\t Step: 45/54\t Train Loss: 3.852818\t Valid Loss: 4.923535\n",
      "Epoch: 762/2000\t Step: 15/54\t Train Loss: 3.799074\t Valid Loss: 4.489585\n",
      "Epoch: 762/2000\t Step: 30/54\t Train Loss: 3.797822\t Valid Loss: 4.456427\n",
      "Epoch: 762/2000\t Step: 45/54\t Train Loss: 3.776883\t Valid Loss: 4.497805\n",
      "Epoch: 763/2000\t Step: 15/54\t Train Loss: 3.873459\t Valid Loss: 4.507860\n",
      "Epoch: 763/2000\t Step: 30/54\t Train Loss: 3.864982\t Valid Loss: 4.501280\n",
      "Epoch: 763/2000\t Step: 45/54\t Train Loss: 3.856784\t Valid Loss: 4.655456\n",
      "Epoch: 764/2000\t Step: 15/54\t Train Loss: 3.870797\t Valid Loss: 4.595728\n",
      "Epoch: 764/2000\t Step: 30/54\t Train Loss: 3.913111\t Valid Loss: 4.625343\n",
      "Epoch: 764/2000\t Step: 45/54\t Train Loss: 3.854419\t Valid Loss: 4.284529\n",
      "Epoch: 765/2000\t Step: 15/54\t Train Loss: 3.861851\t Valid Loss: 4.289951\n",
      "Epoch: 765/2000\t Step: 30/54\t Train Loss: 3.867553\t Valid Loss: 4.236602\n",
      "Epoch: 765/2000\t Step: 45/54\t Train Loss: 3.766593\t Valid Loss: 4.619444\n",
      "Epoch: 766/2000\t Step: 15/54\t Train Loss: 3.791086\t Valid Loss: 4.483719\n",
      "Epoch: 766/2000\t Step: 30/54\t Train Loss: 3.814341\t Valid Loss: 4.425593\n",
      "Epoch: 766/2000\t Step: 45/54\t Train Loss: 3.812102\t Valid Loss: 4.845180\n",
      "Epoch: 767/2000\t Step: 15/54\t Train Loss: 3.847347\t Valid Loss: 4.412025\n",
      "Epoch: 767/2000\t Step: 30/54\t Train Loss: 3.837572\t Valid Loss: 4.553788\n",
      "Epoch: 767/2000\t Step: 45/54\t Train Loss: 3.814385\t Valid Loss: 4.385451\n",
      "Epoch: 768/2000\t Step: 15/54\t Train Loss: 3.779771\t Valid Loss: 4.540865\n",
      "Epoch: 768/2000\t Step: 30/54\t Train Loss: 3.781366\t Valid Loss: 4.484247\n",
      "Epoch: 768/2000\t Step: 45/54\t Train Loss: 3.805527\t Valid Loss: 4.562732\n",
      "Epoch: 769/2000\t Step: 15/54\t Train Loss: 3.733725\t Valid Loss: 4.596985\n",
      "Epoch: 769/2000\t Step: 30/54\t Train Loss: 3.882915\t Valid Loss: 4.594986\n",
      "Epoch: 769/2000\t Step: 45/54\t Train Loss: 3.780050\t Valid Loss: 4.663669\n",
      "Epoch: 770/2000\t Step: 15/54\t Train Loss: 3.812791\t Valid Loss: 4.582021\n",
      "Epoch: 770/2000\t Step: 30/54\t Train Loss: 3.805859\t Valid Loss: 4.355493\n",
      "Epoch: 770/2000\t Step: 45/54\t Train Loss: 3.824030\t Valid Loss: 4.440377\n",
      "Epoch: 771/2000\t Step: 15/54\t Train Loss: 3.822350\t Valid Loss: 4.564981\n",
      "Epoch: 771/2000\t Step: 30/54\t Train Loss: 3.861000\t Valid Loss: 4.553485\n",
      "Epoch: 771/2000\t Step: 45/54\t Train Loss: 3.813692\t Valid Loss: 4.492941\n",
      "Epoch: 772/2000\t Step: 15/54\t Train Loss: 3.832763\t Valid Loss: 4.630592\n",
      "Epoch: 772/2000\t Step: 30/54\t Train Loss: 3.792180\t Valid Loss: 4.463464\n",
      "Epoch: 772/2000\t Step: 45/54\t Train Loss: 3.866418\t Valid Loss: 4.475393\n",
      "Epoch: 773/2000\t Step: 15/54\t Train Loss: 3.851551\t Valid Loss: 4.606085\n",
      "Epoch: 773/2000\t Step: 30/54\t Train Loss: 3.768488\t Valid Loss: 4.770864\n",
      "Epoch: 773/2000\t Step: 45/54\t Train Loss: 3.803049\t Valid Loss: 4.611767\n",
      "Epoch: 774/2000\t Step: 15/54\t Train Loss: 3.781879\t Valid Loss: 4.563418\n",
      "Epoch: 774/2000\t Step: 30/54\t Train Loss: 3.789945\t Valid Loss: 4.385303\n",
      "Epoch: 774/2000\t Step: 45/54\t Train Loss: 3.816272\t Valid Loss: 4.459143\n",
      "Epoch: 775/2000\t Step: 15/54\t Train Loss: 3.797479\t Valid Loss: 4.508321\n",
      "Epoch: 775/2000\t Step: 30/54\t Train Loss: 3.842247\t Valid Loss: 4.492392\n",
      "Epoch: 775/2000\t Step: 45/54\t Train Loss: 3.812879\t Valid Loss: 4.478009\n",
      "Epoch: 776/2000\t Step: 15/54\t Train Loss: 3.798667\t Valid Loss: 4.822235\n",
      "Epoch: 776/2000\t Step: 30/54\t Train Loss: 3.847039\t Valid Loss: 4.497079\n",
      "Epoch: 776/2000\t Step: 45/54\t Train Loss: 3.834654\t Valid Loss: 4.389452\n",
      "Epoch: 777/2000\t Step: 15/54\t Train Loss: 3.879601\t Valid Loss: 4.633110\n",
      "Epoch: 777/2000\t Step: 30/54\t Train Loss: 3.900253\t Valid Loss: 4.450204\n",
      "Epoch: 777/2000\t Step: 45/54\t Train Loss: 3.831676\t Valid Loss: 4.422777\n",
      "Epoch: 778/2000\t Step: 15/54\t Train Loss: 3.834751\t Valid Loss: 4.519469\n",
      "Epoch: 778/2000\t Step: 30/54\t Train Loss: 3.806387\t Valid Loss: 4.506177\n",
      "Epoch: 778/2000\t Step: 45/54\t Train Loss: 3.819166\t Valid Loss: 4.590922\n",
      "Epoch: 779/2000\t Step: 15/54\t Train Loss: 3.859888\t Valid Loss: 4.678636\n",
      "Epoch: 779/2000\t Step: 30/54\t Train Loss: 3.803646\t Valid Loss: 4.653225\n",
      "Epoch: 779/2000\t Step: 45/54\t Train Loss: 3.830607\t Valid Loss: 4.361242\n",
      "Epoch: 780/2000\t Step: 15/54\t Train Loss: 3.772274\t Valid Loss: 4.667245\n",
      "Epoch: 780/2000\t Step: 30/54\t Train Loss: 3.848402\t Valid Loss: 4.510982\n",
      "Epoch: 780/2000\t Step: 45/54\t Train Loss: 3.819928\t Valid Loss: 4.509022\n",
      "Epoch: 781/2000\t Step: 15/54\t Train Loss: 3.848611\t Valid Loss: 4.443898\n",
      "Epoch: 781/2000\t Step: 30/54\t Train Loss: 3.777254\t Valid Loss: 4.457736\n",
      "Epoch: 781/2000\t Step: 45/54\t Train Loss: 3.795680\t Valid Loss: 4.452953\n",
      "Epoch: 782/2000\t Step: 15/54\t Train Loss: 3.774566\t Valid Loss: 4.552849\n",
      "Epoch: 782/2000\t Step: 30/54\t Train Loss: 3.829645\t Valid Loss: 4.639010\n",
      "Epoch: 782/2000\t Step: 45/54\t Train Loss: 3.862352\t Valid Loss: 4.589158\n",
      "Epoch: 783/2000\t Step: 15/54\t Train Loss: 3.761191\t Valid Loss: 4.532772\n",
      "Epoch: 783/2000\t Step: 30/54\t Train Loss: 3.774319\t Valid Loss: 4.685882\n",
      "Epoch: 783/2000\t Step: 45/54\t Train Loss: 3.851000\t Valid Loss: 4.480079\n",
      "Epoch: 784/2000\t Step: 15/54\t Train Loss: 3.831278\t Valid Loss: 4.472307\n",
      "Epoch: 784/2000\t Step: 30/54\t Train Loss: 3.893861\t Valid Loss: 4.514417\n",
      "Epoch: 784/2000\t Step: 45/54\t Train Loss: 3.868292\t Valid Loss: 4.381626\n",
      "Epoch: 785/2000\t Step: 15/54\t Train Loss: 3.764809\t Valid Loss: 4.614085\n",
      "Epoch: 785/2000\t Step: 30/54\t Train Loss: 3.797366\t Valid Loss: 4.506112\n",
      "Epoch: 785/2000\t Step: 45/54\t Train Loss: 3.767665\t Valid Loss: 4.509373\n",
      "Epoch: 786/2000\t Step: 15/54\t Train Loss: 3.756869\t Valid Loss: 4.656004\n",
      "Epoch: 786/2000\t Step: 30/54\t Train Loss: 3.801184\t Valid Loss: 4.745766\n",
      "Epoch: 786/2000\t Step: 45/54\t Train Loss: 3.822803\t Valid Loss: 4.411853\n",
      "Epoch: 787/2000\t Step: 15/54\t Train Loss: 3.781130\t Valid Loss: 4.318030\n",
      "Epoch: 787/2000\t Step: 30/54\t Train Loss: 3.830541\t Valid Loss: 4.641980\n",
      "Epoch: 787/2000\t Step: 45/54\t Train Loss: 3.909719\t Valid Loss: 4.477124\n",
      "Epoch: 788/2000\t Step: 15/54\t Train Loss: 3.754465\t Valid Loss: 4.512420\n",
      "Epoch: 788/2000\t Step: 30/54\t Train Loss: 3.909668\t Valid Loss: 4.490720\n",
      "Epoch: 788/2000\t Step: 45/54\t Train Loss: 3.773830\t Valid Loss: 4.453773\n",
      "Epoch: 789/2000\t Step: 15/54\t Train Loss: 3.785188\t Valid Loss: 4.468093\n",
      "Epoch: 789/2000\t Step: 30/54\t Train Loss: 3.816967\t Valid Loss: 4.324739\n",
      "Epoch: 789/2000\t Step: 45/54\t Train Loss: 3.824074\t Valid Loss: 4.502479\n",
      "Epoch: 790/2000\t Step: 15/54\t Train Loss: 3.822328\t Valid Loss: 4.422831\n",
      "Epoch: 790/2000\t Step: 30/54\t Train Loss: 3.909554\t Valid Loss: 4.413766\n",
      "Epoch: 790/2000\t Step: 45/54\t Train Loss: 3.810293\t Valid Loss: 4.443177\n",
      "Epoch: 791/2000\t Step: 15/54\t Train Loss: 3.871221\t Valid Loss: 4.436388\n",
      "Epoch: 791/2000\t Step: 30/54\t Train Loss: 3.886572\t Valid Loss: 4.483796\n",
      "Epoch: 791/2000\t Step: 45/54\t Train Loss: 3.791826\t Valid Loss: 4.578016\n",
      "Epoch: 792/2000\t Step: 15/54\t Train Loss: 3.796875\t Valid Loss: 4.739407\n",
      "Epoch: 792/2000\t Step: 30/54\t Train Loss: 3.842995\t Valid Loss: 4.485681\n",
      "Epoch: 792/2000\t Step: 45/54\t Train Loss: 3.765213\t Valid Loss: 4.807037\n",
      "Epoch: 793/2000\t Step: 15/54\t Train Loss: 3.809460\t Valid Loss: 4.685006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 793/2000\t Step: 30/54\t Train Loss: 3.911908\t Valid Loss: 4.511225\n",
      "Epoch: 793/2000\t Step: 45/54\t Train Loss: 3.788509\t Valid Loss: 4.480205\n",
      "Epoch: 794/2000\t Step: 15/54\t Train Loss: 3.847078\t Valid Loss: 4.612182\n",
      "Epoch: 794/2000\t Step: 30/54\t Train Loss: 3.809659\t Valid Loss: 4.688082\n",
      "Epoch: 794/2000\t Step: 45/54\t Train Loss: 3.790377\t Valid Loss: 4.522687\n",
      "Epoch: 795/2000\t Step: 15/54\t Train Loss: 3.856737\t Valid Loss: 4.562651\n",
      "Epoch: 795/2000\t Step: 30/54\t Train Loss: 3.736031\t Valid Loss: 4.557793\n",
      "Epoch: 795/2000\t Step: 45/54\t Train Loss: 3.776357\t Valid Loss: 4.715962\n",
      "Epoch: 796/2000\t Step: 15/54\t Train Loss: 3.873658\t Valid Loss: 4.542144\n",
      "Epoch: 796/2000\t Step: 30/54\t Train Loss: 3.900899\t Valid Loss: 4.847457\n",
      "Epoch: 796/2000\t Step: 45/54\t Train Loss: 3.789136\t Valid Loss: 4.495905\n",
      "Epoch: 797/2000\t Step: 15/54\t Train Loss: 3.832093\t Valid Loss: 4.289088\n",
      "Epoch: 797/2000\t Step: 30/54\t Train Loss: 3.884382\t Valid Loss: 4.360527\n",
      "Epoch: 797/2000\t Step: 45/54\t Train Loss: 3.783338\t Valid Loss: 4.412817\n",
      "Epoch: 798/2000\t Step: 15/54\t Train Loss: 3.763934\t Valid Loss: 4.594533\n",
      "Epoch: 798/2000\t Step: 30/54\t Train Loss: 3.814702\t Valid Loss: 4.618220\n",
      "Epoch: 798/2000\t Step: 45/54\t Train Loss: 3.814533\t Valid Loss: 4.414164\n",
      "Epoch: 799/2000\t Step: 15/54\t Train Loss: 3.799591\t Valid Loss: 4.740293\n",
      "Epoch: 799/2000\t Step: 30/54\t Train Loss: 3.795055\t Valid Loss: 4.482775\n",
      "Epoch: 799/2000\t Step: 45/54\t Train Loss: 3.766494\t Valid Loss: 4.725057\n",
      "Epoch: 800/2000\t Step: 15/54\t Train Loss: 3.812634\t Valid Loss: 4.482015\n",
      "Epoch: 800/2000\t Step: 30/54\t Train Loss: 3.764390\t Valid Loss: 4.398735\n",
      "Epoch: 800/2000\t Step: 45/54\t Train Loss: 3.837962\t Valid Loss: 4.741903\n",
      "Epoch: 801/2000\t Step: 15/54\t Train Loss: 3.818382\t Valid Loss: 4.649359\n",
      "Epoch: 801/2000\t Step: 30/54\t Train Loss: 3.757727\t Valid Loss: 4.621385\n",
      "Epoch: 801/2000\t Step: 45/54\t Train Loss: 3.781899\t Valid Loss: 4.527026\n",
      "Epoch: 802/2000\t Step: 15/54\t Train Loss: 3.742129\t Valid Loss: 4.369341\n",
      "Epoch: 802/2000\t Step: 30/54\t Train Loss: 3.793713\t Valid Loss: 4.872481\n",
      "Epoch: 802/2000\t Step: 45/54\t Train Loss: 3.793674\t Valid Loss: 4.596360\n",
      "Epoch: 803/2000\t Step: 15/54\t Train Loss: 3.722867\t Valid Loss: 4.512908\n",
      "Epoch: 803/2000\t Step: 30/54\t Train Loss: 3.780502\t Valid Loss: 4.514659\n",
      "Epoch: 803/2000\t Step: 45/54\t Train Loss: 3.935176\t Valid Loss: 4.631878\n",
      "Epoch: 804/2000\t Step: 15/54\t Train Loss: 3.805727\t Valid Loss: 4.536593\n",
      "Epoch: 804/2000\t Step: 30/54\t Train Loss: 3.815738\t Valid Loss: 4.758395\n",
      "Epoch: 804/2000\t Step: 45/54\t Train Loss: 3.812657\t Valid Loss: 4.441025\n",
      "Epoch: 805/2000\t Step: 15/54\t Train Loss: 3.779029\t Valid Loss: 4.469557\n",
      "Epoch: 805/2000\t Step: 30/54\t Train Loss: 3.798118\t Valid Loss: 4.837624\n",
      "Epoch: 805/2000\t Step: 45/54\t Train Loss: 3.896044\t Valid Loss: 4.314093\n",
      "Epoch: 806/2000\t Step: 15/54\t Train Loss: 3.766873\t Valid Loss: 4.455914\n",
      "Epoch: 806/2000\t Step: 30/54\t Train Loss: 3.810024\t Valid Loss: 4.536464\n",
      "Epoch: 806/2000\t Step: 45/54\t Train Loss: 3.845978\t Valid Loss: 4.794206\n",
      "Epoch: 807/2000\t Step: 15/54\t Train Loss: 3.799342\t Valid Loss: 4.568262\n",
      "Epoch: 807/2000\t Step: 30/54\t Train Loss: 3.796931\t Valid Loss: 4.591112\n",
      "Epoch: 807/2000\t Step: 45/54\t Train Loss: 3.778617\t Valid Loss: 4.603189\n",
      "Epoch: 808/2000\t Step: 15/54\t Train Loss: 3.840628\t Valid Loss: 4.541848\n",
      "Epoch: 808/2000\t Step: 30/54\t Train Loss: 3.752330\t Valid Loss: 4.505629\n",
      "Epoch: 808/2000\t Step: 45/54\t Train Loss: 3.805496\t Valid Loss: 4.304792\n",
      "Epoch: 809/2000\t Step: 15/54\t Train Loss: 3.844854\t Valid Loss: 4.530638\n",
      "Epoch: 809/2000\t Step: 30/54\t Train Loss: 3.795770\t Valid Loss: 4.618327\n",
      "Epoch: 809/2000\t Step: 45/54\t Train Loss: 3.827874\t Valid Loss: 4.379193\n",
      "Epoch: 810/2000\t Step: 15/54\t Train Loss: 3.811248\t Valid Loss: 4.310742\n",
      "Epoch: 810/2000\t Step: 30/54\t Train Loss: 3.776854\t Valid Loss: 4.575163\n",
      "Epoch: 810/2000\t Step: 45/54\t Train Loss: 3.798183\t Valid Loss: 4.568263\n",
      "Epoch: 811/2000\t Step: 15/54\t Train Loss: 3.793695\t Valid Loss: 4.493436\n",
      "Epoch: 811/2000\t Step: 30/54\t Train Loss: 3.835033\t Valid Loss: 4.587834\n",
      "Epoch: 811/2000\t Step: 45/54\t Train Loss: 3.868290\t Valid Loss: 4.361859\n",
      "Epoch: 812/2000\t Step: 15/54\t Train Loss: 3.842443\t Valid Loss: 4.515171\n",
      "Epoch: 812/2000\t Step: 30/54\t Train Loss: 3.835285\t Valid Loss: 4.638609\n",
      "Epoch: 812/2000\t Step: 45/54\t Train Loss: 3.810087\t Valid Loss: 4.508845\n",
      "Epoch: 813/2000\t Step: 15/54\t Train Loss: 3.767309\t Valid Loss: 4.679506\n",
      "Epoch: 813/2000\t Step: 30/54\t Train Loss: 3.853747\t Valid Loss: 4.548499\n",
      "Epoch: 813/2000\t Step: 45/54\t Train Loss: 3.809070\t Valid Loss: 5.041490\n",
      "Epoch: 814/2000\t Step: 15/54\t Train Loss: 3.837365\t Valid Loss: 4.638511\n",
      "Epoch: 814/2000\t Step: 30/54\t Train Loss: 3.828966\t Valid Loss: 4.503952\n",
      "Epoch: 814/2000\t Step: 45/54\t Train Loss: 3.832659\t Valid Loss: 4.510054\n",
      "Epoch: 815/2000\t Step: 15/54\t Train Loss: 3.788784\t Valid Loss: 4.560720\n",
      "Epoch: 815/2000\t Step: 30/54\t Train Loss: 3.772657\t Valid Loss: 4.687514\n",
      "Epoch: 815/2000\t Step: 45/54\t Train Loss: 3.862343\t Valid Loss: 4.451389\n",
      "Epoch: 816/2000\t Step: 15/54\t Train Loss: 3.825600\t Valid Loss: 4.476331\n",
      "Epoch: 816/2000\t Step: 30/54\t Train Loss: 3.895400\t Valid Loss: 4.610078\n",
      "Epoch: 816/2000\t Step: 45/54\t Train Loss: 3.784366\t Valid Loss: 4.544912\n",
      "Epoch: 817/2000\t Step: 15/54\t Train Loss: 3.740566\t Valid Loss: 4.392444\n",
      "Epoch: 817/2000\t Step: 30/54\t Train Loss: 3.808720\t Valid Loss: 4.577545\n",
      "Epoch: 817/2000\t Step: 45/54\t Train Loss: 3.835639\t Valid Loss: 4.611444\n",
      "Epoch: 818/2000\t Step: 15/54\t Train Loss: 3.784333\t Valid Loss: 4.422646\n",
      "Epoch: 818/2000\t Step: 30/54\t Train Loss: 3.878323\t Valid Loss: 4.471156\n",
      "Epoch: 818/2000\t Step: 45/54\t Train Loss: 3.839816\t Valid Loss: 4.379592\n",
      "Epoch: 819/2000\t Step: 15/54\t Train Loss: 3.773532\t Valid Loss: 4.574246\n",
      "Epoch: 819/2000\t Step: 30/54\t Train Loss: 3.745602\t Valid Loss: 4.865150\n",
      "Epoch: 819/2000\t Step: 45/54\t Train Loss: 3.879510\t Valid Loss: 4.358444\n",
      "Epoch: 820/2000\t Step: 15/54\t Train Loss: 3.867058\t Valid Loss: 4.491932\n",
      "Epoch: 820/2000\t Step: 30/54\t Train Loss: 3.883050\t Valid Loss: 4.480832\n",
      "Epoch: 820/2000\t Step: 45/54\t Train Loss: 3.811868\t Valid Loss: 4.504369\n",
      "Epoch: 821/2000\t Step: 15/54\t Train Loss: 3.818506\t Valid Loss: 4.422466\n",
      "Epoch: 821/2000\t Step: 30/54\t Train Loss: 3.802667\t Valid Loss: 4.443063\n",
      "Epoch: 821/2000\t Step: 45/54\t Train Loss: 3.818303\t Valid Loss: 4.519867\n",
      "Epoch: 822/2000\t Step: 15/54\t Train Loss: 3.792363\t Valid Loss: 4.597703\n",
      "Epoch: 822/2000\t Step: 30/54\t Train Loss: 3.821921\t Valid Loss: 4.410387\n",
      "Epoch: 822/2000\t Step: 45/54\t Train Loss: 3.791243\t Valid Loss: 4.320571\n",
      "Epoch: 823/2000\t Step: 15/54\t Train Loss: 3.774757\t Valid Loss: 4.678841\n",
      "Epoch: 823/2000\t Step: 30/54\t Train Loss: 3.811865\t Valid Loss: 4.552849\n",
      "Epoch: 823/2000\t Step: 45/54\t Train Loss: 3.782739\t Valid Loss: 4.386541\n",
      "Epoch: 824/2000\t Step: 15/54\t Train Loss: 3.828340\t Valid Loss: 4.239253\n",
      "Epoch: 824/2000\t Step: 30/54\t Train Loss: 3.777763\t Valid Loss: 4.349787\n",
      "Epoch: 824/2000\t Step: 45/54\t Train Loss: 3.872130\t Valid Loss: 4.507197\n",
      "Epoch: 825/2000\t Step: 15/54\t Train Loss: 3.836258\t Valid Loss: 4.393864\n",
      "Epoch: 825/2000\t Step: 30/54\t Train Loss: 3.773098\t Valid Loss: 4.388907\n",
      "Epoch: 825/2000\t Step: 45/54\t Train Loss: 3.772295\t Valid Loss: 4.691511\n",
      "Epoch: 826/2000\t Step: 15/54\t Train Loss: 3.819940\t Valid Loss: 4.441398\n",
      "Epoch: 826/2000\t Step: 30/54\t Train Loss: 3.827370\t Valid Loss: 4.294768\n",
      "Epoch: 826/2000\t Step: 45/54\t Train Loss: 3.813019\t Valid Loss: 4.686351\n",
      "Epoch: 827/2000\t Step: 15/54\t Train Loss: 3.752393\t Valid Loss: 4.631709\n",
      "Epoch: 827/2000\t Step: 30/54\t Train Loss: 3.792297\t Valid Loss: 4.465818\n",
      "Epoch: 827/2000\t Step: 45/54\t Train Loss: 3.898210\t Valid Loss: 4.555699\n",
      "Epoch: 828/2000\t Step: 15/54\t Train Loss: 3.786224\t Valid Loss: 4.497540\n",
      "Epoch: 828/2000\t Step: 30/54\t Train Loss: 3.789207\t Valid Loss: 4.508411\n",
      "Epoch: 828/2000\t Step: 45/54\t Train Loss: 3.796990\t Valid Loss: 4.557225\n",
      "Epoch: 829/2000\t Step: 15/54\t Train Loss: 3.788196\t Valid Loss: 4.473278\n",
      "Epoch: 829/2000\t Step: 30/54\t Train Loss: 3.754954\t Valid Loss: 4.725433\n",
      "Epoch: 829/2000\t Step: 45/54\t Train Loss: 3.813706\t Valid Loss: 4.780377\n",
      "Epoch: 830/2000\t Step: 15/54\t Train Loss: 3.845610\t Valid Loss: 4.459276\n",
      "Epoch: 830/2000\t Step: 30/54\t Train Loss: 3.800961\t Valid Loss: 4.444259\n",
      "Epoch: 830/2000\t Step: 45/54\t Train Loss: 3.870655\t Valid Loss: 4.380409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 831/2000\t Step: 15/54\t Train Loss: 3.797157\t Valid Loss: 4.928099\n",
      "Epoch: 831/2000\t Step: 30/54\t Train Loss: 3.833450\t Valid Loss: 4.422059\n",
      "Epoch: 831/2000\t Step: 45/54\t Train Loss: 3.780471\t Valid Loss: 4.795848\n",
      "Epoch: 832/2000\t Step: 15/54\t Train Loss: 3.791312\t Valid Loss: 4.523809\n",
      "Epoch: 832/2000\t Step: 30/54\t Train Loss: 3.816212\t Valid Loss: 4.416324\n",
      "Epoch: 832/2000\t Step: 45/54\t Train Loss: 3.840539\t Valid Loss: 4.500228\n",
      "Epoch: 833/2000\t Step: 15/54\t Train Loss: 3.725098\t Valid Loss: 4.659911\n",
      "Epoch: 833/2000\t Step: 30/54\t Train Loss: 3.781509\t Valid Loss: 4.442747\n",
      "Epoch: 833/2000\t Step: 45/54\t Train Loss: 3.755473\t Valid Loss: 4.623715\n",
      "Epoch: 834/2000\t Step: 15/54\t Train Loss: 3.798221\t Valid Loss: 4.549093\n",
      "Epoch: 834/2000\t Step: 30/54\t Train Loss: 3.813946\t Valid Loss: 4.795505\n",
      "Epoch: 834/2000\t Step: 45/54\t Train Loss: 3.802268\t Valid Loss: 4.581012\n",
      "Epoch: 835/2000\t Step: 15/54\t Train Loss: 3.786607\t Valid Loss: 4.641905\n",
      "Epoch: 835/2000\t Step: 30/54\t Train Loss: 3.791395\t Valid Loss: 4.544676\n",
      "Epoch: 835/2000\t Step: 45/54\t Train Loss: 3.822438\t Valid Loss: 4.490206\n",
      "Epoch: 836/2000\t Step: 15/54\t Train Loss: 3.796381\t Valid Loss: 4.801124\n",
      "Epoch: 836/2000\t Step: 30/54\t Train Loss: 3.873298\t Valid Loss: 4.540842\n",
      "Epoch: 836/2000\t Step: 45/54\t Train Loss: 3.806810\t Valid Loss: 4.424052\n",
      "Epoch: 837/2000\t Step: 15/54\t Train Loss: 3.763174\t Valid Loss: 4.522425\n",
      "Epoch: 837/2000\t Step: 30/54\t Train Loss: 3.753772\t Valid Loss: 4.932627\n",
      "Epoch: 837/2000\t Step: 45/54\t Train Loss: 3.788528\t Valid Loss: 4.878760\n",
      "Epoch: 838/2000\t Step: 15/54\t Train Loss: 3.781854\t Valid Loss: 4.434966\n",
      "Epoch: 838/2000\t Step: 30/54\t Train Loss: 3.800867\t Valid Loss: 4.444605\n",
      "Epoch: 838/2000\t Step: 45/54\t Train Loss: 3.781670\t Valid Loss: 4.407994\n",
      "Epoch: 839/2000\t Step: 15/54\t Train Loss: 3.807532\t Valid Loss: 4.607021\n",
      "Epoch: 839/2000\t Step: 30/54\t Train Loss: 3.863671\t Valid Loss: 4.450058\n",
      "Epoch: 839/2000\t Step: 45/54\t Train Loss: 3.815391\t Valid Loss: 4.528890\n",
      "Epoch: 840/2000\t Step: 15/54\t Train Loss: 3.849362\t Valid Loss: 4.453228\n",
      "Epoch: 840/2000\t Step: 30/54\t Train Loss: 3.817142\t Valid Loss: 4.704685\n",
      "Epoch: 840/2000\t Step: 45/54\t Train Loss: 3.768444\t Valid Loss: 4.666103\n",
      "Epoch: 841/2000\t Step: 15/54\t Train Loss: 3.800696\t Valid Loss: 4.446429\n",
      "Epoch: 841/2000\t Step: 30/54\t Train Loss: 3.787915\t Valid Loss: 4.981818\n",
      "Epoch: 841/2000\t Step: 45/54\t Train Loss: 3.831348\t Valid Loss: 4.692402\n",
      "Epoch: 842/2000\t Step: 15/54\t Train Loss: 3.824280\t Valid Loss: 4.663375\n",
      "Epoch: 842/2000\t Step: 30/54\t Train Loss: 3.812508\t Valid Loss: 4.500099\n",
      "Epoch: 842/2000\t Step: 45/54\t Train Loss: 3.831746\t Valid Loss: 4.544190\n",
      "Epoch: 843/2000\t Step: 15/54\t Train Loss: 3.848844\t Valid Loss: 4.658560\n",
      "Epoch: 843/2000\t Step: 30/54\t Train Loss: 3.700731\t Valid Loss: 4.541752\n",
      "Epoch: 843/2000\t Step: 45/54\t Train Loss: 3.775629\t Valid Loss: 4.660697\n",
      "Epoch: 844/2000\t Step: 15/54\t Train Loss: 3.834863\t Valid Loss: 4.575894\n",
      "Epoch: 844/2000\t Step: 30/54\t Train Loss: 3.871451\t Valid Loss: 4.593582\n",
      "Epoch: 844/2000\t Step: 45/54\t Train Loss: 3.860906\t Valid Loss: 4.539534\n",
      "Epoch: 845/2000\t Step: 15/54\t Train Loss: 3.912343\t Valid Loss: 4.586792\n",
      "Epoch: 845/2000\t Step: 30/54\t Train Loss: 3.857763\t Valid Loss: 4.655889\n",
      "Epoch: 845/2000\t Step: 45/54\t Train Loss: 3.834862\t Valid Loss: 4.506085\n",
      "Epoch: 846/2000\t Step: 15/54\t Train Loss: 3.771633\t Valid Loss: 4.432597\n",
      "Epoch: 846/2000\t Step: 30/54\t Train Loss: 3.805252\t Valid Loss: 4.680697\n",
      "Epoch: 846/2000\t Step: 45/54\t Train Loss: 3.846621\t Valid Loss: 4.656580\n",
      "Epoch: 847/2000\t Step: 15/54\t Train Loss: 3.764123\t Valid Loss: 4.903093\n",
      "Epoch: 847/2000\t Step: 30/54\t Train Loss: 3.801555\t Valid Loss: 4.515534\n",
      "Epoch: 847/2000\t Step: 45/54\t Train Loss: 3.792009\t Valid Loss: 4.424987\n",
      "Epoch: 848/2000\t Step: 15/54\t Train Loss: 3.764306\t Valid Loss: 4.627114\n",
      "Epoch: 848/2000\t Step: 30/54\t Train Loss: 3.801528\t Valid Loss: 4.436896\n",
      "Epoch: 848/2000\t Step: 45/54\t Train Loss: 3.837808\t Valid Loss: 4.588168\n",
      "Epoch: 849/2000\t Step: 15/54\t Train Loss: 3.811206\t Valid Loss: 4.477864\n",
      "Epoch: 849/2000\t Step: 30/54\t Train Loss: 3.851184\t Valid Loss: 4.288318\n",
      "Epoch: 849/2000\t Step: 45/54\t Train Loss: 3.821098\t Valid Loss: 4.662161\n",
      "Epoch: 850/2000\t Step: 15/54\t Train Loss: 3.723192\t Valid Loss: 4.700108\n",
      "Epoch: 850/2000\t Step: 30/54\t Train Loss: 3.797379\t Valid Loss: 4.391274\n",
      "Epoch: 850/2000\t Step: 45/54\t Train Loss: 3.790894\t Valid Loss: 4.493020\n",
      "Epoch: 851/2000\t Step: 15/54\t Train Loss: 3.876193\t Valid Loss: 4.738670\n",
      "Epoch: 851/2000\t Step: 30/54\t Train Loss: 3.795446\t Valid Loss: 4.565548\n",
      "Epoch: 851/2000\t Step: 45/54\t Train Loss: 3.854647\t Valid Loss: 4.521139\n",
      "Epoch: 852/2000\t Step: 15/54\t Train Loss: 3.772033\t Valid Loss: 4.620206\n",
      "Epoch: 852/2000\t Step: 30/54\t Train Loss: 3.837287\t Valid Loss: 4.742511\n",
      "Epoch: 852/2000\t Step: 45/54\t Train Loss: 3.765641\t Valid Loss: 4.503122\n",
      "Epoch: 853/2000\t Step: 15/54\t Train Loss: 3.766022\t Valid Loss: 4.840807\n",
      "Epoch: 853/2000\t Step: 30/54\t Train Loss: 3.921512\t Valid Loss: 4.387944\n",
      "Epoch: 853/2000\t Step: 45/54\t Train Loss: 3.918036\t Valid Loss: 4.780529\n",
      "Epoch: 854/2000\t Step: 15/54\t Train Loss: 3.827733\t Valid Loss: 4.622560\n",
      "Epoch: 854/2000\t Step: 30/54\t Train Loss: 3.768340\t Valid Loss: 4.723498\n",
      "Epoch: 854/2000\t Step: 45/54\t Train Loss: 3.758471\t Valid Loss: 4.590073\n",
      "Epoch: 855/2000\t Step: 15/54\t Train Loss: 3.752674\t Valid Loss: 4.571304\n",
      "Epoch: 855/2000\t Step: 30/54\t Train Loss: 3.805565\t Valid Loss: 4.966611\n",
      "Epoch: 855/2000\t Step: 45/54\t Train Loss: 3.774696\t Valid Loss: 4.660866\n",
      "Epoch: 856/2000\t Step: 15/54\t Train Loss: 3.826972\t Valid Loss: 4.296861\n",
      "Epoch: 856/2000\t Step: 30/54\t Train Loss: 3.783212\t Valid Loss: 4.742987\n",
      "Epoch: 856/2000\t Step: 45/54\t Train Loss: 3.819550\t Valid Loss: 4.512595\n",
      "Epoch: 857/2000\t Step: 15/54\t Train Loss: 3.775434\t Valid Loss: 4.521878\n",
      "Epoch: 857/2000\t Step: 30/54\t Train Loss: 3.834780\t Valid Loss: 4.511265\n",
      "Epoch: 857/2000\t Step: 45/54\t Train Loss: 3.730540\t Valid Loss: 4.625962\n",
      "Epoch: 858/2000\t Step: 15/54\t Train Loss: 3.777495\t Valid Loss: 4.713009\n",
      "Epoch: 858/2000\t Step: 30/54\t Train Loss: 3.860966\t Valid Loss: 4.556039\n",
      "Epoch: 858/2000\t Step: 45/54\t Train Loss: 3.869556\t Valid Loss: 4.543058\n",
      "Epoch: 859/2000\t Step: 15/54\t Train Loss: 3.797012\t Valid Loss: 4.757126\n",
      "Epoch: 859/2000\t Step: 30/54\t Train Loss: 3.766971\t Valid Loss: 4.416182\n",
      "Epoch: 859/2000\t Step: 45/54\t Train Loss: 3.773991\t Valid Loss: 4.575742\n",
      "Epoch: 860/2000\t Step: 15/54\t Train Loss: 3.801659\t Valid Loss: 4.688655\n",
      "Epoch: 860/2000\t Step: 30/54\t Train Loss: 3.696835\t Valid Loss: 4.426449\n",
      "Epoch: 860/2000\t Step: 45/54\t Train Loss: 3.771820\t Valid Loss: 4.554359\n",
      "Epoch: 861/2000\t Step: 15/54\t Train Loss: 3.790567\t Valid Loss: 4.597887\n",
      "Epoch: 861/2000\t Step: 30/54\t Train Loss: 3.892786\t Valid Loss: 4.486923\n",
      "Epoch: 861/2000\t Step: 45/54\t Train Loss: 3.788256\t Valid Loss: 4.452463\n",
      "Epoch: 862/2000\t Step: 15/54\t Train Loss: 3.848412\t Valid Loss: 4.820290\n",
      "Epoch: 862/2000\t Step: 30/54\t Train Loss: 3.856035\t Valid Loss: 4.712364\n",
      "Epoch: 862/2000\t Step: 45/54\t Train Loss: 3.768940\t Valid Loss: 4.883055\n",
      "Epoch: 863/2000\t Step: 15/54\t Train Loss: 3.835689\t Valid Loss: 4.803562\n",
      "Epoch: 863/2000\t Step: 30/54\t Train Loss: 3.861412\t Valid Loss: 4.584696\n",
      "Epoch: 863/2000\t Step: 45/54\t Train Loss: 3.790440\t Valid Loss: 4.479123\n",
      "Epoch: 864/2000\t Step: 15/54\t Train Loss: 3.857504\t Valid Loss: 4.602743\n",
      "Epoch: 864/2000\t Step: 30/54\t Train Loss: 3.746352\t Valid Loss: 4.718870\n",
      "Epoch: 864/2000\t Step: 45/54\t Train Loss: 3.797319\t Valid Loss: 4.474093\n",
      "Epoch: 865/2000\t Step: 15/54\t Train Loss: 3.856567\t Valid Loss: 4.369404\n",
      "Epoch: 865/2000\t Step: 30/54\t Train Loss: 3.843083\t Valid Loss: 4.568806\n",
      "Epoch: 865/2000\t Step: 45/54\t Train Loss: 3.779055\t Valid Loss: 4.760310\n",
      "Epoch: 866/2000\t Step: 15/54\t Train Loss: 3.796731\t Valid Loss: 4.459190\n",
      "Epoch: 866/2000\t Step: 30/54\t Train Loss: 3.720472\t Valid Loss: 4.599488\n",
      "Epoch: 866/2000\t Step: 45/54\t Train Loss: 3.865597\t Valid Loss: 4.594622\n",
      "Epoch: 867/2000\t Step: 15/54\t Train Loss: 3.759381\t Valid Loss: 4.403238\n",
      "Epoch: 867/2000\t Step: 30/54\t Train Loss: 3.772214\t Valid Loss: 4.545561\n",
      "Epoch: 867/2000\t Step: 45/54\t Train Loss: 3.851029\t Valid Loss: 4.677985\n",
      "Epoch: 868/2000\t Step: 15/54\t Train Loss: 3.855440\t Valid Loss: 4.532738\n",
      "Epoch: 868/2000\t Step: 30/54\t Train Loss: 3.815341\t Valid Loss: 4.610647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 868/2000\t Step: 45/54\t Train Loss: 3.801361\t Valid Loss: 4.548293\n",
      "Epoch: 869/2000\t Step: 15/54\t Train Loss: 3.832556\t Valid Loss: 4.412378\n",
      "Epoch: 869/2000\t Step: 30/54\t Train Loss: 3.865144\t Valid Loss: 4.697258\n",
      "Epoch: 869/2000\t Step: 45/54\t Train Loss: 3.843257\t Valid Loss: 4.402889\n",
      "Epoch: 870/2000\t Step: 15/54\t Train Loss: 3.799551\t Valid Loss: 4.497018\n",
      "Epoch: 870/2000\t Step: 30/54\t Train Loss: 3.787677\t Valid Loss: 4.508069\n",
      "Epoch: 870/2000\t Step: 45/54\t Train Loss: 3.808562\t Valid Loss: 4.614279\n",
      "Epoch: 871/2000\t Step: 15/54\t Train Loss: 3.799378\t Valid Loss: 4.533179\n",
      "Epoch: 871/2000\t Step: 30/54\t Train Loss: 3.783960\t Valid Loss: 4.600497\n",
      "Epoch: 871/2000\t Step: 45/54\t Train Loss: 3.794420\t Valid Loss: 4.548635\n",
      "Epoch: 872/2000\t Step: 15/54\t Train Loss: 3.838575\t Valid Loss: 4.355325\n",
      "Epoch: 872/2000\t Step: 30/54\t Train Loss: 3.821450\t Valid Loss: 4.285362\n",
      "Epoch: 872/2000\t Step: 45/54\t Train Loss: 3.797921\t Valid Loss: 4.398127\n",
      "Epoch: 873/2000\t Step: 15/54\t Train Loss: 3.927864\t Valid Loss: 4.266451\n",
      "Epoch: 873/2000\t Step: 30/54\t Train Loss: 3.833605\t Valid Loss: 4.344810\n",
      "Epoch: 873/2000\t Step: 45/54\t Train Loss: 3.837732\t Valid Loss: 4.421778\n",
      "Epoch: 874/2000\t Step: 15/54\t Train Loss: 3.752430\t Valid Loss: 4.626747\n",
      "Epoch: 874/2000\t Step: 30/54\t Train Loss: 3.874005\t Valid Loss: 4.577375\n",
      "Epoch: 874/2000\t Step: 45/54\t Train Loss: 3.804392\t Valid Loss: 4.596989\n",
      "Epoch: 875/2000\t Step: 15/54\t Train Loss: 3.872018\t Valid Loss: 4.494721\n",
      "Epoch: 875/2000\t Step: 30/54\t Train Loss: 3.801019\t Valid Loss: 4.474071\n",
      "Epoch: 875/2000\t Step: 45/54\t Train Loss: 3.820326\t Valid Loss: 4.527301\n",
      "Epoch: 876/2000\t Step: 15/54\t Train Loss: 3.765961\t Valid Loss: 4.600953\n",
      "Epoch: 876/2000\t Step: 30/54\t Train Loss: 3.794938\t Valid Loss: 4.854234\n",
      "Epoch: 876/2000\t Step: 45/54\t Train Loss: 3.759554\t Valid Loss: 4.668096\n",
      "Epoch: 877/2000\t Step: 15/54\t Train Loss: 3.890110\t Valid Loss: 4.621325\n",
      "Epoch: 877/2000\t Step: 30/54\t Train Loss: 3.807882\t Valid Loss: 4.469876\n",
      "Epoch: 877/2000\t Step: 45/54\t Train Loss: 3.741789\t Valid Loss: 4.769185\n",
      "Epoch: 878/2000\t Step: 15/54\t Train Loss: 3.809907\t Valid Loss: 4.506335\n",
      "Epoch: 878/2000\t Step: 30/54\t Train Loss: 3.796922\t Valid Loss: 4.529554\n",
      "Epoch: 878/2000\t Step: 45/54\t Train Loss: 3.753541\t Valid Loss: 4.639115\n",
      "Epoch: 879/2000\t Step: 15/54\t Train Loss: 3.823893\t Valid Loss: 4.543779\n",
      "Epoch: 879/2000\t Step: 30/54\t Train Loss: 3.884004\t Valid Loss: 4.856056\n",
      "Epoch: 879/2000\t Step: 45/54\t Train Loss: 3.758287\t Valid Loss: 4.409849\n",
      "Epoch: 880/2000\t Step: 15/54\t Train Loss: 3.732361\t Valid Loss: 4.661989\n",
      "Epoch: 880/2000\t Step: 30/54\t Train Loss: 3.813344\t Valid Loss: 4.455803\n",
      "Epoch: 880/2000\t Step: 45/54\t Train Loss: 3.719428\t Valid Loss: 4.602845\n",
      "Epoch: 881/2000\t Step: 15/54\t Train Loss: 3.785804\t Valid Loss: 4.522500\n",
      "Epoch: 881/2000\t Step: 30/54\t Train Loss: 3.795126\t Valid Loss: 4.363612\n",
      "Epoch: 881/2000\t Step: 45/54\t Train Loss: 3.837410\t Valid Loss: 4.604914\n",
      "Epoch: 882/2000\t Step: 15/54\t Train Loss: 3.811528\t Valid Loss: 4.374326\n",
      "Epoch: 882/2000\t Step: 30/54\t Train Loss: 3.797015\t Valid Loss: 4.528999\n",
      "Epoch: 882/2000\t Step: 45/54\t Train Loss: 3.836022\t Valid Loss: 4.256285\n",
      "Epoch: 883/2000\t Step: 15/54\t Train Loss: 3.865325\t Valid Loss: 4.441537\n",
      "Epoch: 883/2000\t Step: 30/54\t Train Loss: 3.834762\t Valid Loss: 4.647896\n",
      "Epoch: 883/2000\t Step: 45/54\t Train Loss: 3.792813\t Valid Loss: 4.664165\n",
      "Epoch: 884/2000\t Step: 15/54\t Train Loss: 3.785826\t Valid Loss: 4.670799\n",
      "Epoch: 884/2000\t Step: 30/54\t Train Loss: 3.783001\t Valid Loss: 4.418510\n",
      "Epoch: 884/2000\t Step: 45/54\t Train Loss: 3.864023\t Valid Loss: 4.596577\n",
      "Epoch: 885/2000\t Step: 15/54\t Train Loss: 3.806783\t Valid Loss: 4.435657\n",
      "Epoch: 885/2000\t Step: 30/54\t Train Loss: 3.845656\t Valid Loss: 4.602111\n",
      "Epoch: 885/2000\t Step: 45/54\t Train Loss: 3.830630\t Valid Loss: 4.392269\n",
      "Epoch: 886/2000\t Step: 15/54\t Train Loss: 3.822313\t Valid Loss: 4.490091\n",
      "Epoch: 886/2000\t Step: 30/54\t Train Loss: 3.869080\t Valid Loss: 4.599971\n",
      "Epoch: 886/2000\t Step: 45/54\t Train Loss: 3.766883\t Valid Loss: 4.834415\n",
      "Epoch: 887/2000\t Step: 15/54\t Train Loss: 3.769398\t Valid Loss: 4.409174\n",
      "Epoch: 887/2000\t Step: 30/54\t Train Loss: 3.801540\t Valid Loss: 4.640662\n",
      "Epoch: 887/2000\t Step: 45/54\t Train Loss: 3.760270\t Valid Loss: 4.629917\n",
      "Epoch: 888/2000\t Step: 15/54\t Train Loss: 3.745289\t Valid Loss: 4.770498\n",
      "Epoch: 888/2000\t Step: 30/54\t Train Loss: 3.768196\t Valid Loss: 4.569258\n",
      "Epoch: 888/2000\t Step: 45/54\t Train Loss: 3.887097\t Valid Loss: 4.581575\n",
      "Epoch: 889/2000\t Step: 15/54\t Train Loss: 3.794351\t Valid Loss: 4.915064\n",
      "Epoch: 889/2000\t Step: 30/54\t Train Loss: 3.769412\t Valid Loss: 4.497505\n",
      "Epoch: 889/2000\t Step: 45/54\t Train Loss: 3.763059\t Valid Loss: 4.872300\n",
      "Epoch: 890/2000\t Step: 15/54\t Train Loss: 3.801875\t Valid Loss: 4.602982\n",
      "Epoch: 890/2000\t Step: 30/54\t Train Loss: 3.743306\t Valid Loss: 4.701361\n",
      "Epoch: 890/2000\t Step: 45/54\t Train Loss: 3.865818\t Valid Loss: 4.717562\n",
      "Epoch: 891/2000\t Step: 15/54\t Train Loss: 3.860312\t Valid Loss: 4.585854\n",
      "Epoch: 891/2000\t Step: 30/54\t Train Loss: 3.762881\t Valid Loss: 4.535435\n",
      "Epoch: 891/2000\t Step: 45/54\t Train Loss: 3.781674\t Valid Loss: 4.669808\n",
      "Epoch: 892/2000\t Step: 15/54\t Train Loss: 3.832512\t Valid Loss: 4.683884\n",
      "Epoch: 892/2000\t Step: 30/54\t Train Loss: 3.755635\t Valid Loss: 4.619518\n",
      "Epoch: 892/2000\t Step: 45/54\t Train Loss: 3.837649\t Valid Loss: 4.471792\n",
      "Epoch: 893/2000\t Step: 15/54\t Train Loss: 3.787742\t Valid Loss: 5.047967\n",
      "Epoch: 893/2000\t Step: 30/54\t Train Loss: 3.782580\t Valid Loss: 4.854384\n",
      "Epoch: 893/2000\t Step: 45/54\t Train Loss: 3.881182\t Valid Loss: 4.595147\n",
      "Epoch: 894/2000\t Step: 15/54\t Train Loss: 3.773865\t Valid Loss: 4.536991\n",
      "Epoch: 894/2000\t Step: 30/54\t Train Loss: 3.862775\t Valid Loss: 4.487562\n",
      "Epoch: 894/2000\t Step: 45/54\t Train Loss: 3.713543\t Valid Loss: 4.533083\n",
      "Epoch: 895/2000\t Step: 15/54\t Train Loss: 3.754944\t Valid Loss: 4.605338\n",
      "Epoch: 895/2000\t Step: 30/54\t Train Loss: 3.859530\t Valid Loss: 4.566397\n",
      "Epoch: 895/2000\t Step: 45/54\t Train Loss: 3.806160\t Valid Loss: 4.490148\n",
      "Epoch: 896/2000\t Step: 15/54\t Train Loss: 3.824353\t Valid Loss: 4.582239\n",
      "Epoch: 896/2000\t Step: 30/54\t Train Loss: 3.756082\t Valid Loss: 4.623508\n",
      "Epoch: 896/2000\t Step: 45/54\t Train Loss: 3.905454\t Valid Loss: 4.903619\n",
      "Epoch: 897/2000\t Step: 15/54\t Train Loss: 3.740432\t Valid Loss: 4.424283\n",
      "Epoch: 897/2000\t Step: 30/54\t Train Loss: 3.827797\t Valid Loss: 4.579098\n",
      "Epoch: 897/2000\t Step: 45/54\t Train Loss: 3.843553\t Valid Loss: 4.652475\n",
      "Epoch: 898/2000\t Step: 15/54\t Train Loss: 3.776731\t Valid Loss: 4.766484\n",
      "Epoch: 898/2000\t Step: 30/54\t Train Loss: 3.819390\t Valid Loss: 4.544906\n",
      "Epoch: 898/2000\t Step: 45/54\t Train Loss: 3.796336\t Valid Loss: 4.733321\n",
      "Epoch: 899/2000\t Step: 15/54\t Train Loss: 3.777028\t Valid Loss: 4.709153\n",
      "Epoch: 899/2000\t Step: 30/54\t Train Loss: 3.785301\t Valid Loss: 4.789378\n",
      "Epoch: 899/2000\t Step: 45/54\t Train Loss: 3.845182\t Valid Loss: 4.673810\n",
      "Epoch: 900/2000\t Step: 15/54\t Train Loss: 3.783168\t Valid Loss: 4.765545\n",
      "Epoch: 900/2000\t Step: 30/54\t Train Loss: 3.800420\t Valid Loss: 4.607973\n",
      "Epoch: 900/2000\t Step: 45/54\t Train Loss: 3.813561\t Valid Loss: 4.650062\n",
      "Epoch: 901/2000\t Step: 15/54\t Train Loss: 3.787202\t Valid Loss: 4.508759\n",
      "Epoch: 901/2000\t Step: 30/54\t Train Loss: 3.754595\t Valid Loss: 4.527821\n",
      "Epoch: 901/2000\t Step: 45/54\t Train Loss: 3.811237\t Valid Loss: 4.566821\n",
      "Epoch: 902/2000\t Step: 15/54\t Train Loss: 3.808794\t Valid Loss: 4.458333\n",
      "Epoch: 902/2000\t Step: 30/54\t Train Loss: 3.850085\t Valid Loss: 4.916506\n",
      "Epoch: 902/2000\t Step: 45/54\t Train Loss: 3.753267\t Valid Loss: 4.725842\n",
      "Epoch: 903/2000\t Step: 15/54\t Train Loss: 3.799656\t Valid Loss: 4.475937\n",
      "Epoch: 903/2000\t Step: 30/54\t Train Loss: 3.811368\t Valid Loss: 4.957356\n",
      "Epoch: 903/2000\t Step: 45/54\t Train Loss: 3.784453\t Valid Loss: 4.771334\n",
      "Epoch: 904/2000\t Step: 15/54\t Train Loss: 3.803576\t Valid Loss: 4.849919\n",
      "Epoch: 904/2000\t Step: 30/54\t Train Loss: 3.780091\t Valid Loss: 4.513698\n",
      "Epoch: 904/2000\t Step: 45/54\t Train Loss: 3.861374\t Valid Loss: 4.432591\n",
      "Epoch: 905/2000\t Step: 15/54\t Train Loss: 3.791064\t Valid Loss: 4.551845\n",
      "Epoch: 905/2000\t Step: 30/54\t Train Loss: 3.797777\t Valid Loss: 4.507351\n",
      "Epoch: 905/2000\t Step: 45/54\t Train Loss: 3.853801\t Valid Loss: 4.600971\n",
      "Epoch: 906/2000\t Step: 15/54\t Train Loss: 3.789295\t Valid Loss: 4.759740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 906/2000\t Step: 30/54\t Train Loss: 3.710616\t Valid Loss: 4.679449\n",
      "Epoch: 906/2000\t Step: 45/54\t Train Loss: 3.783737\t Valid Loss: 4.732495\n",
      "Epoch: 907/2000\t Step: 15/54\t Train Loss: 3.818635\t Valid Loss: 4.284827\n",
      "Epoch: 907/2000\t Step: 30/54\t Train Loss: 3.747784\t Valid Loss: 4.546971\n",
      "Epoch: 907/2000\t Step: 45/54\t Train Loss: 3.739007\t Valid Loss: 4.642636\n",
      "Epoch: 908/2000\t Step: 15/54\t Train Loss: 3.787846\t Valid Loss: 4.574276\n",
      "Epoch: 908/2000\t Step: 30/54\t Train Loss: 3.832712\t Valid Loss: 4.486705\n",
      "Epoch: 908/2000\t Step: 45/54\t Train Loss: 3.759816\t Valid Loss: 4.579905\n",
      "Epoch: 909/2000\t Step: 15/54\t Train Loss: 3.797426\t Valid Loss: 4.581742\n",
      "Epoch: 909/2000\t Step: 30/54\t Train Loss: 3.730148\t Valid Loss: 4.571347\n",
      "Epoch: 909/2000\t Step: 45/54\t Train Loss: 3.747505\t Valid Loss: 4.766215\n",
      "Epoch: 910/2000\t Step: 15/54\t Train Loss: 3.824054\t Valid Loss: 4.454641\n",
      "Epoch: 910/2000\t Step: 30/54\t Train Loss: 3.756174\t Valid Loss: 4.548411\n",
      "Epoch: 910/2000\t Step: 45/54\t Train Loss: 3.807642\t Valid Loss: 4.757743\n",
      "Epoch: 911/2000\t Step: 15/54\t Train Loss: 3.806743\t Valid Loss: 4.504067\n",
      "Epoch: 911/2000\t Step: 30/54\t Train Loss: 3.736430\t Valid Loss: 4.611734\n",
      "Epoch: 911/2000\t Step: 45/54\t Train Loss: 3.781173\t Valid Loss: 4.950173\n",
      "Epoch: 912/2000\t Step: 15/54\t Train Loss: 3.764060\t Valid Loss: 4.427636\n",
      "Epoch: 912/2000\t Step: 30/54\t Train Loss: 3.732906\t Valid Loss: 4.757644\n",
      "Epoch: 912/2000\t Step: 45/54\t Train Loss: 3.772936\t Valid Loss: 4.518555\n",
      "Epoch: 913/2000\t Step: 15/54\t Train Loss: 3.745171\t Valid Loss: 4.755740\n",
      "Epoch: 913/2000\t Step: 30/54\t Train Loss: 3.809494\t Valid Loss: 4.716244\n",
      "Epoch: 913/2000\t Step: 45/54\t Train Loss: 3.794853\t Valid Loss: 4.861228\n",
      "Epoch: 914/2000\t Step: 15/54\t Train Loss: 3.759713\t Valid Loss: 4.409165\n",
      "Epoch: 914/2000\t Step: 30/54\t Train Loss: 3.838963\t Valid Loss: 4.447451\n",
      "Epoch: 914/2000\t Step: 45/54\t Train Loss: 3.737178\t Valid Loss: 4.730813\n",
      "Epoch: 915/2000\t Step: 15/54\t Train Loss: 3.773908\t Valid Loss: 4.781231\n",
      "Epoch: 915/2000\t Step: 30/54\t Train Loss: 3.806120\t Valid Loss: 4.750903\n",
      "Epoch: 915/2000\t Step: 45/54\t Train Loss: 3.862389\t Valid Loss: 4.576152\n",
      "Epoch: 916/2000\t Step: 15/54\t Train Loss: 3.807973\t Valid Loss: 4.488731\n",
      "Epoch: 916/2000\t Step: 30/54\t Train Loss: 3.861979\t Valid Loss: 4.667999\n",
      "Epoch: 916/2000\t Step: 45/54\t Train Loss: 3.746524\t Valid Loss: 4.480827\n",
      "Epoch: 917/2000\t Step: 15/54\t Train Loss: 3.875205\t Valid Loss: 4.623419\n",
      "Epoch: 917/2000\t Step: 30/54\t Train Loss: 3.819308\t Valid Loss: 5.037571\n",
      "Epoch: 917/2000\t Step: 45/54\t Train Loss: 3.792644\t Valid Loss: 4.384412\n",
      "Epoch: 918/2000\t Step: 15/54\t Train Loss: 3.806199\t Valid Loss: 4.503744\n",
      "Epoch: 918/2000\t Step: 30/54\t Train Loss: 3.822466\t Valid Loss: 4.584334\n",
      "Epoch: 918/2000\t Step: 45/54\t Train Loss: 3.773685\t Valid Loss: 4.604617\n",
      "Epoch: 919/2000\t Step: 15/54\t Train Loss: 3.813283\t Valid Loss: 4.579294\n",
      "Epoch: 919/2000\t Step: 30/54\t Train Loss: 3.755673\t Valid Loss: 4.572317\n",
      "Epoch: 919/2000\t Step: 45/54\t Train Loss: 3.794964\t Valid Loss: 4.588832\n",
      "Epoch: 920/2000\t Step: 15/54\t Train Loss: 3.820693\t Valid Loss: 4.363977\n",
      "Epoch: 920/2000\t Step: 30/54\t Train Loss: 3.810666\t Valid Loss: 4.364617\n",
      "Epoch: 920/2000\t Step: 45/54\t Train Loss: 3.781457\t Valid Loss: 4.767443\n",
      "Epoch: 921/2000\t Step: 15/54\t Train Loss: 3.797155\t Valid Loss: 4.474976\n",
      "Epoch: 921/2000\t Step: 30/54\t Train Loss: 3.776683\t Valid Loss: 4.506547\n",
      "Epoch: 921/2000\t Step: 45/54\t Train Loss: 3.746858\t Valid Loss: 4.908890\n",
      "Epoch: 922/2000\t Step: 15/54\t Train Loss: 3.846251\t Valid Loss: 4.650155\n",
      "Epoch: 922/2000\t Step: 30/54\t Train Loss: 3.770585\t Valid Loss: 4.789330\n",
      "Epoch: 922/2000\t Step: 45/54\t Train Loss: 3.762265\t Valid Loss: 4.548309\n",
      "Epoch: 923/2000\t Step: 15/54\t Train Loss: 3.796080\t Valid Loss: 4.630461\n",
      "Epoch: 923/2000\t Step: 30/54\t Train Loss: 3.790205\t Valid Loss: 4.641649\n",
      "Epoch: 923/2000\t Step: 45/54\t Train Loss: 3.761958\t Valid Loss: 4.533488\n",
      "Epoch: 924/2000\t Step: 15/54\t Train Loss: 3.863421\t Valid Loss: 4.610386\n",
      "Epoch: 924/2000\t Step: 30/54\t Train Loss: 3.780300\t Valid Loss: 4.512763\n",
      "Epoch: 924/2000\t Step: 45/54\t Train Loss: 3.816167\t Valid Loss: 4.784964\n",
      "Epoch: 925/2000\t Step: 15/54\t Train Loss: 3.773461\t Valid Loss: 4.371812\n",
      "Epoch: 925/2000\t Step: 30/54\t Train Loss: 3.800221\t Valid Loss: 4.886180\n",
      "Epoch: 925/2000\t Step: 45/54\t Train Loss: 3.811704\t Valid Loss: 4.718423\n",
      "Epoch: 926/2000\t Step: 15/54\t Train Loss: 3.783869\t Valid Loss: 4.527600\n",
      "Epoch: 926/2000\t Step: 30/54\t Train Loss: 3.804424\t Valid Loss: 4.547493\n",
      "Epoch: 926/2000\t Step: 45/54\t Train Loss: 3.837632\t Valid Loss: 4.589420\n",
      "Epoch: 927/2000\t Step: 15/54\t Train Loss: 3.815941\t Valid Loss: 4.321626\n",
      "Epoch: 927/2000\t Step: 30/54\t Train Loss: 3.820983\t Valid Loss: 4.531593\n",
      "Epoch: 927/2000\t Step: 45/54\t Train Loss: 3.717920\t Valid Loss: 4.731947\n",
      "Epoch: 928/2000\t Step: 15/54\t Train Loss: 3.755318\t Valid Loss: 4.539988\n",
      "Epoch: 928/2000\t Step: 30/54\t Train Loss: 3.778742\t Valid Loss: 4.453214\n",
      "Epoch: 928/2000\t Step: 45/54\t Train Loss: 3.808350\t Valid Loss: 4.675324\n",
      "Epoch: 929/2000\t Step: 15/54\t Train Loss: 3.810551\t Valid Loss: 4.579264\n",
      "Epoch: 929/2000\t Step: 30/54\t Train Loss: 3.786285\t Valid Loss: 4.494006\n",
      "Epoch: 929/2000\t Step: 45/54\t Train Loss: 3.813231\t Valid Loss: 4.335004\n",
      "Epoch: 930/2000\t Step: 15/54\t Train Loss: 3.810582\t Valid Loss: 4.629727\n",
      "Epoch: 930/2000\t Step: 30/54\t Train Loss: 3.819971\t Valid Loss: 4.525593\n",
      "Epoch: 930/2000\t Step: 45/54\t Train Loss: 3.827158\t Valid Loss: 4.810815\n",
      "Epoch: 931/2000\t Step: 15/54\t Train Loss: 3.790290\t Valid Loss: 4.550806\n",
      "Epoch: 931/2000\t Step: 30/54\t Train Loss: 3.829970\t Valid Loss: 4.755068\n",
      "Epoch: 931/2000\t Step: 45/54\t Train Loss: 3.800022\t Valid Loss: 4.408627\n",
      "Epoch: 932/2000\t Step: 15/54\t Train Loss: 3.832648\t Valid Loss: 4.401702\n",
      "Epoch: 932/2000\t Step: 30/54\t Train Loss: 3.800984\t Valid Loss: 4.490502\n",
      "Epoch: 932/2000\t Step: 45/54\t Train Loss: 3.893149\t Valid Loss: 4.455271\n",
      "Epoch: 933/2000\t Step: 15/54\t Train Loss: 3.787188\t Valid Loss: 4.661944\n",
      "Epoch: 933/2000\t Step: 30/54\t Train Loss: 3.762750\t Valid Loss: 4.858731\n",
      "Epoch: 933/2000\t Step: 45/54\t Train Loss: 3.821951\t Valid Loss: 4.662069\n",
      "Epoch: 934/2000\t Step: 15/54\t Train Loss: 3.874980\t Valid Loss: 4.595377\n",
      "Epoch: 934/2000\t Step: 30/54\t Train Loss: 3.793046\t Valid Loss: 4.386230\n",
      "Epoch: 934/2000\t Step: 45/54\t Train Loss: 3.757382\t Valid Loss: 4.694627\n",
      "Epoch: 935/2000\t Step: 15/54\t Train Loss: 3.767091\t Valid Loss: 4.429251\n",
      "Epoch: 935/2000\t Step: 30/54\t Train Loss: 3.920048\t Valid Loss: 4.578943\n",
      "Epoch: 935/2000\t Step: 45/54\t Train Loss: 3.821840\t Valid Loss: 4.382306\n",
      "Epoch: 936/2000\t Step: 15/54\t Train Loss: 3.747044\t Valid Loss: 4.418886\n",
      "Epoch: 936/2000\t Step: 30/54\t Train Loss: 3.738161\t Valid Loss: 4.689284\n",
      "Epoch: 936/2000\t Step: 45/54\t Train Loss: 3.839803\t Valid Loss: 4.690044\n",
      "Epoch: 937/2000\t Step: 15/54\t Train Loss: 3.780509\t Valid Loss: 4.600049\n",
      "Epoch: 937/2000\t Step: 30/54\t Train Loss: 3.791681\t Valid Loss: 4.644909\n",
      "Epoch: 937/2000\t Step: 45/54\t Train Loss: 3.789575\t Valid Loss: 4.671261\n",
      "Epoch: 938/2000\t Step: 15/54\t Train Loss: 3.819922\t Valid Loss: 4.538359\n",
      "Epoch: 938/2000\t Step: 30/54\t Train Loss: 3.824227\t Valid Loss: 4.433634\n",
      "Epoch: 938/2000\t Step: 45/54\t Train Loss: 3.814676\t Valid Loss: 4.424985\n",
      "Epoch: 939/2000\t Step: 15/54\t Train Loss: 3.792637\t Valid Loss: 4.314218\n",
      "Epoch: 939/2000\t Step: 30/54\t Train Loss: 3.828049\t Valid Loss: 4.604049\n",
      "Epoch: 939/2000\t Step: 45/54\t Train Loss: 3.768338\t Valid Loss: 5.049715\n",
      "Epoch: 940/2000\t Step: 15/54\t Train Loss: 3.877564\t Valid Loss: 4.475247\n",
      "Epoch: 940/2000\t Step: 30/54\t Train Loss: 3.842198\t Valid Loss: 4.450939\n",
      "Epoch: 940/2000\t Step: 45/54\t Train Loss: 3.814061\t Valid Loss: 4.563503\n",
      "Epoch: 941/2000\t Step: 15/54\t Train Loss: 3.819508\t Valid Loss: 4.501277\n",
      "Epoch: 941/2000\t Step: 30/54\t Train Loss: 3.858906\t Valid Loss: 4.581689\n",
      "Epoch: 941/2000\t Step: 45/54\t Train Loss: 3.845129\t Valid Loss: 4.493527\n",
      "Epoch: 942/2000\t Step: 15/54\t Train Loss: 3.745103\t Valid Loss: 4.506421\n",
      "Epoch: 942/2000\t Step: 30/54\t Train Loss: 3.778014\t Valid Loss: 4.635041\n",
      "Epoch: 942/2000\t Step: 45/54\t Train Loss: 3.741740\t Valid Loss: 4.835842\n",
      "Epoch: 943/2000\t Step: 15/54\t Train Loss: 3.824775\t Valid Loss: 4.494036\n",
      "Epoch: 943/2000\t Step: 30/54\t Train Loss: 3.821357\t Valid Loss: 4.609457\n",
      "Epoch: 943/2000\t Step: 45/54\t Train Loss: 3.852839\t Valid Loss: 4.365355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 944/2000\t Step: 15/54\t Train Loss: 3.759089\t Valid Loss: 4.621278\n",
      "Epoch: 944/2000\t Step: 30/54\t Train Loss: 3.790548\t Valid Loss: 4.781748\n",
      "Epoch: 944/2000\t Step: 45/54\t Train Loss: 3.794626\t Valid Loss: 4.363391\n",
      "Epoch: 945/2000\t Step: 15/54\t Train Loss: 3.791239\t Valid Loss: 4.383620\n",
      "Epoch: 945/2000\t Step: 30/54\t Train Loss: 3.761977\t Valid Loss: 4.375579\n",
      "Epoch: 945/2000\t Step: 45/54\t Train Loss: 3.804316\t Valid Loss: 4.550225\n",
      "Epoch: 946/2000\t Step: 15/54\t Train Loss: 3.784845\t Valid Loss: 4.553202\n",
      "Epoch: 946/2000\t Step: 30/54\t Train Loss: 3.809951\t Valid Loss: 4.685583\n",
      "Epoch: 946/2000\t Step: 45/54\t Train Loss: 3.806687\t Valid Loss: 4.488475\n",
      "Epoch: 947/2000\t Step: 15/54\t Train Loss: 3.858587\t Valid Loss: 4.499510\n",
      "Epoch: 947/2000\t Step: 30/54\t Train Loss: 3.786802\t Valid Loss: 4.390721\n",
      "Epoch: 947/2000\t Step: 45/54\t Train Loss: 3.730000\t Valid Loss: 4.654290\n",
      "Epoch: 948/2000\t Step: 15/54\t Train Loss: 3.743824\t Valid Loss: 4.996556\n",
      "Epoch: 948/2000\t Step: 30/54\t Train Loss: 3.824631\t Valid Loss: 4.561161\n",
      "Epoch: 948/2000\t Step: 45/54\t Train Loss: 3.823429\t Valid Loss: 4.511825\n",
      "Epoch: 949/2000\t Step: 15/54\t Train Loss: 3.753221\t Valid Loss: 4.716865\n",
      "Epoch: 949/2000\t Step: 30/54\t Train Loss: 3.713161\t Valid Loss: 4.902058\n",
      "Epoch: 949/2000\t Step: 45/54\t Train Loss: 3.743303\t Valid Loss: 4.644800\n",
      "Epoch: 950/2000\t Step: 15/54\t Train Loss: 3.774920\t Valid Loss: 4.611065\n",
      "Epoch: 950/2000\t Step: 30/54\t Train Loss: 3.809325\t Valid Loss: 4.631716\n",
      "Epoch: 950/2000\t Step: 45/54\t Train Loss: 3.784403\t Valid Loss: 4.451748\n",
      "Epoch: 951/2000\t Step: 15/54\t Train Loss: 3.793330\t Valid Loss: 4.254258\n",
      "Epoch: 951/2000\t Step: 30/54\t Train Loss: 3.764131\t Valid Loss: 4.679653\n",
      "Epoch: 951/2000\t Step: 45/54\t Train Loss: 3.820985\t Valid Loss: 4.668311\n",
      "Epoch: 952/2000\t Step: 15/54\t Train Loss: 3.861753\t Valid Loss: 4.464268\n",
      "Epoch: 952/2000\t Step: 30/54\t Train Loss: 3.775739\t Valid Loss: 4.654031\n",
      "Epoch: 952/2000\t Step: 45/54\t Train Loss: 3.815840\t Valid Loss: 4.770466\n",
      "Epoch: 953/2000\t Step: 15/54\t Train Loss: 3.819656\t Valid Loss: 4.622007\n",
      "Epoch: 953/2000\t Step: 30/54\t Train Loss: 3.806149\t Valid Loss: 4.470570\n",
      "Epoch: 953/2000\t Step: 45/54\t Train Loss: 3.775299\t Valid Loss: 4.548837\n",
      "Epoch: 954/2000\t Step: 15/54\t Train Loss: 3.796506\t Valid Loss: 4.510529\n",
      "Epoch: 954/2000\t Step: 30/54\t Train Loss: 3.757852\t Valid Loss: 4.632879\n",
      "Epoch: 954/2000\t Step: 45/54\t Train Loss: 3.751729\t Valid Loss: 4.736542\n",
      "Epoch: 955/2000\t Step: 15/54\t Train Loss: 3.757332\t Valid Loss: 4.694265\n",
      "Epoch: 955/2000\t Step: 30/54\t Train Loss: 3.760106\t Valid Loss: 4.720157\n",
      "Epoch: 955/2000\t Step: 45/54\t Train Loss: 3.775158\t Valid Loss: 4.479322\n",
      "Epoch: 956/2000\t Step: 15/54\t Train Loss: 3.694792\t Valid Loss: 4.637444\n",
      "Epoch: 956/2000\t Step: 30/54\t Train Loss: 3.766681\t Valid Loss: 4.448371\n",
      "Epoch: 956/2000\t Step: 45/54\t Train Loss: 3.784833\t Valid Loss: 4.715533\n",
      "Epoch: 957/2000\t Step: 15/54\t Train Loss: 3.836817\t Valid Loss: 4.800851\n",
      "Epoch: 957/2000\t Step: 30/54\t Train Loss: 3.739601\t Valid Loss: 4.919098\n",
      "Epoch: 957/2000\t Step: 45/54\t Train Loss: 3.794515\t Valid Loss: 4.385277\n",
      "Epoch: 958/2000\t Step: 15/54\t Train Loss: 3.809547\t Valid Loss: 4.629219\n",
      "Epoch: 958/2000\t Step: 30/54\t Train Loss: 3.750640\t Valid Loss: 4.870229\n",
      "Epoch: 958/2000\t Step: 45/54\t Train Loss: 3.863218\t Valid Loss: 4.549770\n",
      "Epoch: 959/2000\t Step: 15/54\t Train Loss: 3.817987\t Valid Loss: 4.696999\n",
      "Epoch: 959/2000\t Step: 30/54\t Train Loss: 3.742446\t Valid Loss: 4.664879\n",
      "Epoch: 959/2000\t Step: 45/54\t Train Loss: 3.716141\t Valid Loss: 4.702494\n",
      "Epoch: 960/2000\t Step: 15/54\t Train Loss: 3.778463\t Valid Loss: 4.642107\n",
      "Epoch: 960/2000\t Step: 30/54\t Train Loss: 3.788449\t Valid Loss: 4.579238\n",
      "Epoch: 960/2000\t Step: 45/54\t Train Loss: 3.813593\t Valid Loss: 4.867683\n",
      "Epoch: 961/2000\t Step: 15/54\t Train Loss: 3.757414\t Valid Loss: 4.488913\n",
      "Epoch: 961/2000\t Step: 30/54\t Train Loss: 3.778175\t Valid Loss: 5.023511\n",
      "Epoch: 961/2000\t Step: 45/54\t Train Loss: 3.823897\t Valid Loss: 4.416654\n",
      "Epoch: 962/2000\t Step: 15/54\t Train Loss: 3.804149\t Valid Loss: 4.356926\n",
      "Epoch: 962/2000\t Step: 30/54\t Train Loss: 3.790397\t Valid Loss: 4.554045\n",
      "Epoch: 962/2000\t Step: 45/54\t Train Loss: 3.713491\t Valid Loss: 4.918153\n",
      "Epoch: 963/2000\t Step: 15/54\t Train Loss: 3.825640\t Valid Loss: 4.418688\n",
      "Epoch: 963/2000\t Step: 30/54\t Train Loss: 3.797447\t Valid Loss: 4.590648\n",
      "Epoch: 963/2000\t Step: 45/54\t Train Loss: 3.769208\t Valid Loss: 4.820242\n",
      "Epoch: 964/2000\t Step: 15/54\t Train Loss: 3.837390\t Valid Loss: 4.372989\n",
      "Epoch: 964/2000\t Step: 30/54\t Train Loss: 3.801753\t Valid Loss: 4.720897\n",
      "Epoch: 964/2000\t Step: 45/54\t Train Loss: 3.794811\t Valid Loss: 4.549629\n",
      "Epoch: 965/2000\t Step: 15/54\t Train Loss: 3.776445\t Valid Loss: 4.556038\n",
      "Epoch: 965/2000\t Step: 30/54\t Train Loss: 3.792499\t Valid Loss: 4.566914\n",
      "Epoch: 965/2000\t Step: 45/54\t Train Loss: 3.803405\t Valid Loss: 4.410456\n",
      "Epoch: 966/2000\t Step: 15/54\t Train Loss: 3.792998\t Valid Loss: 4.610739\n",
      "Epoch: 966/2000\t Step: 30/54\t Train Loss: 3.797044\t Valid Loss: 4.906719\n",
      "Epoch: 966/2000\t Step: 45/54\t Train Loss: 3.783713\t Valid Loss: 4.479745\n",
      "Epoch: 967/2000\t Step: 15/54\t Train Loss: 3.786906\t Valid Loss: 4.878401\n",
      "Epoch: 967/2000\t Step: 30/54\t Train Loss: 3.770222\t Valid Loss: 4.597823\n",
      "Epoch: 967/2000\t Step: 45/54\t Train Loss: 3.780919\t Valid Loss: 4.710452\n",
      "Epoch: 968/2000\t Step: 15/54\t Train Loss: 3.749409\t Valid Loss: 4.542552\n",
      "Epoch: 968/2000\t Step: 30/54\t Train Loss: 3.792161\t Valid Loss: 4.559794\n",
      "Epoch: 968/2000\t Step: 45/54\t Train Loss: 3.792704\t Valid Loss: 4.582233\n",
      "Epoch: 969/2000\t Step: 15/54\t Train Loss: 3.800194\t Valid Loss: 4.582301\n",
      "Epoch: 969/2000\t Step: 30/54\t Train Loss: 3.821207\t Valid Loss: 4.401045\n",
      "Epoch: 969/2000\t Step: 45/54\t Train Loss: 3.822992\t Valid Loss: 4.639887\n",
      "Epoch: 970/2000\t Step: 15/54\t Train Loss: 3.796160\t Valid Loss: 4.524384\n",
      "Epoch: 970/2000\t Step: 30/54\t Train Loss: 3.793990\t Valid Loss: 4.509811\n",
      "Epoch: 970/2000\t Step: 45/54\t Train Loss: 3.808511\t Valid Loss: 4.439333\n",
      "Epoch: 971/2000\t Step: 15/54\t Train Loss: 3.803366\t Valid Loss: 4.454586\n",
      "Epoch: 971/2000\t Step: 30/54\t Train Loss: 3.885962\t Valid Loss: 4.571077\n",
      "Epoch: 971/2000\t Step: 45/54\t Train Loss: 3.778060\t Valid Loss: 4.641835\n",
      "Epoch: 972/2000\t Step: 15/54\t Train Loss: 3.785811\t Valid Loss: 4.508629\n",
      "Epoch: 972/2000\t Step: 30/54\t Train Loss: 3.820524\t Valid Loss: 4.535844\n",
      "Epoch: 972/2000\t Step: 45/54\t Train Loss: 3.720074\t Valid Loss: 4.624554\n",
      "Epoch: 973/2000\t Step: 15/54\t Train Loss: 3.825876\t Valid Loss: 4.394859\n",
      "Epoch: 973/2000\t Step: 30/54\t Train Loss: 3.773487\t Valid Loss: 4.912498\n",
      "Epoch: 973/2000\t Step: 45/54\t Train Loss: 3.760386\t Valid Loss: 4.894212\n",
      "Epoch: 974/2000\t Step: 15/54\t Train Loss: 3.784644\t Valid Loss: 4.891574\n",
      "Epoch: 974/2000\t Step: 30/54\t Train Loss: 3.718013\t Valid Loss: 4.671874\n",
      "Epoch: 974/2000\t Step: 45/54\t Train Loss: 3.726708\t Valid Loss: 4.936124\n",
      "Epoch: 975/2000\t Step: 15/54\t Train Loss: 3.758415\t Valid Loss: 4.936491\n",
      "Epoch: 975/2000\t Step: 30/54\t Train Loss: 3.825398\t Valid Loss: 4.955669\n",
      "Epoch: 975/2000\t Step: 45/54\t Train Loss: 3.788772\t Valid Loss: 4.543888\n",
      "Epoch: 976/2000\t Step: 15/54\t Train Loss: 3.780727\t Valid Loss: 4.526710\n",
      "Epoch: 976/2000\t Step: 30/54\t Train Loss: 3.751816\t Valid Loss: 4.669036\n",
      "Epoch: 976/2000\t Step: 45/54\t Train Loss: 3.826004\t Valid Loss: 4.572601\n",
      "Epoch: 977/2000\t Step: 15/54\t Train Loss: 3.825675\t Valid Loss: 4.754311\n",
      "Epoch: 977/2000\t Step: 30/54\t Train Loss: 3.798406\t Valid Loss: 4.659007\n",
      "Epoch: 977/2000\t Step: 45/54\t Train Loss: 3.804078\t Valid Loss: 4.845561\n",
      "Epoch: 978/2000\t Step: 15/54\t Train Loss: 3.703788\t Valid Loss: 4.793842\n",
      "Epoch: 978/2000\t Step: 30/54\t Train Loss: 3.807904\t Valid Loss: 4.589716\n",
      "Epoch: 978/2000\t Step: 45/54\t Train Loss: 3.826644\t Valid Loss: 4.474193\n",
      "Epoch: 979/2000\t Step: 15/54\t Train Loss: 3.754255\t Valid Loss: 4.482218\n",
      "Epoch: 979/2000\t Step: 30/54\t Train Loss: 3.778092\t Valid Loss: 4.535741\n",
      "Epoch: 979/2000\t Step: 45/54\t Train Loss: 3.797504\t Valid Loss: 4.557983\n",
      "Epoch: 980/2000\t Step: 15/54\t Train Loss: 3.789431\t Valid Loss: 4.484931\n",
      "Epoch: 980/2000\t Step: 30/54\t Train Loss: 3.789598\t Valid Loss: 4.648124\n",
      "Epoch: 980/2000\t Step: 45/54\t Train Loss: 3.818211\t Valid Loss: 4.940866\n",
      "Epoch: 981/2000\t Step: 15/54\t Train Loss: 3.784588\t Valid Loss: 4.449625\n",
      "Epoch: 981/2000\t Step: 30/54\t Train Loss: 3.800138\t Valid Loss: 4.643832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 981/2000\t Step: 45/54\t Train Loss: 3.780166\t Valid Loss: 4.830388\n",
      "Epoch: 982/2000\t Step: 15/54\t Train Loss: 3.771756\t Valid Loss: 4.636364\n",
      "Epoch: 982/2000\t Step: 30/54\t Train Loss: 3.738672\t Valid Loss: 4.634087\n",
      "Epoch: 982/2000\t Step: 45/54\t Train Loss: 3.828560\t Valid Loss: 4.807222\n",
      "Epoch: 983/2000\t Step: 15/54\t Train Loss: 3.849673\t Valid Loss: 4.486862\n",
      "Epoch: 983/2000\t Step: 30/54\t Train Loss: 3.829354\t Valid Loss: 4.502186\n",
      "Epoch: 983/2000\t Step: 45/54\t Train Loss: 3.779252\t Valid Loss: 5.051100\n",
      "Epoch: 984/2000\t Step: 15/54\t Train Loss: 3.823806\t Valid Loss: 4.724032\n",
      "Epoch: 984/2000\t Step: 30/54\t Train Loss: 3.747975\t Valid Loss: 4.814831\n",
      "Epoch: 984/2000\t Step: 45/54\t Train Loss: 3.751054\t Valid Loss: 4.800816\n",
      "Epoch: 985/2000\t Step: 15/54\t Train Loss: 3.739328\t Valid Loss: 4.479001\n",
      "Epoch: 985/2000\t Step: 30/54\t Train Loss: 3.785842\t Valid Loss: 5.186348\n",
      "Epoch: 985/2000\t Step: 45/54\t Train Loss: 3.767649\t Valid Loss: 4.832022\n",
      "Epoch: 986/2000\t Step: 15/54\t Train Loss: 3.764958\t Valid Loss: 4.810294\n",
      "Epoch: 986/2000\t Step: 30/54\t Train Loss: 3.843514\t Valid Loss: 4.531903\n",
      "Epoch: 986/2000\t Step: 45/54\t Train Loss: 3.815612\t Valid Loss: 4.514138\n",
      "Epoch: 987/2000\t Step: 15/54\t Train Loss: 3.831306\t Valid Loss: 4.301670\n",
      "Epoch: 987/2000\t Step: 30/54\t Train Loss: 3.792974\t Valid Loss: 4.481758\n",
      "Epoch: 987/2000\t Step: 45/54\t Train Loss: 3.808449\t Valid Loss: 4.708424\n",
      "Epoch: 988/2000\t Step: 15/54\t Train Loss: 3.883118\t Valid Loss: 4.731499\n",
      "Epoch: 988/2000\t Step: 30/54\t Train Loss: 3.793578\t Valid Loss: 4.431572\n",
      "Epoch: 988/2000\t Step: 45/54\t Train Loss: 3.829312\t Valid Loss: 4.551169\n",
      "Epoch: 989/2000\t Step: 15/54\t Train Loss: 3.798192\t Valid Loss: 4.632169\n",
      "Epoch: 989/2000\t Step: 30/54\t Train Loss: 3.801376\t Valid Loss: 4.561994\n",
      "Epoch: 989/2000\t Step: 45/54\t Train Loss: 3.812931\t Valid Loss: 4.494351\n",
      "Epoch: 990/2000\t Step: 15/54\t Train Loss: 3.763990\t Valid Loss: 4.524861\n",
      "Epoch: 990/2000\t Step: 30/54\t Train Loss: 3.807799\t Valid Loss: 4.403153\n",
      "Epoch: 990/2000\t Step: 45/54\t Train Loss: 3.808154\t Valid Loss: 4.693570\n",
      "Epoch: 991/2000\t Step: 15/54\t Train Loss: 3.762987\t Valid Loss: 4.683336\n",
      "Epoch: 991/2000\t Step: 30/54\t Train Loss: 3.729558\t Valid Loss: 4.784622\n",
      "Epoch: 991/2000\t Step: 45/54\t Train Loss: 3.783513\t Valid Loss: 4.851233\n",
      "Epoch: 992/2000\t Step: 15/54\t Train Loss: 3.804463\t Valid Loss: 4.597114\n",
      "Epoch: 992/2000\t Step: 30/54\t Train Loss: 3.760231\t Valid Loss: 4.565129\n",
      "Epoch: 992/2000\t Step: 45/54\t Train Loss: 3.760147\t Valid Loss: 4.617960\n",
      "Epoch: 993/2000\t Step: 15/54\t Train Loss: 3.834659\t Valid Loss: 4.367199\n",
      "Epoch: 993/2000\t Step: 30/54\t Train Loss: 3.756099\t Valid Loss: 4.719101\n",
      "Epoch: 993/2000\t Step: 45/54\t Train Loss: 3.779613\t Valid Loss: 4.595174\n",
      "Epoch: 994/2000\t Step: 15/54\t Train Loss: 3.833888\t Valid Loss: 4.432771\n",
      "Epoch: 994/2000\t Step: 30/54\t Train Loss: 3.828935\t Valid Loss: 4.555971\n",
      "Epoch: 994/2000\t Step: 45/54\t Train Loss: 3.742736\t Valid Loss: 4.642019\n",
      "Epoch: 995/2000\t Step: 15/54\t Train Loss: 3.810767\t Valid Loss: 4.850060\n",
      "Epoch: 995/2000\t Step: 30/54\t Train Loss: 3.763247\t Valid Loss: 4.738119\n",
      "Epoch: 995/2000\t Step: 45/54\t Train Loss: 3.813773\t Valid Loss: 4.487399\n",
      "Epoch: 996/2000\t Step: 15/54\t Train Loss: 3.833956\t Valid Loss: 4.389298\n",
      "Epoch: 996/2000\t Step: 30/54\t Train Loss: 3.737859\t Valid Loss: 4.745315\n",
      "Epoch: 996/2000\t Step: 45/54\t Train Loss: 3.768077\t Valid Loss: 4.432217\n",
      "Epoch: 997/2000\t Step: 15/54\t Train Loss: 3.762089\t Valid Loss: 4.704158\n",
      "Epoch: 997/2000\t Step: 30/54\t Train Loss: 3.807685\t Valid Loss: 4.723247\n",
      "Epoch: 997/2000\t Step: 45/54\t Train Loss: 3.809201\t Valid Loss: 4.712870\n",
      "Epoch: 998/2000\t Step: 15/54\t Train Loss: 3.811573\t Valid Loss: 4.825994\n",
      "Epoch: 998/2000\t Step: 30/54\t Train Loss: 3.785867\t Valid Loss: 4.660617\n",
      "Epoch: 998/2000\t Step: 45/54\t Train Loss: 3.796526\t Valid Loss: 4.696051\n",
      "Epoch: 999/2000\t Step: 15/54\t Train Loss: 3.823333\t Valid Loss: 4.438147\n",
      "Epoch: 999/2000\t Step: 30/54\t Train Loss: 3.789175\t Valid Loss: 4.759747\n",
      "Epoch: 999/2000\t Step: 45/54\t Train Loss: 3.855920\t Valid Loss: 4.760627\n",
      "Epoch: 1000/2000\t Step: 15/54\t Train Loss: 3.766760\t Valid Loss: 4.672313\n",
      "Epoch: 1000/2000\t Step: 30/54\t Train Loss: 3.752383\t Valid Loss: 4.741720\n",
      "Epoch: 1000/2000\t Step: 45/54\t Train Loss: 3.754599\t Valid Loss: 4.826166\n",
      "Epoch: 1001/2000\t Step: 15/54\t Train Loss: 3.867641\t Valid Loss: 4.821116\n",
      "Epoch: 1001/2000\t Step: 30/54\t Train Loss: 3.787192\t Valid Loss: 4.538391\n",
      "Epoch: 1001/2000\t Step: 45/54\t Train Loss: 3.788878\t Valid Loss: 4.638480\n",
      "Epoch: 1002/2000\t Step: 15/54\t Train Loss: 3.892474\t Valid Loss: 4.417191\n",
      "Epoch: 1002/2000\t Step: 30/54\t Train Loss: 3.842815\t Valid Loss: 4.704786\n",
      "Epoch: 1002/2000\t Step: 45/54\t Train Loss: 3.847791\t Valid Loss: 4.787629\n",
      "Epoch: 1003/2000\t Step: 15/54\t Train Loss: 3.880955\t Valid Loss: 4.897346\n",
      "Epoch: 1003/2000\t Step: 30/54\t Train Loss: 3.812461\t Valid Loss: 4.576925\n",
      "Epoch: 1003/2000\t Step: 45/54\t Train Loss: 3.804079\t Valid Loss: 4.448918\n",
      "Epoch: 1004/2000\t Step: 15/54\t Train Loss: 3.844000\t Valid Loss: 4.505907\n",
      "Epoch: 1004/2000\t Step: 30/54\t Train Loss: 3.785566\t Valid Loss: 4.462299\n",
      "Epoch: 1004/2000\t Step: 45/54\t Train Loss: 3.779950\t Valid Loss: 4.642818\n",
      "Epoch: 1005/2000\t Step: 15/54\t Train Loss: 3.769720\t Valid Loss: 4.611939\n",
      "Epoch: 1005/2000\t Step: 30/54\t Train Loss: 3.823145\t Valid Loss: 4.536712\n",
      "Epoch: 1005/2000\t Step: 45/54\t Train Loss: 3.862283\t Valid Loss: 4.563123\n",
      "Epoch: 1006/2000\t Step: 15/54\t Train Loss: 3.779261\t Valid Loss: 4.670679\n",
      "Epoch: 1006/2000\t Step: 30/54\t Train Loss: 3.841927\t Valid Loss: 4.330868\n",
      "Epoch: 1006/2000\t Step: 45/54\t Train Loss: 3.819329\t Valid Loss: 4.326131\n",
      "Epoch: 1007/2000\t Step: 15/54\t Train Loss: 3.849163\t Valid Loss: 4.704285\n",
      "Epoch: 1007/2000\t Step: 30/54\t Train Loss: 3.745892\t Valid Loss: 4.661373\n",
      "Epoch: 1007/2000\t Step: 45/54\t Train Loss: 3.777181\t Valid Loss: 4.566532\n",
      "Epoch: 1008/2000\t Step: 15/54\t Train Loss: 3.931267\t Valid Loss: 4.573074\n",
      "Epoch: 1008/2000\t Step: 30/54\t Train Loss: 3.763991\t Valid Loss: 4.449851\n",
      "Epoch: 1008/2000\t Step: 45/54\t Train Loss: 3.775385\t Valid Loss: 4.595593\n",
      "Epoch: 1009/2000\t Step: 15/54\t Train Loss: 3.812965\t Valid Loss: 4.426083\n",
      "Epoch: 1009/2000\t Step: 30/54\t Train Loss: 3.810701\t Valid Loss: 4.648238\n",
      "Epoch: 1009/2000\t Step: 45/54\t Train Loss: 3.793735\t Valid Loss: 5.208368\n",
      "Epoch: 1010/2000\t Step: 15/54\t Train Loss: 3.782944\t Valid Loss: 4.592821\n",
      "Epoch: 1010/2000\t Step: 30/54\t Train Loss: 3.708194\t Valid Loss: 4.858641\n",
      "Epoch: 1010/2000\t Step: 45/54\t Train Loss: 3.722760\t Valid Loss: 4.620669\n",
      "Epoch: 1011/2000\t Step: 15/54\t Train Loss: 3.818293\t Valid Loss: 4.664620\n",
      "Epoch: 1011/2000\t Step: 30/54\t Train Loss: 3.812504\t Valid Loss: 4.561385\n",
      "Epoch: 1011/2000\t Step: 45/54\t Train Loss: 3.712178\t Valid Loss: 4.974559\n",
      "Epoch: 1012/2000\t Step: 15/54\t Train Loss: 3.832919\t Valid Loss: 4.635464\n",
      "Epoch: 1012/2000\t Step: 30/54\t Train Loss: 3.770594\t Valid Loss: 4.567618\n",
      "Epoch: 1012/2000\t Step: 45/54\t Train Loss: 3.848763\t Valid Loss: 4.526532\n",
      "Epoch: 1013/2000\t Step: 15/54\t Train Loss: 3.763262\t Valid Loss: 4.577278\n",
      "Epoch: 1013/2000\t Step: 30/54\t Train Loss: 3.812037\t Valid Loss: 4.475547\n",
      "Epoch: 1013/2000\t Step: 45/54\t Train Loss: 3.863759\t Valid Loss: 4.598801\n",
      "Epoch: 1014/2000\t Step: 15/54\t Train Loss: 3.772052\t Valid Loss: 4.851544\n",
      "Epoch: 1014/2000\t Step: 30/54\t Train Loss: 3.726211\t Valid Loss: 4.747510\n",
      "Epoch: 1014/2000\t Step: 45/54\t Train Loss: 3.753890\t Valid Loss: 5.103729\n",
      "Epoch: 1015/2000\t Step: 15/54\t Train Loss: 3.821984\t Valid Loss: 4.632337\n",
      "Epoch: 1015/2000\t Step: 30/54\t Train Loss: 3.748116\t Valid Loss: 4.703105\n",
      "Epoch: 1015/2000\t Step: 45/54\t Train Loss: 3.872241\t Valid Loss: 4.865586\n",
      "Epoch: 1016/2000\t Step: 15/54\t Train Loss: 3.767220\t Valid Loss: 4.808694\n",
      "Epoch: 1016/2000\t Step: 30/54\t Train Loss: 3.823546\t Valid Loss: 4.845124\n",
      "Epoch: 1016/2000\t Step: 45/54\t Train Loss: 3.799688\t Valid Loss: 4.793806\n",
      "Epoch: 1017/2000\t Step: 15/54\t Train Loss: 3.836731\t Valid Loss: 4.561224\n",
      "Epoch: 1017/2000\t Step: 30/54\t Train Loss: 3.888317\t Valid Loss: 4.838787\n",
      "Epoch: 1017/2000\t Step: 45/54\t Train Loss: 3.773196\t Valid Loss: 4.588907\n",
      "Epoch: 1018/2000\t Step: 15/54\t Train Loss: 3.748029\t Valid Loss: 4.768842\n",
      "Epoch: 1018/2000\t Step: 30/54\t Train Loss: 3.746341\t Valid Loss: 4.813627\n",
      "Epoch: 1018/2000\t Step: 45/54\t Train Loss: 3.779489\t Valid Loss: 4.905303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1019/2000\t Step: 15/54\t Train Loss: 3.789779\t Valid Loss: 4.485628\n",
      "Epoch: 1019/2000\t Step: 30/54\t Train Loss: 3.771093\t Valid Loss: 4.495986\n",
      "Epoch: 1019/2000\t Step: 45/54\t Train Loss: 3.809359\t Valid Loss: 4.589354\n",
      "Epoch: 1020/2000\t Step: 15/54\t Train Loss: 3.778659\t Valid Loss: 4.428280\n",
      "Epoch: 1020/2000\t Step: 30/54\t Train Loss: 3.768844\t Valid Loss: 4.688256\n",
      "Epoch: 1020/2000\t Step: 45/54\t Train Loss: 3.731528\t Valid Loss: 4.681767\n",
      "Epoch: 1021/2000\t Step: 15/54\t Train Loss: 3.809733\t Valid Loss: 4.752341\n",
      "Epoch: 1021/2000\t Step: 30/54\t Train Loss: 3.807554\t Valid Loss: 4.713493\n",
      "Epoch: 1021/2000\t Step: 45/54\t Train Loss: 3.827486\t Valid Loss: 4.508640\n",
      "Epoch: 1022/2000\t Step: 15/54\t Train Loss: 3.782659\t Valid Loss: 4.527088\n",
      "Epoch: 1022/2000\t Step: 30/54\t Train Loss: 3.797797\t Valid Loss: 4.813628\n",
      "Epoch: 1022/2000\t Step: 45/54\t Train Loss: 3.797570\t Valid Loss: 4.821031\n",
      "Epoch: 1023/2000\t Step: 15/54\t Train Loss: 3.801202\t Valid Loss: 4.359295\n",
      "Epoch: 1023/2000\t Step: 30/54\t Train Loss: 3.833751\t Valid Loss: 4.676665\n",
      "Epoch: 1023/2000\t Step: 45/54\t Train Loss: 3.794106\t Valid Loss: 4.496806\n",
      "Epoch: 1024/2000\t Step: 15/54\t Train Loss: 3.773824\t Valid Loss: 4.751453\n",
      "Epoch: 1024/2000\t Step: 30/54\t Train Loss: 3.800303\t Valid Loss: 4.645987\n",
      "Epoch: 1024/2000\t Step: 45/54\t Train Loss: 3.822511\t Valid Loss: 4.568352\n",
      "Epoch: 1025/2000\t Step: 15/54\t Train Loss: 3.853035\t Valid Loss: 4.407959\n",
      "Epoch: 1025/2000\t Step: 30/54\t Train Loss: 3.838253\t Valid Loss: 4.707292\n",
      "Epoch: 1025/2000\t Step: 45/54\t Train Loss: 3.778500\t Valid Loss: 4.797006\n",
      "Epoch: 1026/2000\t Step: 15/54\t Train Loss: 3.843226\t Valid Loss: 4.482703\n",
      "Epoch: 1026/2000\t Step: 30/54\t Train Loss: 3.845462\t Valid Loss: 4.329506\n",
      "Epoch: 1026/2000\t Step: 45/54\t Train Loss: 3.814746\t Valid Loss: 4.404689\n",
      "Epoch: 1027/2000\t Step: 15/54\t Train Loss: 3.800866\t Valid Loss: 4.719728\n",
      "Epoch: 1027/2000\t Step: 30/54\t Train Loss: 3.850941\t Valid Loss: 4.852004\n",
      "Epoch: 1027/2000\t Step: 45/54\t Train Loss: 3.803858\t Valid Loss: 4.463140\n",
      "Epoch: 1028/2000\t Step: 15/54\t Train Loss: 3.816296\t Valid Loss: 4.709851\n",
      "Epoch: 1028/2000\t Step: 30/54\t Train Loss: 3.782807\t Valid Loss: 4.727188\n",
      "Epoch: 1028/2000\t Step: 45/54\t Train Loss: 3.789822\t Valid Loss: 4.496291\n",
      "Epoch: 1029/2000\t Step: 15/54\t Train Loss: 3.780587\t Valid Loss: 4.477601\n",
      "Epoch: 1029/2000\t Step: 30/54\t Train Loss: 3.749311\t Valid Loss: 4.595634\n",
      "Epoch: 1029/2000\t Step: 45/54\t Train Loss: 3.813085\t Valid Loss: 4.678349\n",
      "Epoch: 1030/2000\t Step: 15/54\t Train Loss: 3.776951\t Valid Loss: 4.620596\n",
      "Epoch: 1030/2000\t Step: 30/54\t Train Loss: 3.692203\t Valid Loss: 4.743422\n",
      "Epoch: 1030/2000\t Step: 45/54\t Train Loss: 3.812759\t Valid Loss: 4.445689\n",
      "Epoch: 1031/2000\t Step: 15/54\t Train Loss: 3.883337\t Valid Loss: 4.538953\n",
      "Epoch: 1031/2000\t Step: 30/54\t Train Loss: 3.776127\t Valid Loss: 4.608229\n",
      "Epoch: 1031/2000\t Step: 45/54\t Train Loss: 3.782373\t Valid Loss: 4.761683\n",
      "Epoch: 1032/2000\t Step: 15/54\t Train Loss: 3.752065\t Valid Loss: 4.786400\n",
      "Epoch: 1032/2000\t Step: 30/54\t Train Loss: 3.758195\t Valid Loss: 4.722574\n",
      "Epoch: 1032/2000\t Step: 45/54\t Train Loss: 3.786435\t Valid Loss: 4.865266\n",
      "Epoch: 1033/2000\t Step: 15/54\t Train Loss: 3.794081\t Valid Loss: 4.807622\n",
      "Epoch: 1033/2000\t Step: 30/54\t Train Loss: 3.817780\t Valid Loss: 4.751681\n",
      "Epoch: 1033/2000\t Step: 45/54\t Train Loss: 3.752930\t Valid Loss: 4.919468\n",
      "Epoch: 1034/2000\t Step: 15/54\t Train Loss: 3.760222\t Valid Loss: 4.926499\n",
      "Epoch: 1034/2000\t Step: 30/54\t Train Loss: 3.814638\t Valid Loss: 4.725511\n",
      "Epoch: 1034/2000\t Step: 45/54\t Train Loss: 3.851094\t Valid Loss: 4.581436\n",
      "Epoch: 1035/2000\t Step: 15/54\t Train Loss: 3.801511\t Valid Loss: 4.510967\n",
      "Epoch: 1035/2000\t Step: 30/54\t Train Loss: 3.822386\t Valid Loss: 4.497962\n",
      "Epoch: 1035/2000\t Step: 45/54\t Train Loss: 3.783950\t Valid Loss: 4.620028\n",
      "Epoch: 1036/2000\t Step: 15/54\t Train Loss: 3.738917\t Valid Loss: 4.521740\n",
      "Epoch: 1036/2000\t Step: 30/54\t Train Loss: 3.730000\t Valid Loss: 4.715281\n",
      "Epoch: 1036/2000\t Step: 45/54\t Train Loss: 3.762100\t Valid Loss: 4.873617\n",
      "Epoch: 1037/2000\t Step: 15/54\t Train Loss: 3.851259\t Valid Loss: 4.560119\n",
      "Epoch: 1037/2000\t Step: 30/54\t Train Loss: 3.768083\t Valid Loss: 4.514292\n",
      "Epoch: 1037/2000\t Step: 45/54\t Train Loss: 3.729121\t Valid Loss: 4.828502\n",
      "Epoch: 1038/2000\t Step: 15/54\t Train Loss: 3.787316\t Valid Loss: 4.759075\n",
      "Epoch: 1038/2000\t Step: 30/54\t Train Loss: 3.769925\t Valid Loss: 4.688165\n",
      "Epoch: 1038/2000\t Step: 45/54\t Train Loss: 3.753072\t Valid Loss: 4.555952\n",
      "Epoch: 1039/2000\t Step: 15/54\t Train Loss: 3.796474\t Valid Loss: 4.643973\n",
      "Epoch: 1039/2000\t Step: 30/54\t Train Loss: 3.792772\t Valid Loss: 4.463121\n",
      "Epoch: 1039/2000\t Step: 45/54\t Train Loss: 3.772525\t Valid Loss: 4.730689\n",
      "Epoch: 1040/2000\t Step: 15/54\t Train Loss: 3.784715\t Valid Loss: 4.959171\n",
      "Epoch: 1040/2000\t Step: 30/54\t Train Loss: 3.779218\t Valid Loss: 4.534620\n",
      "Epoch: 1040/2000\t Step: 45/54\t Train Loss: 3.785025\t Valid Loss: 4.666073\n",
      "Epoch: 1041/2000\t Step: 15/54\t Train Loss: 3.714204\t Valid Loss: 4.896655\n",
      "Epoch: 1041/2000\t Step: 30/54\t Train Loss: 3.754502\t Valid Loss: 4.663984\n",
      "Epoch: 1041/2000\t Step: 45/54\t Train Loss: 3.806735\t Valid Loss: 4.571038\n",
      "Epoch: 1042/2000\t Step: 15/54\t Train Loss: 3.770709\t Valid Loss: 4.710144\n",
      "Epoch: 1042/2000\t Step: 30/54\t Train Loss: 3.783572\t Valid Loss: 4.540769\n",
      "Epoch: 1042/2000\t Step: 45/54\t Train Loss: 3.749542\t Valid Loss: 4.903481\n",
      "Epoch: 1043/2000\t Step: 15/54\t Train Loss: 3.764260\t Valid Loss: 4.907973\n",
      "Epoch: 1043/2000\t Step: 30/54\t Train Loss: 3.727429\t Valid Loss: 4.966324\n",
      "Epoch: 1043/2000\t Step: 45/54\t Train Loss: 3.793427\t Valid Loss: 4.613110\n",
      "Epoch: 1044/2000\t Step: 15/54\t Train Loss: 3.771672\t Valid Loss: 4.669518\n",
      "Epoch: 1044/2000\t Step: 30/54\t Train Loss: 3.807900\t Valid Loss: 4.609301\n",
      "Epoch: 1044/2000\t Step: 45/54\t Train Loss: 3.881873\t Valid Loss: 5.024392\n",
      "Epoch: 1045/2000\t Step: 15/54\t Train Loss: 3.860547\t Valid Loss: 4.547037\n",
      "Epoch: 1045/2000\t Step: 30/54\t Train Loss: 3.737154\t Valid Loss: 4.676847\n",
      "Epoch: 1045/2000\t Step: 45/54\t Train Loss: 3.720017\t Valid Loss: 4.808438\n",
      "Epoch: 1046/2000\t Step: 15/54\t Train Loss: 3.884766\t Valid Loss: 4.777435\n",
      "Epoch: 1046/2000\t Step: 30/54\t Train Loss: 3.809774\t Valid Loss: 4.516935\n",
      "Epoch: 1046/2000\t Step: 45/54\t Train Loss: 3.879976\t Valid Loss: 4.601930\n",
      "Epoch: 1047/2000\t Step: 15/54\t Train Loss: 3.827292\t Valid Loss: 4.582812\n",
      "Epoch: 1047/2000\t Step: 30/54\t Train Loss: 3.758808\t Valid Loss: 4.843292\n",
      "Epoch: 1047/2000\t Step: 45/54\t Train Loss: 3.731451\t Valid Loss: 4.877544\n",
      "Epoch: 1048/2000\t Step: 15/54\t Train Loss: 3.817451\t Valid Loss: 4.823645\n",
      "Epoch: 1048/2000\t Step: 30/54\t Train Loss: 3.877643\t Valid Loss: 4.561545\n",
      "Epoch: 1048/2000\t Step: 45/54\t Train Loss: 3.754470\t Valid Loss: 4.745458\n",
      "Epoch: 1049/2000\t Step: 15/54\t Train Loss: 3.770904\t Valid Loss: 4.618669\n",
      "Epoch: 1049/2000\t Step: 30/54\t Train Loss: 3.794644\t Valid Loss: 4.721958\n",
      "Epoch: 1049/2000\t Step: 45/54\t Train Loss: 3.744174\t Valid Loss: 4.796756\n",
      "Epoch: 1050/2000\t Step: 15/54\t Train Loss: 3.827841\t Valid Loss: 4.600135\n",
      "Epoch: 1050/2000\t Step: 30/54\t Train Loss: 3.794952\t Valid Loss: 4.865836\n",
      "Epoch: 1050/2000\t Step: 45/54\t Train Loss: 3.739172\t Valid Loss: 4.694890\n",
      "Epoch: 1051/2000\t Step: 15/54\t Train Loss: 3.878547\t Valid Loss: 4.699084\n",
      "Epoch: 1051/2000\t Step: 30/54\t Train Loss: 3.783236\t Valid Loss: 4.813420\n",
      "Epoch: 1051/2000\t Step: 45/54\t Train Loss: 3.759701\t Valid Loss: 5.030962\n",
      "Epoch: 1052/2000\t Step: 15/54\t Train Loss: 3.781889\t Valid Loss: 4.670385\n",
      "Epoch: 1052/2000\t Step: 30/54\t Train Loss: 3.723728\t Valid Loss: 4.828064\n",
      "Epoch: 1052/2000\t Step: 45/54\t Train Loss: 3.788250\t Valid Loss: 4.772129\n",
      "Epoch: 1053/2000\t Step: 15/54\t Train Loss: 3.742358\t Valid Loss: 4.719785\n",
      "Epoch: 1053/2000\t Step: 30/54\t Train Loss: 3.924899\t Valid Loss: 4.750797\n",
      "Epoch: 1053/2000\t Step: 45/54\t Train Loss: 3.774552\t Valid Loss: 4.754212\n",
      "Epoch: 1054/2000\t Step: 15/54\t Train Loss: 3.846871\t Valid Loss: 4.603243\n",
      "Epoch: 1054/2000\t Step: 30/54\t Train Loss: 3.740238\t Valid Loss: 4.677994\n",
      "Epoch: 1054/2000\t Step: 45/54\t Train Loss: 3.808965\t Valid Loss: 4.640481\n",
      "Epoch: 1055/2000\t Step: 15/54\t Train Loss: 3.786623\t Valid Loss: 4.605952\n",
      "Epoch: 1055/2000\t Step: 30/54\t Train Loss: 3.786119\t Valid Loss: 4.573264\n",
      "Epoch: 1055/2000\t Step: 45/54\t Train Loss: 3.874371\t Valid Loss: 4.864110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1056/2000\t Step: 15/54\t Train Loss: 3.735979\t Valid Loss: 4.670428\n",
      "Epoch: 1056/2000\t Step: 30/54\t Train Loss: 3.833106\t Valid Loss: 4.860609\n",
      "Epoch: 1056/2000\t Step: 45/54\t Train Loss: 3.799300\t Valid Loss: 4.869785\n",
      "Epoch: 1057/2000\t Step: 15/54\t Train Loss: 3.773344\t Valid Loss: 4.582648\n",
      "Epoch: 1057/2000\t Step: 30/54\t Train Loss: 3.738834\t Valid Loss: 4.547574\n",
      "Epoch: 1057/2000\t Step: 45/54\t Train Loss: 3.696721\t Valid Loss: 4.781868\n",
      "Epoch: 1058/2000\t Step: 15/54\t Train Loss: 3.782581\t Valid Loss: 4.515487\n",
      "Epoch: 1058/2000\t Step: 30/54\t Train Loss: 3.819930\t Valid Loss: 4.753325\n",
      "Epoch: 1058/2000\t Step: 45/54\t Train Loss: 3.905824\t Valid Loss: 4.786949\n",
      "Epoch: 1059/2000\t Step: 15/54\t Train Loss: 3.833787\t Valid Loss: 4.409143\n",
      "Epoch: 1059/2000\t Step: 30/54\t Train Loss: 3.813156\t Valid Loss: 4.629371\n",
      "Epoch: 1059/2000\t Step: 45/54\t Train Loss: 3.814110\t Valid Loss: 4.659570\n",
      "Epoch: 1060/2000\t Step: 15/54\t Train Loss: 3.753585\t Valid Loss: 4.623651\n",
      "Epoch: 1060/2000\t Step: 30/54\t Train Loss: 3.808840\t Valid Loss: 4.537933\n",
      "Epoch: 1060/2000\t Step: 45/54\t Train Loss: 3.852956\t Valid Loss: 4.859595\n",
      "Epoch: 1061/2000\t Step: 15/54\t Train Loss: 3.775530\t Valid Loss: 4.486255\n",
      "Epoch: 1061/2000\t Step: 30/54\t Train Loss: 3.698000\t Valid Loss: 4.928732\n",
      "Epoch: 1061/2000\t Step: 45/54\t Train Loss: 3.742616\t Valid Loss: 4.563121\n",
      "Epoch: 1062/2000\t Step: 15/54\t Train Loss: 3.779370\t Valid Loss: 4.574273\n",
      "Epoch: 1062/2000\t Step: 30/54\t Train Loss: 3.801187\t Valid Loss: 4.450208\n",
      "Epoch: 1062/2000\t Step: 45/54\t Train Loss: 3.753130\t Valid Loss: 4.969908\n",
      "Epoch: 1063/2000\t Step: 15/54\t Train Loss: 3.777844\t Valid Loss: 4.762033\n",
      "Epoch: 1063/2000\t Step: 30/54\t Train Loss: 3.794710\t Valid Loss: 4.978086\n",
      "Epoch: 1063/2000\t Step: 45/54\t Train Loss: 3.837830\t Valid Loss: 4.654993\n",
      "Epoch: 1064/2000\t Step: 15/54\t Train Loss: 3.815290\t Valid Loss: 4.800265\n",
      "Epoch: 1064/2000\t Step: 30/54\t Train Loss: 3.828470\t Valid Loss: 4.824891\n",
      "Epoch: 1064/2000\t Step: 45/54\t Train Loss: 3.799910\t Valid Loss: 4.562073\n",
      "Epoch: 1065/2000\t Step: 15/54\t Train Loss: 3.738381\t Valid Loss: 4.485315\n",
      "Epoch: 1065/2000\t Step: 30/54\t Train Loss: 3.760804\t Valid Loss: 4.639511\n",
      "Epoch: 1065/2000\t Step: 45/54\t Train Loss: 3.766321\t Valid Loss: 4.784381\n",
      "Epoch: 1066/2000\t Step: 15/54\t Train Loss: 3.827601\t Valid Loss: 4.754825\n",
      "Epoch: 1066/2000\t Step: 30/54\t Train Loss: 3.787933\t Valid Loss: 4.846912\n",
      "Epoch: 1066/2000\t Step: 45/54\t Train Loss: 3.811064\t Valid Loss: 4.685889\n",
      "Epoch: 1067/2000\t Step: 15/54\t Train Loss: 3.773142\t Valid Loss: 4.663991\n",
      "Epoch: 1067/2000\t Step: 30/54\t Train Loss: 3.808291\t Valid Loss: 4.890329\n",
      "Epoch: 1067/2000\t Step: 45/54\t Train Loss: 3.759112\t Valid Loss: 5.189736\n",
      "Epoch: 1068/2000\t Step: 15/54\t Train Loss: 3.745024\t Valid Loss: 4.698143\n",
      "Epoch: 1068/2000\t Step: 30/54\t Train Loss: 3.824265\t Valid Loss: 4.940296\n",
      "Epoch: 1068/2000\t Step: 45/54\t Train Loss: 3.788935\t Valid Loss: 4.977973\n",
      "Epoch: 1069/2000\t Step: 15/54\t Train Loss: 3.908902\t Valid Loss: 4.736535\n",
      "Epoch: 1069/2000\t Step: 30/54\t Train Loss: 3.780352\t Valid Loss: 4.528412\n",
      "Epoch: 1069/2000\t Step: 45/54\t Train Loss: 3.817148\t Valid Loss: 5.056892\n",
      "Epoch: 1070/2000\t Step: 15/54\t Train Loss: 3.828214\t Valid Loss: 4.594390\n",
      "Epoch: 1070/2000\t Step: 30/54\t Train Loss: 3.729485\t Valid Loss: 4.608118\n",
      "Epoch: 1070/2000\t Step: 45/54\t Train Loss: 3.738507\t Valid Loss: 4.877737\n",
      "Epoch: 1071/2000\t Step: 15/54\t Train Loss: 3.805045\t Valid Loss: 4.570140\n",
      "Epoch: 1071/2000\t Step: 30/54\t Train Loss: 3.856055\t Valid Loss: 4.838000\n",
      "Epoch: 1071/2000\t Step: 45/54\t Train Loss: 3.919775\t Valid Loss: 4.627053\n",
      "Epoch: 1072/2000\t Step: 15/54\t Train Loss: 3.776567\t Valid Loss: 5.082017\n",
      "Epoch: 1072/2000\t Step: 30/54\t Train Loss: 3.828492\t Valid Loss: 4.632275\n",
      "Epoch: 1072/2000\t Step: 45/54\t Train Loss: 3.790651\t Valid Loss: 4.827714\n",
      "Epoch: 1073/2000\t Step: 15/54\t Train Loss: 3.800631\t Valid Loss: 4.648253\n",
      "Epoch: 1073/2000\t Step: 30/54\t Train Loss: 3.814571\t Valid Loss: 5.009358\n",
      "Epoch: 1073/2000\t Step: 45/54\t Train Loss: 3.826627\t Valid Loss: 4.814161\n",
      "Epoch: 1074/2000\t Step: 15/54\t Train Loss: 3.757995\t Valid Loss: 4.940437\n",
      "Epoch: 1074/2000\t Step: 30/54\t Train Loss: 3.783885\t Valid Loss: 4.938980\n",
      "Epoch: 1074/2000\t Step: 45/54\t Train Loss: 3.791541\t Valid Loss: 4.896898\n",
      "Epoch: 1075/2000\t Step: 15/54\t Train Loss: 3.802836\t Valid Loss: 4.713912\n",
      "Epoch: 1075/2000\t Step: 30/54\t Train Loss: 3.864963\t Valid Loss: 4.346373\n",
      "Epoch: 1075/2000\t Step: 45/54\t Train Loss: 3.831663\t Valid Loss: 5.112487\n",
      "Epoch: 1076/2000\t Step: 15/54\t Train Loss: 3.806322\t Valid Loss: 4.501526\n",
      "Epoch: 1076/2000\t Step: 30/54\t Train Loss: 3.769724\t Valid Loss: 4.739033\n",
      "Epoch: 1076/2000\t Step: 45/54\t Train Loss: 3.795606\t Valid Loss: 4.845394\n",
      "Epoch: 1077/2000\t Step: 15/54\t Train Loss: 3.718623\t Valid Loss: 4.655608\n",
      "Epoch: 1077/2000\t Step: 30/54\t Train Loss: 3.860136\t Valid Loss: 4.492180\n",
      "Epoch: 1077/2000\t Step: 45/54\t Train Loss: 3.838980\t Valid Loss: 4.701749\n",
      "Epoch: 1078/2000\t Step: 15/54\t Train Loss: 3.770429\t Valid Loss: 4.910758\n",
      "Epoch: 1078/2000\t Step: 30/54\t Train Loss: 3.796386\t Valid Loss: 4.863324\n",
      "Epoch: 1078/2000\t Step: 45/54\t Train Loss: 3.827646\t Valid Loss: 4.815131\n",
      "Epoch: 1079/2000\t Step: 15/54\t Train Loss: 3.790203\t Valid Loss: 4.734746\n",
      "Epoch: 1079/2000\t Step: 30/54\t Train Loss: 3.740652\t Valid Loss: 4.772493\n",
      "Epoch: 1079/2000\t Step: 45/54\t Train Loss: 3.856442\t Valid Loss: 4.410818\n",
      "Epoch: 1080/2000\t Step: 15/54\t Train Loss: 3.814759\t Valid Loss: 4.592885\n",
      "Epoch: 1080/2000\t Step: 30/54\t Train Loss: 3.802539\t Valid Loss: 4.474497\n",
      "Epoch: 1080/2000\t Step: 45/54\t Train Loss: 3.808567\t Valid Loss: 4.524950\n",
      "Epoch: 1081/2000\t Step: 15/54\t Train Loss: 3.834870\t Valid Loss: 4.652572\n",
      "Epoch: 1081/2000\t Step: 30/54\t Train Loss: 3.804565\t Valid Loss: 4.406971\n",
      "Epoch: 1081/2000\t Step: 45/54\t Train Loss: 3.826808\t Valid Loss: 4.705568\n",
      "Epoch: 1082/2000\t Step: 15/54\t Train Loss: 3.786742\t Valid Loss: 4.666951\n",
      "Epoch: 1082/2000\t Step: 30/54\t Train Loss: 3.792779\t Valid Loss: 4.844678\n",
      "Epoch: 1082/2000\t Step: 45/54\t Train Loss: 3.765588\t Valid Loss: 4.897940\n",
      "Epoch: 1083/2000\t Step: 15/54\t Train Loss: 3.836596\t Valid Loss: 4.786020\n",
      "Epoch: 1083/2000\t Step: 30/54\t Train Loss: 3.733768\t Valid Loss: 4.744660\n",
      "Epoch: 1083/2000\t Step: 45/54\t Train Loss: 3.849566\t Valid Loss: 4.854322\n",
      "Epoch: 1084/2000\t Step: 15/54\t Train Loss: 3.801983\t Valid Loss: 4.808568\n",
      "Epoch: 1084/2000\t Step: 30/54\t Train Loss: 3.786444\t Valid Loss: 4.697234\n",
      "Epoch: 1084/2000\t Step: 45/54\t Train Loss: 3.709586\t Valid Loss: 4.872743\n",
      "Epoch: 1085/2000\t Step: 15/54\t Train Loss: 3.758819\t Valid Loss: 4.635022\n",
      "Epoch: 1085/2000\t Step: 30/54\t Train Loss: 3.745763\t Valid Loss: 5.047730\n",
      "Epoch: 1085/2000\t Step: 45/54\t Train Loss: 3.754171\t Valid Loss: 5.195652\n",
      "Epoch: 1086/2000\t Step: 15/54\t Train Loss: 3.805360\t Valid Loss: 4.741764\n",
      "Epoch: 1086/2000\t Step: 30/54\t Train Loss: 3.716774\t Valid Loss: 5.048601\n",
      "Epoch: 1086/2000\t Step: 45/54\t Train Loss: 3.799873\t Valid Loss: 4.961382\n",
      "Epoch: 1087/2000\t Step: 15/54\t Train Loss: 3.772987\t Valid Loss: 5.089058\n",
      "Epoch: 1087/2000\t Step: 30/54\t Train Loss: 3.789421\t Valid Loss: 4.787127\n",
      "Epoch: 1087/2000\t Step: 45/54\t Train Loss: 3.843580\t Valid Loss: 4.887287\n",
      "Epoch: 1088/2000\t Step: 15/54\t Train Loss: 3.775383\t Valid Loss: 5.005171\n",
      "Epoch: 1088/2000\t Step: 30/54\t Train Loss: 3.815668\t Valid Loss: 4.563482\n",
      "Epoch: 1088/2000\t Step: 45/54\t Train Loss: 3.787042\t Valid Loss: 4.762872\n",
      "Epoch: 1089/2000\t Step: 15/54\t Train Loss: 3.773805\t Valid Loss: 4.626663\n",
      "Epoch: 1089/2000\t Step: 30/54\t Train Loss: 3.791070\t Valid Loss: 4.754912\n",
      "Epoch: 1089/2000\t Step: 45/54\t Train Loss: 3.804272\t Valid Loss: 4.669645\n",
      "Epoch: 1090/2000\t Step: 15/54\t Train Loss: 3.740427\t Valid Loss: 4.863640\n",
      "Epoch: 1090/2000\t Step: 30/54\t Train Loss: 3.781925\t Valid Loss: 4.726055\n",
      "Epoch: 1090/2000\t Step: 45/54\t Train Loss: 3.778142\t Valid Loss: 5.123424\n",
      "Epoch: 1091/2000\t Step: 15/54\t Train Loss: 3.777653\t Valid Loss: 4.744604\n",
      "Epoch: 1091/2000\t Step: 30/54\t Train Loss: 3.810429\t Valid Loss: 4.572387\n",
      "Epoch: 1091/2000\t Step: 45/54\t Train Loss: 3.822995\t Valid Loss: 5.088441\n",
      "Epoch: 1092/2000\t Step: 15/54\t Train Loss: 3.730128\t Valid Loss: 5.085504\n",
      "Epoch: 1092/2000\t Step: 30/54\t Train Loss: 3.737775\t Valid Loss: 4.652050\n",
      "Epoch: 1092/2000\t Step: 45/54\t Train Loss: 3.806250\t Valid Loss: 5.054757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1093/2000\t Step: 15/54\t Train Loss: 3.837527\t Valid Loss: 4.893277\n",
      "Epoch: 1093/2000\t Step: 30/54\t Train Loss: 3.779427\t Valid Loss: 4.507635\n",
      "Epoch: 1093/2000\t Step: 45/54\t Train Loss: 3.863146\t Valid Loss: 4.789409\n",
      "Epoch: 1094/2000\t Step: 15/54\t Train Loss: 3.796360\t Valid Loss: 4.440637\n",
      "Epoch: 1094/2000\t Step: 30/54\t Train Loss: 3.744830\t Valid Loss: 4.776990\n",
      "Epoch: 1094/2000\t Step: 45/54\t Train Loss: 3.783318\t Valid Loss: 4.594360\n",
      "Epoch: 1095/2000\t Step: 15/54\t Train Loss: 3.806610\t Valid Loss: 4.688674\n",
      "Epoch: 1095/2000\t Step: 30/54\t Train Loss: 3.788320\t Valid Loss: 4.522329\n",
      "Epoch: 1095/2000\t Step: 45/54\t Train Loss: 3.802353\t Valid Loss: 4.876940\n",
      "Epoch: 1096/2000\t Step: 15/54\t Train Loss: 3.717827\t Valid Loss: 4.584886\n",
      "Epoch: 1096/2000\t Step: 30/54\t Train Loss: 3.763752\t Valid Loss: 5.099110\n",
      "Epoch: 1096/2000\t Step: 45/54\t Train Loss: 3.736661\t Valid Loss: 4.679918\n",
      "Epoch: 1097/2000\t Step: 15/54\t Train Loss: 3.801215\t Valid Loss: 5.019212\n",
      "Epoch: 1097/2000\t Step: 30/54\t Train Loss: 3.771290\t Valid Loss: 4.665004\n",
      "Epoch: 1097/2000\t Step: 45/54\t Train Loss: 3.746654\t Valid Loss: 5.298928\n",
      "Epoch: 1098/2000\t Step: 15/54\t Train Loss: 3.741954\t Valid Loss: 4.494986\n",
      "Epoch: 1098/2000\t Step: 30/54\t Train Loss: 3.796180\t Valid Loss: 4.573775\n",
      "Epoch: 1098/2000\t Step: 45/54\t Train Loss: 3.796263\t Valid Loss: 4.697716\n",
      "Epoch: 1099/2000\t Step: 15/54\t Train Loss: 3.810764\t Valid Loss: 4.773567\n",
      "Epoch: 1099/2000\t Step: 30/54\t Train Loss: 3.816358\t Valid Loss: 4.866996\n",
      "Epoch: 1099/2000\t Step: 45/54\t Train Loss: 3.835762\t Valid Loss: 4.410628\n",
      "Epoch: 1100/2000\t Step: 15/54\t Train Loss: 3.772823\t Valid Loss: 4.961990\n",
      "Epoch: 1100/2000\t Step: 30/54\t Train Loss: 3.797828\t Valid Loss: 4.875231\n",
      "Epoch: 1100/2000\t Step: 45/54\t Train Loss: 3.777423\t Valid Loss: 4.655211\n",
      "Epoch: 1101/2000\t Step: 15/54\t Train Loss: 3.804617\t Valid Loss: 4.454257\n",
      "Epoch: 1101/2000\t Step: 30/54\t Train Loss: 3.743294\t Valid Loss: 4.739290\n",
      "Epoch: 1101/2000\t Step: 45/54\t Train Loss: 3.791176\t Valid Loss: 4.581845\n",
      "Epoch: 1102/2000\t Step: 15/54\t Train Loss: 3.788991\t Valid Loss: 4.522474\n",
      "Epoch: 1102/2000\t Step: 30/54\t Train Loss: 3.707107\t Valid Loss: 4.596938\n",
      "Epoch: 1102/2000\t Step: 45/54\t Train Loss: 3.748361\t Valid Loss: 4.920287\n",
      "Epoch: 1103/2000\t Step: 15/54\t Train Loss: 3.746047\t Valid Loss: 5.120775\n",
      "Epoch: 1103/2000\t Step: 30/54\t Train Loss: 3.777359\t Valid Loss: 4.855249\n",
      "Epoch: 1103/2000\t Step: 45/54\t Train Loss: 3.783647\t Valid Loss: 4.762749\n",
      "Epoch: 1104/2000\t Step: 15/54\t Train Loss: 3.819995\t Valid Loss: 5.246389\n",
      "Epoch: 1104/2000\t Step: 30/54\t Train Loss: 3.749217\t Valid Loss: 4.552415\n",
      "Epoch: 1104/2000\t Step: 45/54\t Train Loss: 3.809575\t Valid Loss: 4.942099\n",
      "Epoch: 1105/2000\t Step: 15/54\t Train Loss: 3.748383\t Valid Loss: 5.075296\n",
      "Epoch: 1105/2000\t Step: 30/54\t Train Loss: 3.875974\t Valid Loss: 4.605442\n",
      "Epoch: 1105/2000\t Step: 45/54\t Train Loss: 3.800146\t Valid Loss: 4.526557\n",
      "Epoch: 1106/2000\t Step: 15/54\t Train Loss: 3.864145\t Valid Loss: 4.951760\n",
      "Epoch: 1106/2000\t Step: 30/54\t Train Loss: 3.823523\t Valid Loss: 5.090587\n",
      "Epoch: 1106/2000\t Step: 45/54\t Train Loss: 3.756374\t Valid Loss: 4.692860\n",
      "Epoch: 1107/2000\t Step: 15/54\t Train Loss: 3.798955\t Valid Loss: 4.944569\n",
      "Epoch: 1107/2000\t Step: 30/54\t Train Loss: 3.755789\t Valid Loss: 4.743103\n",
      "Epoch: 1107/2000\t Step: 45/54\t Train Loss: 3.828951\t Valid Loss: 5.155342\n",
      "Epoch: 1108/2000\t Step: 15/54\t Train Loss: 3.838505\t Valid Loss: 4.676273\n",
      "Epoch: 1108/2000\t Step: 30/54\t Train Loss: 3.784358\t Valid Loss: 4.715692\n",
      "Epoch: 1108/2000\t Step: 45/54\t Train Loss: 3.774817\t Valid Loss: 4.677134\n",
      "Epoch: 1109/2000\t Step: 15/54\t Train Loss: 3.757365\t Valid Loss: 5.137102\n",
      "Epoch: 1109/2000\t Step: 30/54\t Train Loss: 3.723718\t Valid Loss: 4.514036\n",
      "Epoch: 1109/2000\t Step: 45/54\t Train Loss: 3.746529\t Valid Loss: 4.662226\n",
      "Epoch: 1110/2000\t Step: 15/54\t Train Loss: 3.777149\t Valid Loss: 4.650112\n",
      "Epoch: 1110/2000\t Step: 30/54\t Train Loss: 3.743959\t Valid Loss: 4.272740\n",
      "Epoch: 1110/2000\t Step: 45/54\t Train Loss: 3.759357\t Valid Loss: 4.878004\n",
      "Epoch: 1111/2000\t Step: 15/54\t Train Loss: 3.792926\t Valid Loss: 4.641283\n",
      "Epoch: 1111/2000\t Step: 30/54\t Train Loss: 3.865909\t Valid Loss: 4.728067\n",
      "Epoch: 1111/2000\t Step: 45/54\t Train Loss: 3.694528\t Valid Loss: 4.704548\n",
      "Epoch: 1112/2000\t Step: 15/54\t Train Loss: 3.828424\t Valid Loss: 4.654336\n",
      "Epoch: 1112/2000\t Step: 30/54\t Train Loss: 3.798002\t Valid Loss: 4.738971\n",
      "Epoch: 1112/2000\t Step: 45/54\t Train Loss: 3.758099\t Valid Loss: 5.130956\n",
      "Epoch: 1113/2000\t Step: 15/54\t Train Loss: 3.684916\t Valid Loss: 5.062822\n",
      "Epoch: 1113/2000\t Step: 30/54\t Train Loss: 3.773740\t Valid Loss: 4.671696\n",
      "Epoch: 1113/2000\t Step: 45/54\t Train Loss: 3.736078\t Valid Loss: 4.892915\n",
      "Epoch: 1114/2000\t Step: 15/54\t Train Loss: 3.830470\t Valid Loss: 5.060265\n",
      "Epoch: 1114/2000\t Step: 30/54\t Train Loss: 3.773391\t Valid Loss: 4.568610\n",
      "Epoch: 1114/2000\t Step: 45/54\t Train Loss: 3.779937\t Valid Loss: 4.680867\n",
      "Epoch: 1115/2000\t Step: 15/54\t Train Loss: 3.789434\t Valid Loss: 4.598908\n",
      "Epoch: 1115/2000\t Step: 30/54\t Train Loss: 3.789420\t Valid Loss: 4.795775\n",
      "Epoch: 1115/2000\t Step: 45/54\t Train Loss: 3.801388\t Valid Loss: 4.702482\n",
      "Epoch: 1116/2000\t Step: 15/54\t Train Loss: 3.783845\t Valid Loss: 4.903490\n",
      "Epoch: 1116/2000\t Step: 30/54\t Train Loss: 3.703498\t Valid Loss: 4.845137\n",
      "Epoch: 1116/2000\t Step: 45/54\t Train Loss: 3.764615\t Valid Loss: 4.738807\n",
      "Epoch: 1117/2000\t Step: 15/54\t Train Loss: 3.733843\t Valid Loss: 5.073996\n",
      "Epoch: 1117/2000\t Step: 30/54\t Train Loss: 3.789903\t Valid Loss: 5.081428\n",
      "Epoch: 1117/2000\t Step: 45/54\t Train Loss: 3.736250\t Valid Loss: 5.018360\n",
      "Epoch: 1118/2000\t Step: 15/54\t Train Loss: 3.919932\t Valid Loss: 4.749314\n",
      "Epoch: 1118/2000\t Step: 30/54\t Train Loss: 3.798023\t Valid Loss: 4.774785\n",
      "Epoch: 1118/2000\t Step: 45/54\t Train Loss: 3.780875\t Valid Loss: 4.610839\n",
      "Epoch: 1119/2000\t Step: 15/54\t Train Loss: 3.790153\t Valid Loss: 4.640778\n",
      "Epoch: 1119/2000\t Step: 30/54\t Train Loss: 3.750427\t Valid Loss: 4.658370\n",
      "Epoch: 1119/2000\t Step: 45/54\t Train Loss: 3.846083\t Valid Loss: 4.548411\n",
      "Epoch: 1120/2000\t Step: 15/54\t Train Loss: 3.767210\t Valid Loss: 4.936921\n",
      "Epoch: 1120/2000\t Step: 30/54\t Train Loss: 3.751237\t Valid Loss: 4.516047\n",
      "Epoch: 1120/2000\t Step: 45/54\t Train Loss: 3.793463\t Valid Loss: 4.725514\n",
      "Epoch: 1121/2000\t Step: 15/54\t Train Loss: 3.777157\t Valid Loss: 4.626192\n",
      "Epoch: 1121/2000\t Step: 30/54\t Train Loss: 3.790114\t Valid Loss: 4.652757\n",
      "Epoch: 1121/2000\t Step: 45/54\t Train Loss: 3.751434\t Valid Loss: 4.489746\n",
      "Epoch: 1122/2000\t Step: 15/54\t Train Loss: 3.765556\t Valid Loss: 4.537366\n",
      "Epoch: 1122/2000\t Step: 30/54\t Train Loss: 3.856256\t Valid Loss: 5.047176\n",
      "Epoch: 1122/2000\t Step: 45/54\t Train Loss: 3.769915\t Valid Loss: 4.347260\n",
      "Epoch: 1123/2000\t Step: 15/54\t Train Loss: 3.854052\t Valid Loss: 5.021557\n",
      "Epoch: 1123/2000\t Step: 30/54\t Train Loss: 3.764463\t Valid Loss: 4.834486\n",
      "Epoch: 1123/2000\t Step: 45/54\t Train Loss: 3.811236\t Valid Loss: 4.566451\n",
      "Epoch: 1124/2000\t Step: 15/54\t Train Loss: 3.767578\t Valid Loss: 4.549181\n",
      "Epoch: 1124/2000\t Step: 30/54\t Train Loss: 3.829858\t Valid Loss: 4.513835\n",
      "Epoch: 1124/2000\t Step: 45/54\t Train Loss: 3.887142\t Valid Loss: 4.933986\n",
      "Epoch: 1125/2000\t Step: 15/54\t Train Loss: 3.801623\t Valid Loss: 4.530842\n",
      "Epoch: 1125/2000\t Step: 30/54\t Train Loss: 3.822825\t Valid Loss: 4.500230\n",
      "Epoch: 1125/2000\t Step: 45/54\t Train Loss: 3.828214\t Valid Loss: 4.571399\n",
      "Epoch: 1126/2000\t Step: 15/54\t Train Loss: 3.807085\t Valid Loss: 4.471395\n",
      "Epoch: 1126/2000\t Step: 30/54\t Train Loss: 3.738393\t Valid Loss: 5.061527\n",
      "Epoch: 1126/2000\t Step: 45/54\t Train Loss: 3.784128\t Valid Loss: 4.982294\n",
      "Epoch: 1127/2000\t Step: 15/54\t Train Loss: 3.852194\t Valid Loss: 4.755638\n",
      "Epoch: 1127/2000\t Step: 30/54\t Train Loss: 3.784203\t Valid Loss: 4.803562\n",
      "Epoch: 1127/2000\t Step: 45/54\t Train Loss: 3.806696\t Valid Loss: 4.388416\n",
      "Epoch: 1128/2000\t Step: 15/54\t Train Loss: 3.768544\t Valid Loss: 4.625052\n",
      "Epoch: 1128/2000\t Step: 30/54\t Train Loss: 3.800895\t Valid Loss: 4.593602\n",
      "Epoch: 1128/2000\t Step: 45/54\t Train Loss: 3.735881\t Valid Loss: 4.882523\n",
      "Epoch: 1129/2000\t Step: 15/54\t Train Loss: 3.776865\t Valid Loss: 5.056123\n",
      "Epoch: 1129/2000\t Step: 30/54\t Train Loss: 3.820096\t Valid Loss: 4.715818\n",
      "Epoch: 1129/2000\t Step: 45/54\t Train Loss: 3.761330\t Valid Loss: 4.934024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1130/2000\t Step: 15/54\t Train Loss: 3.748864\t Valid Loss: 4.687962\n",
      "Epoch: 1130/2000\t Step: 30/54\t Train Loss: 3.792438\t Valid Loss: 4.491875\n",
      "Epoch: 1130/2000\t Step: 45/54\t Train Loss: 3.678556\t Valid Loss: 4.962760\n",
      "Epoch: 1131/2000\t Step: 15/54\t Train Loss: 3.811430\t Valid Loss: 4.629216\n",
      "Epoch: 1131/2000\t Step: 30/54\t Train Loss: 3.799912\t Valid Loss: 4.768197\n",
      "Epoch: 1131/2000\t Step: 45/54\t Train Loss: 3.805043\t Valid Loss: 4.697164\n",
      "Epoch: 1132/2000\t Step: 15/54\t Train Loss: 3.728169\t Valid Loss: 4.960330\n",
      "Epoch: 1132/2000\t Step: 30/54\t Train Loss: 3.788851\t Valid Loss: 4.950728\n",
      "Epoch: 1132/2000\t Step: 45/54\t Train Loss: 3.762958\t Valid Loss: 4.528144\n",
      "Epoch: 1133/2000\t Step: 15/54\t Train Loss: 3.808966\t Valid Loss: 4.615136\n",
      "Epoch: 1133/2000\t Step: 30/54\t Train Loss: 3.767878\t Valid Loss: 4.700252\n",
      "Epoch: 1133/2000\t Step: 45/54\t Train Loss: 3.829479\t Valid Loss: 4.526467\n",
      "Epoch: 1134/2000\t Step: 15/54\t Train Loss: 3.789951\t Valid Loss: 4.945959\n",
      "Epoch: 1134/2000\t Step: 30/54\t Train Loss: 3.814490\t Valid Loss: 4.456118\n",
      "Epoch: 1134/2000\t Step: 45/54\t Train Loss: 3.774397\t Valid Loss: 4.615121\n",
      "Epoch: 1135/2000\t Step: 15/54\t Train Loss: 3.822588\t Valid Loss: 4.841335\n",
      "Epoch: 1135/2000\t Step: 30/54\t Train Loss: 3.739000\t Valid Loss: 4.816463\n",
      "Epoch: 1135/2000\t Step: 45/54\t Train Loss: 3.800962\t Valid Loss: 4.696774\n",
      "Epoch: 1136/2000\t Step: 15/54\t Train Loss: 3.800810\t Valid Loss: 4.549165\n",
      "Epoch: 1136/2000\t Step: 30/54\t Train Loss: 3.883232\t Valid Loss: 4.618086\n",
      "Epoch: 1136/2000\t Step: 45/54\t Train Loss: 3.733952\t Valid Loss: 4.899201\n",
      "Epoch: 1137/2000\t Step: 15/54\t Train Loss: 3.749064\t Valid Loss: 4.895502\n",
      "Epoch: 1137/2000\t Step: 30/54\t Train Loss: 3.788982\t Valid Loss: 4.771017\n",
      "Epoch: 1137/2000\t Step: 45/54\t Train Loss: 3.837477\t Valid Loss: 4.471240\n",
      "Epoch: 1138/2000\t Step: 15/54\t Train Loss: 3.835967\t Valid Loss: 4.661021\n",
      "Epoch: 1138/2000\t Step: 30/54\t Train Loss: 3.851430\t Valid Loss: 4.717625\n",
      "Epoch: 1138/2000\t Step: 45/54\t Train Loss: 3.736407\t Valid Loss: 4.739642\n",
      "Epoch: 1139/2000\t Step: 15/54\t Train Loss: 3.767130\t Valid Loss: 4.703478\n",
      "Epoch: 1139/2000\t Step: 30/54\t Train Loss: 3.782950\t Valid Loss: 4.851731\n",
      "Epoch: 1139/2000\t Step: 45/54\t Train Loss: 3.765428\t Valid Loss: 5.146358\n",
      "Epoch: 1140/2000\t Step: 15/54\t Train Loss: 3.783389\t Valid Loss: 4.663275\n",
      "Epoch: 1140/2000\t Step: 30/54\t Train Loss: 3.794611\t Valid Loss: 4.504475\n",
      "Epoch: 1140/2000\t Step: 45/54\t Train Loss: 3.811006\t Valid Loss: 4.867150\n",
      "Epoch: 1141/2000\t Step: 15/54\t Train Loss: 3.808815\t Valid Loss: 4.499693\n",
      "Epoch: 1141/2000\t Step: 30/54\t Train Loss: 3.759778\t Valid Loss: 4.609135\n",
      "Epoch: 1141/2000\t Step: 45/54\t Train Loss: 3.819124\t Valid Loss: 4.695311\n",
      "Epoch: 1142/2000\t Step: 15/54\t Train Loss: 3.820747\t Valid Loss: 4.821245\n",
      "Epoch: 1142/2000\t Step: 30/54\t Train Loss: 3.707695\t Valid Loss: 4.651127\n",
      "Epoch: 1142/2000\t Step: 45/54\t Train Loss: 3.844623\t Valid Loss: 4.638007\n",
      "Epoch: 1143/2000\t Step: 15/54\t Train Loss: 3.777129\t Valid Loss: 4.889857\n",
      "Epoch: 1143/2000\t Step: 30/54\t Train Loss: 3.771732\t Valid Loss: 4.678468\n",
      "Epoch: 1143/2000\t Step: 45/54\t Train Loss: 3.781810\t Valid Loss: 4.955478\n",
      "Epoch: 1144/2000\t Step: 15/54\t Train Loss: 3.771752\t Valid Loss: 4.687894\n",
      "Epoch: 1144/2000\t Step: 30/54\t Train Loss: 3.755928\t Valid Loss: 4.592281\n",
      "Epoch: 1144/2000\t Step: 45/54\t Train Loss: 3.741971\t Valid Loss: 4.857552\n",
      "Epoch: 1145/2000\t Step: 15/54\t Train Loss: 3.819817\t Valid Loss: 4.632834\n",
      "Epoch: 1145/2000\t Step: 30/54\t Train Loss: 3.749645\t Valid Loss: 4.812043\n",
      "Epoch: 1145/2000\t Step: 45/54\t Train Loss: 3.796061\t Valid Loss: 4.860943\n",
      "Epoch: 1146/2000\t Step: 15/54\t Train Loss: 3.792648\t Valid Loss: 4.568768\n",
      "Epoch: 1146/2000\t Step: 30/54\t Train Loss: 3.849153\t Valid Loss: 4.330537\n",
      "Epoch: 1146/2000\t Step: 45/54\t Train Loss: 3.847592\t Valid Loss: 4.845504\n",
      "Epoch: 1147/2000\t Step: 15/54\t Train Loss: 3.748191\t Valid Loss: 4.957486\n",
      "Epoch: 1147/2000\t Step: 30/54\t Train Loss: 3.743801\t Valid Loss: 4.749341\n",
      "Epoch: 1147/2000\t Step: 45/54\t Train Loss: 3.822699\t Valid Loss: 4.554966\n",
      "Epoch: 1148/2000\t Step: 15/54\t Train Loss: 3.751618\t Valid Loss: 4.633995\n",
      "Epoch: 1148/2000\t Step: 30/54\t Train Loss: 3.775663\t Valid Loss: 4.558554\n",
      "Epoch: 1148/2000\t Step: 45/54\t Train Loss: 3.729488\t Valid Loss: 4.636875\n",
      "Epoch: 1149/2000\t Step: 15/54\t Train Loss: 3.880751\t Valid Loss: 4.703830\n",
      "Epoch: 1149/2000\t Step: 30/54\t Train Loss: 3.732842\t Valid Loss: 4.799013\n",
      "Epoch: 1149/2000\t Step: 45/54\t Train Loss: 3.786539\t Valid Loss: 5.032421\n",
      "Epoch: 1150/2000\t Step: 15/54\t Train Loss: 3.796199\t Valid Loss: 4.489081\n",
      "Epoch: 1150/2000\t Step: 30/54\t Train Loss: 3.776176\t Valid Loss: 4.772135\n",
      "Epoch: 1150/2000\t Step: 45/54\t Train Loss: 3.757708\t Valid Loss: 4.700872\n",
      "Epoch: 1151/2000\t Step: 15/54\t Train Loss: 3.851171\t Valid Loss: 4.619143\n",
      "Epoch: 1151/2000\t Step: 30/54\t Train Loss: 3.842621\t Valid Loss: 4.644948\n",
      "Epoch: 1151/2000\t Step: 45/54\t Train Loss: 3.744120\t Valid Loss: 4.858319\n",
      "Epoch: 1152/2000\t Step: 15/54\t Train Loss: 3.746135\t Valid Loss: 4.748599\n",
      "Epoch: 1152/2000\t Step: 30/54\t Train Loss: 3.801257\t Valid Loss: 4.734773\n",
      "Epoch: 1152/2000\t Step: 45/54\t Train Loss: 3.709332\t Valid Loss: 4.659292\n",
      "Epoch: 1153/2000\t Step: 15/54\t Train Loss: 3.729082\t Valid Loss: 5.294550\n",
      "Epoch: 1153/2000\t Step: 30/54\t Train Loss: 3.793199\t Valid Loss: 4.942830\n",
      "Epoch: 1153/2000\t Step: 45/54\t Train Loss: 3.769569\t Valid Loss: 5.283952\n",
      "Epoch: 1154/2000\t Step: 15/54\t Train Loss: 3.779383\t Valid Loss: 4.575897\n",
      "Epoch: 1154/2000\t Step: 30/54\t Train Loss: 3.694307\t Valid Loss: 4.925604\n",
      "Epoch: 1154/2000\t Step: 45/54\t Train Loss: 3.748617\t Valid Loss: 4.793031\n",
      "Epoch: 1155/2000\t Step: 15/54\t Train Loss: 3.822057\t Valid Loss: 4.652041\n",
      "Epoch: 1155/2000\t Step: 30/54\t Train Loss: 3.825820\t Valid Loss: 4.767651\n",
      "Epoch: 1155/2000\t Step: 45/54\t Train Loss: 3.690325\t Valid Loss: 5.025487\n",
      "Epoch: 1156/2000\t Step: 15/54\t Train Loss: 3.747960\t Valid Loss: 4.688870\n",
      "Epoch: 1156/2000\t Step: 30/54\t Train Loss: 3.827265\t Valid Loss: 4.645008\n",
      "Epoch: 1156/2000\t Step: 45/54\t Train Loss: 3.775846\t Valid Loss: 4.825604\n",
      "Epoch: 1157/2000\t Step: 15/54\t Train Loss: 3.740618\t Valid Loss: 4.844476\n",
      "Epoch: 1157/2000\t Step: 30/54\t Train Loss: 3.707605\t Valid Loss: 4.621764\n",
      "Epoch: 1157/2000\t Step: 45/54\t Train Loss: 3.805625\t Valid Loss: 4.845256\n",
      "Epoch: 1158/2000\t Step: 15/54\t Train Loss: 3.806838\t Valid Loss: 5.019683\n",
      "Epoch: 1158/2000\t Step: 30/54\t Train Loss: 3.785321\t Valid Loss: 4.753869\n",
      "Epoch: 1158/2000\t Step: 45/54\t Train Loss: 3.720195\t Valid Loss: 4.720799\n",
      "Epoch: 1159/2000\t Step: 15/54\t Train Loss: 3.812320\t Valid Loss: 5.107047\n",
      "Epoch: 1159/2000\t Step: 30/54\t Train Loss: 3.726732\t Valid Loss: 5.011441\n",
      "Epoch: 1159/2000\t Step: 45/54\t Train Loss: 3.795411\t Valid Loss: 5.234129\n",
      "Epoch: 1160/2000\t Step: 15/54\t Train Loss: 3.765828\t Valid Loss: 4.810620\n",
      "Epoch: 1160/2000\t Step: 30/54\t Train Loss: 3.831859\t Valid Loss: 4.858495\n",
      "Epoch: 1160/2000\t Step: 45/54\t Train Loss: 3.794161\t Valid Loss: 4.684724\n",
      "Epoch: 1161/2000\t Step: 15/54\t Train Loss: 3.750329\t Valid Loss: 4.896700\n",
      "Epoch: 1161/2000\t Step: 30/54\t Train Loss: 3.712707\t Valid Loss: 4.542608\n",
      "Epoch: 1161/2000\t Step: 45/54\t Train Loss: 3.794860\t Valid Loss: 4.895120\n",
      "Epoch: 1162/2000\t Step: 15/54\t Train Loss: 3.743713\t Valid Loss: 4.867793\n",
      "Epoch: 1162/2000\t Step: 30/54\t Train Loss: 3.831357\t Valid Loss: 4.996655\n",
      "Epoch: 1162/2000\t Step: 45/54\t Train Loss: 3.793919\t Valid Loss: 4.515874\n",
      "Epoch: 1163/2000\t Step: 15/54\t Train Loss: 3.841174\t Valid Loss: 5.085225\n",
      "Epoch: 1163/2000\t Step: 30/54\t Train Loss: 3.793024\t Valid Loss: 4.909411\n",
      "Epoch: 1163/2000\t Step: 45/54\t Train Loss: 3.783218\t Valid Loss: 4.819962\n",
      "Epoch: 1164/2000\t Step: 15/54\t Train Loss: 3.786597\t Valid Loss: 4.735000\n",
      "Epoch: 1164/2000\t Step: 30/54\t Train Loss: 3.773432\t Valid Loss: 4.653647\n",
      "Epoch: 1164/2000\t Step: 45/54\t Train Loss: 3.768712\t Valid Loss: 4.795450\n",
      "Epoch: 1165/2000\t Step: 15/54\t Train Loss: 3.755974\t Valid Loss: 4.862565\n",
      "Epoch: 1165/2000\t Step: 30/54\t Train Loss: 3.757185\t Valid Loss: 4.890351\n",
      "Epoch: 1165/2000\t Step: 45/54\t Train Loss: 3.731877\t Valid Loss: 4.975370\n",
      "Epoch: 1166/2000\t Step: 15/54\t Train Loss: 3.772254\t Valid Loss: 5.025254\n",
      "Epoch: 1166/2000\t Step: 30/54\t Train Loss: 3.737731\t Valid Loss: 5.339265\n",
      "Epoch: 1166/2000\t Step: 45/54\t Train Loss: 3.804963\t Valid Loss: 5.009402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1167/2000\t Step: 15/54\t Train Loss: 3.754529\t Valid Loss: 4.781844\n",
      "Epoch: 1167/2000\t Step: 30/54\t Train Loss: 3.671568\t Valid Loss: 4.597655\n",
      "Epoch: 1167/2000\t Step: 45/54\t Train Loss: 3.805229\t Valid Loss: 4.789130\n",
      "Epoch: 1168/2000\t Step: 15/54\t Train Loss: 3.749758\t Valid Loss: 4.761981\n",
      "Epoch: 1168/2000\t Step: 30/54\t Train Loss: 3.727318\t Valid Loss: 4.662831\n",
      "Epoch: 1168/2000\t Step: 45/54\t Train Loss: 3.757455\t Valid Loss: 4.768298\n",
      "Epoch: 1169/2000\t Step: 15/54\t Train Loss: 3.744187\t Valid Loss: 4.652923\n",
      "Epoch: 1169/2000\t Step: 30/54\t Train Loss: 3.801957\t Valid Loss: 4.718852\n",
      "Epoch: 1169/2000\t Step: 45/54\t Train Loss: 3.815230\t Valid Loss: 4.818484\n",
      "Epoch: 1170/2000\t Step: 15/54\t Train Loss: 3.797192\t Valid Loss: 4.834912\n",
      "Epoch: 1170/2000\t Step: 30/54\t Train Loss: 3.769603\t Valid Loss: 4.578539\n",
      "Epoch: 1170/2000\t Step: 45/54\t Train Loss: 3.783173\t Valid Loss: 4.518174\n",
      "Epoch: 1171/2000\t Step: 15/54\t Train Loss: 3.771570\t Valid Loss: 4.587407\n",
      "Epoch: 1171/2000\t Step: 30/54\t Train Loss: 3.765945\t Valid Loss: 4.764329\n",
      "Epoch: 1171/2000\t Step: 45/54\t Train Loss: 3.884873\t Valid Loss: 4.970693\n",
      "Epoch: 1172/2000\t Step: 15/54\t Train Loss: 3.836606\t Valid Loss: 4.459877\n",
      "Epoch: 1172/2000\t Step: 30/54\t Train Loss: 3.752039\t Valid Loss: 4.727818\n",
      "Epoch: 1172/2000\t Step: 45/54\t Train Loss: 3.803856\t Valid Loss: 4.935154\n",
      "Epoch: 1173/2000\t Step: 15/54\t Train Loss: 3.785851\t Valid Loss: 4.994563\n",
      "Epoch: 1173/2000\t Step: 30/54\t Train Loss: 3.741246\t Valid Loss: 4.881188\n",
      "Epoch: 1173/2000\t Step: 45/54\t Train Loss: 3.756207\t Valid Loss: 4.959468\n",
      "Epoch: 1174/2000\t Step: 15/54\t Train Loss: 3.730340\t Valid Loss: 4.853930\n",
      "Epoch: 1174/2000\t Step: 30/54\t Train Loss: 3.754551\t Valid Loss: 4.541315\n",
      "Epoch: 1174/2000\t Step: 45/54\t Train Loss: 3.786726\t Valid Loss: 4.928803\n",
      "Epoch: 1175/2000\t Step: 15/54\t Train Loss: 3.821810\t Valid Loss: 4.551071\n",
      "Epoch: 1175/2000\t Step: 30/54\t Train Loss: 3.743548\t Valid Loss: 4.522744\n",
      "Epoch: 1175/2000\t Step: 45/54\t Train Loss: 3.714593\t Valid Loss: 4.597067\n",
      "Epoch: 1176/2000\t Step: 15/54\t Train Loss: 3.778988\t Valid Loss: 4.881624\n",
      "Epoch: 1176/2000\t Step: 30/54\t Train Loss: 3.834993\t Valid Loss: 4.700692\n",
      "Epoch: 1176/2000\t Step: 45/54\t Train Loss: 3.803158\t Valid Loss: 4.511837\n",
      "Epoch: 1177/2000\t Step: 15/54\t Train Loss: 3.807646\t Valid Loss: 4.602867\n",
      "Epoch: 1177/2000\t Step: 30/54\t Train Loss: 3.784736\t Valid Loss: 4.821215\n",
      "Epoch: 1177/2000\t Step: 45/54\t Train Loss: 3.817121\t Valid Loss: 4.833914\n",
      "Epoch: 1178/2000\t Step: 15/54\t Train Loss: 3.767509\t Valid Loss: 4.763325\n",
      "Epoch: 1178/2000\t Step: 30/54\t Train Loss: 3.769284\t Valid Loss: 4.813794\n",
      "Epoch: 1178/2000\t Step: 45/54\t Train Loss: 3.825452\t Valid Loss: 4.928084\n",
      "Epoch: 1179/2000\t Step: 15/54\t Train Loss: 3.754313\t Valid Loss: 4.624994\n",
      "Epoch: 1179/2000\t Step: 30/54\t Train Loss: 3.827218\t Valid Loss: 4.704953\n",
      "Epoch: 1179/2000\t Step: 45/54\t Train Loss: 3.775363\t Valid Loss: 4.560186\n",
      "Epoch: 1180/2000\t Step: 15/54\t Train Loss: 3.769968\t Valid Loss: 4.460582\n",
      "Epoch: 1180/2000\t Step: 30/54\t Train Loss: 3.780104\t Valid Loss: 4.770951\n",
      "Epoch: 1180/2000\t Step: 45/54\t Train Loss: 3.805664\t Valid Loss: 4.645727\n",
      "Epoch: 1181/2000\t Step: 15/54\t Train Loss: 3.718416\t Valid Loss: 4.543817\n",
      "Epoch: 1181/2000\t Step: 30/54\t Train Loss: 3.746858\t Valid Loss: 4.823919\n",
      "Epoch: 1181/2000\t Step: 45/54\t Train Loss: 3.775269\t Valid Loss: 4.942650\n",
      "Epoch: 1182/2000\t Step: 15/54\t Train Loss: 3.754897\t Valid Loss: 4.911032\n",
      "Epoch: 1182/2000\t Step: 30/54\t Train Loss: 3.835311\t Valid Loss: 4.725496\n",
      "Epoch: 1182/2000\t Step: 45/54\t Train Loss: 3.826367\t Valid Loss: 4.646940\n",
      "Epoch: 1183/2000\t Step: 15/54\t Train Loss: 3.810910\t Valid Loss: 4.623292\n",
      "Epoch: 1183/2000\t Step: 30/54\t Train Loss: 3.774612\t Valid Loss: 4.699030\n",
      "Epoch: 1183/2000\t Step: 45/54\t Train Loss: 3.814371\t Valid Loss: 4.972990\n",
      "Epoch: 1184/2000\t Step: 15/54\t Train Loss: 3.703442\t Valid Loss: 4.713210\n",
      "Epoch: 1184/2000\t Step: 30/54\t Train Loss: 3.777824\t Valid Loss: 4.867984\n",
      "Epoch: 1184/2000\t Step: 45/54\t Train Loss: 3.733171\t Valid Loss: 5.117145\n",
      "Epoch: 1185/2000\t Step: 15/54\t Train Loss: 3.800823\t Valid Loss: 4.637377\n",
      "Epoch: 1185/2000\t Step: 30/54\t Train Loss: 3.744582\t Valid Loss: 4.984843\n",
      "Epoch: 1185/2000\t Step: 45/54\t Train Loss: 3.782787\t Valid Loss: 5.039030\n",
      "Epoch: 1186/2000\t Step: 15/54\t Train Loss: 3.884123\t Valid Loss: 4.790935\n",
      "Epoch: 1186/2000\t Step: 30/54\t Train Loss: 3.798684\t Valid Loss: 4.697657\n",
      "Epoch: 1186/2000\t Step: 45/54\t Train Loss: 3.822436\t Valid Loss: 5.090711\n",
      "Epoch: 1187/2000\t Step: 15/54\t Train Loss: 3.818212\t Valid Loss: 4.879935\n",
      "Epoch: 1187/2000\t Step: 30/54\t Train Loss: 3.844838\t Valid Loss: 4.797100\n",
      "Epoch: 1187/2000\t Step: 45/54\t Train Loss: 3.809952\t Valid Loss: 4.884493\n",
      "Epoch: 1188/2000\t Step: 15/54\t Train Loss: 3.780918\t Valid Loss: 4.889541\n",
      "Epoch: 1188/2000\t Step: 30/54\t Train Loss: 3.763810\t Valid Loss: 4.697888\n",
      "Epoch: 1188/2000\t Step: 45/54\t Train Loss: 3.724977\t Valid Loss: 5.167839\n",
      "Epoch: 1189/2000\t Step: 15/54\t Train Loss: 3.788872\t Valid Loss: 4.605516\n",
      "Epoch: 1189/2000\t Step: 30/54\t Train Loss: 3.727285\t Valid Loss: 5.128545\n",
      "Epoch: 1189/2000\t Step: 45/54\t Train Loss: 3.767766\t Valid Loss: 5.037213\n",
      "Epoch: 1190/2000\t Step: 15/54\t Train Loss: 3.838127\t Valid Loss: 4.782606\n",
      "Epoch: 1190/2000\t Step: 30/54\t Train Loss: 3.779012\t Valid Loss: 4.470359\n",
      "Epoch: 1190/2000\t Step: 45/54\t Train Loss: 3.801766\t Valid Loss: 4.671681\n",
      "Epoch: 1191/2000\t Step: 15/54\t Train Loss: 3.766150\t Valid Loss: 4.504526\n",
      "Epoch: 1191/2000\t Step: 30/54\t Train Loss: 3.731547\t Valid Loss: 5.055655\n",
      "Epoch: 1191/2000\t Step: 45/54\t Train Loss: 3.726724\t Valid Loss: 5.006795\n",
      "Epoch: 1192/2000\t Step: 15/54\t Train Loss: 3.827726\t Valid Loss: 5.092413\n",
      "Epoch: 1192/2000\t Step: 30/54\t Train Loss: 3.755771\t Valid Loss: 4.556588\n",
      "Epoch: 1192/2000\t Step: 45/54\t Train Loss: 3.772811\t Valid Loss: 4.817863\n",
      "Epoch: 1193/2000\t Step: 15/54\t Train Loss: 3.752306\t Valid Loss: 4.825965\n",
      "Epoch: 1193/2000\t Step: 30/54\t Train Loss: 3.779797\t Valid Loss: 4.746987\n",
      "Epoch: 1193/2000\t Step: 45/54\t Train Loss: 3.787282\t Valid Loss: 4.826092\n",
      "Epoch: 1194/2000\t Step: 15/54\t Train Loss: 3.802617\t Valid Loss: 4.746633\n",
      "Epoch: 1194/2000\t Step: 30/54\t Train Loss: 3.846742\t Valid Loss: 4.463953\n",
      "Epoch: 1194/2000\t Step: 45/54\t Train Loss: 3.679528\t Valid Loss: 4.583680\n",
      "Epoch: 1195/2000\t Step: 15/54\t Train Loss: 3.857908\t Valid Loss: 5.156207\n",
      "Epoch: 1195/2000\t Step: 30/54\t Train Loss: 3.856277\t Valid Loss: 4.722248\n",
      "Epoch: 1195/2000\t Step: 45/54\t Train Loss: 3.846408\t Valid Loss: 4.701633\n",
      "Epoch: 1196/2000\t Step: 15/54\t Train Loss: 3.783813\t Valid Loss: 5.026294\n",
      "Epoch: 1196/2000\t Step: 30/54\t Train Loss: 3.730306\t Valid Loss: 4.729725\n",
      "Epoch: 1196/2000\t Step: 45/54\t Train Loss: 3.823512\t Valid Loss: 5.154018\n",
      "Epoch: 1197/2000\t Step: 15/54\t Train Loss: 3.770583\t Valid Loss: 4.485902\n",
      "Epoch: 1197/2000\t Step: 30/54\t Train Loss: 3.770884\t Valid Loss: 5.132570\n",
      "Epoch: 1197/2000\t Step: 45/54\t Train Loss: 3.732490\t Valid Loss: 5.015350\n",
      "Epoch: 1198/2000\t Step: 15/54\t Train Loss: 3.764982\t Valid Loss: 4.707244\n",
      "Epoch: 1198/2000\t Step: 30/54\t Train Loss: 3.809669\t Valid Loss: 4.819837\n",
      "Epoch: 1198/2000\t Step: 45/54\t Train Loss: 3.786604\t Valid Loss: 4.787517\n",
      "Epoch: 1199/2000\t Step: 15/54\t Train Loss: 3.792402\t Valid Loss: 4.655262\n",
      "Epoch: 1199/2000\t Step: 30/54\t Train Loss: 3.825161\t Valid Loss: 4.827571\n",
      "Epoch: 1199/2000\t Step: 45/54\t Train Loss: 3.831519\t Valid Loss: 4.820206\n",
      "Epoch: 1200/2000\t Step: 15/54\t Train Loss: 3.774962\t Valid Loss: 4.527690\n",
      "Epoch: 1200/2000\t Step: 30/54\t Train Loss: 3.835052\t Valid Loss: 4.597088\n",
      "Epoch: 1200/2000\t Step: 45/54\t Train Loss: 3.766659\t Valid Loss: 5.081615\n",
      "Epoch: 1201/2000\t Step: 15/54\t Train Loss: 3.745764\t Valid Loss: 4.662944\n",
      "Epoch: 1201/2000\t Step: 30/54\t Train Loss: 3.786658\t Valid Loss: 4.749956\n",
      "Epoch: 1201/2000\t Step: 45/54\t Train Loss: 3.871385\t Valid Loss: 4.636220\n",
      "Epoch: 1202/2000\t Step: 15/54\t Train Loss: 3.765052\t Valid Loss: 4.957888\n",
      "Epoch: 1202/2000\t Step: 30/54\t Train Loss: 3.726299\t Valid Loss: 4.611733\n",
      "Epoch: 1202/2000\t Step: 45/54\t Train Loss: 3.782036\t Valid Loss: 4.710736\n",
      "Epoch: 1203/2000\t Step: 15/54\t Train Loss: 3.760953\t Valid Loss: 5.041230\n",
      "Epoch: 1203/2000\t Step: 30/54\t Train Loss: 3.774919\t Valid Loss: 4.815255\n",
      "Epoch: 1203/2000\t Step: 45/54\t Train Loss: 3.758280\t Valid Loss: 4.449334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1204/2000\t Step: 15/54\t Train Loss: 3.755086\t Valid Loss: 4.708558\n",
      "Epoch: 1204/2000\t Step: 30/54\t Train Loss: 3.753077\t Valid Loss: 5.057214\n",
      "Epoch: 1204/2000\t Step: 45/54\t Train Loss: 3.724751\t Valid Loss: 4.898003\n",
      "Epoch: 1205/2000\t Step: 15/54\t Train Loss: 3.786856\t Valid Loss: 4.665057\n",
      "Epoch: 1205/2000\t Step: 30/54\t Train Loss: 3.785013\t Valid Loss: 4.855523\n",
      "Epoch: 1205/2000\t Step: 45/54\t Train Loss: 3.854682\t Valid Loss: 4.578703\n",
      "Epoch: 1206/2000\t Step: 15/54\t Train Loss: 3.741410\t Valid Loss: 4.686348\n",
      "Epoch: 1206/2000\t Step: 30/54\t Train Loss: 3.812245\t Valid Loss: 5.135623\n",
      "Epoch: 1206/2000\t Step: 45/54\t Train Loss: 3.845618\t Valid Loss: 4.518911\n",
      "Epoch: 1207/2000\t Step: 15/54\t Train Loss: 3.795046\t Valid Loss: 4.868550\n",
      "Epoch: 1207/2000\t Step: 30/54\t Train Loss: 3.806707\t Valid Loss: 4.891901\n",
      "Epoch: 1207/2000\t Step: 45/54\t Train Loss: 3.784200\t Valid Loss: 4.863355\n",
      "Epoch: 1208/2000\t Step: 15/54\t Train Loss: 3.900479\t Valid Loss: 4.388797\n",
      "Epoch: 1208/2000\t Step: 30/54\t Train Loss: 3.763570\t Valid Loss: 4.798406\n",
      "Epoch: 1208/2000\t Step: 45/54\t Train Loss: 3.722600\t Valid Loss: 5.048327\n",
      "Epoch: 1209/2000\t Step: 15/54\t Train Loss: 3.746788\t Valid Loss: 4.734842\n",
      "Epoch: 1209/2000\t Step: 30/54\t Train Loss: 3.782907\t Valid Loss: 5.088910\n",
      "Epoch: 1209/2000\t Step: 45/54\t Train Loss: 3.735406\t Valid Loss: 4.581253\n",
      "Epoch: 1210/2000\t Step: 15/54\t Train Loss: 3.824236\t Valid Loss: 4.954506\n",
      "Epoch: 1210/2000\t Step: 30/54\t Train Loss: 3.827424\t Valid Loss: 4.588562\n",
      "Epoch: 1210/2000\t Step: 45/54\t Train Loss: 3.823640\t Valid Loss: 4.741698\n",
      "Epoch: 1211/2000\t Step: 15/54\t Train Loss: 3.779371\t Valid Loss: 4.898500\n",
      "Epoch: 1211/2000\t Step: 30/54\t Train Loss: 3.797642\t Valid Loss: 5.032472\n",
      "Epoch: 1211/2000\t Step: 45/54\t Train Loss: 3.701354\t Valid Loss: 4.889629\n",
      "Epoch: 1212/2000\t Step: 15/54\t Train Loss: 3.732431\t Valid Loss: 4.901286\n",
      "Epoch: 1212/2000\t Step: 30/54\t Train Loss: 3.786817\t Valid Loss: 4.943616\n",
      "Epoch: 1212/2000\t Step: 45/54\t Train Loss: 3.737947\t Valid Loss: 4.927136\n",
      "Epoch: 1213/2000\t Step: 15/54\t Train Loss: 3.799402\t Valid Loss: 4.405474\n",
      "Epoch: 1213/2000\t Step: 30/54\t Train Loss: 3.796848\t Valid Loss: 4.697887\n",
      "Epoch: 1213/2000\t Step: 45/54\t Train Loss: 3.733972\t Valid Loss: 4.632607\n",
      "Epoch: 1214/2000\t Step: 15/54\t Train Loss: 3.772513\t Valid Loss: 4.724233\n",
      "Epoch: 1214/2000\t Step: 30/54\t Train Loss: 3.754186\t Valid Loss: 4.548469\n",
      "Epoch: 1214/2000\t Step: 45/54\t Train Loss: 3.771170\t Valid Loss: 4.759712\n",
      "Epoch: 1215/2000\t Step: 15/54\t Train Loss: 3.781058\t Valid Loss: 4.770068\n",
      "Epoch: 1215/2000\t Step: 30/54\t Train Loss: 3.755524\t Valid Loss: 4.860798\n",
      "Epoch: 1215/2000\t Step: 45/54\t Train Loss: 3.741870\t Valid Loss: 5.047574\n",
      "Epoch: 1216/2000\t Step: 15/54\t Train Loss: 3.758318\t Valid Loss: 4.898652\n",
      "Epoch: 1216/2000\t Step: 30/54\t Train Loss: 3.734212\t Valid Loss: 4.908242\n",
      "Epoch: 1216/2000\t Step: 45/54\t Train Loss: 3.756332\t Valid Loss: 4.859881\n",
      "Epoch: 1217/2000\t Step: 15/54\t Train Loss: 3.764596\t Valid Loss: 4.678706\n",
      "Epoch: 1217/2000\t Step: 30/54\t Train Loss: 3.778821\t Valid Loss: 4.656452\n",
      "Epoch: 1217/2000\t Step: 45/54\t Train Loss: 3.822778\t Valid Loss: 4.577365\n",
      "Epoch: 1218/2000\t Step: 15/54\t Train Loss: 3.763871\t Valid Loss: 4.837564\n",
      "Epoch: 1218/2000\t Step: 30/54\t Train Loss: 3.754042\t Valid Loss: 4.896737\n",
      "Epoch: 1218/2000\t Step: 45/54\t Train Loss: 3.741156\t Valid Loss: 4.992992\n",
      "Epoch: 1219/2000\t Step: 15/54\t Train Loss: 3.844437\t Valid Loss: 4.768734\n",
      "Epoch: 1219/2000\t Step: 30/54\t Train Loss: 3.771780\t Valid Loss: 4.617246\n",
      "Epoch: 1219/2000\t Step: 45/54\t Train Loss: 3.772983\t Valid Loss: 4.662156\n",
      "Epoch: 1220/2000\t Step: 15/54\t Train Loss: 3.830826\t Valid Loss: 4.740724\n",
      "Epoch: 1220/2000\t Step: 30/54\t Train Loss: 3.773508\t Valid Loss: 4.819927\n",
      "Epoch: 1220/2000\t Step: 45/54\t Train Loss: 3.791592\t Valid Loss: 4.924785\n",
      "Epoch: 1221/2000\t Step: 15/54\t Train Loss: 3.749884\t Valid Loss: 4.818189\n",
      "Epoch: 1221/2000\t Step: 30/54\t Train Loss: 3.724975\t Valid Loss: 5.016729\n",
      "Epoch: 1221/2000\t Step: 45/54\t Train Loss: 3.804684\t Valid Loss: 4.751633\n",
      "Epoch: 1222/2000\t Step: 15/54\t Train Loss: 3.735824\t Valid Loss: 4.661112\n",
      "Epoch: 1222/2000\t Step: 30/54\t Train Loss: 3.765562\t Valid Loss: 4.974894\n",
      "Epoch: 1222/2000\t Step: 45/54\t Train Loss: 3.784488\t Valid Loss: 4.896659\n",
      "Epoch: 1223/2000\t Step: 15/54\t Train Loss: 3.767651\t Valid Loss: 4.640654\n",
      "Epoch: 1223/2000\t Step: 30/54\t Train Loss: 3.814510\t Valid Loss: 4.908461\n",
      "Epoch: 1223/2000\t Step: 45/54\t Train Loss: 3.769801\t Valid Loss: 4.552137\n",
      "Epoch: 1224/2000\t Step: 15/54\t Train Loss: 3.773776\t Valid Loss: 4.548680\n",
      "Epoch: 1224/2000\t Step: 30/54\t Train Loss: 3.758858\t Valid Loss: 4.910253\n",
      "Epoch: 1224/2000\t Step: 45/54\t Train Loss: 3.784458\t Valid Loss: 4.860249\n",
      "Epoch: 1225/2000\t Step: 15/54\t Train Loss: 3.773454\t Valid Loss: 4.850279\n",
      "Epoch: 1225/2000\t Step: 30/54\t Train Loss: 3.712178\t Valid Loss: 5.114211\n",
      "Epoch: 1225/2000\t Step: 45/54\t Train Loss: 3.794286\t Valid Loss: 5.002567\n",
      "Epoch: 1226/2000\t Step: 15/54\t Train Loss: 3.760064\t Valid Loss: 4.758237\n",
      "Epoch: 1226/2000\t Step: 30/54\t Train Loss: 3.773069\t Valid Loss: 4.675178\n",
      "Epoch: 1226/2000\t Step: 45/54\t Train Loss: 3.792545\t Valid Loss: 5.025570\n",
      "Epoch: 1227/2000\t Step: 15/54\t Train Loss: 3.771123\t Valid Loss: 4.872655\n",
      "Epoch: 1227/2000\t Step: 30/54\t Train Loss: 3.775100\t Valid Loss: 5.272353\n",
      "Epoch: 1227/2000\t Step: 45/54\t Train Loss: 3.761646\t Valid Loss: 4.738617\n",
      "Epoch: 1228/2000\t Step: 15/54\t Train Loss: 3.837297\t Valid Loss: 5.035299\n",
      "Epoch: 1228/2000\t Step: 30/54\t Train Loss: 3.810632\t Valid Loss: 4.565396\n",
      "Epoch: 1228/2000\t Step: 45/54\t Train Loss: 3.813414\t Valid Loss: 4.967745\n",
      "Epoch: 1229/2000\t Step: 15/54\t Train Loss: 3.765623\t Valid Loss: 4.593095\n",
      "Epoch: 1229/2000\t Step: 30/54\t Train Loss: 3.788824\t Valid Loss: 4.598722\n",
      "Epoch: 1229/2000\t Step: 45/54\t Train Loss: 3.852951\t Valid Loss: 4.572086\n",
      "Epoch: 1230/2000\t Step: 15/54\t Train Loss: 3.799166\t Valid Loss: 4.810847\n",
      "Epoch: 1230/2000\t Step: 30/54\t Train Loss: 3.772032\t Valid Loss: 4.998346\n",
      "Epoch: 1230/2000\t Step: 45/54\t Train Loss: 3.756664\t Valid Loss: 4.803771\n",
      "Epoch: 1231/2000\t Step: 15/54\t Train Loss: 3.769610\t Valid Loss: 4.980474\n",
      "Epoch: 1231/2000\t Step: 30/54\t Train Loss: 3.856261\t Valid Loss: 4.564605\n",
      "Epoch: 1231/2000\t Step: 45/54\t Train Loss: 3.854827\t Valid Loss: 4.723605\n",
      "Epoch: 1232/2000\t Step: 15/54\t Train Loss: 3.748515\t Valid Loss: 5.005406\n",
      "Epoch: 1232/2000\t Step: 30/54\t Train Loss: 3.792643\t Valid Loss: 4.500943\n",
      "Epoch: 1232/2000\t Step: 45/54\t Train Loss: 3.763054\t Valid Loss: 4.913325\n",
      "Epoch: 1233/2000\t Step: 15/54\t Train Loss: 3.822922\t Valid Loss: 4.533806\n",
      "Epoch: 1233/2000\t Step: 30/54\t Train Loss: 3.751858\t Valid Loss: 4.794796\n",
      "Epoch: 1233/2000\t Step: 45/54\t Train Loss: 3.735328\t Valid Loss: 4.311055\n",
      "Epoch: 1234/2000\t Step: 15/54\t Train Loss: 3.744250\t Valid Loss: 4.474153\n",
      "Epoch: 1234/2000\t Step: 30/54\t Train Loss: 3.780324\t Valid Loss: 4.716622\n",
      "Epoch: 1234/2000\t Step: 45/54\t Train Loss: 3.750811\t Valid Loss: 4.679449\n",
      "Epoch: 1235/2000\t Step: 15/54\t Train Loss: 3.755266\t Valid Loss: 4.563852\n",
      "Epoch: 1235/2000\t Step: 30/54\t Train Loss: 3.813179\t Valid Loss: 4.828854\n",
      "Epoch: 1235/2000\t Step: 45/54\t Train Loss: 3.770101\t Valid Loss: 5.014230\n",
      "Epoch: 1236/2000\t Step: 15/54\t Train Loss: 3.863461\t Valid Loss: 4.770655\n",
      "Epoch: 1236/2000\t Step: 30/54\t Train Loss: 3.770691\t Valid Loss: 4.840910\n",
      "Epoch: 1236/2000\t Step: 45/54\t Train Loss: 3.845148\t Valid Loss: 5.080059\n",
      "Epoch: 1237/2000\t Step: 15/54\t Train Loss: 3.818908\t Valid Loss: 4.706775\n",
      "Epoch: 1237/2000\t Step: 30/54\t Train Loss: 3.682171\t Valid Loss: 4.801510\n",
      "Epoch: 1237/2000\t Step: 45/54\t Train Loss: 3.742251\t Valid Loss: 4.860260\n",
      "Epoch: 1238/2000\t Step: 15/54\t Train Loss: 3.738011\t Valid Loss: 4.844151\n",
      "Epoch: 1238/2000\t Step: 30/54\t Train Loss: 3.805773\t Valid Loss: 4.587230\n",
      "Epoch: 1238/2000\t Step: 45/54\t Train Loss: 3.769837\t Valid Loss: 4.964562\n",
      "Epoch: 1239/2000\t Step: 15/54\t Train Loss: 3.746347\t Valid Loss: 5.036102\n",
      "Epoch: 1239/2000\t Step: 30/54\t Train Loss: 3.854256\t Valid Loss: 4.799873\n",
      "Epoch: 1239/2000\t Step: 45/54\t Train Loss: 3.756847\t Valid Loss: 4.484295\n",
      "Epoch: 1240/2000\t Step: 15/54\t Train Loss: 3.798207\t Valid Loss: 4.641142\n",
      "Epoch: 1240/2000\t Step: 30/54\t Train Loss: 3.792649\t Valid Loss: 4.882812\n",
      "Epoch: 1240/2000\t Step: 45/54\t Train Loss: 3.748719\t Valid Loss: 4.706112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1241/2000\t Step: 15/54\t Train Loss: 3.808246\t Valid Loss: 4.656022\n",
      "Epoch: 1241/2000\t Step: 30/54\t Train Loss: 3.792498\t Valid Loss: 4.976883\n",
      "Epoch: 1241/2000\t Step: 45/54\t Train Loss: 3.751989\t Valid Loss: 5.002457\n",
      "Epoch: 1242/2000\t Step: 15/54\t Train Loss: 3.813652\t Valid Loss: 4.624989\n",
      "Epoch: 1242/2000\t Step: 30/54\t Train Loss: 3.763038\t Valid Loss: 4.785463\n",
      "Epoch: 1242/2000\t Step: 45/54\t Train Loss: 3.729324\t Valid Loss: 5.147035\n",
      "Epoch: 1243/2000\t Step: 15/54\t Train Loss: 3.724152\t Valid Loss: 4.850118\n",
      "Epoch: 1243/2000\t Step: 30/54\t Train Loss: 3.661527\t Valid Loss: 5.168469\n",
      "Epoch: 1243/2000\t Step: 45/54\t Train Loss: 3.749259\t Valid Loss: 4.733661\n",
      "Epoch: 1244/2000\t Step: 15/54\t Train Loss: 3.759935\t Valid Loss: 4.699715\n",
      "Epoch: 1244/2000\t Step: 30/54\t Train Loss: 3.833571\t Valid Loss: 4.781922\n",
      "Epoch: 1244/2000\t Step: 45/54\t Train Loss: 3.786304\t Valid Loss: 4.289050\n",
      "Epoch: 1245/2000\t Step: 15/54\t Train Loss: 3.737267\t Valid Loss: 4.597138\n",
      "Epoch: 1245/2000\t Step: 30/54\t Train Loss: 3.818793\t Valid Loss: 4.594534\n",
      "Epoch: 1245/2000\t Step: 45/54\t Train Loss: 3.710907\t Valid Loss: 4.919375\n",
      "Epoch: 1246/2000\t Step: 15/54\t Train Loss: 3.816179\t Valid Loss: 4.554523\n",
      "Epoch: 1246/2000\t Step: 30/54\t Train Loss: 3.796566\t Valid Loss: 4.855989\n",
      "Epoch: 1246/2000\t Step: 45/54\t Train Loss: 3.796967\t Valid Loss: 4.867565\n",
      "Epoch: 1247/2000\t Step: 15/54\t Train Loss: 3.820759\t Valid Loss: 4.650167\n",
      "Epoch: 1247/2000\t Step: 30/54\t Train Loss: 3.865088\t Valid Loss: 4.442672\n",
      "Epoch: 1247/2000\t Step: 45/54\t Train Loss: 3.735474\t Valid Loss: 4.599356\n",
      "Epoch: 1248/2000\t Step: 15/54\t Train Loss: 3.826591\t Valid Loss: 4.802803\n",
      "Epoch: 1248/2000\t Step: 30/54\t Train Loss: 3.789791\t Valid Loss: 5.082046\n",
      "Epoch: 1248/2000\t Step: 45/54\t Train Loss: 3.830462\t Valid Loss: 4.637798\n",
      "Epoch: 1249/2000\t Step: 15/54\t Train Loss: 3.816307\t Valid Loss: 4.718348\n",
      "Epoch: 1249/2000\t Step: 30/54\t Train Loss: 3.766803\t Valid Loss: 5.083143\n",
      "Epoch: 1249/2000\t Step: 45/54\t Train Loss: 3.723716\t Valid Loss: 4.979657\n",
      "Epoch: 1250/2000\t Step: 15/54\t Train Loss: 3.726902\t Valid Loss: 5.109276\n",
      "Epoch: 1250/2000\t Step: 30/54\t Train Loss: 3.744424\t Valid Loss: 4.903143\n",
      "Epoch: 1250/2000\t Step: 45/54\t Train Loss: 3.728897\t Valid Loss: 4.833697\n",
      "Epoch: 1251/2000\t Step: 15/54\t Train Loss: 3.738372\t Valid Loss: 5.125660\n",
      "Epoch: 1251/2000\t Step: 30/54\t Train Loss: 3.727577\t Valid Loss: 4.625668\n",
      "Epoch: 1251/2000\t Step: 45/54\t Train Loss: 3.706556\t Valid Loss: 5.292164\n",
      "Epoch: 1252/2000\t Step: 15/54\t Train Loss: 3.725692\t Valid Loss: 4.985788\n",
      "Epoch: 1252/2000\t Step: 30/54\t Train Loss: 3.767521\t Valid Loss: 4.806999\n",
      "Epoch: 1252/2000\t Step: 45/54\t Train Loss: 3.785376\t Valid Loss: 5.222546\n",
      "Epoch: 1253/2000\t Step: 15/54\t Train Loss: 3.849840\t Valid Loss: 4.613094\n",
      "Epoch: 1253/2000\t Step: 30/54\t Train Loss: 3.794722\t Valid Loss: 4.920962\n",
      "Epoch: 1253/2000\t Step: 45/54\t Train Loss: 3.757857\t Valid Loss: 4.963682\n",
      "Epoch: 1254/2000\t Step: 15/54\t Train Loss: 3.725991\t Valid Loss: 4.986396\n",
      "Epoch: 1254/2000\t Step: 30/54\t Train Loss: 3.777612\t Valid Loss: 4.990356\n",
      "Epoch: 1254/2000\t Step: 45/54\t Train Loss: 3.694084\t Valid Loss: 4.614753\n",
      "Epoch: 1255/2000\t Step: 15/54\t Train Loss: 3.824823\t Valid Loss: 4.812903\n",
      "Epoch: 1255/2000\t Step: 30/54\t Train Loss: 3.742228\t Valid Loss: 4.905677\n",
      "Epoch: 1255/2000\t Step: 45/54\t Train Loss: 3.755370\t Valid Loss: 4.847802\n",
      "Epoch: 1256/2000\t Step: 15/54\t Train Loss: 3.717847\t Valid Loss: 4.651397\n",
      "Epoch: 1256/2000\t Step: 30/54\t Train Loss: 3.812066\t Valid Loss: 4.909855\n",
      "Epoch: 1256/2000\t Step: 45/54\t Train Loss: 3.704554\t Valid Loss: 5.029563\n",
      "Epoch: 1257/2000\t Step: 15/54\t Train Loss: 3.734011\t Valid Loss: 4.726285\n",
      "Epoch: 1257/2000\t Step: 30/54\t Train Loss: 3.822456\t Valid Loss: 4.840362\n",
      "Epoch: 1257/2000\t Step: 45/54\t Train Loss: 3.780911\t Valid Loss: 4.784079\n",
      "Epoch: 1258/2000\t Step: 15/54\t Train Loss: 3.841912\t Valid Loss: 4.702166\n",
      "Epoch: 1258/2000\t Step: 30/54\t Train Loss: 3.756718\t Valid Loss: 4.780682\n",
      "Epoch: 1258/2000\t Step: 45/54\t Train Loss: 3.798655\t Valid Loss: 4.769748\n",
      "Epoch: 1259/2000\t Step: 15/54\t Train Loss: 3.725280\t Valid Loss: 5.287805\n",
      "Epoch: 1259/2000\t Step: 30/54\t Train Loss: 3.708633\t Valid Loss: 4.567005\n",
      "Epoch: 1259/2000\t Step: 45/54\t Train Loss: 3.814676\t Valid Loss: 5.060558\n",
      "Epoch: 1260/2000\t Step: 15/54\t Train Loss: 3.736589\t Valid Loss: 4.635730\n",
      "Epoch: 1260/2000\t Step: 30/54\t Train Loss: 3.857838\t Valid Loss: 4.526616\n",
      "Epoch: 1260/2000\t Step: 45/54\t Train Loss: 3.744244\t Valid Loss: 4.546185\n",
      "Epoch: 1261/2000\t Step: 15/54\t Train Loss: 3.712998\t Valid Loss: 4.688851\n",
      "Epoch: 1261/2000\t Step: 30/54\t Train Loss: 3.735819\t Valid Loss: 5.272104\n",
      "Epoch: 1261/2000\t Step: 45/54\t Train Loss: 3.816012\t Valid Loss: 4.667827\n",
      "Epoch: 1262/2000\t Step: 15/54\t Train Loss: 3.749501\t Valid Loss: 4.580343\n",
      "Epoch: 1262/2000\t Step: 30/54\t Train Loss: 3.736424\t Valid Loss: 4.460270\n",
      "Epoch: 1262/2000\t Step: 45/54\t Train Loss: 3.759307\t Valid Loss: 5.315175\n",
      "Epoch: 1263/2000\t Step: 15/54\t Train Loss: 3.752916\t Valid Loss: 4.740191\n",
      "Epoch: 1263/2000\t Step: 30/54\t Train Loss: 3.759881\t Valid Loss: 4.838624\n",
      "Epoch: 1263/2000\t Step: 45/54\t Train Loss: 3.816235\t Valid Loss: 4.738725\n",
      "Epoch: 1264/2000\t Step: 15/54\t Train Loss: 3.757522\t Valid Loss: 5.202023\n",
      "Epoch: 1264/2000\t Step: 30/54\t Train Loss: 3.858942\t Valid Loss: 4.911623\n",
      "Epoch: 1264/2000\t Step: 45/54\t Train Loss: 3.732577\t Valid Loss: 4.838423\n",
      "Epoch: 1265/2000\t Step: 15/54\t Train Loss: 3.706540\t Valid Loss: 4.740363\n",
      "Epoch: 1265/2000\t Step: 30/54\t Train Loss: 3.749162\t Valid Loss: 4.585266\n",
      "Epoch: 1265/2000\t Step: 45/54\t Train Loss: 3.810636\t Valid Loss: 4.683658\n",
      "Epoch: 1266/2000\t Step: 15/54\t Train Loss: 3.753001\t Valid Loss: 4.725147\n",
      "Epoch: 1266/2000\t Step: 30/54\t Train Loss: 3.769618\t Valid Loss: 5.188393\n",
      "Epoch: 1266/2000\t Step: 45/54\t Train Loss: 3.802329\t Valid Loss: 4.564406\n",
      "Epoch: 1267/2000\t Step: 15/54\t Train Loss: 3.731265\t Valid Loss: 5.164980\n",
      "Epoch: 1267/2000\t Step: 30/54\t Train Loss: 3.788123\t Valid Loss: 5.256512\n",
      "Epoch: 1267/2000\t Step: 45/54\t Train Loss: 3.752216\t Valid Loss: 5.080889\n",
      "Epoch: 1268/2000\t Step: 15/54\t Train Loss: 3.746632\t Valid Loss: 4.636783\n",
      "Epoch: 1268/2000\t Step: 30/54\t Train Loss: 3.842767\t Valid Loss: 4.855560\n",
      "Epoch: 1268/2000\t Step: 45/54\t Train Loss: 3.766245\t Valid Loss: 5.031929\n",
      "Epoch: 1269/2000\t Step: 15/54\t Train Loss: 3.771873\t Valid Loss: 4.607652\n",
      "Epoch: 1269/2000\t Step: 30/54\t Train Loss: 3.788524\t Valid Loss: 4.808530\n",
      "Epoch: 1269/2000\t Step: 45/54\t Train Loss: 3.812667\t Valid Loss: 4.943736\n",
      "Epoch: 1270/2000\t Step: 15/54\t Train Loss: 3.803703\t Valid Loss: 4.486419\n",
      "Epoch: 1270/2000\t Step: 30/54\t Train Loss: 3.787251\t Valid Loss: 4.642868\n",
      "Epoch: 1270/2000\t Step: 45/54\t Train Loss: 3.752230\t Valid Loss: 4.573966\n",
      "Epoch: 1271/2000\t Step: 15/54\t Train Loss: 3.768449\t Valid Loss: 5.102079\n",
      "Epoch: 1271/2000\t Step: 30/54\t Train Loss: 3.690611\t Valid Loss: 4.917860\n",
      "Epoch: 1271/2000\t Step: 45/54\t Train Loss: 3.815855\t Valid Loss: 5.121701\n",
      "Epoch: 1272/2000\t Step: 15/54\t Train Loss: 3.762684\t Valid Loss: 4.776966\n",
      "Epoch: 1272/2000\t Step: 30/54\t Train Loss: 3.783140\t Valid Loss: 4.994563\n",
      "Epoch: 1272/2000\t Step: 45/54\t Train Loss: 3.775616\t Valid Loss: 4.654953\n",
      "Epoch: 1273/2000\t Step: 15/54\t Train Loss: 3.811456\t Valid Loss: 4.548926\n",
      "Epoch: 1273/2000\t Step: 30/54\t Train Loss: 3.730446\t Valid Loss: 5.360771\n",
      "Epoch: 1273/2000\t Step: 45/54\t Train Loss: 3.798975\t Valid Loss: 4.677376\n",
      "Epoch: 1274/2000\t Step: 15/54\t Train Loss: 3.782852\t Valid Loss: 4.837034\n",
      "Epoch: 1274/2000\t Step: 30/54\t Train Loss: 3.725066\t Valid Loss: 4.909894\n",
      "Epoch: 1274/2000\t Step: 45/54\t Train Loss: 3.770350\t Valid Loss: 4.447458\n",
      "Epoch: 1275/2000\t Step: 15/54\t Train Loss: 3.806561\t Valid Loss: 4.870607\n",
      "Epoch: 1275/2000\t Step: 30/54\t Train Loss: 3.752428\t Valid Loss: 4.649406\n",
      "Epoch: 1275/2000\t Step: 45/54\t Train Loss: 3.842361\t Valid Loss: 4.785593\n",
      "Epoch: 1276/2000\t Step: 15/54\t Train Loss: 3.820328\t Valid Loss: 4.596674\n",
      "Epoch: 1276/2000\t Step: 30/54\t Train Loss: 3.726356\t Valid Loss: 4.970926\n",
      "Epoch: 1276/2000\t Step: 45/54\t Train Loss: 3.805770\t Valid Loss: 4.852499\n",
      "Epoch: 1277/2000\t Step: 15/54\t Train Loss: 3.828938\t Valid Loss: 4.697415\n",
      "Epoch: 1277/2000\t Step: 30/54\t Train Loss: 3.820333\t Valid Loss: 4.613420\n",
      "Epoch: 1277/2000\t Step: 45/54\t Train Loss: 3.774086\t Valid Loss: 5.053795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1278/2000\t Step: 15/54\t Train Loss: 3.748443\t Valid Loss: 5.034247\n",
      "Epoch: 1278/2000\t Step: 30/54\t Train Loss: 3.769745\t Valid Loss: 4.529554\n",
      "Epoch: 1278/2000\t Step: 45/54\t Train Loss: 3.763928\t Valid Loss: 5.194815\n",
      "Epoch: 1279/2000\t Step: 15/54\t Train Loss: 3.766809\t Valid Loss: 4.535499\n",
      "Epoch: 1279/2000\t Step: 30/54\t Train Loss: 3.794709\t Valid Loss: 4.732230\n",
      "Epoch: 1279/2000\t Step: 45/54\t Train Loss: 3.779643\t Valid Loss: 4.978217\n",
      "Epoch: 1280/2000\t Step: 15/54\t Train Loss: 3.762979\t Valid Loss: 4.846242\n",
      "Epoch: 1280/2000\t Step: 30/54\t Train Loss: 3.876076\t Valid Loss: 4.488737\n",
      "Epoch: 1280/2000\t Step: 45/54\t Train Loss: 3.779114\t Valid Loss: 4.957905\n",
      "Epoch: 1281/2000\t Step: 15/54\t Train Loss: 3.711718\t Valid Loss: 5.045857\n",
      "Epoch: 1281/2000\t Step: 30/54\t Train Loss: 3.813700\t Valid Loss: 4.914051\n",
      "Epoch: 1281/2000\t Step: 45/54\t Train Loss: 3.778123\t Valid Loss: 5.033475\n",
      "Epoch: 1282/2000\t Step: 15/54\t Train Loss: 3.746795\t Valid Loss: 4.577579\n",
      "Epoch: 1282/2000\t Step: 30/54\t Train Loss: 3.824254\t Valid Loss: 4.717531\n",
      "Epoch: 1282/2000\t Step: 45/54\t Train Loss: 3.764704\t Valid Loss: 4.625268\n",
      "Epoch: 1283/2000\t Step: 15/54\t Train Loss: 3.744422\t Valid Loss: 4.657868\n",
      "Epoch: 1283/2000\t Step: 30/54\t Train Loss: 3.750684\t Valid Loss: 4.835137\n",
      "Epoch: 1283/2000\t Step: 45/54\t Train Loss: 3.748691\t Valid Loss: 4.742629\n",
      "Epoch: 1284/2000\t Step: 15/54\t Train Loss: 3.775585\t Valid Loss: 4.631391\n",
      "Epoch: 1284/2000\t Step: 30/54\t Train Loss: 3.813782\t Valid Loss: 4.714102\n",
      "Epoch: 1284/2000\t Step: 45/54\t Train Loss: 3.784352\t Valid Loss: 5.035350\n",
      "Epoch: 1285/2000\t Step: 15/54\t Train Loss: 3.718615\t Valid Loss: 4.712505\n",
      "Epoch: 1285/2000\t Step: 30/54\t Train Loss: 3.828249\t Valid Loss: 4.726497\n",
      "Epoch: 1285/2000\t Step: 45/54\t Train Loss: 3.731707\t Valid Loss: 4.514635\n",
      "Epoch: 1286/2000\t Step: 15/54\t Train Loss: 3.770360\t Valid Loss: 5.078535\n",
      "Epoch: 1286/2000\t Step: 30/54\t Train Loss: 3.718422\t Valid Loss: 4.955185\n",
      "Epoch: 1286/2000\t Step: 45/54\t Train Loss: 3.746919\t Valid Loss: 5.017149\n",
      "Epoch: 1287/2000\t Step: 15/54\t Train Loss: 3.760506\t Valid Loss: 4.868218\n",
      "Epoch: 1287/2000\t Step: 30/54\t Train Loss: 3.738078\t Valid Loss: 4.595014\n",
      "Epoch: 1287/2000\t Step: 45/54\t Train Loss: 3.813429\t Valid Loss: 4.611989\n",
      "Epoch: 1288/2000\t Step: 15/54\t Train Loss: 3.719394\t Valid Loss: 4.835950\n",
      "Epoch: 1288/2000\t Step: 30/54\t Train Loss: 3.794764\t Valid Loss: 4.739393\n",
      "Epoch: 1288/2000\t Step: 45/54\t Train Loss: 3.789524\t Valid Loss: 4.603327\n",
      "Epoch: 1289/2000\t Step: 15/54\t Train Loss: 3.773409\t Valid Loss: 4.822511\n",
      "Epoch: 1289/2000\t Step: 30/54\t Train Loss: 3.733734\t Valid Loss: 4.611189\n",
      "Epoch: 1289/2000\t Step: 45/54\t Train Loss: 3.818206\t Valid Loss: 5.053467\n",
      "Epoch: 1290/2000\t Step: 15/54\t Train Loss: 3.712764\t Valid Loss: 4.967326\n",
      "Epoch: 1290/2000\t Step: 30/54\t Train Loss: 3.834338\t Valid Loss: 4.760383\n",
      "Epoch: 1290/2000\t Step: 45/54\t Train Loss: 3.879390\t Valid Loss: 4.618008\n",
      "Epoch: 1291/2000\t Step: 15/54\t Train Loss: 3.784605\t Valid Loss: 5.169706\n",
      "Epoch: 1291/2000\t Step: 30/54\t Train Loss: 3.764887\t Valid Loss: 4.586404\n",
      "Epoch: 1291/2000\t Step: 45/54\t Train Loss: 3.804641\t Valid Loss: 4.848262\n",
      "Epoch: 1292/2000\t Step: 15/54\t Train Loss: 3.781751\t Valid Loss: 4.703605\n",
      "Epoch: 1292/2000\t Step: 30/54\t Train Loss: 3.753672\t Valid Loss: 4.809058\n",
      "Epoch: 1292/2000\t Step: 45/54\t Train Loss: 3.739144\t Valid Loss: 4.992502\n",
      "Epoch: 1293/2000\t Step: 15/54\t Train Loss: 3.770590\t Valid Loss: 4.918739\n",
      "Epoch: 1293/2000\t Step: 30/54\t Train Loss: 3.828739\t Valid Loss: 4.650889\n",
      "Epoch: 1293/2000\t Step: 45/54\t Train Loss: 3.749825\t Valid Loss: 4.901992\n",
      "Epoch: 1294/2000\t Step: 15/54\t Train Loss: 3.792416\t Valid Loss: 4.723583\n",
      "Epoch: 1294/2000\t Step: 30/54\t Train Loss: 3.791825\t Valid Loss: 4.742371\n",
      "Epoch: 1294/2000\t Step: 45/54\t Train Loss: 3.831968\t Valid Loss: 5.033881\n",
      "Epoch: 1295/2000\t Step: 15/54\t Train Loss: 3.727659\t Valid Loss: 4.973744\n",
      "Epoch: 1295/2000\t Step: 30/54\t Train Loss: 3.762570\t Valid Loss: 4.718829\n",
      "Epoch: 1295/2000\t Step: 45/54\t Train Loss: 3.784178\t Valid Loss: 4.722877\n",
      "Epoch: 1296/2000\t Step: 15/54\t Train Loss: 3.704816\t Valid Loss: 4.879491\n",
      "Epoch: 1296/2000\t Step: 30/54\t Train Loss: 3.810510\t Valid Loss: 4.662076\n",
      "Epoch: 1296/2000\t Step: 45/54\t Train Loss: 3.772681\t Valid Loss: 4.889316\n",
      "Epoch: 1297/2000\t Step: 15/54\t Train Loss: 3.826691\t Valid Loss: 4.747350\n",
      "Epoch: 1297/2000\t Step: 30/54\t Train Loss: 3.752723\t Valid Loss: 4.743729\n",
      "Epoch: 1297/2000\t Step: 45/54\t Train Loss: 3.729975\t Valid Loss: 4.796410\n",
      "Epoch: 1298/2000\t Step: 15/54\t Train Loss: 3.762161\t Valid Loss: 4.690980\n",
      "Epoch: 1298/2000\t Step: 30/54\t Train Loss: 3.743844\t Valid Loss: 5.137949\n",
      "Epoch: 1298/2000\t Step: 45/54\t Train Loss: 3.796805\t Valid Loss: 4.682583\n",
      "Epoch: 1299/2000\t Step: 15/54\t Train Loss: 3.774651\t Valid Loss: 4.861555\n",
      "Epoch: 1299/2000\t Step: 30/54\t Train Loss: 3.788497\t Valid Loss: 4.503423\n",
      "Epoch: 1299/2000\t Step: 45/54\t Train Loss: 3.760819\t Valid Loss: 4.896691\n",
      "Epoch: 1300/2000\t Step: 15/54\t Train Loss: 3.732806\t Valid Loss: 4.739968\n",
      "Epoch: 1300/2000\t Step: 30/54\t Train Loss: 3.755277\t Valid Loss: 4.791330\n",
      "Epoch: 1300/2000\t Step: 45/54\t Train Loss: 3.726972\t Valid Loss: 4.726374\n",
      "Epoch: 1301/2000\t Step: 15/54\t Train Loss: 3.754488\t Valid Loss: 4.782679\n",
      "Epoch: 1301/2000\t Step: 30/54\t Train Loss: 3.791412\t Valid Loss: 4.820896\n",
      "Epoch: 1301/2000\t Step: 45/54\t Train Loss: 3.704796\t Valid Loss: 5.117767\n",
      "Epoch: 1302/2000\t Step: 15/54\t Train Loss: 3.723107\t Valid Loss: 4.834389\n",
      "Epoch: 1302/2000\t Step: 30/54\t Train Loss: 3.795426\t Valid Loss: 4.566523\n",
      "Epoch: 1302/2000\t Step: 45/54\t Train Loss: 3.736161\t Valid Loss: 4.649924\n",
      "Epoch: 1303/2000\t Step: 15/54\t Train Loss: 3.822978\t Valid Loss: 4.703463\n",
      "Epoch: 1303/2000\t Step: 30/54\t Train Loss: 3.720159\t Valid Loss: 5.137957\n",
      "Epoch: 1303/2000\t Step: 45/54\t Train Loss: 3.791514\t Valid Loss: 4.578828\n",
      "Epoch: 1304/2000\t Step: 15/54\t Train Loss: 3.770802\t Valid Loss: 4.968169\n",
      "Epoch: 1304/2000\t Step: 30/54\t Train Loss: 3.793561\t Valid Loss: 4.861698\n",
      "Epoch: 1304/2000\t Step: 45/54\t Train Loss: 3.783798\t Valid Loss: 4.839820\n",
      "Epoch: 1305/2000\t Step: 15/54\t Train Loss: 3.715246\t Valid Loss: 4.944328\n",
      "Epoch: 1305/2000\t Step: 30/54\t Train Loss: 3.774699\t Valid Loss: 5.160392\n",
      "Epoch: 1305/2000\t Step: 45/54\t Train Loss: 3.775759\t Valid Loss: 4.490040\n",
      "Epoch: 1306/2000\t Step: 15/54\t Train Loss: 3.783874\t Valid Loss: 4.654987\n",
      "Epoch: 1306/2000\t Step: 30/54\t Train Loss: 3.768054\t Valid Loss: 5.149971\n",
      "Epoch: 1306/2000\t Step: 45/54\t Train Loss: 3.754124\t Valid Loss: 4.724193\n",
      "Epoch: 1307/2000\t Step: 15/54\t Train Loss: 3.752563\t Valid Loss: 4.676986\n",
      "Epoch: 1307/2000\t Step: 30/54\t Train Loss: 3.750575\t Valid Loss: 4.873453\n",
      "Epoch: 1307/2000\t Step: 45/54\t Train Loss: 3.771457\t Valid Loss: 4.626946\n",
      "Epoch: 1308/2000\t Step: 15/54\t Train Loss: 3.808651\t Valid Loss: 4.609078\n",
      "Epoch: 1308/2000\t Step: 30/54\t Train Loss: 3.754386\t Valid Loss: 5.176762\n",
      "Epoch: 1308/2000\t Step: 45/54\t Train Loss: 3.762043\t Valid Loss: 4.565949\n",
      "Epoch: 1309/2000\t Step: 15/54\t Train Loss: 3.691803\t Valid Loss: 5.006099\n",
      "Epoch: 1309/2000\t Step: 30/54\t Train Loss: 3.800092\t Valid Loss: 4.761428\n",
      "Epoch: 1309/2000\t Step: 45/54\t Train Loss: 3.783203\t Valid Loss: 4.710460\n",
      "Epoch: 1310/2000\t Step: 15/54\t Train Loss: 3.749698\t Valid Loss: 4.918868\n",
      "Epoch: 1310/2000\t Step: 30/54\t Train Loss: 3.751469\t Valid Loss: 4.833517\n",
      "Epoch: 1310/2000\t Step: 45/54\t Train Loss: 3.773148\t Valid Loss: 4.677142\n",
      "Epoch: 1311/2000\t Step: 15/54\t Train Loss: 3.677121\t Valid Loss: 4.600497\n",
      "Epoch: 1311/2000\t Step: 30/54\t Train Loss: 3.757625\t Valid Loss: 4.884875\n",
      "Epoch: 1311/2000\t Step: 45/54\t Train Loss: 3.725909\t Valid Loss: 4.938242\n",
      "Epoch: 1312/2000\t Step: 15/54\t Train Loss: 3.777373\t Valid Loss: 4.766142\n",
      "Epoch: 1312/2000\t Step: 30/54\t Train Loss: 3.824418\t Valid Loss: 4.851754\n",
      "Epoch: 1312/2000\t Step: 45/54\t Train Loss: 3.811801\t Valid Loss: 5.125851\n",
      "Epoch: 1313/2000\t Step: 15/54\t Train Loss: 3.774763\t Valid Loss: 5.027250\n",
      "Epoch: 1313/2000\t Step: 30/54\t Train Loss: 3.723125\t Valid Loss: 5.153405\n",
      "Epoch: 1313/2000\t Step: 45/54\t Train Loss: 3.816423\t Valid Loss: 4.644901\n",
      "Epoch: 1314/2000\t Step: 15/54\t Train Loss: 3.765456\t Valid Loss: 4.853118\n",
      "Epoch: 1314/2000\t Step: 30/54\t Train Loss: 3.756072\t Valid Loss: 5.222090\n",
      "Epoch: 1314/2000\t Step: 45/54\t Train Loss: 3.769093\t Valid Loss: 4.655146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1315/2000\t Step: 15/54\t Train Loss: 3.743317\t Valid Loss: 4.641984\n",
      "Epoch: 1315/2000\t Step: 30/54\t Train Loss: 3.765364\t Valid Loss: 5.352253\n",
      "Epoch: 1315/2000\t Step: 45/54\t Train Loss: 3.821447\t Valid Loss: 4.747409\n",
      "Epoch: 1316/2000\t Step: 15/54\t Train Loss: 3.836581\t Valid Loss: 4.698129\n",
      "Epoch: 1316/2000\t Step: 30/54\t Train Loss: 3.795640\t Valid Loss: 4.612333\n",
      "Epoch: 1316/2000\t Step: 45/54\t Train Loss: 3.776116\t Valid Loss: 4.356036\n",
      "Epoch: 1317/2000\t Step: 15/54\t Train Loss: 3.727066\t Valid Loss: 4.572895\n",
      "Epoch: 1317/2000\t Step: 30/54\t Train Loss: 3.805624\t Valid Loss: 4.996091\n",
      "Epoch: 1317/2000\t Step: 45/54\t Train Loss: 3.775778\t Valid Loss: 4.831157\n",
      "Epoch: 1318/2000\t Step: 15/54\t Train Loss: 3.770202\t Valid Loss: 4.665919\n",
      "Epoch: 1318/2000\t Step: 30/54\t Train Loss: 3.836462\t Valid Loss: 4.917537\n",
      "Epoch: 1318/2000\t Step: 45/54\t Train Loss: 3.780953\t Valid Loss: 4.750868\n",
      "Epoch: 1319/2000\t Step: 15/54\t Train Loss: 3.825170\t Valid Loss: 4.692026\n",
      "Epoch: 1319/2000\t Step: 30/54\t Train Loss: 3.886242\t Valid Loss: 4.817566\n",
      "Epoch: 1319/2000\t Step: 45/54\t Train Loss: 3.692410\t Valid Loss: 5.259640\n",
      "Epoch: 1320/2000\t Step: 15/54\t Train Loss: 3.730172\t Valid Loss: 4.779467\n",
      "Epoch: 1320/2000\t Step: 30/54\t Train Loss: 3.812871\t Valid Loss: 4.816981\n",
      "Epoch: 1320/2000\t Step: 45/54\t Train Loss: 3.742114\t Valid Loss: 5.150339\n",
      "Epoch: 1321/2000\t Step: 15/54\t Train Loss: 3.734754\t Valid Loss: 4.753771\n",
      "Epoch: 1321/2000\t Step: 30/54\t Train Loss: 3.830863\t Valid Loss: 4.702496\n",
      "Epoch: 1321/2000\t Step: 45/54\t Train Loss: 3.766158\t Valid Loss: 5.044152\n",
      "Epoch: 1322/2000\t Step: 15/54\t Train Loss: 3.797277\t Valid Loss: 4.785511\n",
      "Epoch: 1322/2000\t Step: 30/54\t Train Loss: 3.764401\t Valid Loss: 4.737136\n",
      "Epoch: 1322/2000\t Step: 45/54\t Train Loss: 3.747641\t Valid Loss: 4.524358\n",
      "Epoch: 1323/2000\t Step: 15/54\t Train Loss: 3.715378\t Valid Loss: 4.714263\n",
      "Epoch: 1323/2000\t Step: 30/54\t Train Loss: 3.748750\t Valid Loss: 4.811102\n",
      "Epoch: 1323/2000\t Step: 45/54\t Train Loss: 3.772192\t Valid Loss: 5.199708\n",
      "Epoch: 1324/2000\t Step: 15/54\t Train Loss: 3.757925\t Valid Loss: 4.640535\n",
      "Epoch: 1324/2000\t Step: 30/54\t Train Loss: 3.733348\t Valid Loss: 4.635124\n",
      "Epoch: 1324/2000\t Step: 45/54\t Train Loss: 3.778960\t Valid Loss: 5.198342\n",
      "Epoch: 1325/2000\t Step: 15/54\t Train Loss: 3.853717\t Valid Loss: 4.814912\n",
      "Epoch: 1325/2000\t Step: 30/54\t Train Loss: 3.804346\t Valid Loss: 4.844015\n",
      "Epoch: 1325/2000\t Step: 45/54\t Train Loss: 3.796877\t Valid Loss: 5.058740\n",
      "Epoch: 1326/2000\t Step: 15/54\t Train Loss: 3.766153\t Valid Loss: 4.977977\n",
      "Epoch: 1326/2000\t Step: 30/54\t Train Loss: 3.768434\t Valid Loss: 5.126408\n",
      "Epoch: 1326/2000\t Step: 45/54\t Train Loss: 3.689729\t Valid Loss: 5.064486\n",
      "Epoch: 1327/2000\t Step: 15/54\t Train Loss: 3.783827\t Valid Loss: 5.174597\n",
      "Epoch: 1327/2000\t Step: 30/54\t Train Loss: 3.783150\t Valid Loss: 4.553111\n",
      "Epoch: 1327/2000\t Step: 45/54\t Train Loss: 3.701943\t Valid Loss: 4.687272\n",
      "Epoch: 1328/2000\t Step: 15/54\t Train Loss: 3.708604\t Valid Loss: 4.854345\n",
      "Epoch: 1328/2000\t Step: 30/54\t Train Loss: 3.758102\t Valid Loss: 5.082206\n",
      "Epoch: 1328/2000\t Step: 45/54\t Train Loss: 3.803741\t Valid Loss: 4.529632\n",
      "Epoch: 1329/2000\t Step: 15/54\t Train Loss: 3.764060\t Valid Loss: 5.008576\n",
      "Epoch: 1329/2000\t Step: 30/54\t Train Loss: 3.817524\t Valid Loss: 5.073849\n",
      "Epoch: 1329/2000\t Step: 45/54\t Train Loss: 3.711393\t Valid Loss: 4.895235\n",
      "Epoch: 1330/2000\t Step: 15/54\t Train Loss: 3.714239\t Valid Loss: 5.291133\n",
      "Epoch: 1330/2000\t Step: 30/54\t Train Loss: 3.786509\t Valid Loss: 4.520540\n",
      "Epoch: 1330/2000\t Step: 45/54\t Train Loss: 3.797945\t Valid Loss: 4.620104\n",
      "Epoch: 1331/2000\t Step: 15/54\t Train Loss: 3.777823\t Valid Loss: 4.579739\n",
      "Epoch: 1331/2000\t Step: 30/54\t Train Loss: 3.771777\t Valid Loss: 4.642324\n",
      "Epoch: 1331/2000\t Step: 45/54\t Train Loss: 3.826933\t Valid Loss: 4.750641\n",
      "Epoch: 1332/2000\t Step: 15/54\t Train Loss: 3.786681\t Valid Loss: 4.767780\n",
      "Epoch: 1332/2000\t Step: 30/54\t Train Loss: 3.813227\t Valid Loss: 4.592100\n",
      "Epoch: 1332/2000\t Step: 45/54\t Train Loss: 3.761750\t Valid Loss: 4.827971\n",
      "Epoch: 1333/2000\t Step: 15/54\t Train Loss: 3.759974\t Valid Loss: 4.932264\n",
      "Epoch: 1333/2000\t Step: 30/54\t Train Loss: 3.864386\t Valid Loss: 5.257696\n",
      "Epoch: 1333/2000\t Step: 45/54\t Train Loss: 3.797199\t Valid Loss: 5.084023\n",
      "Epoch: 1334/2000\t Step: 15/54\t Train Loss: 3.783514\t Valid Loss: 4.608346\n",
      "Epoch: 1334/2000\t Step: 30/54\t Train Loss: 3.750343\t Valid Loss: 4.818094\n",
      "Epoch: 1334/2000\t Step: 45/54\t Train Loss: 3.776183\t Valid Loss: 5.094418\n",
      "Epoch: 1335/2000\t Step: 15/54\t Train Loss: 3.778937\t Valid Loss: 4.804829\n",
      "Epoch: 1335/2000\t Step: 30/54\t Train Loss: 3.725784\t Valid Loss: 4.907600\n",
      "Epoch: 1335/2000\t Step: 45/54\t Train Loss: 3.782282\t Valid Loss: 4.891920\n",
      "Epoch: 1336/2000\t Step: 15/54\t Train Loss: 3.795219\t Valid Loss: 4.892249\n",
      "Epoch: 1336/2000\t Step: 30/54\t Train Loss: 3.742579\t Valid Loss: 4.475308\n",
      "Epoch: 1336/2000\t Step: 45/54\t Train Loss: 3.705256\t Valid Loss: 4.883424\n",
      "Epoch: 1337/2000\t Step: 15/54\t Train Loss: 3.763069\t Valid Loss: 4.781001\n",
      "Epoch: 1337/2000\t Step: 30/54\t Train Loss: 3.777617\t Valid Loss: 5.122678\n",
      "Epoch: 1337/2000\t Step: 45/54\t Train Loss: 3.760915\t Valid Loss: 4.962797\n",
      "Epoch: 1338/2000\t Step: 15/54\t Train Loss: 3.748590\t Valid Loss: 4.858996\n",
      "Epoch: 1338/2000\t Step: 30/54\t Train Loss: 3.721224\t Valid Loss: 4.980236\n",
      "Epoch: 1338/2000\t Step: 45/54\t Train Loss: 3.744910\t Valid Loss: 4.774360\n",
      "Epoch: 1339/2000\t Step: 15/54\t Train Loss: 3.862026\t Valid Loss: 4.956307\n",
      "Epoch: 1339/2000\t Step: 30/54\t Train Loss: 3.806240\t Valid Loss: 4.832783\n",
      "Epoch: 1339/2000\t Step: 45/54\t Train Loss: 3.739202\t Valid Loss: 4.683949\n",
      "Epoch: 1340/2000\t Step: 15/54\t Train Loss: 3.805705\t Valid Loss: 4.467916\n",
      "Epoch: 1340/2000\t Step: 30/54\t Train Loss: 3.837912\t Valid Loss: 4.742131\n",
      "Epoch: 1340/2000\t Step: 45/54\t Train Loss: 3.767748\t Valid Loss: 4.906422\n",
      "Epoch: 1341/2000\t Step: 15/54\t Train Loss: 3.692189\t Valid Loss: 5.065981\n",
      "Epoch: 1341/2000\t Step: 30/54\t Train Loss: 3.725876\t Valid Loss: 4.828104\n",
      "Epoch: 1341/2000\t Step: 45/54\t Train Loss: 3.746836\t Valid Loss: 4.809620\n",
      "Epoch: 1342/2000\t Step: 15/54\t Train Loss: 3.756599\t Valid Loss: 4.757700\n",
      "Epoch: 1342/2000\t Step: 30/54\t Train Loss: 3.780512\t Valid Loss: 5.328198\n",
      "Epoch: 1342/2000\t Step: 45/54\t Train Loss: 3.772532\t Valid Loss: 4.594126\n",
      "Epoch: 1343/2000\t Step: 15/54\t Train Loss: 3.717583\t Valid Loss: 4.968644\n",
      "Epoch: 1343/2000\t Step: 30/54\t Train Loss: 3.714005\t Valid Loss: 4.867437\n",
      "Epoch: 1343/2000\t Step: 45/54\t Train Loss: 3.728003\t Valid Loss: 5.356123\n",
      "Epoch: 1344/2000\t Step: 15/54\t Train Loss: 3.743383\t Valid Loss: 4.841275\n",
      "Epoch: 1344/2000\t Step: 30/54\t Train Loss: 3.739940\t Valid Loss: 5.042637\n",
      "Epoch: 1344/2000\t Step: 45/54\t Train Loss: 3.791080\t Valid Loss: 5.266629\n",
      "Epoch: 1345/2000\t Step: 15/54\t Train Loss: 3.745759\t Valid Loss: 4.906727\n",
      "Epoch: 1345/2000\t Step: 30/54\t Train Loss: 3.789877\t Valid Loss: 4.599053\n",
      "Epoch: 1345/2000\t Step: 45/54\t Train Loss: 3.789196\t Valid Loss: 5.153889\n",
      "Epoch: 1346/2000\t Step: 15/54\t Train Loss: 3.737160\t Valid Loss: 4.985106\n",
      "Epoch: 1346/2000\t Step: 30/54\t Train Loss: 3.761288\t Valid Loss: 4.834212\n",
      "Epoch: 1346/2000\t Step: 45/54\t Train Loss: 3.845056\t Valid Loss: 4.707201\n",
      "Epoch: 1347/2000\t Step: 15/54\t Train Loss: 3.781775\t Valid Loss: 4.808672\n",
      "Epoch: 1347/2000\t Step: 30/54\t Train Loss: 3.751728\t Valid Loss: 4.841448\n",
      "Epoch: 1347/2000\t Step: 45/54\t Train Loss: 3.732659\t Valid Loss: 5.031345\n",
      "Epoch: 1348/2000\t Step: 15/54\t Train Loss: 3.749948\t Valid Loss: 4.634455\n",
      "Epoch: 1348/2000\t Step: 30/54\t Train Loss: 3.765431\t Valid Loss: 5.000729\n",
      "Epoch: 1348/2000\t Step: 45/54\t Train Loss: 3.749979\t Valid Loss: 4.653621\n",
      "Epoch: 1349/2000\t Step: 15/54\t Train Loss: 3.808362\t Valid Loss: 4.762426\n",
      "Epoch: 1349/2000\t Step: 30/54\t Train Loss: 3.792960\t Valid Loss: 4.706636\n",
      "Epoch: 1349/2000\t Step: 45/54\t Train Loss: 3.798210\t Valid Loss: 4.669621\n",
      "Epoch: 1350/2000\t Step: 15/54\t Train Loss: 3.774988\t Valid Loss: 4.461909\n",
      "Epoch: 1350/2000\t Step: 30/54\t Train Loss: 3.790489\t Valid Loss: 4.855643\n",
      "Epoch: 1350/2000\t Step: 45/54\t Train Loss: 3.825624\t Valid Loss: 4.629905\n",
      "Epoch: 1351/2000\t Step: 15/54\t Train Loss: 3.686445\t Valid Loss: 5.192661\n",
      "Epoch: 1351/2000\t Step: 30/54\t Train Loss: 3.807833\t Valid Loss: 4.762228\n",
      "Epoch: 1351/2000\t Step: 45/54\t Train Loss: 3.724870\t Valid Loss: 4.905076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1352/2000\t Step: 15/54\t Train Loss: 3.729233\t Valid Loss: 4.827077\n",
      "Epoch: 1352/2000\t Step: 30/54\t Train Loss: 3.779199\t Valid Loss: 4.915806\n",
      "Epoch: 1352/2000\t Step: 45/54\t Train Loss: 3.802186\t Valid Loss: 4.964296\n",
      "Epoch: 1353/2000\t Step: 15/54\t Train Loss: 3.766943\t Valid Loss: 4.791901\n",
      "Epoch: 1353/2000\t Step: 30/54\t Train Loss: 3.826023\t Valid Loss: 4.431480\n",
      "Epoch: 1353/2000\t Step: 45/54\t Train Loss: 3.766661\t Valid Loss: 4.699062\n",
      "Epoch: 1354/2000\t Step: 15/54\t Train Loss: 3.773001\t Valid Loss: 4.687217\n",
      "Epoch: 1354/2000\t Step: 30/54\t Train Loss: 3.851067\t Valid Loss: 5.172411\n",
      "Epoch: 1354/2000\t Step: 45/54\t Train Loss: 3.734204\t Valid Loss: 4.941445\n",
      "Epoch: 1355/2000\t Step: 15/54\t Train Loss: 3.739518\t Valid Loss: 4.759696\n",
      "Epoch: 1355/2000\t Step: 30/54\t Train Loss: 3.759745\t Valid Loss: 4.816838\n",
      "Epoch: 1355/2000\t Step: 45/54\t Train Loss: 3.768417\t Valid Loss: 5.015797\n",
      "Epoch: 1356/2000\t Step: 15/54\t Train Loss: 3.760121\t Valid Loss: 4.931565\n",
      "Epoch: 1356/2000\t Step: 30/54\t Train Loss: 3.746556\t Valid Loss: 5.022866\n",
      "Epoch: 1356/2000\t Step: 45/54\t Train Loss: 3.789461\t Valid Loss: 4.998769\n",
      "Epoch: 1357/2000\t Step: 15/54\t Train Loss: 3.741223\t Valid Loss: 4.599798\n",
      "Epoch: 1357/2000\t Step: 30/54\t Train Loss: 3.821768\t Valid Loss: 4.738861\n",
      "Epoch: 1357/2000\t Step: 45/54\t Train Loss: 3.753440\t Valid Loss: 5.016591\n",
      "Epoch: 1358/2000\t Step: 15/54\t Train Loss: 3.782078\t Valid Loss: 5.014952\n",
      "Epoch: 1358/2000\t Step: 30/54\t Train Loss: 3.714936\t Valid Loss: 4.667298\n",
      "Epoch: 1358/2000\t Step: 45/54\t Train Loss: 3.765330\t Valid Loss: 4.837266\n",
      "Epoch: 1359/2000\t Step: 15/54\t Train Loss: 3.780394\t Valid Loss: 4.976065\n",
      "Epoch: 1359/2000\t Step: 30/54\t Train Loss: 3.799130\t Valid Loss: 4.829394\n",
      "Epoch: 1359/2000\t Step: 45/54\t Train Loss: 3.729478\t Valid Loss: 4.615093\n",
      "Epoch: 1360/2000\t Step: 15/54\t Train Loss: 3.853150\t Valid Loss: 5.221639\n",
      "Epoch: 1360/2000\t Step: 30/54\t Train Loss: 3.737449\t Valid Loss: 5.373764\n",
      "Epoch: 1360/2000\t Step: 45/54\t Train Loss: 3.839431\t Valid Loss: 4.821416\n",
      "Epoch: 1361/2000\t Step: 15/54\t Train Loss: 3.812933\t Valid Loss: 4.709942\n",
      "Epoch: 1361/2000\t Step: 30/54\t Train Loss: 3.749132\t Valid Loss: 4.697814\n",
      "Epoch: 1361/2000\t Step: 45/54\t Train Loss: 3.762242\t Valid Loss: 4.554407\n",
      "Epoch: 1362/2000\t Step: 15/54\t Train Loss: 3.714571\t Valid Loss: 4.974640\n",
      "Epoch: 1362/2000\t Step: 30/54\t Train Loss: 3.852178\t Valid Loss: 4.575684\n",
      "Epoch: 1362/2000\t Step: 45/54\t Train Loss: 3.727189\t Valid Loss: 5.149687\n",
      "Epoch: 1363/2000\t Step: 15/54\t Train Loss: 3.818937\t Valid Loss: 5.070206\n",
      "Epoch: 1363/2000\t Step: 30/54\t Train Loss: 3.715883\t Valid Loss: 4.816444\n",
      "Epoch: 1363/2000\t Step: 45/54\t Train Loss: 3.770213\t Valid Loss: 4.993807\n",
      "Epoch: 1364/2000\t Step: 15/54\t Train Loss: 3.753671\t Valid Loss: 4.824622\n",
      "Epoch: 1364/2000\t Step: 30/54\t Train Loss: 3.759587\t Valid Loss: 4.933232\n",
      "Epoch: 1364/2000\t Step: 45/54\t Train Loss: 3.705379\t Valid Loss: 4.672335\n",
      "Epoch: 1365/2000\t Step: 15/54\t Train Loss: 3.750398\t Valid Loss: 4.588943\n",
      "Epoch: 1365/2000\t Step: 30/54\t Train Loss: 3.722316\t Valid Loss: 4.998087\n",
      "Epoch: 1365/2000\t Step: 45/54\t Train Loss: 3.741658\t Valid Loss: 5.191763\n",
      "Epoch: 1366/2000\t Step: 15/54\t Train Loss: 3.822348\t Valid Loss: 4.811915\n",
      "Epoch: 1366/2000\t Step: 30/54\t Train Loss: 3.800788\t Valid Loss: 5.170559\n",
      "Epoch: 1366/2000\t Step: 45/54\t Train Loss: 3.795558\t Valid Loss: 4.614466\n",
      "Epoch: 1367/2000\t Step: 15/54\t Train Loss: 3.805744\t Valid Loss: 4.456431\n",
      "Epoch: 1367/2000\t Step: 30/54\t Train Loss: 3.803681\t Valid Loss: 4.503469\n",
      "Epoch: 1367/2000\t Step: 45/54\t Train Loss: 3.753768\t Valid Loss: 4.640094\n",
      "Epoch: 1368/2000\t Step: 15/54\t Train Loss: 3.735848\t Valid Loss: 4.816000\n",
      "Epoch: 1368/2000\t Step: 30/54\t Train Loss: 3.677867\t Valid Loss: 5.066468\n",
      "Epoch: 1368/2000\t Step: 45/54\t Train Loss: 3.775458\t Valid Loss: 5.228766\n",
      "Epoch: 1369/2000\t Step: 15/54\t Train Loss: 3.728612\t Valid Loss: 4.628133\n",
      "Epoch: 1369/2000\t Step: 30/54\t Train Loss: 3.741336\t Valid Loss: 4.682021\n",
      "Epoch: 1369/2000\t Step: 45/54\t Train Loss: 3.775219\t Valid Loss: 4.588700\n",
      "Epoch: 1370/2000\t Step: 15/54\t Train Loss: 3.751683\t Valid Loss: 4.591249\n",
      "Epoch: 1370/2000\t Step: 30/54\t Train Loss: 3.741767\t Valid Loss: 4.992615\n",
      "Epoch: 1370/2000\t Step: 45/54\t Train Loss: 3.746340\t Valid Loss: 5.154467\n",
      "Epoch: 1371/2000\t Step: 15/54\t Train Loss: 3.698787\t Valid Loss: 4.883759\n",
      "Epoch: 1371/2000\t Step: 30/54\t Train Loss: 3.783421\t Valid Loss: 5.055885\n",
      "Epoch: 1371/2000\t Step: 45/54\t Train Loss: 3.821936\t Valid Loss: 4.990798\n",
      "Epoch: 1372/2000\t Step: 15/54\t Train Loss: 3.853539\t Valid Loss: 4.883425\n",
      "Epoch: 1372/2000\t Step: 30/54\t Train Loss: 3.794798\t Valid Loss: 5.143898\n",
      "Epoch: 1372/2000\t Step: 45/54\t Train Loss: 3.779592\t Valid Loss: 4.809475\n",
      "Epoch: 1373/2000\t Step: 15/54\t Train Loss: 3.839847\t Valid Loss: 4.566238\n",
      "Epoch: 1373/2000\t Step: 30/54\t Train Loss: 3.754112\t Valid Loss: 5.150596\n",
      "Epoch: 1373/2000\t Step: 45/54\t Train Loss: 3.808828\t Valid Loss: 4.539073\n",
      "Epoch: 1374/2000\t Step: 15/54\t Train Loss: 3.753677\t Valid Loss: 4.884177\n",
      "Epoch: 1374/2000\t Step: 30/54\t Train Loss: 3.667536\t Valid Loss: 5.114801\n",
      "Epoch: 1374/2000\t Step: 45/54\t Train Loss: 3.750710\t Valid Loss: 5.263021\n",
      "Epoch: 1375/2000\t Step: 15/54\t Train Loss: 3.784502\t Valid Loss: 4.758018\n",
      "Epoch: 1375/2000\t Step: 30/54\t Train Loss: 3.776551\t Valid Loss: 4.774374\n",
      "Epoch: 1375/2000\t Step: 45/54\t Train Loss: 3.783422\t Valid Loss: 4.803503\n",
      "Epoch: 1376/2000\t Step: 15/54\t Train Loss: 3.798916\t Valid Loss: 4.554286\n",
      "Epoch: 1376/2000\t Step: 30/54\t Train Loss: 3.841785\t Valid Loss: 4.599483\n",
      "Epoch: 1376/2000\t Step: 45/54\t Train Loss: 3.800764\t Valid Loss: 4.604848\n",
      "Epoch: 1377/2000\t Step: 15/54\t Train Loss: 3.800026\t Valid Loss: 4.697543\n",
      "Epoch: 1377/2000\t Step: 30/54\t Train Loss: 3.764710\t Valid Loss: 4.765185\n",
      "Epoch: 1377/2000\t Step: 45/54\t Train Loss: 3.740032\t Valid Loss: 4.813229\n",
      "Epoch: 1378/2000\t Step: 15/54\t Train Loss: 3.835698\t Valid Loss: 4.582595\n",
      "Epoch: 1378/2000\t Step: 30/54\t Train Loss: 3.774459\t Valid Loss: 4.822227\n",
      "Epoch: 1378/2000\t Step: 45/54\t Train Loss: 3.780497\t Valid Loss: 4.631378\n",
      "Epoch: 1379/2000\t Step: 15/54\t Train Loss: 3.785853\t Valid Loss: 4.757900\n",
      "Epoch: 1379/2000\t Step: 30/54\t Train Loss: 3.761735\t Valid Loss: 4.624826\n",
      "Epoch: 1379/2000\t Step: 45/54\t Train Loss: 3.766397\t Valid Loss: 5.112630\n",
      "Epoch: 1380/2000\t Step: 15/54\t Train Loss: 3.814959\t Valid Loss: 4.620061\n",
      "Epoch: 1380/2000\t Step: 30/54\t Train Loss: 3.694379\t Valid Loss: 4.958666\n",
      "Epoch: 1380/2000\t Step: 45/54\t Train Loss: 3.764602\t Valid Loss: 4.732250\n",
      "Epoch: 1381/2000\t Step: 15/54\t Train Loss: 3.821800\t Valid Loss: 4.831414\n",
      "Epoch: 1381/2000\t Step: 30/54\t Train Loss: 3.727196\t Valid Loss: 4.820583\n",
      "Epoch: 1381/2000\t Step: 45/54\t Train Loss: 3.821258\t Valid Loss: 4.710285\n",
      "Epoch: 1382/2000\t Step: 15/54\t Train Loss: 3.752041\t Valid Loss: 4.853911\n",
      "Epoch: 1382/2000\t Step: 30/54\t Train Loss: 3.763299\t Valid Loss: 4.887817\n",
      "Epoch: 1382/2000\t Step: 45/54\t Train Loss: 3.836027\t Valid Loss: 4.946201\n",
      "Epoch: 1383/2000\t Step: 15/54\t Train Loss: 3.768726\t Valid Loss: 4.664743\n",
      "Epoch: 1383/2000\t Step: 30/54\t Train Loss: 3.859125\t Valid Loss: 5.276706\n",
      "Epoch: 1383/2000\t Step: 45/54\t Train Loss: 3.755783\t Valid Loss: 4.728059\n",
      "Epoch: 1384/2000\t Step: 15/54\t Train Loss: 3.835137\t Valid Loss: 5.146979\n",
      "Epoch: 1384/2000\t Step: 30/54\t Train Loss: 3.841897\t Valid Loss: 4.646715\n",
      "Epoch: 1384/2000\t Step: 45/54\t Train Loss: 3.785440\t Valid Loss: 4.592306\n",
      "Epoch: 1385/2000\t Step: 15/54\t Train Loss: 3.823289\t Valid Loss: 5.147669\n",
      "Epoch: 1385/2000\t Step: 30/54\t Train Loss: 3.756224\t Valid Loss: 5.399188\n",
      "Epoch: 1385/2000\t Step: 45/54\t Train Loss: 3.798719\t Valid Loss: 4.744770\n",
      "Epoch: 1386/2000\t Step: 15/54\t Train Loss: 3.718605\t Valid Loss: 4.559942\n",
      "Epoch: 1386/2000\t Step: 30/54\t Train Loss: 3.684361\t Valid Loss: 5.270402\n",
      "Epoch: 1386/2000\t Step: 45/54\t Train Loss: 3.869855\t Valid Loss: 4.740635\n",
      "Epoch: 1387/2000\t Step: 15/54\t Train Loss: 3.761847\t Valid Loss: 4.911597\n",
      "Epoch: 1387/2000\t Step: 30/54\t Train Loss: 3.767825\t Valid Loss: 5.493746\n",
      "Epoch: 1387/2000\t Step: 45/54\t Train Loss: 3.714543\t Valid Loss: 5.363281\n",
      "Epoch: 1388/2000\t Step: 15/54\t Train Loss: 3.789457\t Valid Loss: 5.014582\n",
      "Epoch: 1388/2000\t Step: 30/54\t Train Loss: 3.793067\t Valid Loss: 4.733272\n",
      "Epoch: 1388/2000\t Step: 45/54\t Train Loss: 3.786037\t Valid Loss: 4.696735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1389/2000\t Step: 15/54\t Train Loss: 3.732203\t Valid Loss: 5.316853\n",
      "Epoch: 1389/2000\t Step: 30/54\t Train Loss: 3.709067\t Valid Loss: 4.838864\n",
      "Epoch: 1389/2000\t Step: 45/54\t Train Loss: 3.743225\t Valid Loss: 5.297808\n",
      "Epoch: 1390/2000\t Step: 15/54\t Train Loss: 3.784468\t Valid Loss: 5.133230\n",
      "Epoch: 1390/2000\t Step: 30/54\t Train Loss: 3.816789\t Valid Loss: 5.217698\n",
      "Epoch: 1390/2000\t Step: 45/54\t Train Loss: 3.754322\t Valid Loss: 4.832335\n",
      "Epoch: 1391/2000\t Step: 15/54\t Train Loss: 3.838665\t Valid Loss: 4.831997\n",
      "Epoch: 1391/2000\t Step: 30/54\t Train Loss: 3.729340\t Valid Loss: 5.125563\n",
      "Epoch: 1391/2000\t Step: 45/54\t Train Loss: 3.755541\t Valid Loss: 5.080629\n",
      "Epoch: 1392/2000\t Step: 15/54\t Train Loss: 3.709274\t Valid Loss: 5.294377\n",
      "Epoch: 1392/2000\t Step: 30/54\t Train Loss: 3.779005\t Valid Loss: 4.728631\n",
      "Epoch: 1392/2000\t Step: 45/54\t Train Loss: 3.752223\t Valid Loss: 4.890080\n",
      "Epoch: 1393/2000\t Step: 15/54\t Train Loss: 3.753408\t Valid Loss: 4.518287\n",
      "Epoch: 1393/2000\t Step: 30/54\t Train Loss: 3.732887\t Valid Loss: 4.543393\n",
      "Epoch: 1393/2000\t Step: 45/54\t Train Loss: 3.740478\t Valid Loss: 4.996412\n",
      "Epoch: 1394/2000\t Step: 15/54\t Train Loss: 3.748294\t Valid Loss: 5.141392\n",
      "Epoch: 1394/2000\t Step: 30/54\t Train Loss: 3.716990\t Valid Loss: 5.139182\n",
      "Epoch: 1394/2000\t Step: 45/54\t Train Loss: 3.733925\t Valid Loss: 4.893033\n",
      "Epoch: 1395/2000\t Step: 15/54\t Train Loss: 3.796735\t Valid Loss: 4.852950\n",
      "Epoch: 1395/2000\t Step: 30/54\t Train Loss: 3.749954\t Valid Loss: 5.295146\n",
      "Epoch: 1395/2000\t Step: 45/54\t Train Loss: 3.754343\t Valid Loss: 4.602122\n",
      "Epoch: 1396/2000\t Step: 15/54\t Train Loss: 3.744712\t Valid Loss: 5.247397\n",
      "Epoch: 1396/2000\t Step: 30/54\t Train Loss: 3.801188\t Valid Loss: 4.810237\n",
      "Epoch: 1396/2000\t Step: 45/54\t Train Loss: 3.755133\t Valid Loss: 5.284314\n",
      "Epoch: 1397/2000\t Step: 15/54\t Train Loss: 3.830013\t Valid Loss: 4.519583\n",
      "Epoch: 1397/2000\t Step: 30/54\t Train Loss: 3.786201\t Valid Loss: 4.788785\n",
      "Epoch: 1397/2000\t Step: 45/54\t Train Loss: 3.771468\t Valid Loss: 5.170673\n",
      "Epoch: 1398/2000\t Step: 15/54\t Train Loss: 3.793919\t Valid Loss: 5.209912\n",
      "Epoch: 1398/2000\t Step: 30/54\t Train Loss: 3.693961\t Valid Loss: 4.961160\n",
      "Epoch: 1398/2000\t Step: 45/54\t Train Loss: 3.678640\t Valid Loss: 4.998889\n",
      "Epoch: 1399/2000\t Step: 15/54\t Train Loss: 3.892155\t Valid Loss: 4.696921\n",
      "Epoch: 1399/2000\t Step: 30/54\t Train Loss: 3.783544\t Valid Loss: 5.129837\n",
      "Epoch: 1399/2000\t Step: 45/54\t Train Loss: 3.806129\t Valid Loss: 4.831886\n",
      "Epoch: 1400/2000\t Step: 15/54\t Train Loss: 3.761237\t Valid Loss: 4.976474\n",
      "Epoch: 1400/2000\t Step: 30/54\t Train Loss: 3.675995\t Valid Loss: 4.898718\n",
      "Epoch: 1400/2000\t Step: 45/54\t Train Loss: 3.750792\t Valid Loss: 4.576512\n",
      "Epoch: 1401/2000\t Step: 15/54\t Train Loss: 3.786778\t Valid Loss: 4.904513\n",
      "Epoch: 1401/2000\t Step: 30/54\t Train Loss: 3.761312\t Valid Loss: 5.133018\n",
      "Epoch: 1401/2000\t Step: 45/54\t Train Loss: 3.781350\t Valid Loss: 4.619779\n",
      "Epoch: 1402/2000\t Step: 15/54\t Train Loss: 3.722790\t Valid Loss: 4.962441\n",
      "Epoch: 1402/2000\t Step: 30/54\t Train Loss: 3.810391\t Valid Loss: 4.893269\n",
      "Epoch: 1402/2000\t Step: 45/54\t Train Loss: 3.786624\t Valid Loss: 4.598158\n",
      "Epoch: 1403/2000\t Step: 15/54\t Train Loss: 3.743192\t Valid Loss: 5.129482\n",
      "Epoch: 1403/2000\t Step: 30/54\t Train Loss: 3.752329\t Valid Loss: 5.077583\n",
      "Epoch: 1403/2000\t Step: 45/54\t Train Loss: 3.783746\t Valid Loss: 5.288097\n",
      "Epoch: 1404/2000\t Step: 15/54\t Train Loss: 3.779829\t Valid Loss: 4.922250\n",
      "Epoch: 1404/2000\t Step: 30/54\t Train Loss: 3.783002\t Valid Loss: 4.729012\n",
      "Epoch: 1404/2000\t Step: 45/54\t Train Loss: 3.844170\t Valid Loss: 4.632898\n",
      "Epoch: 1405/2000\t Step: 15/54\t Train Loss: 3.748607\t Valid Loss: 4.928349\n",
      "Epoch: 1405/2000\t Step: 30/54\t Train Loss: 3.778724\t Valid Loss: 4.579351\n",
      "Epoch: 1405/2000\t Step: 45/54\t Train Loss: 3.706880\t Valid Loss: 4.657210\n",
      "Epoch: 1406/2000\t Step: 15/54\t Train Loss: 3.811275\t Valid Loss: 4.693785\n",
      "Epoch: 1406/2000\t Step: 30/54\t Train Loss: 3.819921\t Valid Loss: 4.503165\n",
      "Epoch: 1406/2000\t Step: 45/54\t Train Loss: 3.740147\t Valid Loss: 5.068881\n",
      "Epoch: 1407/2000\t Step: 15/54\t Train Loss: 3.762101\t Valid Loss: 4.694823\n",
      "Epoch: 1407/2000\t Step: 30/54\t Train Loss: 3.765120\t Valid Loss: 4.767845\n",
      "Epoch: 1407/2000\t Step: 45/54\t Train Loss: 3.792029\t Valid Loss: 4.755835\n",
      "Epoch: 1408/2000\t Step: 15/54\t Train Loss: 3.730403\t Valid Loss: 4.818233\n",
      "Epoch: 1408/2000\t Step: 30/54\t Train Loss: 3.796814\t Valid Loss: 4.808362\n",
      "Epoch: 1408/2000\t Step: 45/54\t Train Loss: 3.748741\t Valid Loss: 4.837169\n",
      "Epoch: 1409/2000\t Step: 15/54\t Train Loss: 3.748146\t Valid Loss: 4.685213\n",
      "Epoch: 1409/2000\t Step: 30/54\t Train Loss: 3.740986\t Valid Loss: 5.068699\n",
      "Epoch: 1409/2000\t Step: 45/54\t Train Loss: 3.743725\t Valid Loss: 4.843711\n",
      "Epoch: 1410/2000\t Step: 15/54\t Train Loss: 3.792965\t Valid Loss: 4.912289\n",
      "Epoch: 1410/2000\t Step: 30/54\t Train Loss: 3.743864\t Valid Loss: 4.967345\n",
      "Epoch: 1410/2000\t Step: 45/54\t Train Loss: 3.716549\t Valid Loss: 5.099443\n",
      "Epoch: 1411/2000\t Step: 15/54\t Train Loss: 3.680797\t Valid Loss: 5.278429\n",
      "Epoch: 1411/2000\t Step: 30/54\t Train Loss: 3.733578\t Valid Loss: 4.872775\n",
      "Epoch: 1411/2000\t Step: 45/54\t Train Loss: 3.746852\t Valid Loss: 5.131932\n",
      "Epoch: 1412/2000\t Step: 15/54\t Train Loss: 3.694313\t Valid Loss: 5.220033\n",
      "Epoch: 1412/2000\t Step: 30/54\t Train Loss: 3.755296\t Valid Loss: 4.773935\n",
      "Epoch: 1412/2000\t Step: 45/54\t Train Loss: 3.741201\t Valid Loss: 4.982434\n",
      "Epoch: 1413/2000\t Step: 15/54\t Train Loss: 3.742301\t Valid Loss: 5.199249\n",
      "Epoch: 1413/2000\t Step: 30/54\t Train Loss: 3.735581\t Valid Loss: 5.142240\n",
      "Epoch: 1413/2000\t Step: 45/54\t Train Loss: 3.776990\t Valid Loss: 4.864513\n",
      "Epoch: 1414/2000\t Step: 15/54\t Train Loss: 3.712927\t Valid Loss: 5.301372\n",
      "Epoch: 1414/2000\t Step: 30/54\t Train Loss: 3.764160\t Valid Loss: 5.060445\n",
      "Epoch: 1414/2000\t Step: 45/54\t Train Loss: 3.733612\t Valid Loss: 4.856260\n",
      "Epoch: 1415/2000\t Step: 15/54\t Train Loss: 3.820269\t Valid Loss: 4.974357\n",
      "Epoch: 1415/2000\t Step: 30/54\t Train Loss: 3.753966\t Valid Loss: 4.752563\n",
      "Epoch: 1415/2000\t Step: 45/54\t Train Loss: 3.806792\t Valid Loss: 4.791966\n",
      "Epoch: 1416/2000\t Step: 15/54\t Train Loss: 3.803036\t Valid Loss: 5.242122\n",
      "Epoch: 1416/2000\t Step: 30/54\t Train Loss: 3.750408\t Valid Loss: 4.805349\n",
      "Epoch: 1416/2000\t Step: 45/54\t Train Loss: 3.773532\t Valid Loss: 4.854724\n",
      "Epoch: 1417/2000\t Step: 15/54\t Train Loss: 3.790759\t Valid Loss: 5.032385\n",
      "Epoch: 1417/2000\t Step: 30/54\t Train Loss: 3.756744\t Valid Loss: 5.164560\n",
      "Epoch: 1417/2000\t Step: 45/54\t Train Loss: 3.732535\t Valid Loss: 5.397301\n",
      "Epoch: 1418/2000\t Step: 15/54\t Train Loss: 3.767933\t Valid Loss: 4.910042\n",
      "Epoch: 1418/2000\t Step: 30/54\t Train Loss: 3.736627\t Valid Loss: 4.898719\n",
      "Epoch: 1418/2000\t Step: 45/54\t Train Loss: 3.761836\t Valid Loss: 4.613865\n",
      "Epoch: 1419/2000\t Step: 15/54\t Train Loss: 3.747076\t Valid Loss: 4.657944\n",
      "Epoch: 1419/2000\t Step: 30/54\t Train Loss: 3.832570\t Valid Loss: 4.569146\n",
      "Epoch: 1419/2000\t Step: 45/54\t Train Loss: 3.795636\t Valid Loss: 4.795759\n",
      "Epoch: 1420/2000\t Step: 15/54\t Train Loss: 3.801055\t Valid Loss: 4.982194\n",
      "Epoch: 1420/2000\t Step: 30/54\t Train Loss: 3.779948\t Valid Loss: 4.968814\n",
      "Epoch: 1420/2000\t Step: 45/54\t Train Loss: 3.793414\t Valid Loss: 4.718741\n",
      "Epoch: 1421/2000\t Step: 15/54\t Train Loss: 3.767218\t Valid Loss: 5.036961\n",
      "Epoch: 1421/2000\t Step: 30/54\t Train Loss: 3.788410\t Valid Loss: 4.676621\n",
      "Epoch: 1421/2000\t Step: 45/54\t Train Loss: 3.782031\t Valid Loss: 4.737337\n",
      "Epoch: 1422/2000\t Step: 15/54\t Train Loss: 3.807974\t Valid Loss: 4.927130\n",
      "Epoch: 1422/2000\t Step: 30/54\t Train Loss: 3.752543\t Valid Loss: 4.512017\n",
      "Epoch: 1422/2000\t Step: 45/54\t Train Loss: 3.772153\t Valid Loss: 5.027367\n",
      "Epoch: 1423/2000\t Step: 15/54\t Train Loss: 3.752546\t Valid Loss: 4.877726\n",
      "Epoch: 1423/2000\t Step: 30/54\t Train Loss: 3.788545\t Valid Loss: 4.770970\n",
      "Epoch: 1423/2000\t Step: 45/54\t Train Loss: 3.719911\t Valid Loss: 5.051458\n",
      "Epoch: 1424/2000\t Step: 15/54\t Train Loss: 3.712189\t Valid Loss: 5.048134\n",
      "Epoch: 1424/2000\t Step: 30/54\t Train Loss: 3.822700\t Valid Loss: 5.141012\n",
      "Epoch: 1424/2000\t Step: 45/54\t Train Loss: 3.815584\t Valid Loss: 4.992978\n",
      "Epoch: 1425/2000\t Step: 15/54\t Train Loss: 3.729874\t Valid Loss: 4.814495\n",
      "Epoch: 1425/2000\t Step: 30/54\t Train Loss: 3.813728\t Valid Loss: 4.831979\n",
      "Epoch: 1425/2000\t Step: 45/54\t Train Loss: 3.752461\t Valid Loss: 4.633877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1426/2000\t Step: 15/54\t Train Loss: 3.765851\t Valid Loss: 4.688041\n",
      "Epoch: 1426/2000\t Step: 30/54\t Train Loss: 3.723419\t Valid Loss: 5.011374\n",
      "Epoch: 1426/2000\t Step: 45/54\t Train Loss: 3.782665\t Valid Loss: 4.772973\n",
      "Epoch: 1427/2000\t Step: 15/54\t Train Loss: 3.790496\t Valid Loss: 4.918908\n",
      "Epoch: 1427/2000\t Step: 30/54\t Train Loss: 3.823767\t Valid Loss: 5.031111\n",
      "Epoch: 1427/2000\t Step: 45/54\t Train Loss: 3.789018\t Valid Loss: 4.762295\n",
      "Epoch: 1428/2000\t Step: 15/54\t Train Loss: 3.821916\t Valid Loss: 5.012780\n",
      "Epoch: 1428/2000\t Step: 30/54\t Train Loss: 3.779190\t Valid Loss: 5.075312\n",
      "Epoch: 1428/2000\t Step: 45/54\t Train Loss: 3.702262\t Valid Loss: 5.222969\n",
      "Epoch: 1429/2000\t Step: 15/54\t Train Loss: 3.801328\t Valid Loss: 5.478382\n",
      "Epoch: 1429/2000\t Step: 30/54\t Train Loss: 3.744138\t Valid Loss: 5.122277\n",
      "Epoch: 1429/2000\t Step: 45/54\t Train Loss: 3.717568\t Valid Loss: 4.995656\n",
      "Epoch: 1430/2000\t Step: 15/54\t Train Loss: 3.737514\t Valid Loss: 4.930703\n",
      "Epoch: 1430/2000\t Step: 30/54\t Train Loss: 3.770020\t Valid Loss: 5.067138\n",
      "Epoch: 1430/2000\t Step: 45/54\t Train Loss: 3.714172\t Valid Loss: 4.927388\n",
      "Epoch: 1431/2000\t Step: 15/54\t Train Loss: 3.767637\t Valid Loss: 4.786316\n",
      "Epoch: 1431/2000\t Step: 30/54\t Train Loss: 3.754712\t Valid Loss: 5.124212\n",
      "Epoch: 1431/2000\t Step: 45/54\t Train Loss: 3.786556\t Valid Loss: 4.866620\n",
      "Epoch: 1432/2000\t Step: 15/54\t Train Loss: 3.766961\t Valid Loss: 4.963140\n",
      "Epoch: 1432/2000\t Step: 30/54\t Train Loss: 3.755444\t Valid Loss: 5.620347\n",
      "Epoch: 1432/2000\t Step: 45/54\t Train Loss: 3.746950\t Valid Loss: 4.754577\n",
      "Epoch: 1433/2000\t Step: 15/54\t Train Loss: 3.760714\t Valid Loss: 5.249971\n",
      "Epoch: 1433/2000\t Step: 30/54\t Train Loss: 3.725164\t Valid Loss: 4.676167\n",
      "Epoch: 1433/2000\t Step: 45/54\t Train Loss: 3.710292\t Valid Loss: 4.830310\n",
      "Epoch: 1434/2000\t Step: 15/54\t Train Loss: 3.738931\t Valid Loss: 4.737807\n",
      "Epoch: 1434/2000\t Step: 30/54\t Train Loss: 3.785205\t Valid Loss: 4.559699\n",
      "Epoch: 1434/2000\t Step: 45/54\t Train Loss: 3.763479\t Valid Loss: 4.585779\n",
      "Epoch: 1435/2000\t Step: 15/54\t Train Loss: 3.777461\t Valid Loss: 5.090764\n",
      "Epoch: 1435/2000\t Step: 30/54\t Train Loss: 3.711585\t Valid Loss: 4.858252\n",
      "Epoch: 1435/2000\t Step: 45/54\t Train Loss: 3.768155\t Valid Loss: 5.678091\n",
      "Epoch: 1436/2000\t Step: 15/54\t Train Loss: 3.761024\t Valid Loss: 4.767121\n",
      "Epoch: 1436/2000\t Step: 30/54\t Train Loss: 3.758161\t Valid Loss: 4.821085\n",
      "Epoch: 1436/2000\t Step: 45/54\t Train Loss: 3.742823\t Valid Loss: 5.058388\n",
      "Epoch: 1437/2000\t Step: 15/54\t Train Loss: 3.761451\t Valid Loss: 5.461168\n",
      "Epoch: 1437/2000\t Step: 30/54\t Train Loss: 3.741676\t Valid Loss: 5.413436\n",
      "Epoch: 1437/2000\t Step: 45/54\t Train Loss: 3.663953\t Valid Loss: 5.124225\n",
      "Epoch: 1438/2000\t Step: 15/54\t Train Loss: 3.850230\t Valid Loss: 4.962252\n",
      "Epoch: 1438/2000\t Step: 30/54\t Train Loss: 3.755754\t Valid Loss: 4.584735\n",
      "Epoch: 1438/2000\t Step: 45/54\t Train Loss: 3.702296\t Valid Loss: 5.297510\n",
      "Epoch: 1439/2000\t Step: 15/54\t Train Loss: 3.772323\t Valid Loss: 4.833827\n",
      "Epoch: 1439/2000\t Step: 30/54\t Train Loss: 3.783823\t Valid Loss: 5.365375\n",
      "Epoch: 1439/2000\t Step: 45/54\t Train Loss: 3.724361\t Valid Loss: 5.230730\n",
      "Epoch: 1440/2000\t Step: 15/54\t Train Loss: 3.778026\t Valid Loss: 5.021748\n",
      "Epoch: 1440/2000\t Step: 30/54\t Train Loss: 3.741892\t Valid Loss: 5.300200\n",
      "Epoch: 1440/2000\t Step: 45/54\t Train Loss: 3.722809\t Valid Loss: 5.083944\n",
      "Epoch: 1441/2000\t Step: 15/54\t Train Loss: 3.751895\t Valid Loss: 4.616781\n",
      "Epoch: 1441/2000\t Step: 30/54\t Train Loss: 3.749457\t Valid Loss: 5.368343\n",
      "Epoch: 1441/2000\t Step: 45/54\t Train Loss: 3.796139\t Valid Loss: 5.040643\n",
      "Epoch: 1442/2000\t Step: 15/54\t Train Loss: 3.763021\t Valid Loss: 5.538651\n",
      "Epoch: 1442/2000\t Step: 30/54\t Train Loss: 3.862796\t Valid Loss: 5.111792\n",
      "Epoch: 1442/2000\t Step: 45/54\t Train Loss: 3.825049\t Valid Loss: 4.869699\n",
      "Epoch: 1443/2000\t Step: 15/54\t Train Loss: 3.783792\t Valid Loss: 4.728657\n",
      "Epoch: 1443/2000\t Step: 30/54\t Train Loss: 3.751495\t Valid Loss: 4.930960\n",
      "Epoch: 1443/2000\t Step: 45/54\t Train Loss: 3.757958\t Valid Loss: 4.925112\n",
      "Epoch: 1444/2000\t Step: 15/54\t Train Loss: 3.741345\t Valid Loss: 5.218099\n",
      "Epoch: 1444/2000\t Step: 30/54\t Train Loss: 3.733530\t Valid Loss: 5.077502\n",
      "Epoch: 1444/2000\t Step: 45/54\t Train Loss: 3.738470\t Valid Loss: 4.932890\n",
      "Epoch: 1445/2000\t Step: 15/54\t Train Loss: 3.762296\t Valid Loss: 5.229200\n",
      "Epoch: 1445/2000\t Step: 30/54\t Train Loss: 3.765741\t Valid Loss: 4.916927\n",
      "Epoch: 1445/2000\t Step: 45/54\t Train Loss: 3.747195\t Valid Loss: 5.077127\n",
      "Epoch: 1446/2000\t Step: 15/54\t Train Loss: 3.762085\t Valid Loss: 4.986821\n",
      "Epoch: 1446/2000\t Step: 30/54\t Train Loss: 3.717484\t Valid Loss: 4.698255\n",
      "Epoch: 1446/2000\t Step: 45/54\t Train Loss: 3.838519\t Valid Loss: 4.871647\n",
      "Epoch: 1447/2000\t Step: 15/54\t Train Loss: 3.793340\t Valid Loss: 5.304069\n",
      "Epoch: 1447/2000\t Step: 30/54\t Train Loss: 3.752353\t Valid Loss: 5.270786\n",
      "Epoch: 1447/2000\t Step: 45/54\t Train Loss: 3.738967\t Valid Loss: 5.184319\n",
      "Epoch: 1448/2000\t Step: 15/54\t Train Loss: 3.750670\t Valid Loss: 4.706532\n",
      "Epoch: 1448/2000\t Step: 30/54\t Train Loss: 3.763099\t Valid Loss: 5.073145\n",
      "Epoch: 1448/2000\t Step: 45/54\t Train Loss: 3.685322\t Valid Loss: 5.270598\n",
      "Epoch: 1449/2000\t Step: 15/54\t Train Loss: 3.746480\t Valid Loss: 5.367362\n",
      "Epoch: 1449/2000\t Step: 30/54\t Train Loss: 3.761975\t Valid Loss: 4.977180\n",
      "Epoch: 1449/2000\t Step: 45/54\t Train Loss: 3.722517\t Valid Loss: 4.925532\n",
      "Epoch: 1450/2000\t Step: 15/54\t Train Loss: 3.653374\t Valid Loss: 5.083102\n",
      "Epoch: 1450/2000\t Step: 30/54\t Train Loss: 3.819851\t Valid Loss: 4.849419\n",
      "Epoch: 1450/2000\t Step: 45/54\t Train Loss: 3.728781\t Valid Loss: 4.869934\n",
      "Epoch: 1451/2000\t Step: 15/54\t Train Loss: 3.812633\t Valid Loss: 4.927322\n",
      "Epoch: 1451/2000\t Step: 30/54\t Train Loss: 3.855365\t Valid Loss: 4.891864\n",
      "Epoch: 1451/2000\t Step: 45/54\t Train Loss: 3.783804\t Valid Loss: 4.838298\n",
      "Epoch: 1452/2000\t Step: 15/54\t Train Loss: 3.819380\t Valid Loss: 5.174863\n",
      "Epoch: 1452/2000\t Step: 30/54\t Train Loss: 3.755407\t Valid Loss: 5.564324\n",
      "Epoch: 1452/2000\t Step: 45/54\t Train Loss: 3.753477\t Valid Loss: 5.065435\n",
      "Epoch: 1453/2000\t Step: 15/54\t Train Loss: 3.762953\t Valid Loss: 4.647677\n",
      "Epoch: 1453/2000\t Step: 30/54\t Train Loss: 3.786122\t Valid Loss: 5.081588\n",
      "Epoch: 1453/2000\t Step: 45/54\t Train Loss: 3.797637\t Valid Loss: 4.768605\n",
      "Epoch: 1454/2000\t Step: 15/54\t Train Loss: 3.736886\t Valid Loss: 4.972257\n",
      "Epoch: 1454/2000\t Step: 30/54\t Train Loss: 3.731480\t Valid Loss: 5.295037\n",
      "Epoch: 1454/2000\t Step: 45/54\t Train Loss: 3.788015\t Valid Loss: 5.284694\n",
      "Epoch: 1455/2000\t Step: 15/54\t Train Loss: 3.746104\t Valid Loss: 5.294169\n",
      "Epoch: 1455/2000\t Step: 30/54\t Train Loss: 3.853937\t Valid Loss: 4.927732\n",
      "Epoch: 1455/2000\t Step: 45/54\t Train Loss: 3.674891\t Valid Loss: 4.892985\n",
      "Epoch: 1456/2000\t Step: 15/54\t Train Loss: 3.790336\t Valid Loss: 4.845760\n",
      "Epoch: 1456/2000\t Step: 30/54\t Train Loss: 3.814139\t Valid Loss: 5.028406\n",
      "Epoch: 1456/2000\t Step: 45/54\t Train Loss: 3.834521\t Valid Loss: 4.921360\n",
      "Epoch: 1457/2000\t Step: 15/54\t Train Loss: 3.846648\t Valid Loss: 5.095380\n",
      "Epoch: 1457/2000\t Step: 30/54\t Train Loss: 3.799927\t Valid Loss: 4.585437\n",
      "Epoch: 1457/2000\t Step: 45/54\t Train Loss: 3.751501\t Valid Loss: 4.932008\n",
      "Epoch: 1458/2000\t Step: 15/54\t Train Loss: 3.763626\t Valid Loss: 5.187371\n",
      "Epoch: 1458/2000\t Step: 30/54\t Train Loss: 3.688916\t Valid Loss: 5.671613\n",
      "Epoch: 1458/2000\t Step: 45/54\t Train Loss: 3.699174\t Valid Loss: 5.251417\n",
      "Epoch: 1459/2000\t Step: 15/54\t Train Loss: 3.719266\t Valid Loss: 4.681741\n",
      "Epoch: 1459/2000\t Step: 30/54\t Train Loss: 3.813098\t Valid Loss: 5.075517\n",
      "Epoch: 1459/2000\t Step: 45/54\t Train Loss: 3.827496\t Valid Loss: 5.207137\n",
      "Epoch: 1460/2000\t Step: 15/54\t Train Loss: 3.785820\t Valid Loss: 4.838818\n",
      "Epoch: 1460/2000\t Step: 30/54\t Train Loss: 3.811838\t Valid Loss: 4.677754\n",
      "Epoch: 1460/2000\t Step: 45/54\t Train Loss: 3.815069\t Valid Loss: 5.054468\n",
      "Epoch: 1461/2000\t Step: 15/54\t Train Loss: 3.728100\t Valid Loss: 5.303378\n",
      "Epoch: 1461/2000\t Step: 30/54\t Train Loss: 3.737164\t Valid Loss: 5.064382\n",
      "Epoch: 1461/2000\t Step: 45/54\t Train Loss: 3.700123\t Valid Loss: 5.008388\n",
      "Epoch: 1462/2000\t Step: 15/54\t Train Loss: 3.745384\t Valid Loss: 5.410302\n",
      "Epoch: 1462/2000\t Step: 30/54\t Train Loss: 3.781318\t Valid Loss: 4.786587\n",
      "Epoch: 1462/2000\t Step: 45/54\t Train Loss: 3.701771\t Valid Loss: 4.785851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1463/2000\t Step: 15/54\t Train Loss: 3.839972\t Valid Loss: 4.571313\n",
      "Epoch: 1463/2000\t Step: 30/54\t Train Loss: 3.760200\t Valid Loss: 4.506093\n",
      "Epoch: 1463/2000\t Step: 45/54\t Train Loss: 3.724816\t Valid Loss: 5.024278\n",
      "Epoch: 1464/2000\t Step: 15/54\t Train Loss: 3.793110\t Valid Loss: 4.750428\n",
      "Epoch: 1464/2000\t Step: 30/54\t Train Loss: 3.824872\t Valid Loss: 4.863362\n",
      "Epoch: 1464/2000\t Step: 45/54\t Train Loss: 3.760855\t Valid Loss: 4.854312\n",
      "Epoch: 1465/2000\t Step: 15/54\t Train Loss: 3.811112\t Valid Loss: 4.602909\n",
      "Epoch: 1465/2000\t Step: 30/54\t Train Loss: 3.735837\t Valid Loss: 5.003170\n",
      "Epoch: 1465/2000\t Step: 45/54\t Train Loss: 3.797734\t Valid Loss: 5.065936\n",
      "Epoch: 1466/2000\t Step: 15/54\t Train Loss: 3.750177\t Valid Loss: 5.086984\n",
      "Epoch: 1466/2000\t Step: 30/54\t Train Loss: 3.747435\t Valid Loss: 4.899850\n",
      "Epoch: 1466/2000\t Step: 45/54\t Train Loss: 3.773637\t Valid Loss: 4.593592\n",
      "Epoch: 1467/2000\t Step: 15/54\t Train Loss: 3.670011\t Valid Loss: 5.302527\n",
      "Epoch: 1467/2000\t Step: 30/54\t Train Loss: 3.776962\t Valid Loss: 4.908830\n",
      "Epoch: 1467/2000\t Step: 45/54\t Train Loss: 3.727973\t Valid Loss: 4.815261\n",
      "Epoch: 1468/2000\t Step: 15/54\t Train Loss: 3.821352\t Valid Loss: 4.993281\n",
      "Epoch: 1468/2000\t Step: 30/54\t Train Loss: 3.717846\t Valid Loss: 5.512724\n",
      "Epoch: 1468/2000\t Step: 45/54\t Train Loss: 3.852646\t Valid Loss: 4.657674\n",
      "Epoch: 1469/2000\t Step: 15/54\t Train Loss: 3.761284\t Valid Loss: 4.772299\n",
      "Epoch: 1469/2000\t Step: 30/54\t Train Loss: 3.796295\t Valid Loss: 4.805840\n",
      "Epoch: 1469/2000\t Step: 45/54\t Train Loss: 3.724825\t Valid Loss: 4.890879\n",
      "Epoch: 1470/2000\t Step: 15/54\t Train Loss: 3.736329\t Valid Loss: 4.551341\n",
      "Epoch: 1470/2000\t Step: 30/54\t Train Loss: 3.802471\t Valid Loss: 4.970942\n",
      "Epoch: 1470/2000\t Step: 45/54\t Train Loss: 3.776584\t Valid Loss: 4.559891\n",
      "Epoch: 1471/2000\t Step: 15/54\t Train Loss: 3.714304\t Valid Loss: 4.965183\n",
      "Epoch: 1471/2000\t Step: 30/54\t Train Loss: 3.722049\t Valid Loss: 5.177379\n",
      "Epoch: 1471/2000\t Step: 45/54\t Train Loss: 3.771943\t Valid Loss: 4.977018\n",
      "Epoch: 1472/2000\t Step: 15/54\t Train Loss: 3.782743\t Valid Loss: 4.685978\n",
      "Epoch: 1472/2000\t Step: 30/54\t Train Loss: 3.799169\t Valid Loss: 4.948187\n",
      "Epoch: 1472/2000\t Step: 45/54\t Train Loss: 3.705946\t Valid Loss: 4.987532\n",
      "Epoch: 1473/2000\t Step: 15/54\t Train Loss: 3.712767\t Valid Loss: 4.993396\n",
      "Epoch: 1473/2000\t Step: 30/54\t Train Loss: 3.745539\t Valid Loss: 5.205751\n",
      "Epoch: 1473/2000\t Step: 45/54\t Train Loss: 3.753110\t Valid Loss: 5.152105\n",
      "Epoch: 1474/2000\t Step: 15/54\t Train Loss: 3.821084\t Valid Loss: 5.322363\n",
      "Epoch: 1474/2000\t Step: 30/54\t Train Loss: 3.716722\t Valid Loss: 5.018927\n",
      "Epoch: 1474/2000\t Step: 45/54\t Train Loss: 3.724982\t Valid Loss: 4.862747\n",
      "Epoch: 1475/2000\t Step: 15/54\t Train Loss: 3.790531\t Valid Loss: 4.548762\n",
      "Epoch: 1475/2000\t Step: 30/54\t Train Loss: 3.735134\t Valid Loss: 5.141002\n",
      "Epoch: 1475/2000\t Step: 45/54\t Train Loss: 3.733494\t Valid Loss: 4.990320\n",
      "Epoch: 1476/2000\t Step: 15/54\t Train Loss: 3.680871\t Valid Loss: 4.615595\n",
      "Epoch: 1476/2000\t Step: 30/54\t Train Loss: 3.780097\t Valid Loss: 4.709091\n",
      "Epoch: 1476/2000\t Step: 45/54\t Train Loss: 3.743154\t Valid Loss: 5.056528\n",
      "Epoch: 1477/2000\t Step: 15/54\t Train Loss: 3.781435\t Valid Loss: 4.923682\n",
      "Epoch: 1477/2000\t Step: 30/54\t Train Loss: 3.733364\t Valid Loss: 5.316377\n",
      "Epoch: 1477/2000\t Step: 45/54\t Train Loss: 3.725669\t Valid Loss: 4.860065\n",
      "Epoch: 1478/2000\t Step: 15/54\t Train Loss: 3.752125\t Valid Loss: 5.131691\n",
      "Epoch: 1478/2000\t Step: 30/54\t Train Loss: 3.791813\t Valid Loss: 5.409627\n",
      "Epoch: 1478/2000\t Step: 45/54\t Train Loss: 3.697018\t Valid Loss: 5.196358\n",
      "Epoch: 1479/2000\t Step: 15/54\t Train Loss: 3.721251\t Valid Loss: 5.276195\n",
      "Epoch: 1479/2000\t Step: 30/54\t Train Loss: 3.771121\t Valid Loss: 5.001129\n",
      "Epoch: 1479/2000\t Step: 45/54\t Train Loss: 3.837412\t Valid Loss: 4.851545\n",
      "Epoch: 1480/2000\t Step: 15/54\t Train Loss: 3.795668\t Valid Loss: 4.662112\n",
      "Epoch: 1480/2000\t Step: 30/54\t Train Loss: 3.788294\t Valid Loss: 4.868839\n",
      "Epoch: 1480/2000\t Step: 45/54\t Train Loss: 3.773476\t Valid Loss: 5.034216\n",
      "Epoch: 1481/2000\t Step: 15/54\t Train Loss: 3.712580\t Valid Loss: 4.951531\n",
      "Epoch: 1481/2000\t Step: 30/54\t Train Loss: 3.701082\t Valid Loss: 5.012984\n",
      "Epoch: 1481/2000\t Step: 45/54\t Train Loss: 3.800896\t Valid Loss: 4.894704\n",
      "Epoch: 1482/2000\t Step: 15/54\t Train Loss: 3.772709\t Valid Loss: 5.059731\n",
      "Epoch: 1482/2000\t Step: 30/54\t Train Loss: 3.758745\t Valid Loss: 4.780829\n",
      "Epoch: 1482/2000\t Step: 45/54\t Train Loss: 3.776478\t Valid Loss: 4.990408\n",
      "Epoch: 1483/2000\t Step: 15/54\t Train Loss: 3.737402\t Valid Loss: 5.004064\n",
      "Epoch: 1483/2000\t Step: 30/54\t Train Loss: 3.817003\t Valid Loss: 5.151527\n",
      "Epoch: 1483/2000\t Step: 45/54\t Train Loss: 3.726079\t Valid Loss: 5.011264\n",
      "Epoch: 1484/2000\t Step: 15/54\t Train Loss: 3.750082\t Valid Loss: 4.548037\n",
      "Epoch: 1484/2000\t Step: 30/54\t Train Loss: 3.839197\t Valid Loss: 4.810925\n",
      "Epoch: 1484/2000\t Step: 45/54\t Train Loss: 3.738475\t Valid Loss: 4.939395\n",
      "Epoch: 1485/2000\t Step: 15/54\t Train Loss: 3.815028\t Valid Loss: 4.730030\n",
      "Epoch: 1485/2000\t Step: 30/54\t Train Loss: 3.742536\t Valid Loss: 5.253950\n",
      "Epoch: 1485/2000\t Step: 45/54\t Train Loss: 3.764012\t Valid Loss: 5.058871\n",
      "Epoch: 1486/2000\t Step: 15/54\t Train Loss: 3.743372\t Valid Loss: 5.007923\n",
      "Epoch: 1486/2000\t Step: 30/54\t Train Loss: 3.761741\t Valid Loss: 5.145022\n",
      "Epoch: 1486/2000\t Step: 45/54\t Train Loss: 3.796320\t Valid Loss: 4.923740\n",
      "Epoch: 1487/2000\t Step: 15/54\t Train Loss: 3.767574\t Valid Loss: 5.383977\n",
      "Epoch: 1487/2000\t Step: 30/54\t Train Loss: 3.784286\t Valid Loss: 4.884338\n",
      "Epoch: 1487/2000\t Step: 45/54\t Train Loss: 3.823945\t Valid Loss: 4.563983\n",
      "Epoch: 1488/2000\t Step: 15/54\t Train Loss: 3.738715\t Valid Loss: 4.685296\n",
      "Epoch: 1488/2000\t Step: 30/54\t Train Loss: 3.751610\t Valid Loss: 5.251709\n",
      "Epoch: 1488/2000\t Step: 45/54\t Train Loss: 3.727268\t Valid Loss: 4.938798\n",
      "Epoch: 1489/2000\t Step: 15/54\t Train Loss: 3.737993\t Valid Loss: 4.816770\n",
      "Epoch: 1489/2000\t Step: 30/54\t Train Loss: 3.778523\t Valid Loss: 5.131951\n",
      "Epoch: 1489/2000\t Step: 45/54\t Train Loss: 3.714495\t Valid Loss: 5.005151\n",
      "Epoch: 1490/2000\t Step: 15/54\t Train Loss: 3.717918\t Valid Loss: 4.745293\n",
      "Epoch: 1490/2000\t Step: 30/54\t Train Loss: 3.772250\t Valid Loss: 4.769498\n",
      "Epoch: 1490/2000\t Step: 45/54\t Train Loss: 3.716612\t Valid Loss: 5.369843\n",
      "Epoch: 1491/2000\t Step: 15/54\t Train Loss: 3.746754\t Valid Loss: 4.892620\n",
      "Epoch: 1491/2000\t Step: 30/54\t Train Loss: 3.713343\t Valid Loss: 5.666593\n",
      "Epoch: 1491/2000\t Step: 45/54\t Train Loss: 3.751110\t Valid Loss: 5.293586\n",
      "Epoch: 1492/2000\t Step: 15/54\t Train Loss: 3.786194\t Valid Loss: 5.063527\n",
      "Epoch: 1492/2000\t Step: 30/54\t Train Loss: 3.693287\t Valid Loss: 5.067812\n",
      "Epoch: 1492/2000\t Step: 45/54\t Train Loss: 3.748852\t Valid Loss: 5.380113\n",
      "Epoch: 1493/2000\t Step: 15/54\t Train Loss: 3.774904\t Valid Loss: 5.013835\n",
      "Epoch: 1493/2000\t Step: 30/54\t Train Loss: 3.757020\t Valid Loss: 5.078267\n",
      "Epoch: 1493/2000\t Step: 45/54\t Train Loss: 3.756402\t Valid Loss: 4.700724\n",
      "Epoch: 1494/2000\t Step: 15/54\t Train Loss: 3.753202\t Valid Loss: 5.040687\n",
      "Epoch: 1494/2000\t Step: 30/54\t Train Loss: 3.729753\t Valid Loss: 4.978967\n",
      "Epoch: 1494/2000\t Step: 45/54\t Train Loss: 3.811900\t Valid Loss: 4.917658\n",
      "Epoch: 1495/2000\t Step: 15/54\t Train Loss: 3.839597\t Valid Loss: 5.334281\n",
      "Epoch: 1495/2000\t Step: 30/54\t Train Loss: 3.830844\t Valid Loss: 4.816820\n",
      "Epoch: 1495/2000\t Step: 45/54\t Train Loss: 3.799646\t Valid Loss: 5.134597\n",
      "Epoch: 1496/2000\t Step: 15/54\t Train Loss: 3.784042\t Valid Loss: 4.813103\n",
      "Epoch: 1496/2000\t Step: 30/54\t Train Loss: 3.715204\t Valid Loss: 5.316954\n",
      "Epoch: 1496/2000\t Step: 45/54\t Train Loss: 3.738559\t Valid Loss: 5.050530\n",
      "Epoch: 1497/2000\t Step: 15/54\t Train Loss: 3.759866\t Valid Loss: 4.677033\n",
      "Epoch: 1497/2000\t Step: 30/54\t Train Loss: 3.806648\t Valid Loss: 4.868420\n",
      "Epoch: 1497/2000\t Step: 45/54\t Train Loss: 3.748659\t Valid Loss: 4.768137\n",
      "Epoch: 1498/2000\t Step: 15/54\t Train Loss: 3.777310\t Valid Loss: 5.094890\n",
      "Epoch: 1498/2000\t Step: 30/54\t Train Loss: 3.839362\t Valid Loss: 4.314535\n",
      "Epoch: 1498/2000\t Step: 45/54\t Train Loss: 3.695599\t Valid Loss: 5.722401\n",
      "Epoch: 1499/2000\t Step: 15/54\t Train Loss: 3.755383\t Valid Loss: 5.044772\n",
      "Epoch: 1499/2000\t Step: 30/54\t Train Loss: 3.788460\t Valid Loss: 5.072978\n",
      "Epoch: 1499/2000\t Step: 45/54\t Train Loss: 3.751617\t Valid Loss: 4.941858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1500/2000\t Step: 15/54\t Train Loss: 3.771249\t Valid Loss: 4.705804\n",
      "Epoch: 1500/2000\t Step: 30/54\t Train Loss: 3.763573\t Valid Loss: 4.968551\n",
      "Epoch: 1500/2000\t Step: 45/54\t Train Loss: 3.763642\t Valid Loss: 4.963948\n",
      "Epoch: 1501/2000\t Step: 15/54\t Train Loss: 3.668329\t Valid Loss: 4.797235\n",
      "Epoch: 1501/2000\t Step: 30/54\t Train Loss: 3.796636\t Valid Loss: 4.907879\n",
      "Epoch: 1501/2000\t Step: 45/54\t Train Loss: 3.753446\t Valid Loss: 5.291445\n",
      "Epoch: 1502/2000\t Step: 15/54\t Train Loss: 3.814795\t Valid Loss: 4.997555\n",
      "Epoch: 1502/2000\t Step: 30/54\t Train Loss: 3.836982\t Valid Loss: 4.661328\n",
      "Epoch: 1502/2000\t Step: 45/54\t Train Loss: 3.787856\t Valid Loss: 4.610229\n",
      "Epoch: 1503/2000\t Step: 15/54\t Train Loss: 3.785507\t Valid Loss: 4.897089\n",
      "Epoch: 1503/2000\t Step: 30/54\t Train Loss: 3.720347\t Valid Loss: 5.079729\n",
      "Epoch: 1503/2000\t Step: 45/54\t Train Loss: 3.776549\t Valid Loss: 5.046265\n",
      "Epoch: 1504/2000\t Step: 15/54\t Train Loss: 3.762142\t Valid Loss: 4.975126\n",
      "Epoch: 1504/2000\t Step: 30/54\t Train Loss: 3.704759\t Valid Loss: 4.725981\n",
      "Epoch: 1504/2000\t Step: 45/54\t Train Loss: 3.812557\t Valid Loss: 4.550529\n",
      "Epoch: 1505/2000\t Step: 15/54\t Train Loss: 3.735975\t Valid Loss: 4.800557\n",
      "Epoch: 1505/2000\t Step: 30/54\t Train Loss: 3.811972\t Valid Loss: 4.913134\n",
      "Epoch: 1505/2000\t Step: 45/54\t Train Loss: 3.705318\t Valid Loss: 5.250695\n",
      "Epoch: 1506/2000\t Step: 15/54\t Train Loss: 3.811971\t Valid Loss: 5.111018\n",
      "Epoch: 1506/2000\t Step: 30/54\t Train Loss: 3.752381\t Valid Loss: 4.968337\n",
      "Epoch: 1506/2000\t Step: 45/54\t Train Loss: 3.794964\t Valid Loss: 4.968436\n",
      "Epoch: 1507/2000\t Step: 15/54\t Train Loss: 3.676823\t Valid Loss: 4.942406\n",
      "Epoch: 1507/2000\t Step: 30/54\t Train Loss: 3.837512\t Valid Loss: 4.842387\n",
      "Epoch: 1507/2000\t Step: 45/54\t Train Loss: 3.774692\t Valid Loss: 4.593888\n",
      "Epoch: 1508/2000\t Step: 15/54\t Train Loss: 3.768922\t Valid Loss: 4.850901\n",
      "Epoch: 1508/2000\t Step: 30/54\t Train Loss: 3.711452\t Valid Loss: 5.060853\n",
      "Epoch: 1508/2000\t Step: 45/54\t Train Loss: 3.751783\t Valid Loss: 4.804982\n",
      "Epoch: 1509/2000\t Step: 15/54\t Train Loss: 3.775649\t Valid Loss: 5.406069\n",
      "Epoch: 1509/2000\t Step: 30/54\t Train Loss: 3.772443\t Valid Loss: 5.051219\n",
      "Epoch: 1509/2000\t Step: 45/54\t Train Loss: 3.778291\t Valid Loss: 5.154229\n",
      "Epoch: 1510/2000\t Step: 15/54\t Train Loss: 3.787366\t Valid Loss: 4.991616\n",
      "Epoch: 1510/2000\t Step: 30/54\t Train Loss: 3.741854\t Valid Loss: 5.110052\n",
      "Epoch: 1510/2000\t Step: 45/54\t Train Loss: 3.760323\t Valid Loss: 4.610228\n",
      "Epoch: 1511/2000\t Step: 15/54\t Train Loss: 3.718728\t Valid Loss: 4.895160\n",
      "Epoch: 1511/2000\t Step: 30/54\t Train Loss: 3.780547\t Valid Loss: 5.513204\n",
      "Epoch: 1511/2000\t Step: 45/54\t Train Loss: 3.784003\t Valid Loss: 4.720138\n",
      "Epoch: 1512/2000\t Step: 15/54\t Train Loss: 3.707379\t Valid Loss: 5.409852\n",
      "Epoch: 1512/2000\t Step: 30/54\t Train Loss: 3.682332\t Valid Loss: 5.309385\n",
      "Epoch: 1512/2000\t Step: 45/54\t Train Loss: 3.769900\t Valid Loss: 4.747545\n",
      "Epoch: 1513/2000\t Step: 15/54\t Train Loss: 3.781837\t Valid Loss: 4.725409\n",
      "Epoch: 1513/2000\t Step: 30/54\t Train Loss: 3.773599\t Valid Loss: 4.619924\n",
      "Epoch: 1513/2000\t Step: 45/54\t Train Loss: 3.759901\t Valid Loss: 5.304550\n",
      "Epoch: 1514/2000\t Step: 15/54\t Train Loss: 3.685940\t Valid Loss: 5.297797\n",
      "Epoch: 1514/2000\t Step: 30/54\t Train Loss: 3.698386\t Valid Loss: 5.253612\n",
      "Epoch: 1514/2000\t Step: 45/54\t Train Loss: 3.745392\t Valid Loss: 5.512587\n",
      "Epoch: 1515/2000\t Step: 15/54\t Train Loss: 3.750186\t Valid Loss: 4.757598\n",
      "Epoch: 1515/2000\t Step: 30/54\t Train Loss: 3.790223\t Valid Loss: 5.407870\n",
      "Epoch: 1515/2000\t Step: 45/54\t Train Loss: 3.765248\t Valid Loss: 5.085184\n",
      "Epoch: 1516/2000\t Step: 15/54\t Train Loss: 3.830953\t Valid Loss: 4.738539\n",
      "Epoch: 1516/2000\t Step: 30/54\t Train Loss: 3.763828\t Valid Loss: 5.040776\n",
      "Epoch: 1516/2000\t Step: 45/54\t Train Loss: 3.746237\t Valid Loss: 5.282278\n",
      "Epoch: 1517/2000\t Step: 15/54\t Train Loss: 3.719343\t Valid Loss: 4.981610\n",
      "Epoch: 1517/2000\t Step: 30/54\t Train Loss: 3.763518\t Valid Loss: 5.296074\n",
      "Epoch: 1517/2000\t Step: 45/54\t Train Loss: 3.740083\t Valid Loss: 5.141599\n",
      "Epoch: 1518/2000\t Step: 15/54\t Train Loss: 3.842713\t Valid Loss: 4.856250\n",
      "Epoch: 1518/2000\t Step: 30/54\t Train Loss: 3.775578\t Valid Loss: 4.722644\n",
      "Epoch: 1518/2000\t Step: 45/54\t Train Loss: 3.776092\t Valid Loss: 4.917088\n",
      "Epoch: 1519/2000\t Step: 15/54\t Train Loss: 3.743424\t Valid Loss: 5.310989\n",
      "Epoch: 1519/2000\t Step: 30/54\t Train Loss: 3.810823\t Valid Loss: 5.276681\n",
      "Epoch: 1519/2000\t Step: 45/54\t Train Loss: 3.705314\t Valid Loss: 4.777170\n",
      "Epoch: 1520/2000\t Step: 15/54\t Train Loss: 3.715716\t Valid Loss: 5.157904\n",
      "Epoch: 1520/2000\t Step: 30/54\t Train Loss: 3.728035\t Valid Loss: 5.251988\n",
      "Epoch: 1520/2000\t Step: 45/54\t Train Loss: 3.780180\t Valid Loss: 5.318665\n",
      "Epoch: 1521/2000\t Step: 15/54\t Train Loss: 3.692452\t Valid Loss: 5.516510\n",
      "Epoch: 1521/2000\t Step: 30/54\t Train Loss: 3.757056\t Valid Loss: 5.128004\n",
      "Epoch: 1521/2000\t Step: 45/54\t Train Loss: 3.779857\t Valid Loss: 4.932466\n",
      "Epoch: 1522/2000\t Step: 15/54\t Train Loss: 3.714675\t Valid Loss: 5.000599\n",
      "Epoch: 1522/2000\t Step: 30/54\t Train Loss: 3.812002\t Valid Loss: 4.906274\n",
      "Epoch: 1522/2000\t Step: 45/54\t Train Loss: 3.779155\t Valid Loss: 5.177872\n",
      "Epoch: 1523/2000\t Step: 15/54\t Train Loss: 3.771207\t Valid Loss: 5.180214\n",
      "Epoch: 1523/2000\t Step: 30/54\t Train Loss: 3.727827\t Valid Loss: 5.443689\n",
      "Epoch: 1523/2000\t Step: 45/54\t Train Loss: 3.726177\t Valid Loss: 4.984625\n",
      "Epoch: 1524/2000\t Step: 15/54\t Train Loss: 3.758043\t Valid Loss: 5.160135\n",
      "Epoch: 1524/2000\t Step: 30/54\t Train Loss: 3.790287\t Valid Loss: 4.904774\n",
      "Epoch: 1524/2000\t Step: 45/54\t Train Loss: 3.786091\t Valid Loss: 5.212008\n",
      "Epoch: 1525/2000\t Step: 15/54\t Train Loss: 3.801850\t Valid Loss: 5.042123\n",
      "Epoch: 1525/2000\t Step: 30/54\t Train Loss: 3.806807\t Valid Loss: 4.827120\n",
      "Epoch: 1525/2000\t Step: 45/54\t Train Loss: 3.725747\t Valid Loss: 4.743026\n",
      "Epoch: 1526/2000\t Step: 15/54\t Train Loss: 3.730983\t Valid Loss: 5.046420\n",
      "Epoch: 1526/2000\t Step: 30/54\t Train Loss: 3.752811\t Valid Loss: 4.909411\n",
      "Epoch: 1526/2000\t Step: 45/54\t Train Loss: 3.715996\t Valid Loss: 4.960514\n",
      "Epoch: 1527/2000\t Step: 15/54\t Train Loss: 3.803274\t Valid Loss: 5.127881\n",
      "Epoch: 1527/2000\t Step: 30/54\t Train Loss: 3.785523\t Valid Loss: 5.398174\n",
      "Epoch: 1527/2000\t Step: 45/54\t Train Loss: 3.821878\t Valid Loss: 4.678894\n",
      "Epoch: 1528/2000\t Step: 15/54\t Train Loss: 3.808317\t Valid Loss: 4.683516\n",
      "Epoch: 1528/2000\t Step: 30/54\t Train Loss: 3.736068\t Valid Loss: 4.711612\n",
      "Epoch: 1528/2000\t Step: 45/54\t Train Loss: 3.711136\t Valid Loss: 4.906626\n",
      "Epoch: 1529/2000\t Step: 15/54\t Train Loss: 3.707492\t Valid Loss: 5.208752\n",
      "Epoch: 1529/2000\t Step: 30/54\t Train Loss: 3.746059\t Valid Loss: 5.212992\n",
      "Epoch: 1529/2000\t Step: 45/54\t Train Loss: 3.790742\t Valid Loss: 5.067508\n",
      "Epoch: 1530/2000\t Step: 15/54\t Train Loss: 3.708261\t Valid Loss: 4.775875\n",
      "Epoch: 1530/2000\t Step: 30/54\t Train Loss: 3.733133\t Valid Loss: 5.352184\n",
      "Epoch: 1530/2000\t Step: 45/54\t Train Loss: 3.745295\t Valid Loss: 5.189917\n",
      "Epoch: 1531/2000\t Step: 15/54\t Train Loss: 3.801885\t Valid Loss: 5.055833\n",
      "Epoch: 1531/2000\t Step: 30/54\t Train Loss: 3.762517\t Valid Loss: 5.037812\n",
      "Epoch: 1531/2000\t Step: 45/54\t Train Loss: 3.764404\t Valid Loss: 4.794563\n",
      "Epoch: 1532/2000\t Step: 15/54\t Train Loss: 3.823593\t Valid Loss: 4.755428\n",
      "Epoch: 1532/2000\t Step: 30/54\t Train Loss: 3.725679\t Valid Loss: 4.923612\n",
      "Epoch: 1532/2000\t Step: 45/54\t Train Loss: 3.759702\t Valid Loss: 5.334615\n",
      "Epoch: 1533/2000\t Step: 15/54\t Train Loss: 3.829668\t Valid Loss: 5.020393\n",
      "Epoch: 1533/2000\t Step: 30/54\t Train Loss: 3.737889\t Valid Loss: 5.409630\n",
      "Epoch: 1533/2000\t Step: 45/54\t Train Loss: 3.818873\t Valid Loss: 5.076252\n",
      "Epoch: 1534/2000\t Step: 15/54\t Train Loss: 3.785138\t Valid Loss: 4.602011\n",
      "Epoch: 1534/2000\t Step: 30/54\t Train Loss: 3.778574\t Valid Loss: 5.254946\n",
      "Epoch: 1534/2000\t Step: 45/54\t Train Loss: 3.784791\t Valid Loss: 4.878351\n",
      "Epoch: 1535/2000\t Step: 15/54\t Train Loss: 3.740335\t Valid Loss: 5.059874\n",
      "Epoch: 1535/2000\t Step: 30/54\t Train Loss: 3.687834\t Valid Loss: 4.971278\n",
      "Epoch: 1535/2000\t Step: 45/54\t Train Loss: 3.763143\t Valid Loss: 5.181682\n",
      "Epoch: 1536/2000\t Step: 15/54\t Train Loss: 3.795645\t Valid Loss: 4.898572\n",
      "Epoch: 1536/2000\t Step: 30/54\t Train Loss: 3.745291\t Valid Loss: 5.463113\n",
      "Epoch: 1536/2000\t Step: 45/54\t Train Loss: 3.772357\t Valid Loss: 4.770074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1537/2000\t Step: 15/54\t Train Loss: 3.719218\t Valid Loss: 5.219531\n",
      "Epoch: 1537/2000\t Step: 30/54\t Train Loss: 3.729765\t Valid Loss: 4.923304\n",
      "Epoch: 1537/2000\t Step: 45/54\t Train Loss: 3.798166\t Valid Loss: 4.911985\n",
      "Epoch: 1538/2000\t Step: 15/54\t Train Loss: 3.808886\t Valid Loss: 5.069238\n",
      "Epoch: 1538/2000\t Step: 30/54\t Train Loss: 3.779795\t Valid Loss: 4.924205\n",
      "Epoch: 1538/2000\t Step: 45/54\t Train Loss: 3.780219\t Valid Loss: 4.688285\n",
      "Epoch: 1539/2000\t Step: 15/54\t Train Loss: 3.745255\t Valid Loss: 4.984420\n",
      "Epoch: 1539/2000\t Step: 30/54\t Train Loss: 3.731103\t Valid Loss: 5.865021\n",
      "Epoch: 1539/2000\t Step: 45/54\t Train Loss: 3.683855\t Valid Loss: 5.204837\n",
      "Epoch: 1540/2000\t Step: 15/54\t Train Loss: 3.740857\t Valid Loss: 5.402748\n",
      "Epoch: 1540/2000\t Step: 30/54\t Train Loss: 3.756882\t Valid Loss: 4.721575\n",
      "Epoch: 1540/2000\t Step: 45/54\t Train Loss: 3.730710\t Valid Loss: 4.971898\n",
      "Epoch: 1541/2000\t Step: 15/54\t Train Loss: 3.700337\t Valid Loss: 4.801896\n",
      "Epoch: 1541/2000\t Step: 30/54\t Train Loss: 3.766126\t Valid Loss: 4.970965\n",
      "Epoch: 1541/2000\t Step: 45/54\t Train Loss: 3.776133\t Valid Loss: 4.887503\n",
      "Epoch: 1542/2000\t Step: 15/54\t Train Loss: 3.761468\t Valid Loss: 5.131414\n",
      "Epoch: 1542/2000\t Step: 30/54\t Train Loss: 3.797741\t Valid Loss: 4.884760\n",
      "Epoch: 1542/2000\t Step: 45/54\t Train Loss: 3.741113\t Valid Loss: 4.972334\n",
      "Epoch: 1543/2000\t Step: 15/54\t Train Loss: 3.777867\t Valid Loss: 4.824750\n",
      "Epoch: 1543/2000\t Step: 30/54\t Train Loss: 3.765859\t Valid Loss: 4.861485\n",
      "Epoch: 1543/2000\t Step: 45/54\t Train Loss: 3.773544\t Valid Loss: 5.042104\n",
      "Epoch: 1544/2000\t Step: 15/54\t Train Loss: 3.838375\t Valid Loss: 4.963112\n",
      "Epoch: 1544/2000\t Step: 30/54\t Train Loss: 3.821443\t Valid Loss: 4.807982\n",
      "Epoch: 1544/2000\t Step: 45/54\t Train Loss: 3.722559\t Valid Loss: 5.095254\n",
      "Epoch: 1545/2000\t Step: 15/54\t Train Loss: 3.709541\t Valid Loss: 5.057177\n",
      "Epoch: 1545/2000\t Step: 30/54\t Train Loss: 3.756308\t Valid Loss: 4.901366\n",
      "Epoch: 1545/2000\t Step: 45/54\t Train Loss: 3.761967\t Valid Loss: 4.897263\n",
      "Epoch: 1546/2000\t Step: 15/54\t Train Loss: 3.740319\t Valid Loss: 4.690869\n",
      "Epoch: 1546/2000\t Step: 30/54\t Train Loss: 3.710475\t Valid Loss: 5.041572\n",
      "Epoch: 1546/2000\t Step: 45/54\t Train Loss: 3.755871\t Valid Loss: 5.167869\n",
      "Epoch: 1547/2000\t Step: 15/54\t Train Loss: 3.663411\t Valid Loss: 5.455903\n",
      "Epoch: 1547/2000\t Step: 30/54\t Train Loss: 3.763777\t Valid Loss: 4.893937\n",
      "Epoch: 1547/2000\t Step: 45/54\t Train Loss: 3.829694\t Valid Loss: 5.191672\n",
      "Epoch: 1548/2000\t Step: 15/54\t Train Loss: 3.737003\t Valid Loss: 5.076457\n",
      "Epoch: 1548/2000\t Step: 30/54\t Train Loss: 3.793467\t Valid Loss: 5.073054\n",
      "Epoch: 1548/2000\t Step: 45/54\t Train Loss: 3.811635\t Valid Loss: 4.897067\n",
      "Epoch: 1549/2000\t Step: 15/54\t Train Loss: 3.746469\t Valid Loss: 4.785710\n",
      "Epoch: 1549/2000\t Step: 30/54\t Train Loss: 3.797153\t Valid Loss: 5.112544\n",
      "Epoch: 1549/2000\t Step: 45/54\t Train Loss: 3.758287\t Valid Loss: 4.626788\n",
      "Epoch: 1550/2000\t Step: 15/54\t Train Loss: 3.808977\t Valid Loss: 4.692161\n",
      "Epoch: 1550/2000\t Step: 30/54\t Train Loss: 3.784417\t Valid Loss: 4.758532\n",
      "Epoch: 1550/2000\t Step: 45/54\t Train Loss: 3.771638\t Valid Loss: 4.867397\n",
      "Epoch: 1551/2000\t Step: 15/54\t Train Loss: 3.724467\t Valid Loss: 5.055643\n",
      "Epoch: 1551/2000\t Step: 30/54\t Train Loss: 3.743681\t Valid Loss: 4.862219\n",
      "Epoch: 1551/2000\t Step: 45/54\t Train Loss: 3.750368\t Valid Loss: 5.148719\n",
      "Epoch: 1552/2000\t Step: 15/54\t Train Loss: 3.713039\t Valid Loss: 4.603413\n",
      "Epoch: 1552/2000\t Step: 30/54\t Train Loss: 3.773742\t Valid Loss: 5.055389\n",
      "Epoch: 1552/2000\t Step: 45/54\t Train Loss: 3.690732\t Valid Loss: 5.256334\n",
      "Epoch: 1553/2000\t Step: 15/54\t Train Loss: 3.698442\t Valid Loss: 5.133080\n",
      "Epoch: 1553/2000\t Step: 30/54\t Train Loss: 3.744433\t Valid Loss: 5.124355\n",
      "Epoch: 1553/2000\t Step: 45/54\t Train Loss: 3.769111\t Valid Loss: 4.867463\n",
      "Epoch: 1554/2000\t Step: 15/54\t Train Loss: 3.715659\t Valid Loss: 5.071153\n",
      "Epoch: 1554/2000\t Step: 30/54\t Train Loss: 3.674294\t Valid Loss: 5.078172\n",
      "Epoch: 1554/2000\t Step: 45/54\t Train Loss: 3.708374\t Valid Loss: 4.949346\n",
      "Epoch: 1555/2000\t Step: 15/54\t Train Loss: 3.703512\t Valid Loss: 5.272395\n",
      "Epoch: 1555/2000\t Step: 30/54\t Train Loss: 3.811358\t Valid Loss: 5.384597\n",
      "Epoch: 1555/2000\t Step: 45/54\t Train Loss: 3.860054\t Valid Loss: 4.853293\n",
      "Epoch: 1556/2000\t Step: 15/54\t Train Loss: 3.712946\t Valid Loss: 5.122368\n",
      "Epoch: 1556/2000\t Step: 30/54\t Train Loss: 3.729330\t Valid Loss: 5.107918\n",
      "Epoch: 1556/2000\t Step: 45/54\t Train Loss: 3.758328\t Valid Loss: 5.088430\n",
      "Epoch: 1557/2000\t Step: 15/54\t Train Loss: 3.800053\t Valid Loss: 4.904524\n",
      "Epoch: 1557/2000\t Step: 30/54\t Train Loss: 3.773500\t Valid Loss: 4.876952\n",
      "Epoch: 1557/2000\t Step: 45/54\t Train Loss: 3.785079\t Valid Loss: 4.991350\n",
      "Epoch: 1558/2000\t Step: 15/54\t Train Loss: 3.833531\t Valid Loss: 5.007585\n",
      "Epoch: 1558/2000\t Step: 30/54\t Train Loss: 3.727948\t Valid Loss: 5.393125\n",
      "Epoch: 1558/2000\t Step: 45/54\t Train Loss: 3.839353\t Valid Loss: 4.968999\n",
      "Epoch: 1559/2000\t Step: 15/54\t Train Loss: 3.764034\t Valid Loss: 5.157045\n",
      "Epoch: 1559/2000\t Step: 30/54\t Train Loss: 3.708370\t Valid Loss: 5.379443\n",
      "Epoch: 1559/2000\t Step: 45/54\t Train Loss: 3.695154\t Valid Loss: 5.316578\n",
      "Epoch: 1560/2000\t Step: 15/54\t Train Loss: 3.752342\t Valid Loss: 4.943300\n",
      "Epoch: 1560/2000\t Step: 30/54\t Train Loss: 3.762871\t Valid Loss: 5.139233\n",
      "Epoch: 1560/2000\t Step: 45/54\t Train Loss: 3.737494\t Valid Loss: 5.731731\n",
      "Epoch: 1561/2000\t Step: 15/54\t Train Loss: 3.784615\t Valid Loss: 4.727603\n",
      "Epoch: 1561/2000\t Step: 30/54\t Train Loss: 3.770428\t Valid Loss: 4.679467\n",
      "Epoch: 1561/2000\t Step: 45/54\t Train Loss: 3.797994\t Valid Loss: 5.132899\n",
      "Epoch: 1562/2000\t Step: 15/54\t Train Loss: 3.806453\t Valid Loss: 4.793910\n",
      "Epoch: 1562/2000\t Step: 30/54\t Train Loss: 3.690267\t Valid Loss: 5.019347\n",
      "Epoch: 1562/2000\t Step: 45/54\t Train Loss: 3.713016\t Valid Loss: 5.072761\n",
      "Epoch: 1563/2000\t Step: 15/54\t Train Loss: 3.805870\t Valid Loss: 4.615282\n",
      "Epoch: 1563/2000\t Step: 30/54\t Train Loss: 3.685302\t Valid Loss: 4.664350\n",
      "Epoch: 1563/2000\t Step: 45/54\t Train Loss: 3.734275\t Valid Loss: 5.116884\n",
      "Epoch: 1564/2000\t Step: 15/54\t Train Loss: 3.739948\t Valid Loss: 5.311726\n",
      "Epoch: 1564/2000\t Step: 30/54\t Train Loss: 3.815988\t Valid Loss: 5.104374\n",
      "Epoch: 1564/2000\t Step: 45/54\t Train Loss: 3.763415\t Valid Loss: 4.766259\n",
      "Epoch: 1565/2000\t Step: 15/54\t Train Loss: 3.776551\t Valid Loss: 5.089460\n",
      "Epoch: 1565/2000\t Step: 30/54\t Train Loss: 3.774693\t Valid Loss: 5.114483\n",
      "Epoch: 1565/2000\t Step: 45/54\t Train Loss: 3.748219\t Valid Loss: 4.923567\n",
      "Epoch: 1566/2000\t Step: 15/54\t Train Loss: 3.772290\t Valid Loss: 4.943740\n",
      "Epoch: 1566/2000\t Step: 30/54\t Train Loss: 3.745513\t Valid Loss: 5.122138\n",
      "Epoch: 1566/2000\t Step: 45/54\t Train Loss: 3.706218\t Valid Loss: 5.270944\n",
      "Epoch: 1567/2000\t Step: 15/54\t Train Loss: 3.790340\t Valid Loss: 4.751682\n",
      "Epoch: 1567/2000\t Step: 30/54\t Train Loss: 3.782460\t Valid Loss: 4.937561\n",
      "Epoch: 1567/2000\t Step: 45/54\t Train Loss: 3.768219\t Valid Loss: 4.669434\n",
      "Epoch: 1568/2000\t Step: 15/54\t Train Loss: 3.735331\t Valid Loss: 4.840245\n",
      "Epoch: 1568/2000\t Step: 30/54\t Train Loss: 3.779687\t Valid Loss: 5.570643\n",
      "Epoch: 1568/2000\t Step: 45/54\t Train Loss: 3.811456\t Valid Loss: 5.348620\n",
      "Epoch: 1569/2000\t Step: 15/54\t Train Loss: 3.774310\t Valid Loss: 4.767418\n",
      "Epoch: 1569/2000\t Step: 30/54\t Train Loss: 3.745141\t Valid Loss: 5.131871\n",
      "Epoch: 1569/2000\t Step: 45/54\t Train Loss: 3.768369\t Valid Loss: 5.419854\n",
      "Epoch: 1570/2000\t Step: 15/54\t Train Loss: 3.692758\t Valid Loss: 5.166988\n",
      "Epoch: 1570/2000\t Step: 30/54\t Train Loss: 3.833685\t Valid Loss: 5.287950\n",
      "Epoch: 1570/2000\t Step: 45/54\t Train Loss: 3.727136\t Valid Loss: 5.000268\n",
      "Epoch: 1571/2000\t Step: 15/54\t Train Loss: 3.719782\t Valid Loss: 5.204750\n",
      "Epoch: 1571/2000\t Step: 30/54\t Train Loss: 3.724129\t Valid Loss: 5.265282\n",
      "Epoch: 1571/2000\t Step: 45/54\t Train Loss: 3.791211\t Valid Loss: 5.036964\n",
      "Epoch: 1572/2000\t Step: 15/54\t Train Loss: 3.717688\t Valid Loss: 5.107635\n",
      "Epoch: 1572/2000\t Step: 30/54\t Train Loss: 3.801301\t Valid Loss: 5.043607\n",
      "Epoch: 1572/2000\t Step: 45/54\t Train Loss: 3.723809\t Valid Loss: 4.847495\n",
      "Epoch: 1573/2000\t Step: 15/54\t Train Loss: 3.748091\t Valid Loss: 5.361350\n",
      "Epoch: 1573/2000\t Step: 30/54\t Train Loss: 3.748561\t Valid Loss: 5.398272\n",
      "Epoch: 1573/2000\t Step: 45/54\t Train Loss: 3.760385\t Valid Loss: 5.450808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1574/2000\t Step: 15/54\t Train Loss: 3.773059\t Valid Loss: 4.809742\n",
      "Epoch: 1574/2000\t Step: 30/54\t Train Loss: 3.836683\t Valid Loss: 5.007279\n",
      "Epoch: 1574/2000\t Step: 45/54\t Train Loss: 3.720157\t Valid Loss: 5.139613\n",
      "Epoch: 1575/2000\t Step: 15/54\t Train Loss: 3.725855\t Valid Loss: 4.950905\n",
      "Epoch: 1575/2000\t Step: 30/54\t Train Loss: 3.731363\t Valid Loss: 4.621066\n",
      "Epoch: 1575/2000\t Step: 45/54\t Train Loss: 3.770378\t Valid Loss: 4.643710\n",
      "Epoch: 1576/2000\t Step: 15/54\t Train Loss: 3.779939\t Valid Loss: 4.513857\n",
      "Epoch: 1576/2000\t Step: 30/54\t Train Loss: 3.800251\t Valid Loss: 4.729391\n",
      "Epoch: 1576/2000\t Step: 45/54\t Train Loss: 3.724590\t Valid Loss: 4.930631\n",
      "Epoch: 1577/2000\t Step: 15/54\t Train Loss: 3.728850\t Valid Loss: 4.714347\n",
      "Epoch: 1577/2000\t Step: 30/54\t Train Loss: 3.810981\t Valid Loss: 4.587022\n",
      "Epoch: 1577/2000\t Step: 45/54\t Train Loss: 3.781415\t Valid Loss: 4.901579\n",
      "Epoch: 1578/2000\t Step: 15/54\t Train Loss: 3.727200\t Valid Loss: 5.148231\n",
      "Epoch: 1578/2000\t Step: 30/54\t Train Loss: 3.785322\t Valid Loss: 5.030852\n",
      "Epoch: 1578/2000\t Step: 45/54\t Train Loss: 3.801607\t Valid Loss: 5.023038\n",
      "Epoch: 1579/2000\t Step: 15/54\t Train Loss: 3.739711\t Valid Loss: 5.262244\n",
      "Epoch: 1579/2000\t Step: 30/54\t Train Loss: 3.634762\t Valid Loss: 5.048416\n",
      "Epoch: 1579/2000\t Step: 45/54\t Train Loss: 3.700652\t Valid Loss: 5.198534\n",
      "Epoch: 1580/2000\t Step: 15/54\t Train Loss: 3.805144\t Valid Loss: 4.952737\n",
      "Epoch: 1580/2000\t Step: 30/54\t Train Loss: 3.758190\t Valid Loss: 4.872666\n",
      "Epoch: 1580/2000\t Step: 45/54\t Train Loss: 3.725107\t Valid Loss: 5.496415\n",
      "Epoch: 1581/2000\t Step: 15/54\t Train Loss: 3.716667\t Valid Loss: 5.179462\n",
      "Epoch: 1581/2000\t Step: 30/54\t Train Loss: 3.791174\t Valid Loss: 4.774840\n",
      "Epoch: 1581/2000\t Step: 45/54\t Train Loss: 3.805887\t Valid Loss: 4.956924\n",
      "Epoch: 1582/2000\t Step: 15/54\t Train Loss: 3.718105\t Valid Loss: 5.136380\n",
      "Epoch: 1582/2000\t Step: 30/54\t Train Loss: 3.825206\t Valid Loss: 4.737819\n",
      "Epoch: 1582/2000\t Step: 45/54\t Train Loss: 3.814308\t Valid Loss: 4.805927\n",
      "Epoch: 1583/2000\t Step: 15/54\t Train Loss: 3.850911\t Valid Loss: 4.838250\n",
      "Epoch: 1583/2000\t Step: 30/54\t Train Loss: 3.749117\t Valid Loss: 4.653634\n",
      "Epoch: 1583/2000\t Step: 45/54\t Train Loss: 3.734554\t Valid Loss: 5.198469\n",
      "Epoch: 1584/2000\t Step: 15/54\t Train Loss: 3.768239\t Valid Loss: 5.435577\n",
      "Epoch: 1584/2000\t Step: 30/54\t Train Loss: 3.767229\t Valid Loss: 4.969709\n",
      "Epoch: 1584/2000\t Step: 45/54\t Train Loss: 3.771742\t Valid Loss: 4.843057\n",
      "Epoch: 1585/2000\t Step: 15/54\t Train Loss: 3.761179\t Valid Loss: 4.786378\n",
      "Epoch: 1585/2000\t Step: 30/54\t Train Loss: 3.770609\t Valid Loss: 5.161624\n",
      "Epoch: 1585/2000\t Step: 45/54\t Train Loss: 3.743170\t Valid Loss: 4.975507\n",
      "Epoch: 1586/2000\t Step: 15/54\t Train Loss: 3.767248\t Valid Loss: 4.646919\n",
      "Epoch: 1586/2000\t Step: 30/54\t Train Loss: 3.764008\t Valid Loss: 4.860045\n",
      "Epoch: 1586/2000\t Step: 45/54\t Train Loss: 3.724521\t Valid Loss: 5.130343\n",
      "Epoch: 1587/2000\t Step: 15/54\t Train Loss: 3.771359\t Valid Loss: 4.941981\n",
      "Epoch: 1587/2000\t Step: 30/54\t Train Loss: 3.766221\t Valid Loss: 4.696343\n",
      "Epoch: 1587/2000\t Step: 45/54\t Train Loss: 3.732801\t Valid Loss: 4.864462\n",
      "Epoch: 1588/2000\t Step: 15/54\t Train Loss: 3.746771\t Valid Loss: 5.044883\n",
      "Epoch: 1588/2000\t Step: 30/54\t Train Loss: 3.750756\t Valid Loss: 5.099532\n",
      "Epoch: 1588/2000\t Step: 45/54\t Train Loss: 3.781950\t Valid Loss: 5.249338\n",
      "Epoch: 1589/2000\t Step: 15/54\t Train Loss: 3.821166\t Valid Loss: 4.898395\n",
      "Epoch: 1589/2000\t Step: 30/54\t Train Loss: 3.788613\t Valid Loss: 5.138958\n",
      "Epoch: 1589/2000\t Step: 45/54\t Train Loss: 3.785752\t Valid Loss: 5.026471\n",
      "Epoch: 1590/2000\t Step: 15/54\t Train Loss: 3.720516\t Valid Loss: 4.755442\n",
      "Epoch: 1590/2000\t Step: 30/54\t Train Loss: 3.729231\t Valid Loss: 5.279496\n",
      "Epoch: 1590/2000\t Step: 45/54\t Train Loss: 3.713383\t Valid Loss: 4.671094\n",
      "Epoch: 1591/2000\t Step: 15/54\t Train Loss: 3.774691\t Valid Loss: 4.725810\n",
      "Epoch: 1591/2000\t Step: 30/54\t Train Loss: 3.822989\t Valid Loss: 5.061242\n",
      "Epoch: 1591/2000\t Step: 45/54\t Train Loss: 3.809292\t Valid Loss: 5.330068\n",
      "Epoch: 1592/2000\t Step: 15/54\t Train Loss: 3.778471\t Valid Loss: 4.701679\n",
      "Epoch: 1592/2000\t Step: 30/54\t Train Loss: 3.732162\t Valid Loss: 5.154408\n",
      "Epoch: 1592/2000\t Step: 45/54\t Train Loss: 3.715663\t Valid Loss: 4.701970\n",
      "Epoch: 1593/2000\t Step: 15/54\t Train Loss: 3.773883\t Valid Loss: 4.740478\n",
      "Epoch: 1593/2000\t Step: 30/54\t Train Loss: 3.741502\t Valid Loss: 4.965088\n",
      "Epoch: 1593/2000\t Step: 45/54\t Train Loss: 3.787642\t Valid Loss: 4.704772\n",
      "Epoch: 1594/2000\t Step: 15/54\t Train Loss: 3.778927\t Valid Loss: 4.734207\n",
      "Epoch: 1594/2000\t Step: 30/54\t Train Loss: 3.768543\t Valid Loss: 4.812821\n",
      "Epoch: 1594/2000\t Step: 45/54\t Train Loss: 3.797006\t Valid Loss: 5.220885\n",
      "Epoch: 1595/2000\t Step: 15/54\t Train Loss: 3.762218\t Valid Loss: 5.391494\n",
      "Epoch: 1595/2000\t Step: 30/54\t Train Loss: 3.795011\t Valid Loss: 4.811231\n",
      "Epoch: 1595/2000\t Step: 45/54\t Train Loss: 3.765787\t Valid Loss: 4.873305\n",
      "Epoch: 1596/2000\t Step: 15/54\t Train Loss: 3.762530\t Valid Loss: 4.982565\n",
      "Epoch: 1596/2000\t Step: 30/54\t Train Loss: 3.736709\t Valid Loss: 5.112709\n",
      "Epoch: 1596/2000\t Step: 45/54\t Train Loss: 3.758544\t Valid Loss: 5.325316\n",
      "Epoch: 1597/2000\t Step: 15/54\t Train Loss: 3.745989\t Valid Loss: 4.911042\n",
      "Epoch: 1597/2000\t Step: 30/54\t Train Loss: 3.730537\t Valid Loss: 4.986868\n",
      "Epoch: 1597/2000\t Step: 45/54\t Train Loss: 3.840978\t Valid Loss: 5.029178\n",
      "Epoch: 1598/2000\t Step: 15/54\t Train Loss: 3.782666\t Valid Loss: 5.145665\n",
      "Epoch: 1598/2000\t Step: 30/54\t Train Loss: 3.749953\t Valid Loss: 5.034117\n",
      "Epoch: 1598/2000\t Step: 45/54\t Train Loss: 3.753158\t Valid Loss: 4.976494\n",
      "Epoch: 1599/2000\t Step: 15/54\t Train Loss: 3.687531\t Valid Loss: 5.141347\n",
      "Epoch: 1599/2000\t Step: 30/54\t Train Loss: 3.779307\t Valid Loss: 4.815908\n",
      "Epoch: 1599/2000\t Step: 45/54\t Train Loss: 3.770032\t Valid Loss: 4.888487\n",
      "Epoch: 1600/2000\t Step: 15/54\t Train Loss: 3.720154\t Valid Loss: 4.865338\n",
      "Epoch: 1600/2000\t Step: 30/54\t Train Loss: 3.817699\t Valid Loss: 4.666631\n",
      "Epoch: 1600/2000\t Step: 45/54\t Train Loss: 3.667778\t Valid Loss: 4.806153\n",
      "Epoch: 1601/2000\t Step: 15/54\t Train Loss: 3.698398\t Valid Loss: 5.044233\n",
      "Epoch: 1601/2000\t Step: 30/54\t Train Loss: 3.759061\t Valid Loss: 4.666433\n",
      "Epoch: 1601/2000\t Step: 45/54\t Train Loss: 3.808723\t Valid Loss: 4.631512\n",
      "Epoch: 1602/2000\t Step: 15/54\t Train Loss: 3.752832\t Valid Loss: 4.994437\n",
      "Epoch: 1602/2000\t Step: 30/54\t Train Loss: 3.665445\t Valid Loss: 5.379705\n",
      "Epoch: 1602/2000\t Step: 45/54\t Train Loss: 3.746294\t Valid Loss: 4.930599\n",
      "Epoch: 1603/2000\t Step: 15/54\t Train Loss: 3.742876\t Valid Loss: 5.128582\n",
      "Epoch: 1603/2000\t Step: 30/54\t Train Loss: 3.749593\t Valid Loss: 4.899752\n",
      "Epoch: 1603/2000\t Step: 45/54\t Train Loss: 3.779826\t Valid Loss: 4.680986\n",
      "Epoch: 1604/2000\t Step: 15/54\t Train Loss: 3.693899\t Valid Loss: 4.890615\n",
      "Epoch: 1604/2000\t Step: 30/54\t Train Loss: 3.742089\t Valid Loss: 4.975548\n",
      "Epoch: 1604/2000\t Step: 45/54\t Train Loss: 3.798761\t Valid Loss: 4.851817\n",
      "Epoch: 1605/2000\t Step: 15/54\t Train Loss: 3.730053\t Valid Loss: 5.024958\n",
      "Epoch: 1605/2000\t Step: 30/54\t Train Loss: 3.737602\t Valid Loss: 5.091501\n",
      "Epoch: 1605/2000\t Step: 45/54\t Train Loss: 3.784220\t Valid Loss: 4.976105\n",
      "Epoch: 1606/2000\t Step: 15/54\t Train Loss: 3.767121\t Valid Loss: 5.330368\n",
      "Epoch: 1606/2000\t Step: 30/54\t Train Loss: 3.766067\t Valid Loss: 4.790925\n",
      "Epoch: 1606/2000\t Step: 45/54\t Train Loss: 3.764433\t Valid Loss: 5.020962\n",
      "Epoch: 1607/2000\t Step: 15/54\t Train Loss: 3.791396\t Valid Loss: 4.700391\n",
      "Epoch: 1607/2000\t Step: 30/54\t Train Loss: 3.781652\t Valid Loss: 4.833542\n",
      "Epoch: 1607/2000\t Step: 45/54\t Train Loss: 3.740715\t Valid Loss: 5.417866\n",
      "Epoch: 1608/2000\t Step: 15/54\t Train Loss: 3.727499\t Valid Loss: 4.723970\n",
      "Epoch: 1608/2000\t Step: 30/54\t Train Loss: 3.754864\t Valid Loss: 4.985369\n",
      "Epoch: 1608/2000\t Step: 45/54\t Train Loss: 3.762946\t Valid Loss: 5.114316\n",
      "Epoch: 1609/2000\t Step: 15/54\t Train Loss: 3.762335\t Valid Loss: 4.684336\n",
      "Epoch: 1609/2000\t Step: 30/54\t Train Loss: 3.722922\t Valid Loss: 5.008760\n",
      "Epoch: 1609/2000\t Step: 45/54\t Train Loss: 3.769020\t Valid Loss: 5.036141\n",
      "Epoch: 1610/2000\t Step: 15/54\t Train Loss: 3.753545\t Valid Loss: 5.207018\n",
      "Epoch: 1610/2000\t Step: 30/54\t Train Loss: 3.639904\t Valid Loss: 5.190096\n",
      "Epoch: 1610/2000\t Step: 45/54\t Train Loss: 3.745117\t Valid Loss: 5.346611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1611/2000\t Step: 15/54\t Train Loss: 3.719004\t Valid Loss: 5.313925\n",
      "Epoch: 1611/2000\t Step: 30/54\t Train Loss: 3.739592\t Valid Loss: 5.116884\n",
      "Epoch: 1611/2000\t Step: 45/54\t Train Loss: 3.788710\t Valid Loss: 4.970894\n",
      "Epoch: 1612/2000\t Step: 15/54\t Train Loss: 3.805415\t Valid Loss: 4.701219\n",
      "Epoch: 1612/2000\t Step: 30/54\t Train Loss: 3.758531\t Valid Loss: 5.019938\n",
      "Epoch: 1612/2000\t Step: 45/54\t Train Loss: 3.838212\t Valid Loss: 4.784728\n",
      "Epoch: 1613/2000\t Step: 15/54\t Train Loss: 3.665352\t Valid Loss: 5.010947\n",
      "Epoch: 1613/2000\t Step: 30/54\t Train Loss: 3.757858\t Valid Loss: 5.200468\n",
      "Epoch: 1613/2000\t Step: 45/54\t Train Loss: 3.717893\t Valid Loss: 5.240719\n",
      "Epoch: 1614/2000\t Step: 15/54\t Train Loss: 3.736437\t Valid Loss: 4.934337\n",
      "Epoch: 1614/2000\t Step: 30/54\t Train Loss: 3.737148\t Valid Loss: 5.359460\n",
      "Epoch: 1614/2000\t Step: 45/54\t Train Loss: 3.751585\t Valid Loss: 5.437575\n",
      "Epoch: 1615/2000\t Step: 15/54\t Train Loss: 3.834749\t Valid Loss: 4.780088\n",
      "Epoch: 1615/2000\t Step: 30/54\t Train Loss: 3.749133\t Valid Loss: 5.236936\n",
      "Epoch: 1615/2000\t Step: 45/54\t Train Loss: 3.793777\t Valid Loss: 4.909912\n",
      "Epoch: 1616/2000\t Step: 15/54\t Train Loss: 3.719756\t Valid Loss: 5.245492\n",
      "Epoch: 1616/2000\t Step: 30/54\t Train Loss: 3.762760\t Valid Loss: 4.943274\n",
      "Epoch: 1616/2000\t Step: 45/54\t Train Loss: 3.728235\t Valid Loss: 5.190699\n",
      "Epoch: 1617/2000\t Step: 15/54\t Train Loss: 3.820336\t Valid Loss: 4.485493\n",
      "Epoch: 1617/2000\t Step: 30/54\t Train Loss: 3.755493\t Valid Loss: 4.774814\n",
      "Epoch: 1617/2000\t Step: 45/54\t Train Loss: 3.752636\t Valid Loss: 5.166852\n",
      "Epoch: 1618/2000\t Step: 15/54\t Train Loss: 3.780145\t Valid Loss: 5.451562\n",
      "Epoch: 1618/2000\t Step: 30/54\t Train Loss: 3.756601\t Valid Loss: 4.548567\n",
      "Epoch: 1618/2000\t Step: 45/54\t Train Loss: 3.847396\t Valid Loss: 5.261295\n",
      "Epoch: 1619/2000\t Step: 15/54\t Train Loss: 3.825808\t Valid Loss: 5.225157\n",
      "Epoch: 1619/2000\t Step: 30/54\t Train Loss: 3.776028\t Valid Loss: 5.292756\n",
      "Epoch: 1619/2000\t Step: 45/54\t Train Loss: 3.740687\t Valid Loss: 4.992705\n",
      "Epoch: 1620/2000\t Step: 15/54\t Train Loss: 3.809773\t Valid Loss: 5.179792\n",
      "Epoch: 1620/2000\t Step: 30/54\t Train Loss: 3.714579\t Valid Loss: 5.198283\n",
      "Epoch: 1620/2000\t Step: 45/54\t Train Loss: 3.805514\t Valid Loss: 5.171940\n",
      "Epoch: 1621/2000\t Step: 15/54\t Train Loss: 3.746426\t Valid Loss: 5.182781\n",
      "Epoch: 1621/2000\t Step: 30/54\t Train Loss: 3.688147\t Valid Loss: 5.049568\n",
      "Epoch: 1621/2000\t Step: 45/54\t Train Loss: 3.796500\t Valid Loss: 5.367525\n",
      "Epoch: 1622/2000\t Step: 15/54\t Train Loss: 3.777360\t Valid Loss: 5.406294\n",
      "Epoch: 1622/2000\t Step: 30/54\t Train Loss: 3.796726\t Valid Loss: 4.710905\n",
      "Epoch: 1622/2000\t Step: 45/54\t Train Loss: 3.797113\t Valid Loss: 5.220544\n",
      "Epoch: 1623/2000\t Step: 15/54\t Train Loss: 3.723342\t Valid Loss: 5.131136\n",
      "Epoch: 1623/2000\t Step: 30/54\t Train Loss: 3.797559\t Valid Loss: 5.391507\n",
      "Epoch: 1623/2000\t Step: 45/54\t Train Loss: 3.748852\t Valid Loss: 5.322405\n",
      "Epoch: 1624/2000\t Step: 15/54\t Train Loss: 3.735498\t Valid Loss: 4.759222\n",
      "Epoch: 1624/2000\t Step: 30/54\t Train Loss: 3.790454\t Valid Loss: 5.760404\n",
      "Epoch: 1624/2000\t Step: 45/54\t Train Loss: 3.699736\t Valid Loss: 5.071744\n",
      "Epoch: 1625/2000\t Step: 15/54\t Train Loss: 3.759616\t Valid Loss: 5.105512\n",
      "Epoch: 1625/2000\t Step: 30/54\t Train Loss: 3.824466\t Valid Loss: 5.297994\n",
      "Epoch: 1625/2000\t Step: 45/54\t Train Loss: 3.730328\t Valid Loss: 5.431559\n",
      "Epoch: 1626/2000\t Step: 15/54\t Train Loss: 3.725919\t Valid Loss: 5.402958\n",
      "Epoch: 1626/2000\t Step: 30/54\t Train Loss: 3.703776\t Valid Loss: 5.144035\n",
      "Epoch: 1626/2000\t Step: 45/54\t Train Loss: 3.737782\t Valid Loss: 5.456060\n",
      "Epoch: 1627/2000\t Step: 15/54\t Train Loss: 3.753799\t Valid Loss: 4.942239\n",
      "Epoch: 1627/2000\t Step: 30/54\t Train Loss: 3.819927\t Valid Loss: 4.955867\n",
      "Epoch: 1627/2000\t Step: 45/54\t Train Loss: 3.815420\t Valid Loss: 4.675819\n",
      "Epoch: 1628/2000\t Step: 15/54\t Train Loss: 3.717303\t Valid Loss: 5.160419\n",
      "Epoch: 1628/2000\t Step: 30/54\t Train Loss: 3.730704\t Valid Loss: 4.676014\n",
      "Epoch: 1628/2000\t Step: 45/54\t Train Loss: 3.818616\t Valid Loss: 5.312934\n",
      "Epoch: 1629/2000\t Step: 15/54\t Train Loss: 3.747714\t Valid Loss: 5.014675\n",
      "Epoch: 1629/2000\t Step: 30/54\t Train Loss: 3.814692\t Valid Loss: 5.329149\n",
      "Epoch: 1629/2000\t Step: 45/54\t Train Loss: 3.740849\t Valid Loss: 4.883255\n",
      "Epoch: 1630/2000\t Step: 15/54\t Train Loss: 3.757334\t Valid Loss: 5.003918\n",
      "Epoch: 1630/2000\t Step: 30/54\t Train Loss: 3.787626\t Valid Loss: 5.102746\n",
      "Epoch: 1630/2000\t Step: 45/54\t Train Loss: 3.782849\t Valid Loss: 4.937177\n",
      "Epoch: 1631/2000\t Step: 15/54\t Train Loss: 3.808382\t Valid Loss: 4.744483\n",
      "Epoch: 1631/2000\t Step: 30/54\t Train Loss: 3.766546\t Valid Loss: 4.811182\n",
      "Epoch: 1631/2000\t Step: 45/54\t Train Loss: 3.774876\t Valid Loss: 5.389237\n",
      "Epoch: 1632/2000\t Step: 15/54\t Train Loss: 3.770902\t Valid Loss: 4.771926\n",
      "Epoch: 1632/2000\t Step: 30/54\t Train Loss: 3.689074\t Valid Loss: 4.755989\n",
      "Epoch: 1632/2000\t Step: 45/54\t Train Loss: 3.712284\t Valid Loss: 5.338422\n",
      "Epoch: 1633/2000\t Step: 15/54\t Train Loss: 3.816468\t Valid Loss: 5.008163\n",
      "Epoch: 1633/2000\t Step: 30/54\t Train Loss: 3.767894\t Valid Loss: 5.060393\n",
      "Epoch: 1633/2000\t Step: 45/54\t Train Loss: 3.765743\t Valid Loss: 5.184994\n",
      "Epoch: 1634/2000\t Step: 15/54\t Train Loss: 3.719240\t Valid Loss: 4.752984\n",
      "Epoch: 1634/2000\t Step: 30/54\t Train Loss: 3.695620\t Valid Loss: 5.116696\n",
      "Epoch: 1634/2000\t Step: 45/54\t Train Loss: 3.767752\t Valid Loss: 5.244687\n",
      "Epoch: 1635/2000\t Step: 15/54\t Train Loss: 3.746108\t Valid Loss: 4.987923\n",
      "Epoch: 1635/2000\t Step: 30/54\t Train Loss: 3.777960\t Valid Loss: 5.000309\n",
      "Epoch: 1635/2000\t Step: 45/54\t Train Loss: 3.746755\t Valid Loss: 5.315214\n",
      "Epoch: 1636/2000\t Step: 15/54\t Train Loss: 3.775268\t Valid Loss: 5.681820\n",
      "Epoch: 1636/2000\t Step: 30/54\t Train Loss: 3.785985\t Valid Loss: 5.228535\n",
      "Epoch: 1636/2000\t Step: 45/54\t Train Loss: 3.784446\t Valid Loss: 5.585274\n",
      "Epoch: 1637/2000\t Step: 15/54\t Train Loss: 3.761264\t Valid Loss: 4.440972\n",
      "Epoch: 1637/2000\t Step: 30/54\t Train Loss: 3.769945\t Valid Loss: 5.184068\n",
      "Epoch: 1637/2000\t Step: 45/54\t Train Loss: 3.705941\t Valid Loss: 5.024783\n",
      "Epoch: 1638/2000\t Step: 15/54\t Train Loss: 3.697143\t Valid Loss: 5.242159\n",
      "Epoch: 1638/2000\t Step: 30/54\t Train Loss: 3.696479\t Valid Loss: 5.202199\n",
      "Epoch: 1638/2000\t Step: 45/54\t Train Loss: 3.769448\t Valid Loss: 5.331849\n",
      "Epoch: 1639/2000\t Step: 15/54\t Train Loss: 3.706052\t Valid Loss: 5.363539\n",
      "Epoch: 1639/2000\t Step: 30/54\t Train Loss: 3.736463\t Valid Loss: 5.095177\n",
      "Epoch: 1639/2000\t Step: 45/54\t Train Loss: 3.765106\t Valid Loss: 4.611774\n",
      "Epoch: 1640/2000\t Step: 15/54\t Train Loss: 3.705369\t Valid Loss: 4.880764\n",
      "Epoch: 1640/2000\t Step: 30/54\t Train Loss: 3.785676\t Valid Loss: 5.348640\n",
      "Epoch: 1640/2000\t Step: 45/54\t Train Loss: 3.676072\t Valid Loss: 5.308032\n",
      "Epoch: 1641/2000\t Step: 15/54\t Train Loss: 3.680458\t Valid Loss: 5.137260\n",
      "Epoch: 1641/2000\t Step: 30/54\t Train Loss: 3.733507\t Valid Loss: 5.687340\n",
      "Epoch: 1641/2000\t Step: 45/54\t Train Loss: 3.736685\t Valid Loss: 5.512123\n",
      "Epoch: 1642/2000\t Step: 15/54\t Train Loss: 3.720603\t Valid Loss: 4.921000\n",
      "Epoch: 1642/2000\t Step: 30/54\t Train Loss: 3.763686\t Valid Loss: 4.884940\n",
      "Epoch: 1642/2000\t Step: 45/54\t Train Loss: 3.753379\t Valid Loss: 4.828537\n",
      "Epoch: 1643/2000\t Step: 15/54\t Train Loss: 3.789288\t Valid Loss: 4.742283\n",
      "Epoch: 1643/2000\t Step: 30/54\t Train Loss: 3.752991\t Valid Loss: 4.844524\n",
      "Epoch: 1643/2000\t Step: 45/54\t Train Loss: 3.741731\t Valid Loss: 5.100840\n",
      "Epoch: 1644/2000\t Step: 15/54\t Train Loss: 3.664407\t Valid Loss: 4.834904\n",
      "Epoch: 1644/2000\t Step: 30/54\t Train Loss: 3.706908\t Valid Loss: 5.094034\n",
      "Epoch: 1644/2000\t Step: 45/54\t Train Loss: 3.845574\t Valid Loss: 4.765482\n",
      "Epoch: 1645/2000\t Step: 15/54\t Train Loss: 3.811050\t Valid Loss: 5.113335\n",
      "Epoch: 1645/2000\t Step: 30/54\t Train Loss: 3.792711\t Valid Loss: 4.845252\n",
      "Epoch: 1645/2000\t Step: 45/54\t Train Loss: 3.825809\t Valid Loss: 4.658492\n",
      "Epoch: 1646/2000\t Step: 15/54\t Train Loss: 3.819839\t Valid Loss: 4.875936\n",
      "Epoch: 1646/2000\t Step: 30/54\t Train Loss: 3.811481\t Valid Loss: 4.733173\n",
      "Epoch: 1646/2000\t Step: 45/54\t Train Loss: 3.860775\t Valid Loss: 4.802538\n",
      "Epoch: 1647/2000\t Step: 15/54\t Train Loss: 3.774138\t Valid Loss: 4.849032\n",
      "Epoch: 1647/2000\t Step: 30/54\t Train Loss: 3.778046\t Valid Loss: 5.109121\n",
      "Epoch: 1647/2000\t Step: 45/54\t Train Loss: 3.741898\t Valid Loss: 5.044151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1648/2000\t Step: 15/54\t Train Loss: 3.766513\t Valid Loss: 4.660447\n",
      "Epoch: 1648/2000\t Step: 30/54\t Train Loss: 3.702954\t Valid Loss: 5.596740\n",
      "Epoch: 1648/2000\t Step: 45/54\t Train Loss: 3.771239\t Valid Loss: 5.393620\n",
      "Epoch: 1649/2000\t Step: 15/54\t Train Loss: 3.777915\t Valid Loss: 5.173601\n",
      "Epoch: 1649/2000\t Step: 30/54\t Train Loss: 3.768349\t Valid Loss: 5.220600\n",
      "Epoch: 1649/2000\t Step: 45/54\t Train Loss: 3.715230\t Valid Loss: 5.267142\n",
      "Epoch: 1650/2000\t Step: 15/54\t Train Loss: 3.644572\t Valid Loss: 6.002942\n",
      "Epoch: 1650/2000\t Step: 30/54\t Train Loss: 3.778865\t Valid Loss: 5.507143\n",
      "Epoch: 1650/2000\t Step: 45/54\t Train Loss: 3.722541\t Valid Loss: 5.317247\n",
      "Epoch: 1651/2000\t Step: 15/54\t Train Loss: 3.761003\t Valid Loss: 5.305112\n",
      "Epoch: 1651/2000\t Step: 30/54\t Train Loss: 3.750161\t Valid Loss: 5.017587\n",
      "Epoch: 1651/2000\t Step: 45/54\t Train Loss: 3.788361\t Valid Loss: 5.535861\n",
      "Epoch: 1652/2000\t Step: 15/54\t Train Loss: 3.732882\t Valid Loss: 5.576214\n",
      "Epoch: 1652/2000\t Step: 30/54\t Train Loss: 3.728581\t Valid Loss: 5.647355\n",
      "Epoch: 1652/2000\t Step: 45/54\t Train Loss: 3.803648\t Valid Loss: 5.488028\n",
      "Epoch: 1653/2000\t Step: 15/54\t Train Loss: 3.772987\t Valid Loss: 5.045523\n",
      "Epoch: 1653/2000\t Step: 30/54\t Train Loss: 3.730389\t Valid Loss: 4.919267\n",
      "Epoch: 1653/2000\t Step: 45/54\t Train Loss: 3.710647\t Valid Loss: 4.849031\n",
      "Epoch: 1654/2000\t Step: 15/54\t Train Loss: 3.814686\t Valid Loss: 4.848524\n",
      "Epoch: 1654/2000\t Step: 30/54\t Train Loss: 3.750995\t Valid Loss: 4.841005\n",
      "Epoch: 1654/2000\t Step: 45/54\t Train Loss: 3.724392\t Valid Loss: 4.866960\n",
      "Epoch: 1655/2000\t Step: 15/54\t Train Loss: 3.750418\t Valid Loss: 4.661928\n",
      "Epoch: 1655/2000\t Step: 30/54\t Train Loss: 3.732813\t Valid Loss: 5.220172\n",
      "Epoch: 1655/2000\t Step: 45/54\t Train Loss: 3.773346\t Valid Loss: 4.770391\n",
      "Epoch: 1656/2000\t Step: 15/54\t Train Loss: 3.739623\t Valid Loss: 5.073712\n",
      "Epoch: 1656/2000\t Step: 30/54\t Train Loss: 3.788681\t Valid Loss: 4.576632\n",
      "Epoch: 1656/2000\t Step: 45/54\t Train Loss: 3.742086\t Valid Loss: 5.041049\n",
      "Epoch: 1657/2000\t Step: 15/54\t Train Loss: 3.738030\t Valid Loss: 4.795260\n",
      "Epoch: 1657/2000\t Step: 30/54\t Train Loss: 3.801111\t Valid Loss: 4.674585\n",
      "Epoch: 1657/2000\t Step: 45/54\t Train Loss: 3.770789\t Valid Loss: 4.588576\n",
      "Epoch: 1658/2000\t Step: 15/54\t Train Loss: 3.796165\t Valid Loss: 4.810447\n",
      "Epoch: 1658/2000\t Step: 30/54\t Train Loss: 3.830258\t Valid Loss: 4.613825\n",
      "Epoch: 1658/2000\t Step: 45/54\t Train Loss: 3.822195\t Valid Loss: 4.702733\n",
      "Epoch: 1659/2000\t Step: 15/54\t Train Loss: 3.801916\t Valid Loss: 4.860023\n",
      "Epoch: 1659/2000\t Step: 30/54\t Train Loss: 3.726389\t Valid Loss: 5.036866\n",
      "Epoch: 1659/2000\t Step: 45/54\t Train Loss: 3.749544\t Valid Loss: 5.108203\n",
      "Epoch: 1660/2000\t Step: 15/54\t Train Loss: 3.705730\t Valid Loss: 5.147848\n",
      "Epoch: 1660/2000\t Step: 30/54\t Train Loss: 3.774377\t Valid Loss: 4.799906\n",
      "Epoch: 1660/2000\t Step: 45/54\t Train Loss: 3.830751\t Valid Loss: 5.433551\n",
      "Epoch: 1661/2000\t Step: 15/54\t Train Loss: 3.669508\t Valid Loss: 4.903013\n",
      "Epoch: 1661/2000\t Step: 30/54\t Train Loss: 3.741257\t Valid Loss: 5.086142\n",
      "Epoch: 1661/2000\t Step: 45/54\t Train Loss: 3.709647\t Valid Loss: 4.874575\n",
      "Epoch: 1662/2000\t Step: 15/54\t Train Loss: 3.742249\t Valid Loss: 5.215168\n",
      "Epoch: 1662/2000\t Step: 30/54\t Train Loss: 3.655381\t Valid Loss: 5.444819\n",
      "Epoch: 1662/2000\t Step: 45/54\t Train Loss: 3.790046\t Valid Loss: 4.894073\n",
      "Epoch: 1663/2000\t Step: 15/54\t Train Loss: 3.784491\t Valid Loss: 4.906271\n",
      "Epoch: 1663/2000\t Step: 30/54\t Train Loss: 3.840874\t Valid Loss: 4.441082\n",
      "Epoch: 1663/2000\t Step: 45/54\t Train Loss: 3.752769\t Valid Loss: 5.134081\n",
      "Epoch: 1664/2000\t Step: 15/54\t Train Loss: 3.773025\t Valid Loss: 4.804002\n",
      "Epoch: 1664/2000\t Step: 30/54\t Train Loss: 3.769207\t Valid Loss: 5.137067\n",
      "Epoch: 1664/2000\t Step: 45/54\t Train Loss: 3.782698\t Valid Loss: 4.992831\n",
      "Epoch: 1665/2000\t Step: 15/54\t Train Loss: 3.670499\t Valid Loss: 5.037616\n",
      "Epoch: 1665/2000\t Step: 30/54\t Train Loss: 3.698280\t Valid Loss: 4.957543\n",
      "Epoch: 1665/2000\t Step: 45/54\t Train Loss: 3.726369\t Valid Loss: 4.961703\n",
      "Epoch: 1666/2000\t Step: 15/54\t Train Loss: 3.847563\t Valid Loss: 4.461644\n",
      "Epoch: 1666/2000\t Step: 30/54\t Train Loss: 3.808270\t Valid Loss: 4.940593\n",
      "Epoch: 1666/2000\t Step: 45/54\t Train Loss: 3.772130\t Valid Loss: 4.593776\n",
      "Epoch: 1667/2000\t Step: 15/54\t Train Loss: 3.819170\t Valid Loss: 4.740105\n",
      "Epoch: 1667/2000\t Step: 30/54\t Train Loss: 3.673055\t Valid Loss: 5.187387\n",
      "Epoch: 1667/2000\t Step: 45/54\t Train Loss: 3.695769\t Valid Loss: 4.963640\n",
      "Epoch: 1668/2000\t Step: 15/54\t Train Loss: 3.708992\t Valid Loss: 4.840689\n",
      "Epoch: 1668/2000\t Step: 30/54\t Train Loss: 3.795838\t Valid Loss: 5.150129\n",
      "Epoch: 1668/2000\t Step: 45/54\t Train Loss: 3.748187\t Valid Loss: 5.113087\n",
      "Epoch: 1669/2000\t Step: 15/54\t Train Loss: 3.784030\t Valid Loss: 5.564813\n",
      "Epoch: 1669/2000\t Step: 30/54\t Train Loss: 3.781467\t Valid Loss: 5.129674\n",
      "Epoch: 1669/2000\t Step: 45/54\t Train Loss: 3.676434\t Valid Loss: 5.268347\n",
      "Epoch: 1670/2000\t Step: 15/54\t Train Loss: 3.821027\t Valid Loss: 5.353832\n",
      "Epoch: 1670/2000\t Step: 30/54\t Train Loss: 3.734766\t Valid Loss: 5.463397\n",
      "Epoch: 1670/2000\t Step: 45/54\t Train Loss: 3.780617\t Valid Loss: 5.204941\n",
      "Epoch: 1671/2000\t Step: 15/54\t Train Loss: 3.721115\t Valid Loss: 4.775517\n",
      "Epoch: 1671/2000\t Step: 30/54\t Train Loss: 3.753157\t Valid Loss: 5.247489\n",
      "Epoch: 1671/2000\t Step: 45/54\t Train Loss: 3.732742\t Valid Loss: 5.228624\n",
      "Epoch: 1672/2000\t Step: 15/54\t Train Loss: 3.683518\t Valid Loss: 4.782523\n",
      "Epoch: 1672/2000\t Step: 30/54\t Train Loss: 3.757668\t Valid Loss: 5.147617\n",
      "Epoch: 1672/2000\t Step: 45/54\t Train Loss: 3.735296\t Valid Loss: 4.977943\n",
      "Epoch: 1673/2000\t Step: 15/54\t Train Loss: 3.784585\t Valid Loss: 4.694392\n",
      "Epoch: 1673/2000\t Step: 30/54\t Train Loss: 3.776620\t Valid Loss: 4.820775\n",
      "Epoch: 1673/2000\t Step: 45/54\t Train Loss: 3.746389\t Valid Loss: 5.346512\n",
      "Epoch: 1674/2000\t Step: 15/54\t Train Loss: 3.710162\t Valid Loss: 5.080574\n",
      "Epoch: 1674/2000\t Step: 30/54\t Train Loss: 3.739281\t Valid Loss: 4.885545\n",
      "Epoch: 1674/2000\t Step: 45/54\t Train Loss: 3.750847\t Valid Loss: 5.098776\n",
      "Epoch: 1675/2000\t Step: 15/54\t Train Loss: 3.773645\t Valid Loss: 5.097038\n",
      "Epoch: 1675/2000\t Step: 30/54\t Train Loss: 3.756903\t Valid Loss: 5.375730\n",
      "Epoch: 1675/2000\t Step: 45/54\t Train Loss: 3.798122\t Valid Loss: 4.706985\n",
      "Epoch: 1676/2000\t Step: 15/54\t Train Loss: 3.709758\t Valid Loss: 5.089124\n",
      "Epoch: 1676/2000\t Step: 30/54\t Train Loss: 3.745805\t Valid Loss: 5.006734\n",
      "Epoch: 1676/2000\t Step: 45/54\t Train Loss: 3.808179\t Valid Loss: 5.042091\n",
      "Epoch: 1677/2000\t Step: 15/54\t Train Loss: 3.723384\t Valid Loss: 5.230544\n",
      "Epoch: 1677/2000\t Step: 30/54\t Train Loss: 3.680015\t Valid Loss: 4.863773\n",
      "Epoch: 1677/2000\t Step: 45/54\t Train Loss: 3.730649\t Valid Loss: 5.122978\n",
      "Epoch: 1678/2000\t Step: 15/54\t Train Loss: 3.749014\t Valid Loss: 4.991068\n",
      "Epoch: 1678/2000\t Step: 30/54\t Train Loss: 3.683514\t Valid Loss: 5.037558\n",
      "Epoch: 1678/2000\t Step: 45/54\t Train Loss: 3.712752\t Valid Loss: 5.150663\n",
      "Epoch: 1679/2000\t Step: 15/54\t Train Loss: 3.801034\t Valid Loss: 4.909660\n",
      "Epoch: 1679/2000\t Step: 30/54\t Train Loss: 3.713716\t Valid Loss: 4.849700\n",
      "Epoch: 1679/2000\t Step: 45/54\t Train Loss: 3.771029\t Valid Loss: 5.163879\n",
      "Epoch: 1680/2000\t Step: 15/54\t Train Loss: 3.780461\t Valid Loss: 4.733188\n",
      "Epoch: 1680/2000\t Step: 30/54\t Train Loss: 3.826446\t Valid Loss: 5.046728\n",
      "Epoch: 1680/2000\t Step: 45/54\t Train Loss: 3.699649\t Valid Loss: 4.840144\n",
      "Epoch: 1681/2000\t Step: 15/54\t Train Loss: 3.737096\t Valid Loss: 5.042669\n",
      "Epoch: 1681/2000\t Step: 30/54\t Train Loss: 3.714332\t Valid Loss: 5.157638\n",
      "Epoch: 1681/2000\t Step: 45/54\t Train Loss: 3.687713\t Valid Loss: 5.462941\n",
      "Epoch: 1682/2000\t Step: 15/54\t Train Loss: 3.742013\t Valid Loss: 4.708282\n",
      "Epoch: 1682/2000\t Step: 30/54\t Train Loss: 3.733767\t Valid Loss: 4.947104\n",
      "Epoch: 1682/2000\t Step: 45/54\t Train Loss: 3.747881\t Valid Loss: 4.888412\n",
      "Epoch: 1683/2000\t Step: 15/54\t Train Loss: 3.748922\t Valid Loss: 5.151995\n",
      "Epoch: 1683/2000\t Step: 30/54\t Train Loss: 3.705916\t Valid Loss: 5.297963\n",
      "Epoch: 1683/2000\t Step: 45/54\t Train Loss: 3.793613\t Valid Loss: 5.126656\n",
      "Epoch: 1684/2000\t Step: 15/54\t Train Loss: 3.841110\t Valid Loss: 4.940491\n",
      "Epoch: 1684/2000\t Step: 30/54\t Train Loss: 3.795621\t Valid Loss: 4.887610\n",
      "Epoch: 1684/2000\t Step: 45/54\t Train Loss: 3.751386\t Valid Loss: 5.132457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1685/2000\t Step: 15/54\t Train Loss: 3.789679\t Valid Loss: 4.692624\n",
      "Epoch: 1685/2000\t Step: 30/54\t Train Loss: 3.771199\t Valid Loss: 4.820028\n",
      "Epoch: 1685/2000\t Step: 45/54\t Train Loss: 3.709034\t Valid Loss: 5.052397\n",
      "Epoch: 1686/2000\t Step: 15/54\t Train Loss: 3.672505\t Valid Loss: 5.218279\n",
      "Epoch: 1686/2000\t Step: 30/54\t Train Loss: 3.691865\t Valid Loss: 5.339927\n",
      "Epoch: 1686/2000\t Step: 45/54\t Train Loss: 3.733746\t Valid Loss: 4.973723\n",
      "Epoch: 1687/2000\t Step: 15/54\t Train Loss: 3.800916\t Valid Loss: 4.706258\n",
      "Epoch: 1687/2000\t Step: 30/54\t Train Loss: 3.783035\t Valid Loss: 5.068945\n",
      "Epoch: 1687/2000\t Step: 45/54\t Train Loss: 3.699399\t Valid Loss: 5.254286\n",
      "Epoch: 1688/2000\t Step: 15/54\t Train Loss: 3.727262\t Valid Loss: 5.354452\n",
      "Epoch: 1688/2000\t Step: 30/54\t Train Loss: 3.735944\t Valid Loss: 5.581870\n",
      "Epoch: 1688/2000\t Step: 45/54\t Train Loss: 3.733501\t Valid Loss: 5.394400\n",
      "Epoch: 1689/2000\t Step: 15/54\t Train Loss: 3.791224\t Valid Loss: 5.358923\n",
      "Epoch: 1689/2000\t Step: 30/54\t Train Loss: 3.800870\t Valid Loss: 4.569648\n",
      "Epoch: 1689/2000\t Step: 45/54\t Train Loss: 3.698006\t Valid Loss: 5.355329\n",
      "Epoch: 1690/2000\t Step: 15/54\t Train Loss: 3.765419\t Valid Loss: 5.092531\n",
      "Epoch: 1690/2000\t Step: 30/54\t Train Loss: 3.777480\t Valid Loss: 5.149028\n",
      "Epoch: 1690/2000\t Step: 45/54\t Train Loss: 3.742366\t Valid Loss: 5.117981\n",
      "Epoch: 1691/2000\t Step: 15/54\t Train Loss: 3.799562\t Valid Loss: 4.906375\n",
      "Epoch: 1691/2000\t Step: 30/54\t Train Loss: 3.764079\t Valid Loss: 4.900836\n",
      "Epoch: 1691/2000\t Step: 45/54\t Train Loss: 3.697518\t Valid Loss: 5.403647\n",
      "Epoch: 1692/2000\t Step: 15/54\t Train Loss: 3.749567\t Valid Loss: 5.461210\n",
      "Epoch: 1692/2000\t Step: 30/54\t Train Loss: 3.769805\t Valid Loss: 4.805073\n",
      "Epoch: 1692/2000\t Step: 45/54\t Train Loss: 3.798222\t Valid Loss: 5.054695\n",
      "Epoch: 1693/2000\t Step: 15/54\t Train Loss: 3.724209\t Valid Loss: 4.679138\n",
      "Epoch: 1693/2000\t Step: 30/54\t Train Loss: 3.814645\t Valid Loss: 5.044055\n",
      "Epoch: 1693/2000\t Step: 45/54\t Train Loss: 3.746096\t Valid Loss: 5.367896\n",
      "Epoch: 1694/2000\t Step: 15/54\t Train Loss: 3.754499\t Valid Loss: 4.946776\n",
      "Epoch: 1694/2000\t Step: 30/54\t Train Loss: 3.735118\t Valid Loss: 5.747314\n",
      "Epoch: 1694/2000\t Step: 45/54\t Train Loss: 3.775426\t Valid Loss: 5.375931\n",
      "Epoch: 1695/2000\t Step: 15/54\t Train Loss: 3.689197\t Valid Loss: 4.944269\n",
      "Epoch: 1695/2000\t Step: 30/54\t Train Loss: 3.743123\t Valid Loss: 5.331219\n",
      "Epoch: 1695/2000\t Step: 45/54\t Train Loss: 3.738399\t Valid Loss: 5.329909\n",
      "Epoch: 1696/2000\t Step: 15/54\t Train Loss: 3.754531\t Valid Loss: 5.133210\n",
      "Epoch: 1696/2000\t Step: 30/54\t Train Loss: 3.778949\t Valid Loss: 4.899518\n",
      "Epoch: 1696/2000\t Step: 45/54\t Train Loss: 3.713710\t Valid Loss: 5.059090\n",
      "Epoch: 1697/2000\t Step: 15/54\t Train Loss: 3.783520\t Valid Loss: 5.309149\n",
      "Epoch: 1697/2000\t Step: 30/54\t Train Loss: 3.679918\t Valid Loss: 5.571216\n",
      "Epoch: 1697/2000\t Step: 45/54\t Train Loss: 3.805656\t Valid Loss: 5.343498\n",
      "Epoch: 1698/2000\t Step: 15/54\t Train Loss: 3.814848\t Valid Loss: 4.789656\n",
      "Epoch: 1698/2000\t Step: 30/54\t Train Loss: 3.802184\t Valid Loss: 5.611512\n",
      "Epoch: 1698/2000\t Step: 45/54\t Train Loss: 3.748241\t Valid Loss: 5.377672\n",
      "Epoch: 1699/2000\t Step: 15/54\t Train Loss: 3.699537\t Valid Loss: 5.095198\n",
      "Epoch: 1699/2000\t Step: 30/54\t Train Loss: 3.698254\t Valid Loss: 5.679717\n",
      "Epoch: 1699/2000\t Step: 45/54\t Train Loss: 3.753011\t Valid Loss: 5.649913\n",
      "Epoch: 1700/2000\t Step: 15/54\t Train Loss: 3.787907\t Valid Loss: 5.456957\n",
      "Epoch: 1700/2000\t Step: 30/54\t Train Loss: 3.793715\t Valid Loss: 4.871075\n",
      "Epoch: 1700/2000\t Step: 45/54\t Train Loss: 3.793898\t Valid Loss: 5.066041\n",
      "Epoch: 1701/2000\t Step: 15/54\t Train Loss: 3.761202\t Valid Loss: 5.022913\n",
      "Epoch: 1701/2000\t Step: 30/54\t Train Loss: 3.755925\t Valid Loss: 5.278127\n",
      "Epoch: 1701/2000\t Step: 45/54\t Train Loss: 3.756531\t Valid Loss: 4.751466\n",
      "Epoch: 1702/2000\t Step: 15/54\t Train Loss: 3.776937\t Valid Loss: 4.519985\n",
      "Epoch: 1702/2000\t Step: 30/54\t Train Loss: 3.769849\t Valid Loss: 4.831971\n",
      "Epoch: 1702/2000\t Step: 45/54\t Train Loss: 3.733603\t Valid Loss: 4.911217\n",
      "Epoch: 1703/2000\t Step: 15/54\t Train Loss: 3.806552\t Valid Loss: 4.659884\n",
      "Epoch: 1703/2000\t Step: 30/54\t Train Loss: 3.664790\t Valid Loss: 5.078857\n",
      "Epoch: 1703/2000\t Step: 45/54\t Train Loss: 3.755694\t Valid Loss: 4.671287\n",
      "Epoch: 1704/2000\t Step: 15/54\t Train Loss: 3.774043\t Valid Loss: 5.318889\n",
      "Epoch: 1704/2000\t Step: 30/54\t Train Loss: 3.748181\t Valid Loss: 5.003805\n",
      "Epoch: 1704/2000\t Step: 45/54\t Train Loss: 3.726885\t Valid Loss: 5.387190\n",
      "Epoch: 1705/2000\t Step: 15/54\t Train Loss: 3.833539\t Valid Loss: 4.870730\n",
      "Epoch: 1705/2000\t Step: 30/54\t Train Loss: 3.724704\t Valid Loss: 4.745873\n",
      "Epoch: 1705/2000\t Step: 45/54\t Train Loss: 3.644622\t Valid Loss: 5.117762\n",
      "Epoch: 1706/2000\t Step: 15/54\t Train Loss: 3.761784\t Valid Loss: 4.870768\n",
      "Epoch: 1706/2000\t Step: 30/54\t Train Loss: 3.735048\t Valid Loss: 5.126469\n",
      "Epoch: 1706/2000\t Step: 45/54\t Train Loss: 3.719383\t Valid Loss: 5.549853\n",
      "Epoch: 1707/2000\t Step: 15/54\t Train Loss: 3.675272\t Valid Loss: 4.760981\n",
      "Epoch: 1707/2000\t Step: 30/54\t Train Loss: 3.744778\t Valid Loss: 5.084138\n",
      "Epoch: 1707/2000\t Step: 45/54\t Train Loss: 3.806366\t Valid Loss: 5.080371\n",
      "Epoch: 1708/2000\t Step: 15/54\t Train Loss: 3.772285\t Valid Loss: 4.752875\n",
      "Epoch: 1708/2000\t Step: 30/54\t Train Loss: 3.743777\t Valid Loss: 4.865703\n",
      "Epoch: 1708/2000\t Step: 45/54\t Train Loss: 3.653379\t Valid Loss: 5.574262\n",
      "Epoch: 1709/2000\t Step: 15/54\t Train Loss: 3.728858\t Valid Loss: 5.670554\n",
      "Epoch: 1709/2000\t Step: 30/54\t Train Loss: 3.707627\t Valid Loss: 4.916399\n",
      "Epoch: 1709/2000\t Step: 45/54\t Train Loss: 3.715740\t Valid Loss: 4.975691\n",
      "Epoch: 1710/2000\t Step: 15/54\t Train Loss: 3.668826\t Valid Loss: 5.045460\n",
      "Epoch: 1710/2000\t Step: 30/54\t Train Loss: 3.736259\t Valid Loss: 5.751339\n",
      "Epoch: 1710/2000\t Step: 45/54\t Train Loss: 3.699144\t Valid Loss: 5.341761\n",
      "Epoch: 1711/2000\t Step: 15/54\t Train Loss: 3.803314\t Valid Loss: 4.986934\n",
      "Epoch: 1711/2000\t Step: 30/54\t Train Loss: 3.810255\t Valid Loss: 4.408816\n",
      "Epoch: 1711/2000\t Step: 45/54\t Train Loss: 3.791970\t Valid Loss: 4.731280\n",
      "Epoch: 1712/2000\t Step: 15/54\t Train Loss: 3.727606\t Valid Loss: 4.626191\n",
      "Epoch: 1712/2000\t Step: 30/54\t Train Loss: 3.737046\t Valid Loss: 5.247465\n",
      "Epoch: 1712/2000\t Step: 45/54\t Train Loss: 3.767519\t Valid Loss: 5.083119\n",
      "Epoch: 1713/2000\t Step: 15/54\t Train Loss: 3.779669\t Valid Loss: 5.235476\n",
      "Epoch: 1713/2000\t Step: 30/54\t Train Loss: 3.743060\t Valid Loss: 5.147306\n",
      "Epoch: 1713/2000\t Step: 45/54\t Train Loss: 3.707112\t Valid Loss: 5.847847\n",
      "Epoch: 1714/2000\t Step: 15/54\t Train Loss: 3.841396\t Valid Loss: 5.038363\n",
      "Epoch: 1714/2000\t Step: 30/54\t Train Loss: 3.798489\t Valid Loss: 5.280420\n",
      "Epoch: 1714/2000\t Step: 45/54\t Train Loss: 3.776851\t Valid Loss: 4.909491\n",
      "Epoch: 1715/2000\t Step: 15/54\t Train Loss: 3.742397\t Valid Loss: 4.763864\n",
      "Epoch: 1715/2000\t Step: 30/54\t Train Loss: 3.806252\t Valid Loss: 5.490816\n",
      "Epoch: 1715/2000\t Step: 45/54\t Train Loss: 3.763586\t Valid Loss: 5.095593\n",
      "Epoch: 1716/2000\t Step: 15/54\t Train Loss: 3.738696\t Valid Loss: 4.908685\n",
      "Epoch: 1716/2000\t Step: 30/54\t Train Loss: 3.792624\t Valid Loss: 5.242851\n",
      "Epoch: 1716/2000\t Step: 45/54\t Train Loss: 3.737984\t Valid Loss: 5.702693\n",
      "Epoch: 1717/2000\t Step: 15/54\t Train Loss: 3.674058\t Valid Loss: 5.648553\n",
      "Epoch: 1717/2000\t Step: 30/54\t Train Loss: 3.786747\t Valid Loss: 4.731461\n",
      "Epoch: 1717/2000\t Step: 45/54\t Train Loss: 3.720622\t Valid Loss: 5.067211\n",
      "Epoch: 1718/2000\t Step: 15/54\t Train Loss: 3.712907\t Valid Loss: 5.437527\n",
      "Epoch: 1718/2000\t Step: 30/54\t Train Loss: 3.703717\t Valid Loss: 5.251296\n",
      "Epoch: 1718/2000\t Step: 45/54\t Train Loss: 3.744430\t Valid Loss: 4.825908\n",
      "Epoch: 1719/2000\t Step: 15/54\t Train Loss: 3.678824\t Valid Loss: 5.176202\n",
      "Epoch: 1719/2000\t Step: 30/54\t Train Loss: 3.774397\t Valid Loss: 5.429244\n",
      "Epoch: 1719/2000\t Step: 45/54\t Train Loss: 3.743863\t Valid Loss: 4.870205\n",
      "Epoch: 1720/2000\t Step: 15/54\t Train Loss: 3.715416\t Valid Loss: 4.881768\n",
      "Epoch: 1720/2000\t Step: 30/54\t Train Loss: 3.742858\t Valid Loss: 5.290376\n",
      "Epoch: 1720/2000\t Step: 45/54\t Train Loss: 3.785230\t Valid Loss: 5.233962\n",
      "Epoch: 1721/2000\t Step: 15/54\t Train Loss: 3.662267\t Valid Loss: 5.480178\n",
      "Epoch: 1721/2000\t Step: 30/54\t Train Loss: 3.703870\t Valid Loss: 5.002397\n",
      "Epoch: 1721/2000\t Step: 45/54\t Train Loss: 3.749791\t Valid Loss: 5.403428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1722/2000\t Step: 15/54\t Train Loss: 3.775200\t Valid Loss: 5.164942\n",
      "Epoch: 1722/2000\t Step: 30/54\t Train Loss: 3.747434\t Valid Loss: 5.147652\n",
      "Epoch: 1722/2000\t Step: 45/54\t Train Loss: 3.798481\t Valid Loss: 4.888901\n",
      "Epoch: 1723/2000\t Step: 15/54\t Train Loss: 3.758136\t Valid Loss: 5.266657\n",
      "Epoch: 1723/2000\t Step: 30/54\t Train Loss: 3.749873\t Valid Loss: 5.362067\n",
      "Epoch: 1723/2000\t Step: 45/54\t Train Loss: 3.796247\t Valid Loss: 4.920753\n",
      "Epoch: 1724/2000\t Step: 15/54\t Train Loss: 3.781711\t Valid Loss: 4.871220\n",
      "Epoch: 1724/2000\t Step: 30/54\t Train Loss: 3.617278\t Valid Loss: 4.923608\n",
      "Epoch: 1724/2000\t Step: 45/54\t Train Loss: 3.771328\t Valid Loss: 5.292809\n",
      "Epoch: 1725/2000\t Step: 15/54\t Train Loss: 3.652494\t Valid Loss: 5.512305\n",
      "Epoch: 1725/2000\t Step: 30/54\t Train Loss: 3.730678\t Valid Loss: 5.331540\n",
      "Epoch: 1725/2000\t Step: 45/54\t Train Loss: 3.740111\t Valid Loss: 5.557942\n",
      "Epoch: 1726/2000\t Step: 15/54\t Train Loss: 3.738144\t Valid Loss: 5.301064\n",
      "Epoch: 1726/2000\t Step: 30/54\t Train Loss: 3.845995\t Valid Loss: 5.353773\n",
      "Epoch: 1726/2000\t Step: 45/54\t Train Loss: 3.695332\t Valid Loss: 4.936868\n",
      "Epoch: 1727/2000\t Step: 15/54\t Train Loss: 3.785907\t Valid Loss: 4.836518\n",
      "Epoch: 1727/2000\t Step: 30/54\t Train Loss: 3.787571\t Valid Loss: 5.172970\n",
      "Epoch: 1727/2000\t Step: 45/54\t Train Loss: 3.725574\t Valid Loss: 4.919479\n",
      "Epoch: 1728/2000\t Step: 15/54\t Train Loss: 3.679465\t Valid Loss: 5.323556\n",
      "Epoch: 1728/2000\t Step: 30/54\t Train Loss: 3.794247\t Valid Loss: 5.087835\n",
      "Epoch: 1728/2000\t Step: 45/54\t Train Loss: 3.795262\t Valid Loss: 4.611566\n",
      "Epoch: 1729/2000\t Step: 15/54\t Train Loss: 3.747227\t Valid Loss: 4.620958\n",
      "Epoch: 1729/2000\t Step: 30/54\t Train Loss: 3.765829\t Valid Loss: 5.428792\n",
      "Epoch: 1729/2000\t Step: 45/54\t Train Loss: 3.746785\t Valid Loss: 5.608202\n",
      "Epoch: 1730/2000\t Step: 15/54\t Train Loss: 3.765467\t Valid Loss: 5.319217\n",
      "Epoch: 1730/2000\t Step: 30/54\t Train Loss: 3.743385\t Valid Loss: 4.841285\n",
      "Epoch: 1730/2000\t Step: 45/54\t Train Loss: 3.787657\t Valid Loss: 5.360289\n",
      "Epoch: 1731/2000\t Step: 15/54\t Train Loss: 3.788442\t Valid Loss: 5.364310\n",
      "Epoch: 1731/2000\t Step: 30/54\t Train Loss: 3.769064\t Valid Loss: 5.003196\n",
      "Epoch: 1731/2000\t Step: 45/54\t Train Loss: 3.781479\t Valid Loss: 5.505203\n",
      "Epoch: 1732/2000\t Step: 15/54\t Train Loss: 3.734119\t Valid Loss: 4.821444\n",
      "Epoch: 1732/2000\t Step: 30/54\t Train Loss: 3.772905\t Valid Loss: 4.739319\n",
      "Epoch: 1732/2000\t Step: 45/54\t Train Loss: 3.767627\t Valid Loss: 4.761322\n",
      "Epoch: 1733/2000\t Step: 15/54\t Train Loss: 3.777261\t Valid Loss: 4.881436\n",
      "Epoch: 1733/2000\t Step: 30/54\t Train Loss: 3.792395\t Valid Loss: 4.803173\n",
      "Epoch: 1733/2000\t Step: 45/54\t Train Loss: 3.798512\t Valid Loss: 5.141699\n",
      "Epoch: 1734/2000\t Step: 15/54\t Train Loss: 3.736682\t Valid Loss: 5.482613\n",
      "Epoch: 1734/2000\t Step: 30/54\t Train Loss: 3.764036\t Valid Loss: 5.389885\n",
      "Epoch: 1734/2000\t Step: 45/54\t Train Loss: 3.742133\t Valid Loss: 5.444214\n",
      "Epoch: 1735/2000\t Step: 15/54\t Train Loss: 3.719123\t Valid Loss: 5.071589\n",
      "Epoch: 1735/2000\t Step: 30/54\t Train Loss: 3.719351\t Valid Loss: 4.877231\n",
      "Epoch: 1735/2000\t Step: 45/54\t Train Loss: 3.725334\t Valid Loss: 5.583069\n",
      "Epoch: 1736/2000\t Step: 15/54\t Train Loss: 3.766500\t Valid Loss: 5.467344\n",
      "Epoch: 1736/2000\t Step: 30/54\t Train Loss: 3.745066\t Valid Loss: 5.128276\n",
      "Epoch: 1736/2000\t Step: 45/54\t Train Loss: 3.614121\t Valid Loss: 5.469306\n",
      "Epoch: 1737/2000\t Step: 15/54\t Train Loss: 3.814912\t Valid Loss: 5.387122\n",
      "Epoch: 1737/2000\t Step: 30/54\t Train Loss: 3.699240\t Valid Loss: 5.318145\n",
      "Epoch: 1737/2000\t Step: 45/54\t Train Loss: 3.702195\t Valid Loss: 5.367240\n",
      "Epoch: 1738/2000\t Step: 15/54\t Train Loss: 3.741913\t Valid Loss: 5.099870\n",
      "Epoch: 1738/2000\t Step: 30/54\t Train Loss: 3.755747\t Valid Loss: 5.287883\n",
      "Epoch: 1738/2000\t Step: 45/54\t Train Loss: 3.780055\t Valid Loss: 4.970951\n",
      "Epoch: 1739/2000\t Step: 15/54\t Train Loss: 3.699169\t Valid Loss: 5.000662\n",
      "Epoch: 1739/2000\t Step: 30/54\t Train Loss: 3.745150\t Valid Loss: 5.286085\n",
      "Epoch: 1739/2000\t Step: 45/54\t Train Loss: 3.830254\t Valid Loss: 4.842219\n",
      "Epoch: 1740/2000\t Step: 15/54\t Train Loss: 3.711082\t Valid Loss: 4.777305\n",
      "Epoch: 1740/2000\t Step: 30/54\t Train Loss: 3.766181\t Valid Loss: 5.000422\n",
      "Epoch: 1740/2000\t Step: 45/54\t Train Loss: 3.775058\t Valid Loss: 4.888376\n",
      "Epoch: 1741/2000\t Step: 15/54\t Train Loss: 3.736459\t Valid Loss: 4.802449\n",
      "Epoch: 1741/2000\t Step: 30/54\t Train Loss: 3.878487\t Valid Loss: 4.755222\n",
      "Epoch: 1741/2000\t Step: 45/54\t Train Loss: 3.772108\t Valid Loss: 4.989911\n",
      "Epoch: 1742/2000\t Step: 15/54\t Train Loss: 3.777876\t Valid Loss: 5.176499\n",
      "Epoch: 1742/2000\t Step: 30/54\t Train Loss: 3.793249\t Valid Loss: 5.032620\n",
      "Epoch: 1742/2000\t Step: 45/54\t Train Loss: 3.721176\t Valid Loss: 5.373997\n",
      "Epoch: 1743/2000\t Step: 15/54\t Train Loss: 3.797366\t Valid Loss: 4.769272\n",
      "Epoch: 1743/2000\t Step: 30/54\t Train Loss: 3.727473\t Valid Loss: 5.336028\n",
      "Epoch: 1743/2000\t Step: 45/54\t Train Loss: 3.716401\t Valid Loss: 5.583334\n",
      "Epoch: 1744/2000\t Step: 15/54\t Train Loss: 3.804427\t Valid Loss: 5.080592\n",
      "Epoch: 1744/2000\t Step: 30/54\t Train Loss: 3.733419\t Valid Loss: 4.747379\n",
      "Epoch: 1744/2000\t Step: 45/54\t Train Loss: 3.857649\t Valid Loss: 5.146549\n",
      "Epoch: 1745/2000\t Step: 15/54\t Train Loss: 3.804734\t Valid Loss: 5.039427\n",
      "Epoch: 1745/2000\t Step: 30/54\t Train Loss: 3.740565\t Valid Loss: 5.157365\n",
      "Epoch: 1745/2000\t Step: 45/54\t Train Loss: 3.735159\t Valid Loss: 5.118287\n",
      "Epoch: 1746/2000\t Step: 15/54\t Train Loss: 3.681485\t Valid Loss: 5.353696\n",
      "Epoch: 1746/2000\t Step: 30/54\t Train Loss: 3.694408\t Valid Loss: 5.620233\n",
      "Epoch: 1746/2000\t Step: 45/54\t Train Loss: 3.696405\t Valid Loss: 5.456219\n",
      "Epoch: 1747/2000\t Step: 15/54\t Train Loss: 3.800010\t Valid Loss: 5.027812\n",
      "Epoch: 1747/2000\t Step: 30/54\t Train Loss: 3.655594\t Valid Loss: 5.345345\n",
      "Epoch: 1747/2000\t Step: 45/54\t Train Loss: 3.742624\t Valid Loss: 4.943300\n",
      "Epoch: 1748/2000\t Step: 15/54\t Train Loss: 3.837106\t Valid Loss: 4.623673\n",
      "Epoch: 1748/2000\t Step: 30/54\t Train Loss: 3.806317\t Valid Loss: 5.235167\n",
      "Epoch: 1748/2000\t Step: 45/54\t Train Loss: 3.791105\t Valid Loss: 5.332783\n",
      "Epoch: 1749/2000\t Step: 15/54\t Train Loss: 3.768757\t Valid Loss: 5.661176\n",
      "Epoch: 1749/2000\t Step: 30/54\t Train Loss: 3.744939\t Valid Loss: 5.109081\n",
      "Epoch: 1749/2000\t Step: 45/54\t Train Loss: 3.774185\t Valid Loss: 5.234278\n",
      "Epoch: 1750/2000\t Step: 15/54\t Train Loss: 3.690489\t Valid Loss: 5.012925\n",
      "Epoch: 1750/2000\t Step: 30/54\t Train Loss: 3.781575\t Valid Loss: 5.695106\n",
      "Epoch: 1750/2000\t Step: 45/54\t Train Loss: 3.746243\t Valid Loss: 5.470239\n",
      "Epoch: 1751/2000\t Step: 15/54\t Train Loss: 3.772803\t Valid Loss: 5.100583\n",
      "Epoch: 1751/2000\t Step: 30/54\t Train Loss: 3.700990\t Valid Loss: 5.304382\n",
      "Epoch: 1751/2000\t Step: 45/54\t Train Loss: 3.752414\t Valid Loss: 5.240417\n",
      "Epoch: 1752/2000\t Step: 15/54\t Train Loss: 3.805894\t Valid Loss: 4.517004\n",
      "Epoch: 1752/2000\t Step: 30/54\t Train Loss: 3.731624\t Valid Loss: 5.253407\n",
      "Epoch: 1752/2000\t Step: 45/54\t Train Loss: 3.795359\t Valid Loss: 5.481186\n",
      "Epoch: 1753/2000\t Step: 15/54\t Train Loss: 3.778359\t Valid Loss: 5.461256\n",
      "Epoch: 1753/2000\t Step: 30/54\t Train Loss: 3.740933\t Valid Loss: 4.820560\n",
      "Epoch: 1753/2000\t Step: 45/54\t Train Loss: 3.756884\t Valid Loss: 5.550426\n",
      "Epoch: 1754/2000\t Step: 15/54\t Train Loss: 3.783855\t Valid Loss: 5.364255\n",
      "Epoch: 1754/2000\t Step: 30/54\t Train Loss: 3.793545\t Valid Loss: 5.010621\n",
      "Epoch: 1754/2000\t Step: 45/54\t Train Loss: 3.701677\t Valid Loss: 5.144843\n",
      "Epoch: 1755/2000\t Step: 15/54\t Train Loss: 3.725136\t Valid Loss: 5.756748\n",
      "Epoch: 1755/2000\t Step: 30/54\t Train Loss: 3.732584\t Valid Loss: 5.247672\n",
      "Epoch: 1755/2000\t Step: 45/54\t Train Loss: 3.731163\t Valid Loss: 4.799148\n",
      "Epoch: 1756/2000\t Step: 15/54\t Train Loss: 3.773793\t Valid Loss: 5.083301\n",
      "Epoch: 1756/2000\t Step: 30/54\t Train Loss: 3.781919\t Valid Loss: 5.320828\n",
      "Epoch: 1756/2000\t Step: 45/54\t Train Loss: 3.836123\t Valid Loss: 5.028062\n",
      "Epoch: 1757/2000\t Step: 15/54\t Train Loss: 3.699518\t Valid Loss: 5.329518\n",
      "Epoch: 1757/2000\t Step: 30/54\t Train Loss: 3.740239\t Valid Loss: 4.549180\n",
      "Epoch: 1757/2000\t Step: 45/54\t Train Loss: 3.743968\t Valid Loss: 5.409798\n",
      "Epoch: 1758/2000\t Step: 15/54\t Train Loss: 3.749619\t Valid Loss: 5.659168\n",
      "Epoch: 1758/2000\t Step: 30/54\t Train Loss: 3.669030\t Valid Loss: 5.479358\n",
      "Epoch: 1758/2000\t Step: 45/54\t Train Loss: 3.736674\t Valid Loss: 5.714666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1759/2000\t Step: 15/54\t Train Loss: 3.779718\t Valid Loss: 5.196666\n",
      "Epoch: 1759/2000\t Step: 30/54\t Train Loss: 3.656729\t Valid Loss: 4.869177\n",
      "Epoch: 1759/2000\t Step: 45/54\t Train Loss: 3.683399\t Valid Loss: 5.257167\n",
      "Epoch: 1760/2000\t Step: 15/54\t Train Loss: 3.759051\t Valid Loss: 4.707567\n",
      "Epoch: 1760/2000\t Step: 30/54\t Train Loss: 3.729867\t Valid Loss: 5.317300\n",
      "Epoch: 1760/2000\t Step: 45/54\t Train Loss: 3.690434\t Valid Loss: 5.021700\n",
      "Epoch: 1761/2000\t Step: 15/54\t Train Loss: 3.771512\t Valid Loss: 5.117500\n",
      "Epoch: 1761/2000\t Step: 30/54\t Train Loss: 3.759902\t Valid Loss: 5.011244\n",
      "Epoch: 1761/2000\t Step: 45/54\t Train Loss: 3.778225\t Valid Loss: 5.091332\n",
      "Epoch: 1762/2000\t Step: 15/54\t Train Loss: 3.695722\t Valid Loss: 4.934225\n",
      "Epoch: 1762/2000\t Step: 30/54\t Train Loss: 3.759848\t Valid Loss: 5.251002\n",
      "Epoch: 1762/2000\t Step: 45/54\t Train Loss: 3.705290\t Valid Loss: 4.969712\n",
      "Epoch: 1763/2000\t Step: 15/54\t Train Loss: 3.772315\t Valid Loss: 5.078408\n",
      "Epoch: 1763/2000\t Step: 30/54\t Train Loss: 3.800077\t Valid Loss: 5.002762\n",
      "Epoch: 1763/2000\t Step: 45/54\t Train Loss: 3.717909\t Valid Loss: 5.216918\n",
      "Epoch: 1764/2000\t Step: 15/54\t Train Loss: 3.765946\t Valid Loss: 5.182512\n",
      "Epoch: 1764/2000\t Step: 30/54\t Train Loss: 3.703084\t Valid Loss: 5.372410\n",
      "Epoch: 1764/2000\t Step: 45/54\t Train Loss: 3.702924\t Valid Loss: 5.298036\n",
      "Epoch: 1765/2000\t Step: 15/54\t Train Loss: 3.803613\t Valid Loss: 5.529962\n",
      "Epoch: 1765/2000\t Step: 30/54\t Train Loss: 3.826164\t Valid Loss: 4.913502\n",
      "Epoch: 1765/2000\t Step: 45/54\t Train Loss: 3.772670\t Valid Loss: 5.372258\n",
      "Epoch: 1766/2000\t Step: 15/54\t Train Loss: 3.740151\t Valid Loss: 5.180646\n",
      "Epoch: 1766/2000\t Step: 30/54\t Train Loss: 3.706481\t Valid Loss: 5.255542\n",
      "Epoch: 1766/2000\t Step: 45/54\t Train Loss: 3.782873\t Valid Loss: 5.453407\n",
      "Epoch: 1767/2000\t Step: 15/54\t Train Loss: 3.756524\t Valid Loss: 4.765043\n",
      "Epoch: 1767/2000\t Step: 30/54\t Train Loss: 3.727286\t Valid Loss: 5.291669\n",
      "Epoch: 1767/2000\t Step: 45/54\t Train Loss: 3.773509\t Valid Loss: 4.996678\n",
      "Epoch: 1768/2000\t Step: 15/54\t Train Loss: 3.798540\t Valid Loss: 5.127232\n",
      "Epoch: 1768/2000\t Step: 30/54\t Train Loss: 3.778746\t Valid Loss: 4.878449\n",
      "Epoch: 1768/2000\t Step: 45/54\t Train Loss: 3.748278\t Valid Loss: 5.124988\n",
      "Epoch: 1769/2000\t Step: 15/54\t Train Loss: 3.783536\t Valid Loss: 4.716938\n",
      "Epoch: 1769/2000\t Step: 30/54\t Train Loss: 3.732079\t Valid Loss: 5.295834\n",
      "Epoch: 1769/2000\t Step: 45/54\t Train Loss: 3.705842\t Valid Loss: 5.529893\n",
      "Epoch: 1770/2000\t Step: 15/54\t Train Loss: 3.736660\t Valid Loss: 5.045705\n",
      "Epoch: 1770/2000\t Step: 30/54\t Train Loss: 3.792876\t Valid Loss: 5.169227\n",
      "Epoch: 1770/2000\t Step: 45/54\t Train Loss: 3.818721\t Valid Loss: 4.925464\n",
      "Epoch: 1771/2000\t Step: 15/54\t Train Loss: 3.701223\t Valid Loss: 4.774277\n",
      "Epoch: 1771/2000\t Step: 30/54\t Train Loss: 3.771899\t Valid Loss: 5.225307\n",
      "Epoch: 1771/2000\t Step: 45/54\t Train Loss: 3.723147\t Valid Loss: 5.170983\n",
      "Epoch: 1772/2000\t Step: 15/54\t Train Loss: 3.751599\t Valid Loss: 5.090498\n",
      "Epoch: 1772/2000\t Step: 30/54\t Train Loss: 3.807802\t Valid Loss: 5.586013\n",
      "Epoch: 1772/2000\t Step: 45/54\t Train Loss: 3.779846\t Valid Loss: 5.233335\n",
      "Epoch: 1773/2000\t Step: 15/54\t Train Loss: 3.838245\t Valid Loss: 4.911677\n",
      "Epoch: 1773/2000\t Step: 30/54\t Train Loss: 3.803303\t Valid Loss: 5.158331\n",
      "Epoch: 1773/2000\t Step: 45/54\t Train Loss: 3.788689\t Valid Loss: 4.912130\n",
      "Epoch: 1774/2000\t Step: 15/54\t Train Loss: 3.739594\t Valid Loss: 4.963593\n",
      "Epoch: 1774/2000\t Step: 30/54\t Train Loss: 3.775069\t Valid Loss: 5.140530\n",
      "Epoch: 1774/2000\t Step: 45/54\t Train Loss: 3.795969\t Valid Loss: 5.105992\n",
      "Epoch: 1775/2000\t Step: 15/54\t Train Loss: 3.762271\t Valid Loss: 5.476800\n",
      "Epoch: 1775/2000\t Step: 30/54\t Train Loss: 3.685483\t Valid Loss: 5.131658\n",
      "Epoch: 1775/2000\t Step: 45/54\t Train Loss: 3.718571\t Valid Loss: 5.251470\n",
      "Epoch: 1776/2000\t Step: 15/54\t Train Loss: 3.780479\t Valid Loss: 5.397461\n",
      "Epoch: 1776/2000\t Step: 30/54\t Train Loss: 3.795624\t Valid Loss: 5.991228\n",
      "Epoch: 1776/2000\t Step: 45/54\t Train Loss: 3.714897\t Valid Loss: 5.024159\n",
      "Epoch: 1777/2000\t Step: 15/54\t Train Loss: 3.805560\t Valid Loss: 5.515974\n",
      "Epoch: 1777/2000\t Step: 30/54\t Train Loss: 3.728579\t Valid Loss: 5.169748\n",
      "Epoch: 1777/2000\t Step: 45/54\t Train Loss: 3.720560\t Valid Loss: 5.273350\n",
      "Epoch: 1778/2000\t Step: 15/54\t Train Loss: 3.747450\t Valid Loss: 5.456095\n",
      "Epoch: 1778/2000\t Step: 30/54\t Train Loss: 3.699211\t Valid Loss: 5.183992\n",
      "Epoch: 1778/2000\t Step: 45/54\t Train Loss: 3.747994\t Valid Loss: 5.392868\n",
      "Epoch: 1779/2000\t Step: 15/54\t Train Loss: 3.759645\t Valid Loss: 5.046891\n",
      "Epoch: 1779/2000\t Step: 30/54\t Train Loss: 3.734023\t Valid Loss: 5.204984\n",
      "Epoch: 1779/2000\t Step: 45/54\t Train Loss: 3.732852\t Valid Loss: 5.195500\n",
      "Epoch: 1780/2000\t Step: 15/54\t Train Loss: 3.782228\t Valid Loss: 5.494763\n",
      "Epoch: 1780/2000\t Step: 30/54\t Train Loss: 3.785797\t Valid Loss: 5.546674\n",
      "Epoch: 1780/2000\t Step: 45/54\t Train Loss: 3.707724\t Valid Loss: 5.415185\n",
      "Epoch: 1781/2000\t Step: 15/54\t Train Loss: 3.770475\t Valid Loss: 5.416744\n",
      "Epoch: 1781/2000\t Step: 30/54\t Train Loss: 3.812095\t Valid Loss: 5.241087\n",
      "Epoch: 1781/2000\t Step: 45/54\t Train Loss: 3.742951\t Valid Loss: 5.384312\n",
      "Epoch: 1782/2000\t Step: 15/54\t Train Loss: 3.787011\t Valid Loss: 5.287991\n",
      "Epoch: 1782/2000\t Step: 30/54\t Train Loss: 3.742829\t Valid Loss: 4.781665\n",
      "Epoch: 1782/2000\t Step: 45/54\t Train Loss: 3.776204\t Valid Loss: 5.434055\n",
      "Epoch: 1783/2000\t Step: 15/54\t Train Loss: 3.723719\t Valid Loss: 5.653741\n",
      "Epoch: 1783/2000\t Step: 30/54\t Train Loss: 3.699146\t Valid Loss: 5.359656\n",
      "Epoch: 1783/2000\t Step: 45/54\t Train Loss: 3.819379\t Valid Loss: 5.000869\n",
      "Epoch: 1784/2000\t Step: 15/54\t Train Loss: 3.805296\t Valid Loss: 5.254884\n",
      "Epoch: 1784/2000\t Step: 30/54\t Train Loss: 3.755206\t Valid Loss: 5.183527\n",
      "Epoch: 1784/2000\t Step: 45/54\t Train Loss: 3.680489\t Valid Loss: 5.705657\n",
      "Epoch: 1785/2000\t Step: 15/54\t Train Loss: 3.863957\t Valid Loss: 4.701582\n",
      "Epoch: 1785/2000\t Step: 30/54\t Train Loss: 3.748335\t Valid Loss: 5.026646\n",
      "Epoch: 1785/2000\t Step: 45/54\t Train Loss: 3.685294\t Valid Loss: 5.359257\n",
      "Epoch: 1786/2000\t Step: 15/54\t Train Loss: 3.749479\t Valid Loss: 5.618202\n",
      "Epoch: 1786/2000\t Step: 30/54\t Train Loss: 3.741725\t Valid Loss: 5.327146\n",
      "Epoch: 1786/2000\t Step: 45/54\t Train Loss: 3.778950\t Valid Loss: 5.091270\n",
      "Epoch: 1787/2000\t Step: 15/54\t Train Loss: 3.712923\t Valid Loss: 5.584479\n",
      "Epoch: 1787/2000\t Step: 30/54\t Train Loss: 3.776884\t Valid Loss: 5.657017\n",
      "Epoch: 1787/2000\t Step: 45/54\t Train Loss: 3.717663\t Valid Loss: 5.352772\n",
      "Epoch: 1788/2000\t Step: 15/54\t Train Loss: 3.763429\t Valid Loss: 5.446147\n",
      "Epoch: 1788/2000\t Step: 30/54\t Train Loss: 3.738860\t Valid Loss: 4.994983\n",
      "Epoch: 1788/2000\t Step: 45/54\t Train Loss: 3.705103\t Valid Loss: 5.063148\n",
      "Epoch: 1789/2000\t Step: 15/54\t Train Loss: 3.784685\t Valid Loss: 5.394033\n",
      "Epoch: 1789/2000\t Step: 30/54\t Train Loss: 3.704742\t Valid Loss: 5.361546\n",
      "Epoch: 1789/2000\t Step: 45/54\t Train Loss: 3.698888\t Valid Loss: 4.843494\n",
      "Epoch: 1790/2000\t Step: 15/54\t Train Loss: 3.709793\t Valid Loss: 5.471720\n",
      "Epoch: 1790/2000\t Step: 30/54\t Train Loss: 3.728236\t Valid Loss: 5.190347\n",
      "Epoch: 1790/2000\t Step: 45/54\t Train Loss: 3.701315\t Valid Loss: 6.433840\n",
      "Epoch: 1791/2000\t Step: 15/54\t Train Loss: 3.783021\t Valid Loss: 5.242294\n",
      "Epoch: 1791/2000\t Step: 30/54\t Train Loss: 3.714371\t Valid Loss: 5.269604\n",
      "Epoch: 1791/2000\t Step: 45/54\t Train Loss: 3.804476\t Valid Loss: 4.994442\n",
      "Epoch: 1792/2000\t Step: 15/54\t Train Loss: 3.794289\t Valid Loss: 5.156592\n",
      "Epoch: 1792/2000\t Step: 30/54\t Train Loss: 3.821010\t Valid Loss: 5.093792\n",
      "Epoch: 1792/2000\t Step: 45/54\t Train Loss: 3.727587\t Valid Loss: 5.398710\n",
      "Epoch: 1793/2000\t Step: 15/54\t Train Loss: 3.682939\t Valid Loss: 5.278438\n",
      "Epoch: 1793/2000\t Step: 30/54\t Train Loss: 3.727360\t Valid Loss: 5.197167\n",
      "Epoch: 1793/2000\t Step: 45/54\t Train Loss: 3.795912\t Valid Loss: 5.038387\n",
      "Epoch: 1794/2000\t Step: 15/54\t Train Loss: 3.701618\t Valid Loss: 5.264574\n",
      "Epoch: 1794/2000\t Step: 30/54\t Train Loss: 3.718416\t Valid Loss: 5.543660\n",
      "Epoch: 1794/2000\t Step: 45/54\t Train Loss: 3.791778\t Valid Loss: 4.988545\n",
      "Epoch: 1795/2000\t Step: 15/54\t Train Loss: 3.771267\t Valid Loss: 5.451929\n",
      "Epoch: 1795/2000\t Step: 30/54\t Train Loss: 3.770918\t Valid Loss: 5.407817\n",
      "Epoch: 1795/2000\t Step: 45/54\t Train Loss: 3.772415\t Valid Loss: 5.316136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1796/2000\t Step: 15/54\t Train Loss: 3.733407\t Valid Loss: 5.029150\n",
      "Epoch: 1796/2000\t Step: 30/54\t Train Loss: 3.684995\t Valid Loss: 5.605855\n",
      "Epoch: 1796/2000\t Step: 45/54\t Train Loss: 3.713885\t Valid Loss: 5.592057\n",
      "Epoch: 1797/2000\t Step: 15/54\t Train Loss: 3.714632\t Valid Loss: 5.298882\n",
      "Epoch: 1797/2000\t Step: 30/54\t Train Loss: 3.745719\t Valid Loss: 5.045901\n",
      "Epoch: 1797/2000\t Step: 45/54\t Train Loss: 3.736423\t Valid Loss: 5.622681\n",
      "Epoch: 1798/2000\t Step: 15/54\t Train Loss: 3.740832\t Valid Loss: 5.374901\n",
      "Epoch: 1798/2000\t Step: 30/54\t Train Loss: 3.713179\t Valid Loss: 5.043682\n",
      "Epoch: 1798/2000\t Step: 45/54\t Train Loss: 3.696797\t Valid Loss: 5.570808\n",
      "Epoch: 1799/2000\t Step: 15/54\t Train Loss: 3.677548\t Valid Loss: 5.917419\n",
      "Epoch: 1799/2000\t Step: 30/54\t Train Loss: 3.709267\t Valid Loss: 5.094239\n",
      "Epoch: 1799/2000\t Step: 45/54\t Train Loss: 3.746995\t Valid Loss: 5.057612\n",
      "Epoch: 1800/2000\t Step: 15/54\t Train Loss: 3.762753\t Valid Loss: 5.055654\n",
      "Epoch: 1800/2000\t Step: 30/54\t Train Loss: 3.785417\t Valid Loss: 5.093088\n",
      "Epoch: 1800/2000\t Step: 45/54\t Train Loss: 3.716720\t Valid Loss: 5.325971\n",
      "Epoch: 1801/2000\t Step: 15/54\t Train Loss: 3.722362\t Valid Loss: 4.640068\n",
      "Epoch: 1801/2000\t Step: 30/54\t Train Loss: 3.796411\t Valid Loss: 4.707098\n",
      "Epoch: 1801/2000\t Step: 45/54\t Train Loss: 3.841379\t Valid Loss: 4.674309\n",
      "Epoch: 1802/2000\t Step: 15/54\t Train Loss: 3.750948\t Valid Loss: 4.776217\n",
      "Epoch: 1802/2000\t Step: 30/54\t Train Loss: 3.799030\t Valid Loss: 4.875564\n",
      "Epoch: 1802/2000\t Step: 45/54\t Train Loss: 3.832699\t Valid Loss: 4.980913\n",
      "Epoch: 1803/2000\t Step: 15/54\t Train Loss: 3.834917\t Valid Loss: 4.602477\n",
      "Epoch: 1803/2000\t Step: 30/54\t Train Loss: 3.758774\t Valid Loss: 5.141751\n",
      "Epoch: 1803/2000\t Step: 45/54\t Train Loss: 3.753804\t Valid Loss: 5.341512\n",
      "Epoch: 1804/2000\t Step: 15/54\t Train Loss: 3.730961\t Valid Loss: 5.252780\n",
      "Epoch: 1804/2000\t Step: 30/54\t Train Loss: 3.757437\t Valid Loss: 5.224098\n",
      "Epoch: 1804/2000\t Step: 45/54\t Train Loss: 3.732764\t Valid Loss: 5.034259\n",
      "Epoch: 1805/2000\t Step: 15/54\t Train Loss: 3.760380\t Valid Loss: 4.952324\n",
      "Epoch: 1805/2000\t Step: 30/54\t Train Loss: 3.708481\t Valid Loss: 4.791027\n",
      "Epoch: 1805/2000\t Step: 45/54\t Train Loss: 3.751867\t Valid Loss: 5.423864\n",
      "Epoch: 1806/2000\t Step: 15/54\t Train Loss: 3.698681\t Valid Loss: 5.417683\n",
      "Epoch: 1806/2000\t Step: 30/54\t Train Loss: 3.743936\t Valid Loss: 5.008913\n",
      "Epoch: 1806/2000\t Step: 45/54\t Train Loss: 3.731474\t Valid Loss: 5.360003\n",
      "Epoch: 1807/2000\t Step: 15/54\t Train Loss: 3.668563\t Valid Loss: 5.621711\n",
      "Epoch: 1807/2000\t Step: 30/54\t Train Loss: 3.739216\t Valid Loss: 4.993688\n",
      "Epoch: 1807/2000\t Step: 45/54\t Train Loss: 3.713387\t Valid Loss: 4.955004\n",
      "Epoch: 1808/2000\t Step: 15/54\t Train Loss: 3.727090\t Valid Loss: 5.009292\n",
      "Epoch: 1808/2000\t Step: 30/54\t Train Loss: 3.769053\t Valid Loss: 5.456365\n",
      "Epoch: 1808/2000\t Step: 45/54\t Train Loss: 3.716577\t Valid Loss: 5.137192\n",
      "Epoch: 1809/2000\t Step: 15/54\t Train Loss: 3.717652\t Valid Loss: 5.168396\n",
      "Epoch: 1809/2000\t Step: 30/54\t Train Loss: 3.689398\t Valid Loss: 5.211567\n",
      "Epoch: 1809/2000\t Step: 45/54\t Train Loss: 3.683398\t Valid Loss: 5.339584\n",
      "Epoch: 1810/2000\t Step: 15/54\t Train Loss: 3.761262\t Valid Loss: 5.397933\n",
      "Epoch: 1810/2000\t Step: 30/54\t Train Loss: 3.767972\t Valid Loss: 5.646298\n",
      "Epoch: 1810/2000\t Step: 45/54\t Train Loss: 3.728474\t Valid Loss: 5.144271\n",
      "Epoch: 1811/2000\t Step: 15/54\t Train Loss: 3.713660\t Valid Loss: 5.711606\n",
      "Epoch: 1811/2000\t Step: 30/54\t Train Loss: 3.746766\t Valid Loss: 4.862422\n",
      "Epoch: 1811/2000\t Step: 45/54\t Train Loss: 3.719206\t Valid Loss: 5.557207\n",
      "Epoch: 1812/2000\t Step: 15/54\t Train Loss: 3.684247\t Valid Loss: 5.506163\n",
      "Epoch: 1812/2000\t Step: 30/54\t Train Loss: 3.738712\t Valid Loss: 5.248868\n",
      "Epoch: 1812/2000\t Step: 45/54\t Train Loss: 3.763928\t Valid Loss: 5.969604\n",
      "Epoch: 1813/2000\t Step: 15/54\t Train Loss: 3.691893\t Valid Loss: 5.421292\n",
      "Epoch: 1813/2000\t Step: 30/54\t Train Loss: 3.699169\t Valid Loss: 5.004519\n",
      "Epoch: 1813/2000\t Step: 45/54\t Train Loss: 3.699010\t Valid Loss: 5.852264\n",
      "Epoch: 1814/2000\t Step: 15/54\t Train Loss: 3.728896\t Valid Loss: 5.150964\n",
      "Epoch: 1814/2000\t Step: 30/54\t Train Loss: 3.775676\t Valid Loss: 5.030036\n",
      "Epoch: 1814/2000\t Step: 45/54\t Train Loss: 3.763139\t Valid Loss: 5.432796\n",
      "Epoch: 1815/2000\t Step: 15/54\t Train Loss: 3.774903\t Valid Loss: 5.058879\n",
      "Epoch: 1815/2000\t Step: 30/54\t Train Loss: 3.766042\t Valid Loss: 5.628903\n",
      "Epoch: 1815/2000\t Step: 45/54\t Train Loss: 3.761193\t Valid Loss: 5.281196\n",
      "Epoch: 1816/2000\t Step: 15/54\t Train Loss: 3.824415\t Valid Loss: 5.182431\n",
      "Epoch: 1816/2000\t Step: 30/54\t Train Loss: 3.769450\t Valid Loss: 4.635213\n",
      "Epoch: 1816/2000\t Step: 45/54\t Train Loss: 3.722929\t Valid Loss: 5.400066\n",
      "Epoch: 1817/2000\t Step: 15/54\t Train Loss: 3.670998\t Valid Loss: 5.656001\n",
      "Epoch: 1817/2000\t Step: 30/54\t Train Loss: 3.698923\t Valid Loss: 4.762417\n",
      "Epoch: 1817/2000\t Step: 45/54\t Train Loss: 3.776221\t Valid Loss: 5.168198\n",
      "Epoch: 1818/2000\t Step: 15/54\t Train Loss: 3.796816\t Valid Loss: 4.858689\n",
      "Epoch: 1818/2000\t Step: 30/54\t Train Loss: 3.760787\t Valid Loss: 4.746214\n",
      "Epoch: 1818/2000\t Step: 45/54\t Train Loss: 3.711957\t Valid Loss: 5.757556\n",
      "Epoch: 1819/2000\t Step: 15/54\t Train Loss: 3.816401\t Valid Loss: 5.046599\n",
      "Epoch: 1819/2000\t Step: 30/54\t Train Loss: 3.844131\t Valid Loss: 4.739774\n",
      "Epoch: 1819/2000\t Step: 45/54\t Train Loss: 3.760905\t Valid Loss: 5.050572\n",
      "Epoch: 1820/2000\t Step: 15/54\t Train Loss: 3.691556\t Valid Loss: 5.324265\n",
      "Epoch: 1820/2000\t Step: 30/54\t Train Loss: 3.712372\t Valid Loss: 5.144114\n",
      "Epoch: 1820/2000\t Step: 45/54\t Train Loss: 3.674041\t Valid Loss: 4.896869\n",
      "Epoch: 1821/2000\t Step: 15/54\t Train Loss: 3.746845\t Valid Loss: 4.927468\n",
      "Epoch: 1821/2000\t Step: 30/54\t Train Loss: 3.717658\t Valid Loss: 5.127235\n",
      "Epoch: 1821/2000\t Step: 45/54\t Train Loss: 3.726947\t Valid Loss: 5.429707\n",
      "Epoch: 1822/2000\t Step: 15/54\t Train Loss: 3.762970\t Valid Loss: 5.083221\n",
      "Epoch: 1822/2000\t Step: 30/54\t Train Loss: 3.820544\t Valid Loss: 4.941369\n",
      "Epoch: 1822/2000\t Step: 45/54\t Train Loss: 3.753336\t Valid Loss: 5.079445\n",
      "Epoch: 1823/2000\t Step: 15/54\t Train Loss: 3.734620\t Valid Loss: 5.219456\n",
      "Epoch: 1823/2000\t Step: 30/54\t Train Loss: 3.702252\t Valid Loss: 5.273461\n",
      "Epoch: 1823/2000\t Step: 45/54\t Train Loss: 3.654181\t Valid Loss: 5.359366\n",
      "Epoch: 1824/2000\t Step: 15/54\t Train Loss: 3.809329\t Valid Loss: 5.032234\n",
      "Epoch: 1824/2000\t Step: 30/54\t Train Loss: 3.762090\t Valid Loss: 5.030902\n",
      "Epoch: 1824/2000\t Step: 45/54\t Train Loss: 3.711744\t Valid Loss: 4.744421\n",
      "Epoch: 1825/2000\t Step: 15/54\t Train Loss: 3.752629\t Valid Loss: 4.733072\n",
      "Epoch: 1825/2000\t Step: 30/54\t Train Loss: 3.691460\t Valid Loss: 5.038877\n",
      "Epoch: 1825/2000\t Step: 45/54\t Train Loss: 3.756165\t Valid Loss: 5.303227\n",
      "Epoch: 1826/2000\t Step: 15/54\t Train Loss: 3.729765\t Valid Loss: 5.554764\n",
      "Epoch: 1826/2000\t Step: 30/54\t Train Loss: 3.741748\t Valid Loss: 5.468725\n",
      "Epoch: 1826/2000\t Step: 45/54\t Train Loss: 3.801076\t Valid Loss: 5.217834\n",
      "Epoch: 1827/2000\t Step: 15/54\t Train Loss: 3.761621\t Valid Loss: 5.253035\n",
      "Epoch: 1827/2000\t Step: 30/54\t Train Loss: 3.760992\t Valid Loss: 5.139493\n",
      "Epoch: 1827/2000\t Step: 45/54\t Train Loss: 3.789933\t Valid Loss: 5.356381\n",
      "Epoch: 1828/2000\t Step: 15/54\t Train Loss: 3.757939\t Valid Loss: 5.225881\n",
      "Epoch: 1828/2000\t Step: 30/54\t Train Loss: 3.742759\t Valid Loss: 5.335733\n",
      "Epoch: 1828/2000\t Step: 45/54\t Train Loss: 3.814718\t Valid Loss: 5.718177\n",
      "Epoch: 1829/2000\t Step: 15/54\t Train Loss: 3.735312\t Valid Loss: 5.549350\n",
      "Epoch: 1829/2000\t Step: 30/54\t Train Loss: 3.706059\t Valid Loss: 5.303910\n",
      "Epoch: 1829/2000\t Step: 45/54\t Train Loss: 3.791079\t Valid Loss: 5.535186\n",
      "Epoch: 1830/2000\t Step: 15/54\t Train Loss: 3.761566\t Valid Loss: 5.445601\n",
      "Epoch: 1830/2000\t Step: 30/54\t Train Loss: 3.678353\t Valid Loss: 5.310451\n",
      "Epoch: 1830/2000\t Step: 45/54\t Train Loss: 3.752179\t Valid Loss: 5.176230\n",
      "Epoch: 1831/2000\t Step: 15/54\t Train Loss: 3.733192\t Valid Loss: 5.001078\n",
      "Epoch: 1831/2000\t Step: 30/54\t Train Loss: 3.786736\t Valid Loss: 5.534401\n",
      "Epoch: 1831/2000\t Step: 45/54\t Train Loss: 3.731412\t Valid Loss: 4.951491\n",
      "Epoch: 1832/2000\t Step: 15/54\t Train Loss: 3.789367\t Valid Loss: 5.204940\n",
      "Epoch: 1832/2000\t Step: 30/54\t Train Loss: 3.704124\t Valid Loss: 5.158236\n",
      "Epoch: 1832/2000\t Step: 45/54\t Train Loss: 3.743549\t Valid Loss: 5.378084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1833/2000\t Step: 15/54\t Train Loss: 3.708720\t Valid Loss: 5.108384\n",
      "Epoch: 1833/2000\t Step: 30/54\t Train Loss: 3.725521\t Valid Loss: 5.006506\n",
      "Epoch: 1833/2000\t Step: 45/54\t Train Loss: 3.791429\t Valid Loss: 5.130333\n",
      "Epoch: 1834/2000\t Step: 15/54\t Train Loss: 3.715889\t Valid Loss: 5.021497\n",
      "Epoch: 1834/2000\t Step: 30/54\t Train Loss: 3.828247\t Valid Loss: 4.769099\n",
      "Epoch: 1834/2000\t Step: 45/54\t Train Loss: 3.712475\t Valid Loss: 5.126389\n",
      "Epoch: 1835/2000\t Step: 15/54\t Train Loss: 3.711889\t Valid Loss: 5.262728\n",
      "Epoch: 1835/2000\t Step: 30/54\t Train Loss: 3.792306\t Valid Loss: 5.644361\n",
      "Epoch: 1835/2000\t Step: 45/54\t Train Loss: 3.751816\t Valid Loss: 5.260059\n",
      "Epoch: 1836/2000\t Step: 15/54\t Train Loss: 3.729740\t Valid Loss: 5.608868\n",
      "Epoch: 1836/2000\t Step: 30/54\t Train Loss: 3.736626\t Valid Loss: 5.051267\n",
      "Epoch: 1836/2000\t Step: 45/54\t Train Loss: 3.731300\t Valid Loss: 5.382974\n",
      "Epoch: 1837/2000\t Step: 15/54\t Train Loss: 3.612171\t Valid Loss: 4.953766\n",
      "Epoch: 1837/2000\t Step: 30/54\t Train Loss: 3.792046\t Valid Loss: 4.992359\n",
      "Epoch: 1837/2000\t Step: 45/54\t Train Loss: 3.675409\t Valid Loss: 5.528474\n",
      "Epoch: 1838/2000\t Step: 15/54\t Train Loss: 3.712801\t Valid Loss: 5.415404\n",
      "Epoch: 1838/2000\t Step: 30/54\t Train Loss: 3.700465\t Valid Loss: 6.009503\n",
      "Epoch: 1838/2000\t Step: 45/54\t Train Loss: 3.715546\t Valid Loss: 5.432392\n",
      "Epoch: 1839/2000\t Step: 15/54\t Train Loss: 3.795198\t Valid Loss: 5.157431\n",
      "Epoch: 1839/2000\t Step: 30/54\t Train Loss: 3.680440\t Valid Loss: 5.567142\n",
      "Epoch: 1839/2000\t Step: 45/54\t Train Loss: 3.710440\t Valid Loss: 5.617545\n",
      "Epoch: 1840/2000\t Step: 15/54\t Train Loss: 3.703167\t Valid Loss: 5.453209\n",
      "Epoch: 1840/2000\t Step: 30/54\t Train Loss: 3.662341\t Valid Loss: 4.917004\n",
      "Epoch: 1840/2000\t Step: 45/54\t Train Loss: 3.712356\t Valid Loss: 5.360530\n",
      "Epoch: 1841/2000\t Step: 15/54\t Train Loss: 3.716437\t Valid Loss: 4.702482\n",
      "Epoch: 1841/2000\t Step: 30/54\t Train Loss: 3.783284\t Valid Loss: 5.099857\n",
      "Epoch: 1841/2000\t Step: 45/54\t Train Loss: 3.783192\t Valid Loss: 5.596664\n",
      "Epoch: 1842/2000\t Step: 15/54\t Train Loss: 3.728116\t Valid Loss: 5.186265\n",
      "Epoch: 1842/2000\t Step: 30/54\t Train Loss: 3.781013\t Valid Loss: 5.297543\n",
      "Epoch: 1842/2000\t Step: 45/54\t Train Loss: 3.799905\t Valid Loss: 5.148994\n",
      "Epoch: 1843/2000\t Step: 15/54\t Train Loss: 3.733795\t Valid Loss: 4.633958\n",
      "Epoch: 1843/2000\t Step: 30/54\t Train Loss: 3.726048\t Valid Loss: 5.070386\n",
      "Epoch: 1843/2000\t Step: 45/54\t Train Loss: 3.765250\t Valid Loss: 5.310449\n",
      "Epoch: 1844/2000\t Step: 15/54\t Train Loss: 3.746152\t Valid Loss: 4.874709\n",
      "Epoch: 1844/2000\t Step: 30/54\t Train Loss: 3.767118\t Valid Loss: 5.362561\n",
      "Epoch: 1844/2000\t Step: 45/54\t Train Loss: 3.644553\t Valid Loss: 6.353008\n",
      "Epoch: 1845/2000\t Step: 15/54\t Train Loss: 3.710885\t Valid Loss: 5.055600\n",
      "Epoch: 1845/2000\t Step: 30/54\t Train Loss: 3.732354\t Valid Loss: 5.432357\n",
      "Epoch: 1845/2000\t Step: 45/54\t Train Loss: 3.759500\t Valid Loss: 5.966015\n",
      "Epoch: 1846/2000\t Step: 15/54\t Train Loss: 3.770481\t Valid Loss: 4.902843\n",
      "Epoch: 1846/2000\t Step: 30/54\t Train Loss: 3.786781\t Valid Loss: 5.790756\n",
      "Epoch: 1846/2000\t Step: 45/54\t Train Loss: 3.735250\t Valid Loss: 5.049178\n",
      "Epoch: 1847/2000\t Step: 15/54\t Train Loss: 3.766179\t Valid Loss: 5.173450\n",
      "Epoch: 1847/2000\t Step: 30/54\t Train Loss: 3.778356\t Valid Loss: 5.302588\n",
      "Epoch: 1847/2000\t Step: 45/54\t Train Loss: 3.737835\t Valid Loss: 5.366616\n",
      "Epoch: 1848/2000\t Step: 15/54\t Train Loss: 3.719937\t Valid Loss: 5.202991\n",
      "Epoch: 1848/2000\t Step: 30/54\t Train Loss: 3.819159\t Valid Loss: 4.583856\n",
      "Epoch: 1848/2000\t Step: 45/54\t Train Loss: 3.712171\t Valid Loss: 5.303922\n",
      "Epoch: 1849/2000\t Step: 15/54\t Train Loss: 3.781100\t Valid Loss: 5.219650\n",
      "Epoch: 1849/2000\t Step: 30/54\t Train Loss: 3.747435\t Valid Loss: 5.013164\n",
      "Epoch: 1849/2000\t Step: 45/54\t Train Loss: 3.709631\t Valid Loss: 4.805308\n",
      "Epoch: 1850/2000\t Step: 15/54\t Train Loss: 3.795720\t Valid Loss: 5.352531\n",
      "Epoch: 1850/2000\t Step: 30/54\t Train Loss: 3.699922\t Valid Loss: 5.620192\n",
      "Epoch: 1850/2000\t Step: 45/54\t Train Loss: 3.769173\t Valid Loss: 5.436395\n",
      "Epoch: 1851/2000\t Step: 15/54\t Train Loss: 3.779515\t Valid Loss: 4.830120\n",
      "Epoch: 1851/2000\t Step: 30/54\t Train Loss: 3.766894\t Valid Loss: 4.967083\n",
      "Epoch: 1851/2000\t Step: 45/54\t Train Loss: 3.794103\t Valid Loss: 5.179178\n",
      "Epoch: 1852/2000\t Step: 15/54\t Train Loss: 3.720241\t Valid Loss: 5.090341\n",
      "Epoch: 1852/2000\t Step: 30/54\t Train Loss: 3.762312\t Valid Loss: 4.903685\n",
      "Epoch: 1852/2000\t Step: 45/54\t Train Loss: 3.737212\t Valid Loss: 5.386159\n",
      "Epoch: 1853/2000\t Step: 15/54\t Train Loss: 3.753889\t Valid Loss: 5.123927\n",
      "Epoch: 1853/2000\t Step: 30/54\t Train Loss: 3.755118\t Valid Loss: 5.474078\n",
      "Epoch: 1853/2000\t Step: 45/54\t Train Loss: 3.696690\t Valid Loss: 5.645103\n",
      "Epoch: 1854/2000\t Step: 15/54\t Train Loss: 3.806556\t Valid Loss: 6.298857\n",
      "Epoch: 1854/2000\t Step: 30/54\t Train Loss: 3.747502\t Valid Loss: 5.261833\n",
      "Epoch: 1854/2000\t Step: 45/54\t Train Loss: 3.790646\t Valid Loss: 4.899802\n",
      "Epoch: 1855/2000\t Step: 15/54\t Train Loss: 3.725110\t Valid Loss: 5.121278\n",
      "Epoch: 1855/2000\t Step: 30/54\t Train Loss: 3.746026\t Valid Loss: 5.619196\n",
      "Epoch: 1855/2000\t Step: 45/54\t Train Loss: 3.674979\t Valid Loss: 4.895048\n",
      "Epoch: 1856/2000\t Step: 15/54\t Train Loss: 3.696227\t Valid Loss: 4.898736\n",
      "Epoch: 1856/2000\t Step: 30/54\t Train Loss: 3.711525\t Valid Loss: 4.869166\n",
      "Epoch: 1856/2000\t Step: 45/54\t Train Loss: 3.749293\t Valid Loss: 5.013943\n",
      "Epoch: 1857/2000\t Step: 15/54\t Train Loss: 3.689760\t Valid Loss: 5.346398\n",
      "Epoch: 1857/2000\t Step: 30/54\t Train Loss: 3.713641\t Valid Loss: 5.343402\n",
      "Epoch: 1857/2000\t Step: 45/54\t Train Loss: 3.794523\t Valid Loss: 5.262760\n",
      "Epoch: 1858/2000\t Step: 15/54\t Train Loss: 3.646618\t Valid Loss: 5.263640\n",
      "Epoch: 1858/2000\t Step: 30/54\t Train Loss: 3.763741\t Valid Loss: 5.184845\n",
      "Epoch: 1858/2000\t Step: 45/54\t Train Loss: 3.720117\t Valid Loss: 5.707549\n",
      "Epoch: 1859/2000\t Step: 15/54\t Train Loss: 3.771131\t Valid Loss: 5.155485\n",
      "Epoch: 1859/2000\t Step: 30/54\t Train Loss: 3.751159\t Valid Loss: 4.945620\n",
      "Epoch: 1859/2000\t Step: 45/54\t Train Loss: 3.773664\t Valid Loss: 5.345308\n",
      "Epoch: 1860/2000\t Step: 15/54\t Train Loss: 3.758156\t Valid Loss: 4.859584\n",
      "Epoch: 1860/2000\t Step: 30/54\t Train Loss: 3.723413\t Valid Loss: 4.952000\n",
      "Epoch: 1860/2000\t Step: 45/54\t Train Loss: 3.711122\t Valid Loss: 5.236729\n",
      "Epoch: 1861/2000\t Step: 15/54\t Train Loss: 3.751495\t Valid Loss: 5.645586\n",
      "Epoch: 1861/2000\t Step: 30/54\t Train Loss: 3.786168\t Valid Loss: 5.213397\n",
      "Epoch: 1861/2000\t Step: 45/54\t Train Loss: 3.708884\t Valid Loss: 5.226951\n",
      "Epoch: 1862/2000\t Step: 15/54\t Train Loss: 3.711222\t Valid Loss: 5.133953\n",
      "Epoch: 1862/2000\t Step: 30/54\t Train Loss: 3.773195\t Valid Loss: 5.513201\n",
      "Epoch: 1862/2000\t Step: 45/54\t Train Loss: 3.815658\t Valid Loss: 5.101572\n",
      "Epoch: 1863/2000\t Step: 15/54\t Train Loss: 3.737622\t Valid Loss: 4.704734\n",
      "Epoch: 1863/2000\t Step: 30/54\t Train Loss: 3.772466\t Valid Loss: 5.062854\n",
      "Epoch: 1863/2000\t Step: 45/54\t Train Loss: 3.686663\t Valid Loss: 4.996114\n",
      "Epoch: 1864/2000\t Step: 15/54\t Train Loss: 3.754730\t Valid Loss: 5.069027\n",
      "Epoch: 1864/2000\t Step: 30/54\t Train Loss: 3.645268\t Valid Loss: 5.625694\n",
      "Epoch: 1864/2000\t Step: 45/54\t Train Loss: 3.735643\t Valid Loss: 5.232255\n",
      "Epoch: 1865/2000\t Step: 15/54\t Train Loss: 3.720861\t Valid Loss: 5.179137\n",
      "Epoch: 1865/2000\t Step: 30/54\t Train Loss: 3.772675\t Valid Loss: 5.266725\n",
      "Epoch: 1865/2000\t Step: 45/54\t Train Loss: 3.755762\t Valid Loss: 6.004192\n",
      "Epoch: 1866/2000\t Step: 15/54\t Train Loss: 3.699059\t Valid Loss: 6.008042\n",
      "Epoch: 1866/2000\t Step: 30/54\t Train Loss: 3.794640\t Valid Loss: 5.714918\n",
      "Epoch: 1866/2000\t Step: 45/54\t Train Loss: 3.744596\t Valid Loss: 5.326222\n",
      "Epoch: 1867/2000\t Step: 15/54\t Train Loss: 3.735717\t Valid Loss: 5.068588\n",
      "Epoch: 1867/2000\t Step: 30/54\t Train Loss: 3.705517\t Valid Loss: 5.258228\n",
      "Epoch: 1867/2000\t Step: 45/54\t Train Loss: 3.768113\t Valid Loss: 4.667345\n",
      "Epoch: 1868/2000\t Step: 15/54\t Train Loss: 3.702607\t Valid Loss: 5.142373\n",
      "Epoch: 1868/2000\t Step: 30/54\t Train Loss: 3.730881\t Valid Loss: 5.042067\n",
      "Epoch: 1868/2000\t Step: 45/54\t Train Loss: 3.784783\t Valid Loss: 5.099299\n",
      "Epoch: 1869/2000\t Step: 15/54\t Train Loss: 3.778332\t Valid Loss: 4.872574\n",
      "Epoch: 1869/2000\t Step: 30/54\t Train Loss: 3.694636\t Valid Loss: 5.351468\n",
      "Epoch: 1869/2000\t Step: 45/54\t Train Loss: 3.738100\t Valid Loss: 5.012317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1870/2000\t Step: 15/54\t Train Loss: 3.787904\t Valid Loss: 4.647089\n",
      "Epoch: 1870/2000\t Step: 30/54\t Train Loss: 3.782755\t Valid Loss: 5.020447\n",
      "Epoch: 1870/2000\t Step: 45/54\t Train Loss: 3.689430\t Valid Loss: 5.115451\n",
      "Epoch: 1871/2000\t Step: 15/54\t Train Loss: 3.755778\t Valid Loss: 5.227292\n",
      "Epoch: 1871/2000\t Step: 30/54\t Train Loss: 3.750210\t Valid Loss: 4.968622\n",
      "Epoch: 1871/2000\t Step: 45/54\t Train Loss: 3.774143\t Valid Loss: 5.490344\n",
      "Epoch: 1872/2000\t Step: 15/54\t Train Loss: 3.809247\t Valid Loss: 5.149003\n",
      "Epoch: 1872/2000\t Step: 30/54\t Train Loss: 3.709925\t Valid Loss: 4.895420\n",
      "Epoch: 1872/2000\t Step: 45/54\t Train Loss: 3.735562\t Valid Loss: 5.486351\n",
      "Epoch: 1873/2000\t Step: 15/54\t Train Loss: 3.757150\t Valid Loss: 4.992097\n",
      "Epoch: 1873/2000\t Step: 30/54\t Train Loss: 3.761474\t Valid Loss: 5.342152\n",
      "Epoch: 1873/2000\t Step: 45/54\t Train Loss: 3.682769\t Valid Loss: 4.747658\n",
      "Epoch: 1874/2000\t Step: 15/54\t Train Loss: 3.763766\t Valid Loss: 5.232149\n",
      "Epoch: 1874/2000\t Step: 30/54\t Train Loss: 3.794590\t Valid Loss: 5.372034\n",
      "Epoch: 1874/2000\t Step: 45/54\t Train Loss: 3.676510\t Valid Loss: 5.197827\n",
      "Epoch: 1875/2000\t Step: 15/54\t Train Loss: 3.664254\t Valid Loss: 5.638354\n",
      "Epoch: 1875/2000\t Step: 30/54\t Train Loss: 3.790164\t Valid Loss: 4.798408\n",
      "Epoch: 1875/2000\t Step: 45/54\t Train Loss: 3.678020\t Valid Loss: 5.027731\n",
      "Epoch: 1876/2000\t Step: 15/54\t Train Loss: 3.699505\t Valid Loss: 5.761677\n",
      "Epoch: 1876/2000\t Step: 30/54\t Train Loss: 3.727287\t Valid Loss: 4.996290\n",
      "Epoch: 1876/2000\t Step: 45/54\t Train Loss: 3.736374\t Valid Loss: 4.818378\n",
      "Epoch: 1877/2000\t Step: 15/54\t Train Loss: 3.693945\t Valid Loss: 4.920959\n",
      "Epoch: 1877/2000\t Step: 30/54\t Train Loss: 3.697027\t Valid Loss: 5.430781\n",
      "Epoch: 1877/2000\t Step: 45/54\t Train Loss: 3.756729\t Valid Loss: 5.271699\n",
      "Epoch: 1878/2000\t Step: 15/54\t Train Loss: 3.693556\t Valid Loss: 5.062799\n",
      "Epoch: 1878/2000\t Step: 30/54\t Train Loss: 3.726073\t Valid Loss: 5.357564\n",
      "Epoch: 1878/2000\t Step: 45/54\t Train Loss: 3.726148\t Valid Loss: 5.167649\n",
      "Epoch: 1879/2000\t Step: 15/54\t Train Loss: 3.803529\t Valid Loss: 4.529693\n",
      "Epoch: 1879/2000\t Step: 30/54\t Train Loss: 3.739847\t Valid Loss: 4.608664\n",
      "Epoch: 1879/2000\t Step: 45/54\t Train Loss: 3.740031\t Valid Loss: 5.277598\n",
      "Epoch: 1880/2000\t Step: 15/54\t Train Loss: 3.747696\t Valid Loss: 5.516699\n",
      "Epoch: 1880/2000\t Step: 30/54\t Train Loss: 3.770625\t Valid Loss: 5.530118\n",
      "Epoch: 1880/2000\t Step: 45/54\t Train Loss: 3.708994\t Valid Loss: 4.839536\n",
      "Epoch: 1881/2000\t Step: 15/54\t Train Loss: 3.780981\t Valid Loss: 5.778095\n",
      "Epoch: 1881/2000\t Step: 30/54\t Train Loss: 3.732276\t Valid Loss: 5.415111\n",
      "Epoch: 1881/2000\t Step: 45/54\t Train Loss: 3.701753\t Valid Loss: 5.116822\n",
      "Epoch: 1882/2000\t Step: 15/54\t Train Loss: 3.684482\t Valid Loss: 5.384438\n",
      "Epoch: 1882/2000\t Step: 30/54\t Train Loss: 3.807160\t Valid Loss: 5.652289\n",
      "Epoch: 1882/2000\t Step: 45/54\t Train Loss: 3.721541\t Valid Loss: 5.293960\n",
      "Epoch: 1883/2000\t Step: 15/54\t Train Loss: 3.692536\t Valid Loss: 5.374906\n",
      "Epoch: 1883/2000\t Step: 30/54\t Train Loss: 3.727363\t Valid Loss: 5.289878\n",
      "Epoch: 1883/2000\t Step: 45/54\t Train Loss: 3.786441\t Valid Loss: 4.714211\n",
      "Epoch: 1884/2000\t Step: 15/54\t Train Loss: 3.693258\t Valid Loss: 5.401516\n",
      "Epoch: 1884/2000\t Step: 30/54\t Train Loss: 3.753662\t Valid Loss: 5.186300\n",
      "Epoch: 1884/2000\t Step: 45/54\t Train Loss: 3.704170\t Valid Loss: 5.559121\n",
      "Epoch: 1885/2000\t Step: 15/54\t Train Loss: 3.699495\t Valid Loss: 5.435348\n",
      "Epoch: 1885/2000\t Step: 30/54\t Train Loss: 3.717600\t Valid Loss: 4.903287\n",
      "Epoch: 1885/2000\t Step: 45/54\t Train Loss: 3.736452\t Valid Loss: 5.227064\n",
      "Epoch: 1886/2000\t Step: 15/54\t Train Loss: 3.645087\t Valid Loss: 4.920059\n",
      "Epoch: 1886/2000\t Step: 30/54\t Train Loss: 3.765186\t Valid Loss: 5.188798\n",
      "Epoch: 1886/2000\t Step: 45/54\t Train Loss: 3.768439\t Valid Loss: 4.998401\n",
      "Epoch: 1887/2000\t Step: 15/54\t Train Loss: 3.769007\t Valid Loss: 4.966943\n",
      "Epoch: 1887/2000\t Step: 30/54\t Train Loss: 3.768395\t Valid Loss: 5.292106\n",
      "Epoch: 1887/2000\t Step: 45/54\t Train Loss: 3.786458\t Valid Loss: 5.587728\n",
      "Epoch: 1888/2000\t Step: 15/54\t Train Loss: 3.775275\t Valid Loss: 4.738176\n",
      "Epoch: 1888/2000\t Step: 30/54\t Train Loss: 3.712972\t Valid Loss: 5.241819\n",
      "Epoch: 1888/2000\t Step: 45/54\t Train Loss: 3.791284\t Valid Loss: 4.625830\n",
      "Epoch: 1889/2000\t Step: 15/54\t Train Loss: 3.756805\t Valid Loss: 5.804059\n",
      "Epoch: 1889/2000\t Step: 30/54\t Train Loss: 3.700904\t Valid Loss: 5.346139\n",
      "Epoch: 1889/2000\t Step: 45/54\t Train Loss: 3.745497\t Valid Loss: 5.196926\n",
      "Epoch: 1890/2000\t Step: 15/54\t Train Loss: 3.685227\t Valid Loss: 4.998972\n",
      "Epoch: 1890/2000\t Step: 30/54\t Train Loss: 3.684826\t Valid Loss: 5.339496\n",
      "Epoch: 1890/2000\t Step: 45/54\t Train Loss: 3.795546\t Valid Loss: 5.412427\n",
      "Epoch: 1891/2000\t Step: 15/54\t Train Loss: 3.667731\t Valid Loss: 5.533028\n",
      "Epoch: 1891/2000\t Step: 30/54\t Train Loss: 3.757021\t Valid Loss: 5.004712\n",
      "Epoch: 1891/2000\t Step: 45/54\t Train Loss: 3.772529\t Valid Loss: 5.464827\n",
      "Epoch: 1892/2000\t Step: 15/54\t Train Loss: 3.800313\t Valid Loss: 5.085069\n",
      "Epoch: 1892/2000\t Step: 30/54\t Train Loss: 3.782662\t Valid Loss: 5.149223\n",
      "Epoch: 1892/2000\t Step: 45/54\t Train Loss: 3.733692\t Valid Loss: 5.272386\n",
      "Epoch: 1893/2000\t Step: 15/54\t Train Loss: 3.790842\t Valid Loss: 5.070029\n",
      "Epoch: 1893/2000\t Step: 30/54\t Train Loss: 3.831415\t Valid Loss: 5.360771\n",
      "Epoch: 1893/2000\t Step: 45/54\t Train Loss: 3.807923\t Valid Loss: 5.745836\n",
      "Epoch: 1894/2000\t Step: 15/54\t Train Loss: 3.723327\t Valid Loss: 4.980180\n",
      "Epoch: 1894/2000\t Step: 30/54\t Train Loss: 3.727829\t Valid Loss: 5.000490\n",
      "Epoch: 1894/2000\t Step: 45/54\t Train Loss: 3.751969\t Valid Loss: 4.819127\n",
      "Epoch: 1895/2000\t Step: 15/54\t Train Loss: 3.768265\t Valid Loss: 4.845758\n",
      "Epoch: 1895/2000\t Step: 30/54\t Train Loss: 3.759026\t Valid Loss: 4.713046\n",
      "Epoch: 1895/2000\t Step: 45/54\t Train Loss: 3.756213\t Valid Loss: 4.948020\n",
      "Epoch: 1896/2000\t Step: 15/54\t Train Loss: 3.637530\t Valid Loss: 5.881017\n",
      "Epoch: 1896/2000\t Step: 30/54\t Train Loss: 3.868037\t Valid Loss: 5.359490\n",
      "Epoch: 1896/2000\t Step: 45/54\t Train Loss: 3.745719\t Valid Loss: 5.362936\n",
      "Epoch: 1897/2000\t Step: 15/54\t Train Loss: 3.712674\t Valid Loss: 5.112878\n",
      "Epoch: 1897/2000\t Step: 30/54\t Train Loss: 3.768513\t Valid Loss: 5.052470\n",
      "Epoch: 1897/2000\t Step: 45/54\t Train Loss: 3.720708\t Valid Loss: 5.030177\n",
      "Epoch: 1898/2000\t Step: 15/54\t Train Loss: 3.694435\t Valid Loss: 5.551111\n",
      "Epoch: 1898/2000\t Step: 30/54\t Train Loss: 3.781903\t Valid Loss: 5.552461\n",
      "Epoch: 1898/2000\t Step: 45/54\t Train Loss: 3.769486\t Valid Loss: 5.279408\n",
      "Epoch: 1899/2000\t Step: 15/54\t Train Loss: 3.814926\t Valid Loss: 4.770245\n",
      "Epoch: 1899/2000\t Step: 30/54\t Train Loss: 3.795987\t Valid Loss: 5.125762\n",
      "Epoch: 1899/2000\t Step: 45/54\t Train Loss: 3.770863\t Valid Loss: 5.241977\n",
      "Epoch: 1900/2000\t Step: 15/54\t Train Loss: 3.775865\t Valid Loss: 5.306966\n",
      "Epoch: 1900/2000\t Step: 30/54\t Train Loss: 3.716870\t Valid Loss: 5.223628\n",
      "Epoch: 1900/2000\t Step: 45/54\t Train Loss: 3.740705\t Valid Loss: 5.456986\n",
      "Epoch: 1901/2000\t Step: 15/54\t Train Loss: 3.712835\t Valid Loss: 5.045067\n",
      "Epoch: 1901/2000\t Step: 30/54\t Train Loss: 3.699968\t Valid Loss: 5.054641\n",
      "Epoch: 1901/2000\t Step: 45/54\t Train Loss: 3.791948\t Valid Loss: 4.824231\n",
      "Epoch: 1902/2000\t Step: 15/54\t Train Loss: 3.774319\t Valid Loss: 4.874918\n",
      "Epoch: 1902/2000\t Step: 30/54\t Train Loss: 3.795671\t Valid Loss: 5.031247\n",
      "Epoch: 1902/2000\t Step: 45/54\t Train Loss: 3.707593\t Valid Loss: 5.270247\n",
      "Epoch: 1903/2000\t Step: 15/54\t Train Loss: 3.675900\t Valid Loss: 5.188927\n",
      "Epoch: 1903/2000\t Step: 30/54\t Train Loss: 3.813605\t Valid Loss: 5.444028\n",
      "Epoch: 1903/2000\t Step: 45/54\t Train Loss: 3.711020\t Valid Loss: 5.843834\n",
      "Epoch: 1904/2000\t Step: 15/54\t Train Loss: 3.773734\t Valid Loss: 5.200704\n",
      "Epoch: 1904/2000\t Step: 30/54\t Train Loss: 3.690320\t Valid Loss: 5.068715\n",
      "Epoch: 1904/2000\t Step: 45/54\t Train Loss: 3.741054\t Valid Loss: 5.464754\n",
      "Epoch: 1905/2000\t Step: 15/54\t Train Loss: 3.694983\t Valid Loss: 5.439878\n",
      "Epoch: 1905/2000\t Step: 30/54\t Train Loss: 3.796017\t Valid Loss: 5.051663\n",
      "Epoch: 1905/2000\t Step: 45/54\t Train Loss: 3.750016\t Valid Loss: 5.387695\n",
      "Epoch: 1906/2000\t Step: 15/54\t Train Loss: 3.718304\t Valid Loss: 5.429289\n",
      "Epoch: 1906/2000\t Step: 30/54\t Train Loss: 3.817911\t Valid Loss: 5.501049\n",
      "Epoch: 1906/2000\t Step: 45/54\t Train Loss: 3.777192\t Valid Loss: 5.760433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1907/2000\t Step: 15/54\t Train Loss: 3.806714\t Valid Loss: 5.551778\n",
      "Epoch: 1907/2000\t Step: 30/54\t Train Loss: 3.800908\t Valid Loss: 5.344654\n",
      "Epoch: 1907/2000\t Step: 45/54\t Train Loss: 3.751102\t Valid Loss: 5.052199\n",
      "Epoch: 1908/2000\t Step: 15/54\t Train Loss: 3.808175\t Valid Loss: 5.003663\n",
      "Epoch: 1908/2000\t Step: 30/54\t Train Loss: 3.731591\t Valid Loss: 5.175417\n",
      "Epoch: 1908/2000\t Step: 45/54\t Train Loss: 3.734883\t Valid Loss: 4.856093\n",
      "Epoch: 1909/2000\t Step: 15/54\t Train Loss: 3.645395\t Valid Loss: 5.356672\n",
      "Epoch: 1909/2000\t Step: 30/54\t Train Loss: 3.726873\t Valid Loss: 5.735622\n",
      "Epoch: 1909/2000\t Step: 45/54\t Train Loss: 3.753860\t Valid Loss: 5.378694\n",
      "Epoch: 1910/2000\t Step: 15/54\t Train Loss: 3.843944\t Valid Loss: 5.177164\n",
      "Epoch: 1910/2000\t Step: 30/54\t Train Loss: 3.749625\t Valid Loss: 4.824211\n",
      "Epoch: 1910/2000\t Step: 45/54\t Train Loss: 3.704025\t Valid Loss: 4.870733\n",
      "Epoch: 1911/2000\t Step: 15/54\t Train Loss: 3.732897\t Valid Loss: 4.764208\n",
      "Epoch: 1911/2000\t Step: 30/54\t Train Loss: 3.806427\t Valid Loss: 5.353389\n",
      "Epoch: 1911/2000\t Step: 45/54\t Train Loss: 3.760115\t Valid Loss: 5.104078\n",
      "Epoch: 1912/2000\t Step: 15/54\t Train Loss: 3.715900\t Valid Loss: 5.122037\n",
      "Epoch: 1912/2000\t Step: 30/54\t Train Loss: 3.767388\t Valid Loss: 5.137268\n",
      "Epoch: 1912/2000\t Step: 45/54\t Train Loss: 3.691048\t Valid Loss: 5.315695\n",
      "Epoch: 1913/2000\t Step: 15/54\t Train Loss: 3.786715\t Valid Loss: 5.246405\n",
      "Epoch: 1913/2000\t Step: 30/54\t Train Loss: 3.674256\t Valid Loss: 5.616164\n",
      "Epoch: 1913/2000\t Step: 45/54\t Train Loss: 3.711872\t Valid Loss: 5.263385\n",
      "Epoch: 1914/2000\t Step: 15/54\t Train Loss: 3.746314\t Valid Loss: 5.249911\n",
      "Epoch: 1914/2000\t Step: 30/54\t Train Loss: 3.696262\t Valid Loss: 5.307583\n",
      "Epoch: 1914/2000\t Step: 45/54\t Train Loss: 3.714084\t Valid Loss: 5.763688\n",
      "Epoch: 1915/2000\t Step: 15/54\t Train Loss: 3.740969\t Valid Loss: 5.343577\n",
      "Epoch: 1915/2000\t Step: 30/54\t Train Loss: 3.689847\t Valid Loss: 5.269594\n",
      "Epoch: 1915/2000\t Step: 45/54\t Train Loss: 3.678242\t Valid Loss: 5.089348\n",
      "Epoch: 1916/2000\t Step: 15/54\t Train Loss: 3.696703\t Valid Loss: 5.258612\n",
      "Epoch: 1916/2000\t Step: 30/54\t Train Loss: 3.730908\t Valid Loss: 4.978419\n",
      "Epoch: 1916/2000\t Step: 45/54\t Train Loss: 3.742547\t Valid Loss: 5.266843\n",
      "Epoch: 1917/2000\t Step: 15/54\t Train Loss: 3.795285\t Valid Loss: 4.870242\n",
      "Epoch: 1917/2000\t Step: 30/54\t Train Loss: 3.739932\t Valid Loss: 5.455871\n",
      "Epoch: 1917/2000\t Step: 45/54\t Train Loss: 3.762829\t Valid Loss: 5.011008\n",
      "Epoch: 1918/2000\t Step: 15/54\t Train Loss: 3.777526\t Valid Loss: 5.328899\n",
      "Epoch: 1918/2000\t Step: 30/54\t Train Loss: 3.740541\t Valid Loss: 5.202832\n",
      "Epoch: 1918/2000\t Step: 45/54\t Train Loss: 3.746965\t Valid Loss: 5.641513\n",
      "Epoch: 1919/2000\t Step: 15/54\t Train Loss: 3.729289\t Valid Loss: 4.878922\n",
      "Epoch: 1919/2000\t Step: 30/54\t Train Loss: 3.746346\t Valid Loss: 5.042361\n",
      "Epoch: 1919/2000\t Step: 45/54\t Train Loss: 3.763473\t Valid Loss: 4.769940\n",
      "Epoch: 1920/2000\t Step: 15/54\t Train Loss: 3.766514\t Valid Loss: 5.402301\n",
      "Epoch: 1920/2000\t Step: 30/54\t Train Loss: 3.724009\t Valid Loss: 5.061005\n",
      "Epoch: 1920/2000\t Step: 45/54\t Train Loss: 3.750980\t Valid Loss: 5.143522\n",
      "Epoch: 1921/2000\t Step: 15/54\t Train Loss: 3.771079\t Valid Loss: 5.134896\n",
      "Epoch: 1921/2000\t Step: 30/54\t Train Loss: 3.781757\t Valid Loss: 5.135927\n",
      "Epoch: 1921/2000\t Step: 45/54\t Train Loss: 3.770074\t Valid Loss: 5.725694\n",
      "Epoch: 1922/2000\t Step: 15/54\t Train Loss: 3.748464\t Valid Loss: 5.173793\n",
      "Epoch: 1922/2000\t Step: 30/54\t Train Loss: 3.675467\t Valid Loss: 5.468982\n",
      "Epoch: 1922/2000\t Step: 45/54\t Train Loss: 3.681285\t Valid Loss: 5.300686\n",
      "Epoch: 1923/2000\t Step: 15/54\t Train Loss: 3.739835\t Valid Loss: 5.174007\n",
      "Epoch: 1923/2000\t Step: 30/54\t Train Loss: 3.767234\t Valid Loss: 4.956532\n",
      "Epoch: 1923/2000\t Step: 45/54\t Train Loss: 3.746810\t Valid Loss: 4.847080\n",
      "Epoch: 1924/2000\t Step: 15/54\t Train Loss: 3.815740\t Valid Loss: 4.794493\n",
      "Epoch: 1924/2000\t Step: 30/54\t Train Loss: 3.810013\t Valid Loss: 4.876955\n",
      "Epoch: 1924/2000\t Step: 45/54\t Train Loss: 3.691701\t Valid Loss: 5.398198\n",
      "Epoch: 1925/2000\t Step: 15/54\t Train Loss: 3.718123\t Valid Loss: 5.244269\n",
      "Epoch: 1925/2000\t Step: 30/54\t Train Loss: 3.809813\t Valid Loss: 5.214740\n",
      "Epoch: 1925/2000\t Step: 45/54\t Train Loss: 3.757057\t Valid Loss: 5.596201\n",
      "Epoch: 1926/2000\t Step: 15/54\t Train Loss: 3.770531\t Valid Loss: 4.846234\n",
      "Epoch: 1926/2000\t Step: 30/54\t Train Loss: 3.709389\t Valid Loss: 5.248956\n",
      "Epoch: 1926/2000\t Step: 45/54\t Train Loss: 3.738438\t Valid Loss: 5.376266\n",
      "Epoch: 1927/2000\t Step: 15/54\t Train Loss: 3.741478\t Valid Loss: 5.016980\n",
      "Epoch: 1927/2000\t Step: 30/54\t Train Loss: 3.787694\t Valid Loss: 4.973401\n",
      "Epoch: 1927/2000\t Step: 45/54\t Train Loss: 3.687689\t Valid Loss: 5.050365\n",
      "Epoch: 1928/2000\t Step: 15/54\t Train Loss: 3.719111\t Valid Loss: 5.153071\n",
      "Epoch: 1928/2000\t Step: 30/54\t Train Loss: 3.741740\t Valid Loss: 5.048212\n",
      "Epoch: 1928/2000\t Step: 45/54\t Train Loss: 3.694715\t Valid Loss: 4.561042\n",
      "Epoch: 1929/2000\t Step: 15/54\t Train Loss: 3.686183\t Valid Loss: 5.344528\n",
      "Epoch: 1929/2000\t Step: 30/54\t Train Loss: 3.687942\t Valid Loss: 5.117157\n",
      "Epoch: 1929/2000\t Step: 45/54\t Train Loss: 3.700490\t Valid Loss: 5.318102\n",
      "Epoch: 1930/2000\t Step: 15/54\t Train Loss: 3.769299\t Valid Loss: 5.027851\n",
      "Epoch: 1930/2000\t Step: 30/54\t Train Loss: 3.720763\t Valid Loss: 5.229329\n",
      "Epoch: 1930/2000\t Step: 45/54\t Train Loss: 3.725523\t Valid Loss: 5.562280\n",
      "Epoch: 1931/2000\t Step: 15/54\t Train Loss: 3.739839\t Valid Loss: 5.410540\n",
      "Epoch: 1931/2000\t Step: 30/54\t Train Loss: 3.749366\t Valid Loss: 5.260869\n",
      "Epoch: 1931/2000\t Step: 45/54\t Train Loss: 3.727375\t Valid Loss: 5.292790\n",
      "Epoch: 1932/2000\t Step: 15/54\t Train Loss: 3.605428\t Valid Loss: 5.499382\n",
      "Epoch: 1932/2000\t Step: 30/54\t Train Loss: 3.729220\t Valid Loss: 5.179368\n",
      "Epoch: 1932/2000\t Step: 45/54\t Train Loss: 3.740813\t Valid Loss: 5.744193\n",
      "Epoch: 1933/2000\t Step: 15/54\t Train Loss: 3.773507\t Valid Loss: 4.801627\n",
      "Epoch: 1933/2000\t Step: 30/54\t Train Loss: 3.739414\t Valid Loss: 4.954339\n",
      "Epoch: 1933/2000\t Step: 45/54\t Train Loss: 3.808973\t Valid Loss: 4.873320\n",
      "Epoch: 1934/2000\t Step: 15/54\t Train Loss: 3.793988\t Valid Loss: 5.327556\n",
      "Epoch: 1934/2000\t Step: 30/54\t Train Loss: 3.734697\t Valid Loss: 5.416219\n",
      "Epoch: 1934/2000\t Step: 45/54\t Train Loss: 3.729157\t Valid Loss: 5.355913\n",
      "Epoch: 1935/2000\t Step: 15/54\t Train Loss: 3.654946\t Valid Loss: 5.239125\n",
      "Epoch: 1935/2000\t Step: 30/54\t Train Loss: 3.765792\t Valid Loss: 5.443098\n",
      "Epoch: 1935/2000\t Step: 45/54\t Train Loss: 3.834102\t Valid Loss: 5.183362\n",
      "Epoch: 1936/2000\t Step: 15/54\t Train Loss: 3.770795\t Valid Loss: 5.008406\n",
      "Epoch: 1936/2000\t Step: 30/54\t Train Loss: 3.759619\t Valid Loss: 5.716880\n",
      "Epoch: 1936/2000\t Step: 45/54\t Train Loss: 3.709066\t Valid Loss: 5.157389\n",
      "Epoch: 1937/2000\t Step: 15/54\t Train Loss: 3.648584\t Valid Loss: 5.242516\n",
      "Epoch: 1937/2000\t Step: 30/54\t Train Loss: 3.735507\t Valid Loss: 5.324872\n",
      "Epoch: 1937/2000\t Step: 45/54\t Train Loss: 3.768578\t Valid Loss: 5.242066\n",
      "Epoch: 1938/2000\t Step: 15/54\t Train Loss: 3.786863\t Valid Loss: 5.455234\n",
      "Epoch: 1938/2000\t Step: 30/54\t Train Loss: 3.718944\t Valid Loss: 5.249577\n",
      "Epoch: 1938/2000\t Step: 45/54\t Train Loss: 3.708182\t Valid Loss: 4.978639\n",
      "Epoch: 1939/2000\t Step: 15/54\t Train Loss: 3.714064\t Valid Loss: 5.273371\n",
      "Epoch: 1939/2000\t Step: 30/54\t Train Loss: 3.750365\t Valid Loss: 6.492031\n",
      "Epoch: 1939/2000\t Step: 45/54\t Train Loss: 3.712386\t Valid Loss: 5.779817\n",
      "Epoch: 1940/2000\t Step: 15/54\t Train Loss: 3.767309\t Valid Loss: 4.868114\n",
      "Epoch: 1940/2000\t Step: 30/54\t Train Loss: 3.822644\t Valid Loss: 4.857231\n",
      "Epoch: 1940/2000\t Step: 45/54\t Train Loss: 3.748017\t Valid Loss: 5.115055\n",
      "Epoch: 1941/2000\t Step: 15/54\t Train Loss: 3.670005\t Valid Loss: 5.417726\n",
      "Epoch: 1941/2000\t Step: 30/54\t Train Loss: 3.697302\t Valid Loss: 5.497928\n",
      "Epoch: 1941/2000\t Step: 45/54\t Train Loss: 3.693939\t Valid Loss: 5.899606\n",
      "Epoch: 1942/2000\t Step: 15/54\t Train Loss: 3.696789\t Valid Loss: 5.179499\n",
      "Epoch: 1942/2000\t Step: 30/54\t Train Loss: 3.727580\t Valid Loss: 5.446715\n",
      "Epoch: 1942/2000\t Step: 45/54\t Train Loss: 3.736322\t Valid Loss: 5.180767\n",
      "Epoch: 1943/2000\t Step: 15/54\t Train Loss: 3.749923\t Valid Loss: 4.677056\n",
      "Epoch: 1943/2000\t Step: 30/54\t Train Loss: 3.763144\t Valid Loss: 5.544396\n",
      "Epoch: 1943/2000\t Step: 45/54\t Train Loss: 3.731505\t Valid Loss: 5.110274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1944/2000\t Step: 15/54\t Train Loss: 3.774705\t Valid Loss: 4.840871\n",
      "Epoch: 1944/2000\t Step: 30/54\t Train Loss: 3.740151\t Valid Loss: 5.240195\n",
      "Epoch: 1944/2000\t Step: 45/54\t Train Loss: 3.794020\t Valid Loss: 5.833493\n",
      "Epoch: 1945/2000\t Step: 15/54\t Train Loss: 3.774089\t Valid Loss: 5.094897\n",
      "Epoch: 1945/2000\t Step: 30/54\t Train Loss: 3.802347\t Valid Loss: 5.273247\n",
      "Epoch: 1945/2000\t Step: 45/54\t Train Loss: 3.796080\t Valid Loss: 4.811233\n",
      "Epoch: 1946/2000\t Step: 15/54\t Train Loss: 3.691042\t Valid Loss: 6.027079\n",
      "Epoch: 1946/2000\t Step: 30/54\t Train Loss: 3.713694\t Valid Loss: 5.253168\n",
      "Epoch: 1946/2000\t Step: 45/54\t Train Loss: 3.679878\t Valid Loss: 5.188564\n",
      "Epoch: 1947/2000\t Step: 15/54\t Train Loss: 3.818774\t Valid Loss: 4.878452\n",
      "Epoch: 1947/2000\t Step: 30/54\t Train Loss: 3.748717\t Valid Loss: 5.053751\n",
      "Epoch: 1947/2000\t Step: 45/54\t Train Loss: 3.738909\t Valid Loss: 5.526461\n",
      "Epoch: 1948/2000\t Step: 15/54\t Train Loss: 3.737851\t Valid Loss: 4.968030\n",
      "Epoch: 1948/2000\t Step: 30/54\t Train Loss: 3.749705\t Valid Loss: 5.014096\n",
      "Epoch: 1948/2000\t Step: 45/54\t Train Loss: 3.742817\t Valid Loss: 5.504783\n",
      "Epoch: 1949/2000\t Step: 15/54\t Train Loss: 3.757772\t Valid Loss: 5.593955\n",
      "Epoch: 1949/2000\t Step: 30/54\t Train Loss: 3.797738\t Valid Loss: 4.868849\n",
      "Epoch: 1949/2000\t Step: 45/54\t Train Loss: 3.701756\t Valid Loss: 4.903806\n",
      "Epoch: 1950/2000\t Step: 15/54\t Train Loss: 3.767458\t Valid Loss: 5.494272\n",
      "Epoch: 1950/2000\t Step: 30/54\t Train Loss: 3.782020\t Valid Loss: 5.510227\n",
      "Epoch: 1950/2000\t Step: 45/54\t Train Loss: 3.749381\t Valid Loss: 5.152116\n",
      "Epoch: 1951/2000\t Step: 15/54\t Train Loss: 3.793708\t Valid Loss: 5.009514\n",
      "Epoch: 1951/2000\t Step: 30/54\t Train Loss: 3.750674\t Valid Loss: 5.132102\n",
      "Epoch: 1951/2000\t Step: 45/54\t Train Loss: 3.728886\t Valid Loss: 5.277707\n",
      "Epoch: 1952/2000\t Step: 15/54\t Train Loss: 3.800157\t Valid Loss: 5.058397\n",
      "Epoch: 1952/2000\t Step: 30/54\t Train Loss: 3.724097\t Valid Loss: 5.059728\n",
      "Epoch: 1952/2000\t Step: 45/54\t Train Loss: 3.723780\t Valid Loss: 4.769374\n",
      "Epoch: 1953/2000\t Step: 15/54\t Train Loss: 3.742761\t Valid Loss: 6.039606\n",
      "Epoch: 1953/2000\t Step: 30/54\t Train Loss: 3.754196\t Valid Loss: 4.695779\n",
      "Epoch: 1953/2000\t Step: 45/54\t Train Loss: 3.717591\t Valid Loss: 5.277702\n",
      "Epoch: 1954/2000\t Step: 15/54\t Train Loss: 3.760691\t Valid Loss: 5.559737\n",
      "Epoch: 1954/2000\t Step: 30/54\t Train Loss: 3.818349\t Valid Loss: 5.574752\n",
      "Epoch: 1954/2000\t Step: 45/54\t Train Loss: 3.754595\t Valid Loss: 4.867734\n",
      "Epoch: 1955/2000\t Step: 15/54\t Train Loss: 3.758777\t Valid Loss: 5.420292\n",
      "Epoch: 1955/2000\t Step: 30/54\t Train Loss: 3.845645\t Valid Loss: 4.879764\n",
      "Epoch: 1955/2000\t Step: 45/54\t Train Loss: 3.711123\t Valid Loss: 5.197074\n",
      "Epoch: 1956/2000\t Step: 15/54\t Train Loss: 3.738917\t Valid Loss: 5.235976\n",
      "Epoch: 1956/2000\t Step: 30/54\t Train Loss: 3.685632\t Valid Loss: 5.030379\n",
      "Epoch: 1956/2000\t Step: 45/54\t Train Loss: 3.694536\t Valid Loss: 5.721531\n",
      "Epoch: 1957/2000\t Step: 15/54\t Train Loss: 3.732771\t Valid Loss: 5.096155\n",
      "Epoch: 1957/2000\t Step: 30/54\t Train Loss: 3.724572\t Valid Loss: 5.382689\n",
      "Epoch: 1957/2000\t Step: 45/54\t Train Loss: 3.714020\t Valid Loss: 5.173051\n",
      "Epoch: 1958/2000\t Step: 15/54\t Train Loss: 3.809497\t Valid Loss: 5.111895\n",
      "Epoch: 1958/2000\t Step: 30/54\t Train Loss: 3.737600\t Valid Loss: 5.095292\n",
      "Epoch: 1958/2000\t Step: 45/54\t Train Loss: 3.735702\t Valid Loss: 5.544408\n",
      "Epoch: 1959/2000\t Step: 15/54\t Train Loss: 3.690991\t Valid Loss: 5.383310\n",
      "Epoch: 1959/2000\t Step: 30/54\t Train Loss: 3.707774\t Valid Loss: 5.630212\n",
      "Epoch: 1959/2000\t Step: 45/54\t Train Loss: 3.797322\t Valid Loss: 4.915383\n",
      "Epoch: 1960/2000\t Step: 15/54\t Train Loss: 3.695258\t Valid Loss: 5.664240\n",
      "Epoch: 1960/2000\t Step: 30/54\t Train Loss: 3.739309\t Valid Loss: 5.314873\n",
      "Epoch: 1960/2000\t Step: 45/54\t Train Loss: 3.699231\t Valid Loss: 5.380459\n",
      "Epoch: 1961/2000\t Step: 15/54\t Train Loss: 3.668030\t Valid Loss: 5.638590\n",
      "Epoch: 1961/2000\t Step: 30/54\t Train Loss: 3.687870\t Valid Loss: 5.063216\n",
      "Epoch: 1961/2000\t Step: 45/54\t Train Loss: 3.688709\t Valid Loss: 5.404866\n",
      "Epoch: 1962/2000\t Step: 15/54\t Train Loss: 3.782499\t Valid Loss: 4.891622\n",
      "Epoch: 1962/2000\t Step: 30/54\t Train Loss: 3.748038\t Valid Loss: 5.474172\n",
      "Epoch: 1962/2000\t Step: 45/54\t Train Loss: 3.704710\t Valid Loss: 5.279311\n",
      "Epoch: 1963/2000\t Step: 15/54\t Train Loss: 3.731586\t Valid Loss: 4.947817\n",
      "Epoch: 1963/2000\t Step: 30/54\t Train Loss: 3.734902\t Valid Loss: 5.403240\n",
      "Epoch: 1963/2000\t Step: 45/54\t Train Loss: 3.794913\t Valid Loss: 5.336581\n",
      "Epoch: 1964/2000\t Step: 15/54\t Train Loss: 3.797091\t Valid Loss: 5.613901\n",
      "Epoch: 1964/2000\t Step: 30/54\t Train Loss: 3.774379\t Valid Loss: 5.800538\n",
      "Epoch: 1964/2000\t Step: 45/54\t Train Loss: 3.697122\t Valid Loss: 5.506341\n",
      "Epoch: 1965/2000\t Step: 15/54\t Train Loss: 3.727136\t Valid Loss: 5.732128\n",
      "Epoch: 1965/2000\t Step: 30/54\t Train Loss: 3.731575\t Valid Loss: 4.881922\n",
      "Epoch: 1965/2000\t Step: 45/54\t Train Loss: 3.780331\t Valid Loss: 5.264837\n",
      "Epoch: 1966/2000\t Step: 15/54\t Train Loss: 3.738762\t Valid Loss: 5.034227\n",
      "Epoch: 1966/2000\t Step: 30/54\t Train Loss: 3.774144\t Valid Loss: 4.744065\n",
      "Epoch: 1966/2000\t Step: 45/54\t Train Loss: 3.770413\t Valid Loss: 4.960872\n",
      "Epoch: 1967/2000\t Step: 15/54\t Train Loss: 3.694215\t Valid Loss: 5.446650\n",
      "Epoch: 1967/2000\t Step: 30/54\t Train Loss: 3.730929\t Valid Loss: 5.006714\n",
      "Epoch: 1967/2000\t Step: 45/54\t Train Loss: 3.742097\t Valid Loss: 5.897230\n",
      "Epoch: 1968/2000\t Step: 15/54\t Train Loss: 3.665444\t Valid Loss: 4.904887\n",
      "Epoch: 1968/2000\t Step: 30/54\t Train Loss: 3.763083\t Valid Loss: 5.279197\n",
      "Epoch: 1968/2000\t Step: 45/54\t Train Loss: 3.710116\t Valid Loss: 5.879536\n",
      "Epoch: 1969/2000\t Step: 15/54\t Train Loss: 3.786100\t Valid Loss: 5.480321\n",
      "Epoch: 1969/2000\t Step: 30/54\t Train Loss: 3.718661\t Valid Loss: 5.164391\n",
      "Epoch: 1969/2000\t Step: 45/54\t Train Loss: 3.770531\t Valid Loss: 4.955266\n",
      "Epoch: 1970/2000\t Step: 15/54\t Train Loss: 3.743841\t Valid Loss: 4.911839\n",
      "Epoch: 1970/2000\t Step: 30/54\t Train Loss: 3.751788\t Valid Loss: 4.882404\n",
      "Epoch: 1970/2000\t Step: 45/54\t Train Loss: 3.701072\t Valid Loss: 5.058801\n",
      "Epoch: 1971/2000\t Step: 15/54\t Train Loss: 3.743632\t Valid Loss: 5.328276\n",
      "Epoch: 1971/2000\t Step: 30/54\t Train Loss: 3.740923\t Valid Loss: 5.359388\n",
      "Epoch: 1971/2000\t Step: 45/54\t Train Loss: 3.786206\t Valid Loss: 5.228558\n",
      "Epoch: 1972/2000\t Step: 15/54\t Train Loss: 3.721263\t Valid Loss: 6.176158\n",
      "Epoch: 1972/2000\t Step: 30/54\t Train Loss: 3.700503\t Valid Loss: 5.492291\n",
      "Epoch: 1972/2000\t Step: 45/54\t Train Loss: 3.648891\t Valid Loss: 5.457452\n",
      "Epoch: 1973/2000\t Step: 15/54\t Train Loss: 3.713316\t Valid Loss: 5.198569\n",
      "Epoch: 1973/2000\t Step: 30/54\t Train Loss: 3.729753\t Valid Loss: 4.870330\n",
      "Epoch: 1973/2000\t Step: 45/54\t Train Loss: 3.774911\t Valid Loss: 5.560438\n",
      "Epoch: 1974/2000\t Step: 15/54\t Train Loss: 3.727963\t Valid Loss: 5.160817\n",
      "Epoch: 1974/2000\t Step: 30/54\t Train Loss: 3.755082\t Valid Loss: 5.214695\n",
      "Epoch: 1974/2000\t Step: 45/54\t Train Loss: 3.733321\t Valid Loss: 5.670015\n",
      "Epoch: 1975/2000\t Step: 15/54\t Train Loss: 3.733491\t Valid Loss: 5.764743\n",
      "Epoch: 1975/2000\t Step: 30/54\t Train Loss: 3.679491\t Valid Loss: 5.361056\n",
      "Epoch: 1975/2000\t Step: 45/54\t Train Loss: 3.689460\t Valid Loss: 4.870496\n",
      "Epoch: 1976/2000\t Step: 15/54\t Train Loss: 3.740964\t Valid Loss: 4.946406\n",
      "Epoch: 1976/2000\t Step: 30/54\t Train Loss: 3.714356\t Valid Loss: 5.335993\n",
      "Epoch: 1976/2000\t Step: 45/54\t Train Loss: 3.732614\t Valid Loss: 5.098694\n",
      "Epoch: 1977/2000\t Step: 15/54\t Train Loss: 3.656524\t Valid Loss: 5.777513\n",
      "Epoch: 1977/2000\t Step: 30/54\t Train Loss: 3.746853\t Valid Loss: 4.916366\n",
      "Epoch: 1977/2000\t Step: 45/54\t Train Loss: 3.759131\t Valid Loss: 5.865824\n",
      "Epoch: 1978/2000\t Step: 15/54\t Train Loss: 3.724773\t Valid Loss: 5.424927\n",
      "Epoch: 1978/2000\t Step: 30/54\t Train Loss: 3.764463\t Valid Loss: 4.749830\n",
      "Epoch: 1978/2000\t Step: 45/54\t Train Loss: 3.785874\t Valid Loss: 5.435516\n",
      "Epoch: 1979/2000\t Step: 15/54\t Train Loss: 3.769709\t Valid Loss: 5.150789\n",
      "Epoch: 1979/2000\t Step: 30/54\t Train Loss: 3.671217\t Valid Loss: 5.922478\n",
      "Epoch: 1979/2000\t Step: 45/54\t Train Loss: 3.799757\t Valid Loss: 5.970181\n",
      "Epoch: 1980/2000\t Step: 15/54\t Train Loss: 3.675165\t Valid Loss: 5.712605\n",
      "Epoch: 1980/2000\t Step: 30/54\t Train Loss: 3.755294\t Valid Loss: 5.386549\n",
      "Epoch: 1980/2000\t Step: 45/54\t Train Loss: 3.741014\t Valid Loss: 5.042207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1981/2000\t Step: 15/54\t Train Loss: 3.749226\t Valid Loss: 5.377334\n",
      "Epoch: 1981/2000\t Step: 30/54\t Train Loss: 3.802964\t Valid Loss: 5.099428\n",
      "Epoch: 1981/2000\t Step: 45/54\t Train Loss: 3.764096\t Valid Loss: 4.836354\n",
      "Epoch: 1982/2000\t Step: 15/54\t Train Loss: 3.758276\t Valid Loss: 5.226682\n",
      "Epoch: 1982/2000\t Step: 30/54\t Train Loss: 3.706701\t Valid Loss: 4.813703\n",
      "Epoch: 1982/2000\t Step: 45/54\t Train Loss: 3.691742\t Valid Loss: 6.287093\n",
      "Epoch: 1983/2000\t Step: 15/54\t Train Loss: 3.751294\t Valid Loss: 5.572870\n",
      "Epoch: 1983/2000\t Step: 30/54\t Train Loss: 3.817627\t Valid Loss: 5.378955\n",
      "Epoch: 1983/2000\t Step: 45/54\t Train Loss: 3.658621\t Valid Loss: 5.360959\n",
      "Epoch: 1984/2000\t Step: 15/54\t Train Loss: 3.751976\t Valid Loss: 5.129937\n",
      "Epoch: 1984/2000\t Step: 30/54\t Train Loss: 3.718070\t Valid Loss: 5.394584\n",
      "Epoch: 1984/2000\t Step: 45/54\t Train Loss: 3.743008\t Valid Loss: 5.472304\n",
      "Epoch: 1985/2000\t Step: 15/54\t Train Loss: 3.709549\t Valid Loss: 5.465386\n",
      "Epoch: 1985/2000\t Step: 30/54\t Train Loss: 3.759401\t Valid Loss: 4.599243\n",
      "Epoch: 1985/2000\t Step: 45/54\t Train Loss: 3.748334\t Valid Loss: 5.056380\n",
      "Epoch: 1986/2000\t Step: 15/54\t Train Loss: 3.644371\t Valid Loss: 5.595453\n",
      "Epoch: 1986/2000\t Step: 30/54\t Train Loss: 3.703845\t Valid Loss: 5.640492\n",
      "Epoch: 1986/2000\t Step: 45/54\t Train Loss: 3.698122\t Valid Loss: 5.676327\n",
      "Epoch: 1987/2000\t Step: 15/54\t Train Loss: 3.743474\t Valid Loss: 4.724302\n",
      "Epoch: 1987/2000\t Step: 30/54\t Train Loss: 3.747813\t Valid Loss: 4.599435\n",
      "Epoch: 1987/2000\t Step: 45/54\t Train Loss: 3.723464\t Valid Loss: 5.082846\n",
      "Epoch: 1988/2000\t Step: 15/54\t Train Loss: 3.750773\t Valid Loss: 5.263959\n",
      "Epoch: 1988/2000\t Step: 30/54\t Train Loss: 3.749186\t Valid Loss: 5.038755\n",
      "Epoch: 1988/2000\t Step: 45/54\t Train Loss: 3.768964\t Valid Loss: 5.304169\n",
      "Epoch: 1989/2000\t Step: 15/54\t Train Loss: 3.733540\t Valid Loss: 5.212233\n",
      "Epoch: 1989/2000\t Step: 30/54\t Train Loss: 3.821223\t Valid Loss: 4.825121\n",
      "Epoch: 1989/2000\t Step: 45/54\t Train Loss: 3.756660\t Valid Loss: 4.828907\n",
      "Epoch: 1990/2000\t Step: 15/54\t Train Loss: 3.694148\t Valid Loss: 4.926065\n",
      "Epoch: 1990/2000\t Step: 30/54\t Train Loss: 3.778110\t Valid Loss: 5.434130\n",
      "Epoch: 1990/2000\t Step: 45/54\t Train Loss: 3.746397\t Valid Loss: 5.176284\n",
      "Epoch: 1991/2000\t Step: 15/54\t Train Loss: 3.816379\t Valid Loss: 5.092784\n",
      "Epoch: 1991/2000\t Step: 30/54\t Train Loss: 3.748116\t Valid Loss: 5.285152\n",
      "Epoch: 1991/2000\t Step: 45/54\t Train Loss: 3.745259\t Valid Loss: 4.911508\n",
      "Epoch: 1992/2000\t Step: 15/54\t Train Loss: 3.786602\t Valid Loss: 4.727588\n",
      "Epoch: 1992/2000\t Step: 30/54\t Train Loss: 3.665236\t Valid Loss: 5.070398\n",
      "Epoch: 1992/2000\t Step: 45/54\t Train Loss: 3.659013\t Valid Loss: 5.085190\n",
      "Epoch: 1993/2000\t Step: 15/54\t Train Loss: 3.707763\t Valid Loss: 5.710412\n",
      "Epoch: 1993/2000\t Step: 30/54\t Train Loss: 3.678203\t Valid Loss: 5.517597\n",
      "Epoch: 1993/2000\t Step: 45/54\t Train Loss: 3.668899\t Valid Loss: 5.513654\n",
      "Epoch: 1994/2000\t Step: 15/54\t Train Loss: 3.756993\t Valid Loss: 5.676287\n",
      "Epoch: 1994/2000\t Step: 30/54\t Train Loss: 3.763544\t Valid Loss: 5.584608\n",
      "Epoch: 1994/2000\t Step: 45/54\t Train Loss: 3.662204\t Valid Loss: 5.880461\n",
      "Epoch: 1995/2000\t Step: 15/54\t Train Loss: 3.670732\t Valid Loss: 5.597922\n",
      "Epoch: 1995/2000\t Step: 30/54\t Train Loss: 3.738046\t Valid Loss: 5.201671\n",
      "Epoch: 1995/2000\t Step: 45/54\t Train Loss: 3.764911\t Valid Loss: 5.325078\n",
      "Epoch: 1996/2000\t Step: 15/54\t Train Loss: 3.694385\t Valid Loss: 4.921816\n",
      "Epoch: 1996/2000\t Step: 30/54\t Train Loss: 3.791669\t Valid Loss: 4.815035\n",
      "Epoch: 1996/2000\t Step: 45/54\t Train Loss: 3.699782\t Valid Loss: 5.731716\n",
      "Epoch: 1997/2000\t Step: 15/54\t Train Loss: 3.714311\t Valid Loss: 5.149993\n",
      "Epoch: 1997/2000\t Step: 30/54\t Train Loss: 3.775919\t Valid Loss: 5.254181\n",
      "Epoch: 1997/2000\t Step: 45/54\t Train Loss: 3.747527\t Valid Loss: 5.179570\n",
      "Epoch: 1998/2000\t Step: 15/54\t Train Loss: 3.761774\t Valid Loss: 5.289558\n",
      "Epoch: 1998/2000\t Step: 30/54\t Train Loss: 3.794742\t Valid Loss: 5.344246\n",
      "Epoch: 1998/2000\t Step: 45/54\t Train Loss: 3.775439\t Valid Loss: 5.233502\n",
      "Epoch: 1999/2000\t Step: 15/54\t Train Loss: 3.750301\t Valid Loss: 5.288260\n",
      "Epoch: 1999/2000\t Step: 30/54\t Train Loss: 3.711783\t Valid Loss: 5.379971\n",
      "Epoch: 1999/2000\t Step: 45/54\t Train Loss: 3.780137\t Valid Loss: 5.447280\n",
      "Epoch: 2000/2000\t Step: 15/54\t Train Loss: 3.742923\t Valid Loss: 4.926737\n",
      "Epoch: 2000/2000\t Step: 30/54\t Train Loss: 3.752859\t Valid Loss: 5.904719\n",
      "Epoch: 2000/2000\t Step: 45/54\t Train Loss: 3.727492\t Valid Loss: 5.277642\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    valid_min = np.inf\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        print_count = 0\n",
    "        \n",
    "        for train_input, train_smpl, train_acc in train_loader:\n",
    "            print_count += 1\n",
    "            \n",
    "            train_input = train_input.to(device).float()\n",
    "            train_smpl = train_smpl.to(device).float()\n",
    "            train_acc = train_acc.to(device).float()\n",
    "            \n",
    "            h = model.init_hidden(train_input.shape[0])\n",
    "            h = tuple([each.data for each in h])\n",
    "            \n",
    "            model.zero_grad()\n",
    "            smpl_mu, acc_mu, smpl_sigma, acc_sigma = model(train_input, h)\n",
    "            smpl_loss = criterion(smpl_mu, train_smpl, smpl_sigma) # 자세 추정을 위한 Loss\n",
    "            acc_loss = criterion(acc_mu, train_acc, acc_sigma) # 가속도 복원을 위한 Loss\n",
    "            final_loss = smpl_loss + acc_loss\n",
    "            \n",
    "            final_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if print_count % print_every == 0:\n",
    "                train_losses.append(final_loss.item())\n",
    "                \n",
    "                # Validation 코드 다시 작성해야함\n",
    "                \"\"\"\n",
    "                temp_losses = []\n",
    "                model.eval()\n",
    "                \n",
    "                for valid_input, valid_smpl, valid_acc in valid_dataset:\n",
    "                    valid_input = valid_input.to(device).float()\n",
    "                    valid_smpl = valid_smpl.to(device).float()\n",
    "                    valid_acc = valid_acc.to(device).float()\n",
    "                    \n",
    "                    valid_h = model.init_hidden(valid_input.shape[0])\n",
    "                    valid_h = tuple([each.data for each in valid_h])\n",
    "                    \n",
    "                    model.zero_grad()\n",
    "                    smpl_mu, acc_mu, smpl_sigma, acc_sigma = model(valid_input, valid_h)\n",
    "                    smpl_loss = criterion(smpl_mu, valid_smpl, smpl_sigma)\n",
    "                    acc_loss = criterion(acc_mu, valid_acc, acc_sigma)\n",
    "                    valid_final_loss = smpl_loss + acc_loss\n",
    "                    \n",
    "                    temp_losses.append(valid_final_loss.item())\n",
    "                \n",
    "                valid_loss = np.mean(temp_losses)\n",
    "                valid_losses.append(valid_loss)\n",
    "                \n",
    "                if valid_loss < valid_min:\n",
    "                    valid_min = valid_loss\n",
    "                    torch.save(model.state_dict(), 'model.pt')\n",
    "                \"\"\"\n",
    "\n",
    "                print(\"Epoch: {}/{}\\t\".format(e+1, epochs),\n",
    "                      \"Step: {}/{}\\t\".format(print_count, len(train_loader)),\n",
    "                      \"Train Loss: {:.6f}\\t\".format(final_loss.item()))\n",
    "                      #\"Valid Loss: {:.6f}\".format(valid_loss))\n",
    "                \n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f4e2bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(6000), train_losses)\n",
    "plt.xlabel(\"Epochs(x3)\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb448768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(6000), valid_losses)\n",
    "plt.xlabel(\"Epochs(x3)\")\n",
    "plt.ylabel(\"Valid Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490bbd31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
